{"generatedAt":1675118188779,"generateTime":90,"contents":[{"_path":"/all","_dir":"","_draft":false,"_partial":false,"_locale":"en","total":141,"apps":[{"id":"adguardhome-sync","name":"adguardhome-sync","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a tool to synchronize AdGuardHome config to replica instances.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/adguardhomesync-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/adguardhome-sync"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-adguardhome-sync"}],"containers":[{"name":"adguardhome-sync","image":"linuxserver/adguardhome-sync","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"CONFIGFILE","default":"/config/adguardhome-sync.yaml","description":"Set a custom config file."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"8080","description":"Port for AdGuardHome Sync's web API.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"adguardhome-sync","project_url":"https://github.com/bakito/adguardhome-sync/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/adguardhomesync-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a tool to synchronize AdGuardHome config to replica instances.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Port for AdGuardHome Sync's web API."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONFIGFILE","env_value":"/config/adguardhome-sync.yaml","desc":"Set a custom config file."}],"opt_param_usage_include_vols":false,"app_setup_block_enabled":true,"app_setup_block":"Edit the adguardhome-sync.yaml with your AdGuardHome instance details, for more information check out [AdGuardHome Sync](https://github.com/bakito/adguardhome-sync/).\n","changelogs":[{"date":"03.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"18.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"09.08.21:","desc":"Rebase to Alpine 3.14."},{"date":"08.04.21:","desc":"Initial Release."}]}},"setup":"Edit the adguardhome-sync.yaml with your AdGuardHome instance details, for more information check out [AdGuardHome Sync](https://github.com/bakito/adguardhome-sync/).\n"},{"id":"airsonic-advanced","name":"airsonic-advanced","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/airsonic-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/airsonic-advanced"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-airsonic-advanced"}],"containers":[{"name":"airsonic-advanced","image":"linuxserver/airsonic-advanced","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CONTEXT_PATH","default":"<URL_BASE>","description":"For setting url-base in reverse proxy setups."},{"id":"JAVA_OPTS","default":"<options>","description":"For passing additional java options."}],"volumes":[{"container":"/media","description":"Location of other media."},{"container":"/config","description":"Configuration file location.","key":"config"},{"container":"/music","description":"Location of music."},{"container":"/playlists","description":"Location for playlists to be saved to."},{"container":"/podcasts","description":"Location of podcasts."}],"ports":[{"container":"4040","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"airsonic-advanced","project_url":"https://github.com/airsonic-advanced/airsonic-advanced","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/airsonic-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Latest releases of Airsonic-Advanced"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/config>","desc":"Configuration file location."},{"vol_path":"/music","vol_host_path":"</path/to/music>","desc":"Location of music."},{"vol_path":"/playlists","vol_host_path":"</path/to/playlists>","desc":"Location for playlists to be saved to."},{"vol_path":"/podcasts","vol_host_path":"</path/to/podcasts>","desc":"Location of podcasts."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4040","internal_port":"4040","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONTEXT_PATH","env_value":"<URL_BASE>","desc":"For setting url-base in reverse proxy setups."},{"env_var":"JAVA_OPTS","env_value":"<options>","desc":"For passing additional java options."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/media","vol_host_path":"</path/to/other media>","desc":"Location of other media."}],"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/snd","device_host_path":"/dev/snd","desc":"Only needed to pass your host sound device to Airsonic's Java jukebox player."}],"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"\nWe don't formally support upgrading from Airsonic to Airsonic Advanced, it may or may not work for you and we'd recommend making backups before attempting this. Following the upgrade you may experience a forced rescan of your library so take this into account if you have a lot of files.\n\nPlease see notes about upgrading from v10 to v11 [here](https://github.com/airsonic-advanced/airsonic-advanced#usage)\n\nAccess WebUI at `<your-ip>:4040`.\n\nDefault user/pass is admin/admin\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`. For some reverse proxies, you may need to pass `JAVA_OPTS=-Dserver.use-forward-headers=true` for airsonic to generate the proper URL schemes.\n\nNote that if you want to use [Airsonic's Java jukebox player](https://airsonic.github.io/docs/jukebox/), then `PGID` will need to match the group of your sound device (e.g. `/dev/snd`).\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"25.07.22:","desc":"Add vorbis-tools."},{"date":"02.01.22:","desc":"Initial Release."}]}},"setup":"\nWe don't formally support upgrading from Airsonic to Airsonic Advanced, it may or may not work for you and we'd recommend making backups before attempting this. Following the upgrade you may experience a forced rescan of your library so take this into account if you have a lot of files.\n\nPlease see notes about upgrading from v10 to v11 [here](https://github.com/airsonic-advanced/airsonic-advanced#usage)\n\nAccess WebUI at `<your-ip>:4040`.\n\nDefault user/pass is admin/admin\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`. For some reverse proxies, you may need to pass `JAVA_OPTS=-Dserver.use-forward-headers=true` for airsonic to generate the proper URL schemes.\n\nNote that if you want to use [Airsonic's Java jukebox player](https://airsonic.github.io/docs/jukebox/), then `PGID` will need to match the group of your sound device (e.g. `/dev/snd`).\n"},{"id":"apprise-api","name":"apprise-api","description":"[{{ project_name|capitalize }}]({{ project_url }}) Takes advantage of [Apprise](https://github.com/caronc/apprise) through your network with a user-friendly API.\n\n* Send notifications to more then 65+ services.\n* An incredibly lightweight gateway to Apprise.\n* A production ready micro-service at your disposal.\n\nApprise API was designed to easily fit into existing (and new) eco-systems that are looking for a simple notification solution.\n","icon":"https://raw.githubusercontent.com/caronc/apprise-api/master/apprise_api/static/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/apprise-api"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-apprise-api"}],"containers":[{"name":"apprise-api","image":"linuxserver/apprise-api","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where config is stored.","key":"config"}],"ports":[{"container":"8000","description":"Port for apprise's interface and API.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"apprise-api","project_url":"https://github.com/caronc/apprise-api","project_logo":"https://raw.githubusercontent.com/caronc/apprise-api/master/apprise_api/static/logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) Takes advantage of [Apprise](https://github.com/caronc/apprise) through your network with a user-friendly API.\n\n* Send notifications to more then 65+ services.\n* An incredibly lightweight gateway to Apprise.\n* A production ready micro-service at your disposal.\n\nApprise API was designed to easily fit into existing (and new) eco-systems that are looking for a simple notification solution.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where config is stored."}],"param_device_map":false,"param_devices":[],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Port for apprise's interface and API."}],"opt_param_usage_include_env":false,"opt_param_env_vars":[],"opt_param_usage_include_vols":false,"opt_param_volumes":[],"opt_param_usage_include_ports":false,"opt_param_ports":[],"opt_param_device_map":false,"opt_param_devices":[],"cap_add_param":false,"cap_add_param_vars":[],"opt_cap_add_param":false,"opt_cap_add_param_vars":[],"optional_block_1":false,"optional_block_1_items":"","privileged":false,"app_setup_block_enabled":false,"app_setup_block":[],"changelogs":[{"date":"17.10.22:","desc":"Rebase to alpine 3.16, migrate to S6V3"},{"date":"28.02.21:","desc":"Rebase to alpine 3.15."},{"date":"03.11.21:","desc":"Increase uWSGI buffer size to 32kb."},{"date":"16.05.21:","desc":"Add linuxserver wheel index."},{"date":"26.02.21:","desc":"Initial Release."}]}}},{"id":"audacity","name":"audacity","description":"[Audacity]({{ project_url }}) is an easy-to-use, multi-track audio editor and recorder. Developed by a group of volunteers as open source.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/audacity-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/audacity"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-audacity"}],"containers":[{"name":"audacity","image":"linuxserver/audacity","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and images","key":"config"}],"ports":[{"container":"3000","description":"Audacity desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"audacity","project_url":"https://www.audacityteam.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/audacity-logo.png","project_blurb":"[Audacity]({{ project_url }}) is an easy-to-use, multi-track audio editor and recorder. Developed by a group of volunteers as open source.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and images"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Audacity desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"13.12.22:","desc":"Rebase to Jammy."},{"date":"14.09.21:","desc":"Use the official appimage, switch to single arch (x86_64). Armhf and aarch64 users can remain on version 3.0.2 but there won't be further updates."},{"date":"07.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"babybuddy","name":"babybuddy","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a buddy for babies! Helps caregivers track sleep, feedings, diaper changes, tummy time and more to learn about and predict baby's needs without (as much) guess work.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/babybuddy-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/babybuddy"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-babybuddy"}],"containers":[{"name":"babybuddy","image":"linuxserver/babybuddy","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"CSRF_TRUSTED_ORIGINS","default":"http://127.0.0.1:8000,https://babybuddy.domain.com","description":"Add any address you'd like to access babybuddy at (comma separated, no spaces)"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration and data.","key":"config"}],"ports":[{"container":"8000","description":"the port for the web ui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"babybuddy","project_url":"https://github.com/babybuddy/babybuddy","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/babybuddy-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a buddy for babies! Helps caregivers track sleep, feedings, diaper changes, tummy time and more to learn about and predict baby's needs without (as much) guess work.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"the port for the web ui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"CSRF_TRUSTED_ORIGINS","env_value":"http://127.0.0.1:8000,https://babybuddy.domain.com","desc":"Add any address you'd like to access babybuddy at (comma separated, no spaces)"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8000` (or whichever host port is mapped in docker arguments). The default user/pass are `admin:admin`.\n\nBy default BabyBuddy uses sqlite3. To use an external database like postgresql or mysql/mariadb instead, you can use the environment variables listed in [BabyBuddy docs](https://github.com/babybuddy/babybuddy#configuration).\n","changelogs":[{"date":"16.01.23:","desc":"Rebase to Alpine 3.17."},{"date":"23.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"28.05.22:","desc":"Add missing PUID/PGID vars to readme."},{"date":"03.04.22:","desc":"Rebase to alpine-nginx baseimage. Add `CSRF_TRUSTED_ORIGINS` env var."},{"date":"11.12.21:","desc":"Add py3-mysqlclient for mysql/mariadb."},{"date":"14.11.21:","desc":"Add lxml dependencies (temp fix for amd64 by force compiling lxml)."},{"date":"25.07.21:","desc":"Add libpq for postgresql."},{"date":"08.07.21:","desc":"Fix pip install issue."},{"date":"05.07.21:","desc":"Update Gunicorn parameters to prevent `WORKER_TIMEOUT` issue."},{"date":"22.06.21:","desc":"Initial release."}]}},"setup":"Access the webui at `<your-ip>:8000` (or whichever host port is mapped in docker arguments). The default user/pass are `admin:admin`.\n\nBy default BabyBuddy uses sqlite3. To use an external database like postgresql or mysql/mariadb instead, you can use the environment variables listed in [BabyBuddy docs](https://github.com/babybuddy/babybuddy#configuration).\n"},{"id":"bazarr","name":"bazarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/bazarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/bazarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-bazarr"}],"containers":[{"name":"bazarr","image":"linuxserver/bazarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/movies","description":"Location of your movies"},{"container":"/tv","description":"Location of your TV Shows"},{"container":"/config","description":"Bazarr data","key":"config"}],"ports":[{"container":"6767","description":"Allows HTTP access to the internal webserver.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"bazarr","project_url":"https://www.bazarr.media/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/bazarr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from Bazarr"},{"tag":"development","desc":"Pre-releases from Bazarr"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/bazarr/config","desc":"Bazarr data"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6767","internal_port":"6767","port_desc":"Allows HTTP access to the internal webserver."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/movies","vol_host_path":"/path/to/movies","desc":"Location of your movies"},{"vol_path":"/tv","vol_host_path":"/path/to/tv","desc":"Location of your TV Shows"}],"app_setup_block_enabled":true,"app_setup_block":"- Once running the URL will be `http://<host-ip>:6767`.\n- You must complete all the setup parameters in the webui before you can save the config.\n","changelogs":[{"date":"23.01.23:","desc":"Rebase master branch to Alpine 3.17."},{"date":"11.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"15.15.21:","desc":"Temp fix for lxml, compile from scratch to avoid broken official wheel."},{"date":"25.10.21:","desc":"Rebase to alpine 3.14. Fix numpy wheel."},{"date":"22.10.21:","desc":"Added openblas package to prevent numpy error."},{"date":"16.05.21:","desc":"Use wheel index."},{"date":"19.04.21:","desc":"Install from release zip."},{"date":"07.04.21:","desc":"Move app to /app/bazarr/bin, add `package_info`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"23.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.05.20:","desc":"Add donation links for Bazarr to Github sponsors button and container log."},{"date":"08.04.20:","desc":"Removed /movies and /tv volumes from Dockerfiles."},{"date":"28.12.19:","desc":"Upgrade to Python 3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"12.06.19:","desc":"Swap to install deps using maintainers requirements.txt, add ffmpeg for ffprobe."},{"date":"17.04.19:","desc":"Add default UTC timezone if user does not set it."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.09.18:","desc":"Initial release."}]}},"setup":"- Once running the URL will be `http://<host-ip>:6767`.\n- You must complete all the setup parameters in the webui before you can save the config.\n"},{"id":"beets","name":"beets","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/beets-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/beets"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-beets"}],"containers":[{"name":"beets","image":"linuxserver/beets","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/music","description":"Music library"},{"container":"/downloads","description":"Non processed music"}],"ports":[{"container":"8337","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"beets","project_url":"http://beets.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/beets-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Beets Releases"},{"tag":"nightly","desc":"Built against head of Beets git, generally considered unstable but a likely choice for power users of the application."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/music","vol_host_path":"</path/to/music/library>","desc":"Music library"},{"vol_path":"/downloads","vol_host_path":"</path/to/ingest>","desc":"Non processed music"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8337","internal_port":"8337","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Edit the config file in /config\n\nTo edit the config from within the container use `beet config -e`\n\nFor a command prompt as user abc `docker exec -it -u abc beets bash`\n\nSee [Beets](http://beets.io/) for more info.\n\nContains [beets-extrafiles](https://github.com/Holzhaus/beets-extrafiles) plugin, [configuration details](https://github.com/Holzhaus/beets-extrafiles#usage)\n","changelogs":[{"date":"15.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.05.19:","desc":"Add flac and mp3val binaries required for badfiles plugin."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.03.19:","desc":"Swap copyartifacts for extrafiles, update endpoints with nightly tag."},{"date":"01.03.19:","desc":"Switch to python3."},{"date":"07.02.19:","desc":"Add fftw-dev build dependency for chromaprint."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.08.18:","desc":"Rebase to alpine 3.8, use alpine repo version of pylast."},{"date":"12.08.18:","desc":"Add requests pip package."},{"date":"04.03.18:","desc":"Upgrade mp3gain to 1.6.1."},{"date":"02.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"27.12.17:","desc":"Add beautifulsoup4 pip package."},{"date":"06.12.17:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"16.01.17:","desc":"Add packages required for replaygain."},{"date":"24.12.16:","desc":"Add [beets-copyartifacts](https://github.com/sbarakat/beets-copyartifacts) plugin."},{"date":"07.12.16:","desc":"Edit cmake options for chromaprint, should now build and install fpcalc, add gstreamer lib"},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"01.10.16:","desc":"Add nano and editor variable to allow editing of the config from the container command line."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"24.09.16:","desc":"Rebase to alpine linux."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.01.16:","desc":"Change ffpmeg repository, other version crashes container"},{"date":"06.11.15:","desc":"Initial Release"},{"date":"29.11.15:","desc":"Take out term setting, causing issues with key entry for some users"}]}},"setup":"Edit the config file in /config\n\nTo edit the config from within the container use `beet config -e`\n\nFor a command prompt as user abc `docker exec -it -u abc beets bash`\n\nSee [Beets](http://beets.io/) for more info.\n\nContains [beets-extrafiles](https://github.com/Holzhaus/beets-extrafiles) plugin, [configuration details](https://github.com/Holzhaus/beets-extrafiles#usage)\n"},{"id":"blender","name":"blender","description":"[Blender]({{ project_url }}) is a free and open-source 3D computer graphics software toolset used for creating animated films, visual effects, art, 3D printed models, motion graphics, interactive 3D applications, virtual reality, and computer games. **This image does not support GPU rendering out of the box only accelerated workspace experience**","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/blender-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/blender"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-blender"}],"containers":[{"name":"blender","image":"linuxserver/blender","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Blender desktop gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"blender","project_url":"https://www.blender.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/blender-logo.png","project_blurb":"[Blender]({{ project_url }}) is a free and open-source 3D computer graphics software toolset used for creating animated films, visual effects, art, 3D printed models, motion graphics, interactive 3D applications, virtual reality, and computer games. **This image does not support GPU rendering out of the box only accelerated workspace experience**","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Blender desktop gui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for hardware acceleration (Linux hosts only)"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, this may be required depending on your Docker and storage configuration."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration\n\nThis only applies to your desktop experience, this container is capable of supporting accelerated rendering with /dev/dri mounted in, but the AMD HIP and Nvidia CUDA runtimes are massive which are not installed by default in this container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nArm devices can run this image, but generally should not mount in /dev/dri. The OpenGL ES version is not high enough to run Blender. The program can run on these platforms though, leveraging CPU LLVMPipe rendering.\n\nDue to lack of arm32/64 binaries from the upstream project, our arm32/64 images install the latest version from the ubuntu repo, which is usually behind and thus the version the image is tagged with does not match the version contained.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"13.12.22:","desc":"Rebase to Jammy, migrate to s6v3."},{"date":"06.05.22:","desc":"Use the full semver version in image tags. Arm32/64 version tags are inaccurate due to installing from ubuntu repo, which is usually behind."},{"date":"12.03.22:","desc":"Initial Release."}]}},"setup":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration\n\nThis only applies to your desktop experience, this container is capable of supporting accelerated rendering with /dev/dri mounted in, but the AMD HIP and Nvidia CUDA runtimes are massive which are not installed by default in this container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nArm devices can run this image, but generally should not mount in /dev/dri. The OpenGL ES version is not high enough to run Blender. The program can run on these platforms though, leveraging CPU LLVMPipe rendering.\n\nDue to lack of arm32/64 binaries from the upstream project, our arm32/64 images install the latest version from the ubuntu repo, which is usually behind and thus the version the image is tagged with does not match the version contained.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n"},{"id":"boinc","name":"boinc","description":"[BOINC]({{ project_url }}) is a platform for high-throughput computing on a large scale (thousands or millions of computers). It can be used for volunteer computing (using consumer devices) or grid computing (using organizational resources). It supports virtualized, parallel, and GPU-based applications.","icon":"https://raw.githubusercontent.com/BOINC/boinc/master/doc/logo/boinc_logo_black.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/boinc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-boinc"}],"containers":[{"name":"boinc","image":"linuxserver/boinc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PASSWORD","default":"","description":"Optionally set a password for the gui."}],"volumes":[{"container":"/config","description":"Where BOINC should store its database and config.","key":"config"}],"ports":[{"container":"8080","description":"Boinc desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"boinc","project_url":"https://boinc.berkeley.edu/","project_logo":"https://raw.githubusercontent.com/BOINC/boinc/master/doc/logo/boinc_logo_black.jpg","project_blurb":"[BOINC]({{ project_url }}) is a platform for high-throughput computing on a large scale (thousands or millions of computers). It can be used for volunteer computing (using consumer devices) or grid computing (using organizational resources). It supports virtualized, parallel, and GPU-based applications.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where BOINC should store its database and config."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Boinc desktop gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PASSWORD","env_value":"","desc":"Optionally set a password for the gui."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU (vaapi)."}],"opt_cap_add_param":false,"optional_block_1":false,"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"This image sets up the BOINC client and manager and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n\nIt is recommended to switch to `Advanced View` in the top menu, because the `Computing Preferences` don't seem to be displayed in `Simple View`.\n\nSometimes, the pop-up windows may open in a tiny box in the upper left corner of the screen. When that happens, you can find the corner and resize them.\n\n## GPU Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n```--device=/dev/dri:/dev/dri```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the BOINC docker container.\n","changelogs":[{"date":"14.11.22:","desc":"Fix opencl driver."},{"date":"18.09.22:","desc":"Rebase to jammy."},{"date":"24.02.22:","desc":"Rebase to focal."},{"date":"31.01.22:","desc":"Improve device permissions setting verbosity."},{"date":"23.03.21:","desc":"Rebase to rdesktop-web baseimage. Deprecate `GUAC_USER` and `GUAC_PASS` env vars. Existing users can set the new var `PASSWORD` for the user `abc`."},{"date":"01.04.20:","desc":"Install boinc from ppa."},{"date":"17.03.20:","desc":"Add armhf and aarch64 builds and switch to multi-arch image."},{"date":"16.03.20:","desc":"Clean up old pid files."},{"date":"15.03.20:","desc":"Initial release."}]}},"setup":"This image sets up the BOINC client and manager and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n\nIt is recommended to switch to `Advanced View` in the top menu, because the `Computing Preferences` don't seem to be displayed in `Simple View`.\n\nSometimes, the pop-up windows may open in a tiny box in the upper left corner of the screen. When that happens, you can find the corner and resize them.\n\n## GPU Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n```--device=/dev/dri:/dev/dri```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the BOINC docker container.\n"},{"id":"booksonic-air","name":"booksonic-air","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a platform for accessing the audiobooks you own wherever you are. At the moment the platform consists of:\n* Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic.\n* Booksonic App - An DSub based Android app for connection to Booksonic-Air servers.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/booksonic-air.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/booksonic-air"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-booksonic-air"}],"containers":[{"name":"booksonic-air","image":"linuxserver/booksonic-air","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CONTEXT_PATH","default":"url-base","description":"Base url for use with reverse proxies etc."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/audiobooks","description":"Audiobooks."},{"container":"/podcasts","description":"Podcasts."},{"container":"/othermedia","description":"Other media."}],"ports":[{"container":"4040","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"booksonic-air","project_url":"http://booksonic.org","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/booksonic-air.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a platform for accessing the audiobooks you own wherever you are. At the moment the platform consists of:\n* Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic.\n* Booksonic App - An DSub based Android app for connection to Booksonic-Air servers.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable booksonic-air releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"CONTEXT_PATH","env_value":"url-base","desc":"Base url for use with reverse proxies etc."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/audiobooks","vol_host_path":"</path/to/audiobooks>","desc":"Audiobooks."},{"vol_path":"/podcasts","vol_host_path":"</path/to/podcasts>","desc":"Podcasts."},{"vol_path":"/othermedia","vol_host_path":"</path/to/othermedia>","desc":"Other media."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4040","internal_port":"4040","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Whilst this is a more up to date rebase of the original Booksonic server, upgrading in place is not supported and a fresh install has been recommended. Default user/pass is admin/admin","changelogs":[{"date":"18.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"15.09.20:","desc":"Initial Release."}]}},"setup":"Whilst this is a more up to date rebase of the original Booksonic server, upgrading in place is not supported and a fresh install has been recommended. Default user/pass is admin/admin"},{"id":"bookstack","name":"bookstack","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free and open source Wiki designed for creating beautiful documentation. Featuring a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease.\n\nPowered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore.\n\nFor more information on BookStack visit their website and check it out: https://www.bookstackapp.com\n","icon":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/bookstack-logo500x500.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/bookstack"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-bookstack"}],"containers":[{"name":"bookstack","image":"linuxserver/bookstack","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"APP_URL","default":"","description":"for specifying the IP:port or URL your application will be accessed on (ie. `http://192.168.1.1:6875` or `https://bookstack.mydomain.com`"},{"id":"DB_HOST","default":"<yourdbhost>","description":"for specifying the database host"},{"id":"DB_PORT","default":"<yourdbport>","description":"for specifying the database port if not default 3306"},{"id":"DB_USER","default":"<yourdbuser>","description":"for specifying the database user"},{"id":"DB_PASS","default":"<yourdbpass>","description":"for specifying the database password (non-alphanumeric passwords must be properly escaped.)"},{"id":"DB_DATABASE","default":"bookstackapp","description":"for specifying the database to be used"}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"}],"ports":[{"container":"80","description":"will map the container's port 80 to port 6875 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"bookstack","project_url":"https://github.com/BookStackApp/BookStack","project_logo":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/bookstack-logo500x500.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free and open source Wiki designed for creating beautiful documentation. Featuring a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease.\n\nPowered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore.\n\nFor more information on BookStack visit their website and check it out: https://www.bookstackapp.com\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"APP_URL","env_value":"","desc":"for specifying the IP:port or URL your application will be accessed on (ie. `http://192.168.1.1:6875` or `https://bookstack.mydomain.com`"},{"env_var":"DB_HOST","env_value":"<yourdbhost>","desc":"for specifying the database host"},{"env_var":"DB_PORT","env_value":"<yourdbport>","desc":"for specifying the database port if not default 3306"},{"env_var":"DB_USER","env_value":"<yourdbuser>","desc":"for specifying the database user"},{"env_var":"DB_PASS","env_value":"<yourdbpass>","desc":"for specifying the database password (non-alphanumeric passwords must be properly escaped.)"},{"env_var":"DB_DATABASE","env_value":"bookstackapp","desc":"for specifying the database to be used"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6875","internal_port":"80","port_desc":"will map the container's port 80 to port 6875 on the host"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"custom_compose":"---\nversion: \"2\"\nservices:\n  bookstack:\n    image: lscr.io/linuxserver/bookstack\n    container_name: bookstack\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - APP_URL=\n      - DB_HOST=bookstack_db\n      - DB_PORT=3306\n      - DB_USER=bookstack\n      - DB_PASS=<yourdbpass>\n      - DB_DATABASE=bookstackapp\n    volumes:\n      - /path/to/data:/config\n    ports:\n      - 6875:80\n    restart: unless-stopped\n    depends_on:\n      - bookstack_db\n  bookstack_db:\n    image: lscr.io/linuxserver/mariadb\n    container_name: bookstack_db\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - MYSQL_ROOT_PASSWORD=<yourdbpass>\n      - TZ=Europe/London\n      - MYSQL_DATABASE=bookstackapp\n      - MYSQL_USER=bookstack\n      - MYSQL_PASSWORD=<yourdbpass>\n    volumes:\n      - /path/to/data:/config\n    restart: unless-stopped\n","app_setup_block_enabled":true,"app_setup_block":"\nThe default username is admin@admin.com with the password of **password**, access the container at http://dockerhost:6875.\n\nThis application is dependent on a MySQL database be it one you already have or a new one. If you do not already have one, set up our MariaDB container here https://hub.docker.com/r/linuxserver/mariadb/.\n\n\nIf you intend to use this application behind a subfolder reverse proxy, such as our SWAG container or Traefik you will need to make sure that the `APP_URL` environment variable is set to your external domain, or it will not work\n\nDocumentation for BookStack can be found at https://www.bookstackapp.com/docs/\n\n### Advanced Users (full control over the .env file)\nIf you wish to use the extra functionality of BookStack such as email, Memcache, LDAP and so on you will need to make your own .env file with guidance from the BookStack documentation.\n  \nWhen you create the container, do not set any arguments for any SQL settings. The container will copy an exemplary .env file to /config/www/.env on your host system for you to edit.\n\n#### PDF Rendering\n[wkhtmltopdf](https://wkhtmltopdf.org/) is available to use as an alternative PDF rendering generator as described at https://www.bookstackapp.com/docs/admin/pdf-rendering/.\n\nThe path to wkhtmltopdf in this image to include in your .env file is `/usr/bin/wkhtmltopdf`.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"16.01.23:","desc":"Wrap `.env` values in quotes."},{"date":"05.01.23:","desc":"Fix db password setting (sed escape `&`)."},{"date":"21.12.22:","desc":"Update db info in .env file when env vars are updated."},{"date":"10.10.22:","desc":"Remove password escape logic which caused problems for a small subset of users."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"14.03.22:","desc":"Add symlinks for theme support."},{"date":"11.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"12.01.21:","desc":"Remove unused requirement, as of release 0.31.0."},{"date":"17.12.20:","desc":"Make APP_URL var required (upstream changes)."},{"date":"17.09.20:","desc":"Rebase to alpine 3.12. Fix APP_URL setting. Bump php post max and upload max filesizes to 100MB by default."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"26.07.19:","desc":"Use old version of tidyhtml pending upstream fixes."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"14.06.19:","desc":"Add wkhtmltopdf to image for PDF rendering."},{"date":"20.04.19:","desc":"Rebase to Alpine 3.9, add MySQL init logic."},{"date":"22.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"20.01.19:","desc":"Added php7-curl"},{"date":"04.11.18:","desc":"Added php7-ldap"},{"date":"15.10.18:","desc":"Changed functionality for advanced users"},{"date":"08.10.18:","desc":"Advanced mode, symlink changes, sed fixing, docs updated, added some composer files"},{"date":"23.09.28:","desc":"Updates pre-release"},{"date":"02.07.18:","desc":"Initial Release."}]}},"setup":"\nThe default username is admin@admin.com with the password of **password**, access the container at http://dockerhost:6875.\n\nThis application is dependent on a MySQL database be it one you already have or a new one. If you do not already have one, set up our MariaDB container here https://hub.docker.com/r/linuxserver/mariadb/.\n\n\nIf you intend to use this application behind a subfolder reverse proxy, such as our SWAG container or Traefik you will need to make sure that the `APP_URL` environment variable is set to your external domain, or it will not work\n\nDocumentation for BookStack can be found at https://www.bookstackapp.com/docs/\n\n### Advanced Users (full control over the .env file)\nIf you wish to use the extra functionality of BookStack such as email, Memcache, LDAP and so on you will need to make your own .env file with guidance from the BookStack documentation.\n  \nWhen you create the container, do not set any arguments for any SQL settings. The container will copy an exemplary .env file to /config/www/.env on your host system for you to edit.\n\n#### PDF Rendering\n[wkhtmltopdf](https://wkhtmltopdf.org/) is available to use as an alternative PDF rendering generator as described at https://www.bookstackapp.com/docs/admin/pdf-rendering/.\n\nThe path to wkhtmltopdf in this image to include in your .env file is `/usr/bin/wkhtmltopdf`.\n"},{"id":"budge","name":"budge","description":"[{{ project_name }}]({{ project_url }}) is an open source 'budgeting with envelopes' personal finance app.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/budge.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/budge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-budge"}],"containers":[{"name":"budge","image":"linuxserver/budge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Persistent config files","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"budge","project_url":"https://github.com/linuxserver/budge","project_logo":"","project_blurb":"[{{ project_name }}]({{ project_url }}) is an open source 'budgeting with envelopes' personal finance app.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/{{ project_name }}/config","desc":"Persistent config files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"app_setup_block_enabled":true,"app_setup_block":"Access the web gui at http://SERVERIP:PORT\n","changelogs":[{"date":"29.11.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"04.15.22:","desc":"Added NPM command to run db migrations."},{"date":"02.05.22:","desc":"Initial Release."}]}},"setup":"Access the web gui at http://SERVERIP:PORT\n"},{"id":"calibre","name":"calibre","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a powerful and easy to use e-book manager. Users say its outstanding and a must-have. Itll allow you to do nearly everything and it takes things a step beyond normal e-book software. Its also completely free and open source and great for both casual users and computer experts.","icon":"https://github.com/kovidgoyal/calibre/raw/master/resources/images/lt.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/calibre"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-calibre"}],"containers":[{"name":"calibre","image":"linuxserver/calibre","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PASSWORD","default":"","description":"Optionally set a password for the gui."},{"id":"CLI_ARGS","default":"","description":"Optionally pass cli start arguments to calibre."}],"volumes":[{"container":"/config","description":"Where calibre should store its database and library.","key":"config"}],"ports":[{"container":"8080","description":"Calibre desktop gui.","protocol":"tcp","web":false},{"container":"8081","description":"Calibre webserver gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"calibre","project_url":"https://calibre-ebook.com/","project_logo":"https://github.com/kovidgoyal/calibre/raw/master/resources/images/lt.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a powerful and easy to use e-book manager. Users say its outstanding and a must-have. Itll allow you to do nearly everything and it takes things a step beyond normal e-book software. Its also completely free and open source and great for both casual users and computer experts.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-<version tag>"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-<version tag>"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where calibre should store its database and library."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Calibre desktop gui."},{"external_port":"8081","internal_port":"8081","port_desc":"Calibre webserver gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PASSWORD","env_value":"","desc":"Optionally set a password for the gui."},{"env_var":"CLI_ARGS","env_value":"","desc":"Optionally pass cli start arguments to calibre."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"This image sets up the calibre desktop app and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nPort 8081 is reserved for Calibre's built-in webserver, which can be enabled within the desktop app settings, and the internal port must be set to `8081` although it will then be available at the host mapped port for external access.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n","changelogs":[{"date":"19.10.22:","desc":"Set the window title to `Calibre`. Remove websocat as it is now handled properly in the baseimage."},{"date":"18.10.22:","desc":"Deprecate Arch branch."},{"date":"07.10.22:","desc":"Start calibre window maximized."},{"date":"16.09.22:","desc":"Rebase to jammy."},{"date":"24.07.22:","desc":"Add arm64 build for master branch."},{"date":"11.07.22:","desc":"Update dependencies for Calibre 6."},{"date":"28.05.22:","desc":"Rebase to focal."},{"date":"31.03.22:","desc":"Fix umask."},{"date":"28.02.22:","desc":"Add speech support to bionic image."},{"date":"05.01.22:","desc":"Add arch branch for arm platforms."},{"date":"20.04.21:","desc":"Fix the HOME folder."},{"date":"19.04.21:","desc":"Add libnss3 back in. Make sure Calibre can access environment variables."},{"date":"18.04.21:","desc":"Start calibre on container start rather than gui connect."},{"date":"15.04.21:","desc":"Rebase to rdesktop-web baseimage. Deprecate `GUAC_USER` and `GUAC_PASS` env vars. Existing users can set the new var `PASSWORD` for the user `abc`."},{"date":"25.09.20:","desc":"Switch to python3, add various new dependencies for calibre 5.0."},{"date":"10.05.19:","desc":"Add new env var `CLI_ARGS` to pass start arguments to calibre."},{"date":"18.03.19:","desc":"Let Calibre access environment variables, add optional umask setting."},{"date":"23.10.19:","desc":"Remove reccomended deps and zenity for character compatibility."},{"date":"18.10.19:","desc":"Add python-xdg."},{"date":"08.10.19:","desc":"Add fonts-wqy-microhei ttf-wqy-zenhei fcitx-rime dependency to resolve issue with Chinese encoding."},{"date":"04.10.19:","desc":"Add libxkbcommon-x11-0 dependency to resolve issue with Calibre 4."},{"date":"08.08.19:","desc":"Add zenity for international character support in dialog boxes."},{"date":"12.07.19:","desc":"Download binary from calibre website instead of github."},{"date":"29.04.19:","desc":"Initial release."}]}},"setup":"This image sets up the calibre desktop app and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nPort 8081 is reserved for Calibre's built-in webserver, which can be enabled within the desktop app settings, and the internal port must be set to `8081` although it will then be available at the host mapped port for external access.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n"},{"id":"calibre-web","name":"calibre-web","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database.   It is also possible to integrate google drive and edit metadata and your calibre library through the app itself.\n\nThis software is a fork of library and licensed under the GPL v3 License.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/calibre-web-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/calibre-web"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-calibre-web"}],"containers":[{"name":"calibre-web","image":"linuxserver/calibre-web","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"DOCKER_MODS","default":"linuxserver/mods:universal-calibre","description":"#optional & **x86-64 only** Adds the ability to perform ebook conversion"},{"id":"OAUTHLIB_RELAX_TOKEN_SCOPE","default":"1","description":"Optionally set this to allow Google OAUTH to work"}],"volumes":[{"container":"/config","description":"Where calibre-web stores the internal database and config.","key":"config"},{"container":"/books","description":"Where your preexisting calibre database is located."}],"ports":[{"container":"8083","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"calibre-web","project_url":"https://github.com/janeczku/calibre-web","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/calibre-web-icon.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database.   It is also possible to integrate google drive and edit metadata and your calibre library through the app itself.\n\nThis software is a fork of library and licensed under the GPL v3 License.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Releases of Calibre-Web"},{"tag":"nightly","desc":"Commits to the master branch of Calibre-Web"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where calibre-web stores the internal database and config."},{"vol_path":"/books","vol_host_path":"/path/to/calibre/library","desc":"Where your preexisting calibre database is located."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8083","internal_port":"8083","port_desc":"WebUI"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_MODS","env_value":"linuxserver/mods:universal-calibre","desc":"#optional & **x86-64 only** Adds the ability to perform ebook conversion"},{"env_var":"OAUTHLIB_RELAX_TOKEN_SCOPE","env_value":"1","desc":"Optionally set this to allow Google OAUTH to work"}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://your-ip:8083`\n\nOn the initial setup screen, enter `/books` as your calibre library location.\n\n**Default admin login:**\n*Username:* admin\n*Password:* admin123\n\nUnrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of `/usr/bin/unrar`\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable ebook conversion utilising Calibre, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as shown in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Calibre E-Book Converter** to `/usr/bin/ebook-convert`\n\nThis image contains the [kepubify](https://pgaskin.net/kepubify/) ebook conversion tool (MIT License) to convert epub to kepub.  In the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Kepubify E-Book Converter** to `/usr/bin/kepubify`\n","changelogs":[{"date":"27.12.22:","desc":"Add ghostscript, libxtst6, libxkbfile-dev."},{"date":"20.12.22:","desc":"Improve init script and prevent harmless error."},{"date":"19.10.22:","desc":"Rebase to jammy. Upgrade to s6v3. Clean up build dependencies."},{"date":"04.11.21:","desc":"Update pip arguments to ignore distro installed packages."},{"date":"24.06.21:","desc":"Add note on optional OAUTHLIB_RELAX_TOKEN_SCOPE for Google OAUTH support."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"10.02.21:","desc":"Add libxrandr2"},{"date":"25.01.21:","desc":"Add nightly tag"},{"date":"19.01.21:","desc":"Add python3-pkg-resources"},{"date":"13.01.21:","desc":"Rebase to Ubuntu Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"12.10.20:","desc":"Add libxi6"},{"date":"12.07.20:","desc":"Add kepubify for arm64v8"},{"date":"05.06.20:","desc":"Add kepubify for x86-64 and arm32v7"},{"date":"06.05.20:","desc":"Add libxslt1.1 and update ImageMagick policy"},{"date":"19.01.20:","desc":"Adding LDAP libs."},{"date":"13.10.19:","desc":"Migrate to Python3."},{"date":"01.08.19:","desc":"Add libxcomposite1."},{"date":"13.06.19:","desc":"Add docker mod to enable optional ebook conversion on x86-64.  Add unrar."},{"date":"02.06.19:","desc":"Rebase to Ubuntu Bionic & add Gdrive support."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"23.02.19:","desc":"Rebase to alpine 3.9, use repo version of imagemagick."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"03.01.19:","desc":"Remove guest user from default app.db."},{"date":"16.08.18:","desc":"Rebase to alpine 3.8."},{"date":"03.07.18:","desc":"New build pushed, all versions below `67` have [vulnerability](https://github.com/janeczku/calibre-web/issues/534)."},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"06.12.17:","desc":"Rebase to alpine 3.7."},{"date":"27.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"24.07.17:","desc":"Curl version for imagemagick."},{"date":"17.07.17:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://your-ip:8083`\n\nOn the initial setup screen, enter `/books` as your calibre library location.\n\n**Default admin login:**\n*Username:* admin\n*Password:* admin123\n\nUnrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of `/usr/bin/unrar`\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable ebook conversion utilising Calibre, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as shown in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Calibre E-Book Converter** to `/usr/bin/ebook-convert`\n\nThis image contains the [kepubify](https://pgaskin.net/kepubify/) ebook conversion tool (MIT License) to convert epub to kepub.  In the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Kepubify E-Book Converter** to `/usr/bin/kepubify`\n"},{"id":"changedetection.io","name":"changedetection.io","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides free, open-source web page monitoring, notification and change detection.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/changedetection-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/changedetection.io"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-changedetection.io"}],"containers":[{"name":"changedetection.io","image":"linuxserver/changedetection.io","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"","description":"Specify the full URL (including protocol) when running behind a reverse proxy"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"5000","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"changedetection.io","project_url":"https://github.com/dgtlmoon/changedetection.io","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/changedetection-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides free, open-source web page monitoring, notification and change detection.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5000","internal_port":"5000","port_desc":"WebUI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"","desc":"Specify the full URL (including protocol) when running behind a reverse proxy"}],"custom_compose":"---\nversion: \"2.1\"\nservices:\n  changedetection:\n    image: lscr.io/linuxserver/changedetection.io:latest\n    container_name: changedetection\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/London\n      - BASE_URL= #optional\n    volumes:\n      - /path/to/appdata/config:/config\n    ports:\n      - 5000:5000\n    restart: unless-stopped\n","app_setup_block_enabled":true,"app_setup_block":"Webui is accessible at http://SERVERIP:PORT\n\nPlease note that this image does not contain the [Playwright content fetcher](https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher#docker-compose-based) due to a lack of support for muslc-based systems. If you require this feature please use [Selenium](https://github.com/linuxserver/docker-changedetection.io/issues/3#issuecomment-1250251715) or the [official container](https://github.com/dgtlmoon/changedetection.io#docker)\n\nFor more info read [the wiki](https://github.com/dgtlmoon/changedetection.io/wiki).\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"09.10.22:","desc":"Add make as build dep to fix pip jq build on armhf."},{"date":"07.08.22:","desc":"Initial release."}]}},"setup":"Webui is accessible at http://SERVERIP:PORT\n\nPlease note that this image does not contain the [Playwright content fetcher](https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher#docker-compose-based) due to a lack of support for muslc-based systems. If you require this feature please use [Selenium](https://github.com/linuxserver/docker-changedetection.io/issues/3#issuecomment-1250251715) or the [official container](https://github.com/dgtlmoon/changedetection.io#docker)\n\nFor more info read [the wiki](https://github.com/dgtlmoon/changedetection.io/wiki).\n"},{"id":"code-server","name":"code-server","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/codeserver.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/code-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-code-server"}],"containers":[{"name":"code-server","image":"linuxserver/code-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"param_usage_include_ports":false,"param_usage_include_vols":false,"param_usage_include_env":false,"param_volumes":[],"param_ports":[],"param_env_vars":[]}}},{"id":"cops","name":"cops","description":"[{{ project_name|capitalize }}]({{ project_url }}) by Sbastien Lucas, stands for Calibre OPDS (and HTML) Php Server.\n\nCOPS links to your Calibre library database and allows downloading and emailing of books directly from a web browser and provides a OPDS feed to connect to your devices.\n\nChanges in your Calibre library are reflected immediately in your COPS pages.\n\nSee : [COPS's home]({{ project_url }}) for more details.\n\nDon't forget to check the [Wiki](https://github.com/seblucas/cops/wiki).\n\n## Why? (taken from the author's site)\n\nIn my opinion Calibre is a marvelous tool but is too big and has too much\ndependencies to be used for its content server.\n\nThat's the main reason why I coded this OPDS server. I needed a simple\ntool to be installed on a small server (Seagate Dockstar in my case).\n\nI initially thought of Calibre2OPDS but as it generate static file no\nsearch was possible.\n\nLater I added an simple HTML catalog that should be usable on my Kobo.\n\nSo COPS's main advantages are :\n * No need for many dependencies.\n * No need for a lot of CPU or RAM.\n * Not much code.\n * Search is available.\n * With Dropbox / owncloud it's very easy to have an up to date OPDS server.\n * It was fun to code.\n\nIf you want to use the OPDS feed don't forget to specify feed.php at the end of your URL.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/cops-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/cops"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-cops"}],"containers":[{"name":"cops","image":"linuxserver/cops","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"COPS Application Data.","key":"config"},{"container":"/books","description":"Calibre metadata.db location."}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"cops","project_url":"http://blog.slucas.fr/en/oss/calibre-opds-php-server","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/cops-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) by Sbastien Lucas, stands for Calibre OPDS (and HTML) Php Server.\n\nCOPS links to your Calibre library database and allows downloading and emailing of books directly from a web browser and provides a OPDS feed to connect to your devices.\n\nChanges in your Calibre library are reflected immediately in your COPS pages.\n\nSee : [COPS's home]({{ project_url }}) for more details.\n\nDon't forget to check the [Wiki](https://github.com/seblucas/cops/wiki).\n\n## Why? (taken from the author's site)\n\nIn my opinion Calibre is a marvelous tool but is too big and has too much\ndependencies to be used for its content server.\n\nThat's the main reason why I coded this OPDS server. I needed a simple\ntool to be installed on a small server (Seagate Dockstar in my case).\n\nI initially thought of Calibre2OPDS but as it generate static file no\nsearch was possible.\n\nLater I added an simple HTML catalog that should be usable on my Kobo.\n\nSo COPS's main advantages are :\n * No need for many dependencies.\n * No need for a lot of CPU or RAM.\n * Not much code.\n * Search is available.\n * With Dropbox / owncloud it's very easy to have an up to date OPDS server.\n * It was fun to code.\n\nIf you want to use the OPDS feed don't forget to specify feed.php at the end of your URL.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"COPS Application Data."},{"vol_path":"/books","vol_host_path":"<path to data>","desc":"Calibre metadata.db location."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<docker host ip>:80`. For connecting via OPDS on a mobile device use `http://<docker host ip>:80/feed.php`. It is strongly suggested that you reverse proxy this prior to exposing to the internet. For more information, such as requiring credentials, check the COPS Wiki (linked above).\n\nThe linuxserver version gives you access to `config_local.php` in `/config` to customise your install to suit your needs, it also includes the dependencies required to directly view epub books in your browser.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.11.20:","desc":"Pin composer version to 1.10.17."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"27.02.19:","desc":"Upgrade packages during install to prevent mismatch with baseimage."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Add multiarch and pipeline logic."},{"date":"21.08.18:","desc":"Rebase to alpine 3.8."},{"date":"02.07.18:","desc":"Add php7-ctype dependency."},{"date":"08.01.18:","desc":"Rebase to alpine 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.04.17:","desc":"Add composer packages, reduce layers."},{"date":"02.04.17:","desc":"Updated to version 1.1.0."},{"date":"05.02.17:","desc":"Updated to Alpine 3.5 & PHP7."},{"date":"24.10.16:","desc":"Updated to implement user based config."},{"date":"24.10.16:","desc":"Updated to version 1.0.1."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"28.09.16:","desc":"Add php5-zlib."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"29.08.16:","desc":"Add php5-opcache."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"12.08.16:","desc":"Initial Release."}]}},"setup":"Access the webui at `http://<docker host ip>:80`. For connecting via OPDS on a mobile device use `http://<docker host ip>:80/feed.php`. It is strongly suggested that you reverse proxy this prior to exposing to the internet. For more information, such as requiring credentials, check the COPS Wiki (linked above).\n\nThe linuxserver version gives you access to `config_local.php` in `/config` to customise your install to suit your needs, it also includes the dependencies required to directly view epub books in your browser.\n"},{"id":"daapd","name":"daapd","description":"[{{ project_name|capitalize }}]({{ project_url }}) (iTunes) media server with support for AirPlay devices, Apple Remote (and compatibles), Chromecast, MPD and internet radio.","icon":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/daapd-git.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/daapd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-daapd"}],"containers":[{"name":"daapd","image":"linuxserver/daapd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where daapd server stores its config and dbase files.","key":"config"},{"container":"/music","description":"Map to your music folder."}]}],"meta":{"readme-vars":{"project_name":"daapd","project_url":"https://owntone.github.io/owntone-server/","project_logo":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/daapd-git.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (iTunes) media server with support for AirPlay devices, Apple Remote (and compatibles), Chromecast, MPD and internet radio.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where daapd server stores its config and dbase files."},{"vol_path":"/music","vol_host_path":"<path to music>","desc":"Map to your music folder."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Map your music folder, open up itunes on the same LAN to see your music there.\n\nThe web interface is available at `http://<your ip>:3689`\n\nFor further setup options of remotes etc, check out the daapd website, [Owntone]({{ project_url }}).\n\n## Enable spotify connect server\n\nEnable the spotify connect server by creating a pipe named 'spotify' in the root of your mounted music folder (not possible on most network mounts):\n\n```sh\nmkfifo <music_folder>/spotify\n```\n\nThe spotify connect server should show up as the 'forked-daapd' device in your Spotify application.\n\nIt is recommended to set the `pipe_autostart` option to `true` in your forked-daapd config.\n","changelogs":[{"date":"31.05.22:","desc":"Make sure the user has access to the audio device."},{"date":"31.05.22:","desc":"Add new deps, flex and bison."},{"date":"12.02.22:","desc":"Rebase to Alpine 3.15."},{"date":"14.09.21:","desc":"Enabled librespot. Disabled spotify on ARMv7"},{"date":"10.07.21:","desc":"Change of paths to work with the new package name, OwnTone."},{"date":"02.04.21:","desc":"Update upstream repo, again."},{"date":"30.03.21:","desc":"Update upstream repo."},{"date":"06.10.20:","desc":"Enabled Spotify on Alpine 3.12 for X86_64 and ARMv7."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"16.01.20:","desc":"Rebase to alpine linux 3.11 and build antlr3c from source."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"20.08.18:","desc":"Rebase to alpine linux 3.8."},{"date":"09.06.18:","desc":"Use buildstage and update dependencies."},{"date":"05.03.18:","desc":"Use updated configure ac and disable avcodecsend to hopefully mitigate crashes with V26."},{"date":"25.02.18:","desc":"Query version before pull and build latest release."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"07.12.17:","desc":"Rebase to alpine linux 3.7."},{"date":"03.12.17:","desc":"Bump to 25.0, cpu core counting routine for faster builds, linting fixes."},{"date":"26.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"10.01.17:","desc":"Bump to 24.2."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"17.09.16:","desc":"Rebase to alpine linux, remove redundant spotify support, move to main repository."},{"date":"28.02.16:","desc":"Add chromecast support, bump dependency versions."},{"date":"04.01.16:","desc":"Disable ipv6 by default because in v23.4 it doesn't work in unraid with it set."},{"date":"17.12.15:","desc":"Add in spotify support."},{"date":"25.11.15:","desc":"Initial Release."}]}},"setup":"Map your music folder, open up itunes on the same LAN to see your music there.\n\nThe web interface is available at `http://<your ip>:3689`\n\nFor further setup options of remotes etc, check out the daapd website, [Owntone]({{ project_url }}).\n\n## Enable spotify connect server\n\nEnable the spotify connect server by creating a pipe named 'spotify' in the root of your mounted music folder (not possible on most network mounts):\n\n```sh\nmkfifo <music_folder>/spotify\n```\n\nThe spotify connect server should show up as the 'forked-daapd' device in your Spotify application.\n\nIt is recommended to set the `pipe_autostart` option to `true` in your forked-daapd config.\n"},{"id":"darktable","name":"darktable","description":"[darktable]({{ project_url }}) is an open source photography workflow application and raw developer. A virtual lighttable and darkroom for photographers. It manages your digital negatives in a database, lets you view them through a zoomable lighttable and enables you to develop raw images and enhance them.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/darktable-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/darktable"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-darktable"}],"containers":[{"name":"darktable","image":"linuxserver/darktable","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and images","key":"config"}],"ports":[{"container":"3000","description":"Darktable desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"darktable","project_url":"https://www.darktable.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/darktable-logo.png","project_blurb":"[darktable]({{ project_url }}) is an open source photography workflow application and raw developer. A virtual lighttable and darkroom for photographers. It manages your digital negatives in a database, lets you view them through a zoomable lighttable and enables you to develop raw images and enhance them.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and images"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Darktable desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"31.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"01.10.21:","desc":"Rebase to Alpine 3.14."},{"date":"07.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"davos","name":"davos","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an FTP automation tool that periodically scans given host locations for new files. It can be configured for various purposes, including listening for specific files to appear in the host location, ready for it to download and then move, if required. It also supports completion notifications as well as downstream API calls, to further the workflow.\n","icon":"https://raw.githubusercontent.com/linuxserver/davos/master/docs/list.PNG","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/davos"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-davos"}],"containers":[{"name":"davos","image":"linuxserver/davos","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/config","description":"davos's config location. This is where it stores its database file and logs.","key":"config"},{"container":"/download","description":"davos's file download location"}],"ports":[{"container":"8080","description":"This is the default port that davos runs under","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"davos","project_url":"https://github.com/linuxserver/davos","project_logo":"https://raw.githubusercontent.com/linuxserver/davos/master/docs/list.PNG","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an FTP automation tool that periodically scans given host locations for new files. It can be configured for various purposes, including listening for specific files to appear in the host location, ready for it to download and then move, if required. It also supports completion notifications as well as downstream API calls, to further the workflow.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"davos's config location. This is where it stores its database file and logs."},{"vol_path":"/download","vol_host_path":"<path to downloads folder>","desc":"davos's file download location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"This is the default port that davos runs under"}],"app_setup_block_enabled":true,"app_setup_block":"The application does not require any set up other than starting the docker container. Further documentation can be found on the [davos GitHub repository page](https://github.com/linuxserver/davos).\n","changelogs":[{"date":"15.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.03.19:","desc":"Updating runtime deps due to change in OpenJRE."},{"date":"08.03.19:","desc":"Updating build environment to pass proper build flags and use gradle wrapper."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.11.16:","desc":"Initial Release."}]}},"setup":"The application does not require any set up other than starting the docker container. Further documentation can be found on the [davos GitHub repository page](https://github.com/linuxserver/davos).\n"},{"id":"ddclient","name":"ddclient","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Perl client used to update dynamic DNS entries for accounts on Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ddclient-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ddclient"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ddclient"}],"containers":[{"name":"ddclient","image":"linuxserver/ddclient","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where ddclient should store its config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"ddclient","project_url":"https://github.com/ddclient/ddclient","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ddclient-logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Perl client used to update dynamic DNS entries for accounts on Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways.","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where ddclient should store its config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Edit the `ddclient.conf` file found in your `/config` volume (also see official [ddclient documentation](https://ddclient.net)). This config file has many providers to choose from and you basically just have to uncomment your provider and add username/password where requested. If you modify ddclient.conf, ddclient will automaticcaly restart and read the config.\n\n### Get dynamic IP from Fritz.Box\nIf ddclient shall fetch the dynamic (public) IP-address from a fritz.box (AVM) add the following line to `/config/ddclient.conf`:\n````\nuse=cmd, cmd=/etc/ddclient/get-ip-from-fritzbox\n````\n","changelogs":[{"date":"20.10.22:","desc":"Update build instructions for 3.10.0. Update default `ddclient.conf`."},{"date":"15.01.22:","desc":"Rebase to Alpine 3.15"},{"date":"15.05.21:","desc":"Distribute script 'sample-get-ip-from-fritzbox' from ddclient repo"},{"date":"08.03.21:","desc":"Added bind-tools to provide nsupdate"},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"08.02.20:","desc":"Ingest from Github."},{"date":"06.02.19:","desc":"Fix permissions."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.03.19:","desc":"Add perl-io-socket-inet6 for ipv6 support."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"22.08.18:","desc":"Rebase to alpine 3.8."},{"date":"10.08.18:","desc":"Update to ddclient v3.9.0. For Cloudflare users, please ensure you remove the line `server=www.cloudflare.com` from your `ddclient.conf`."},{"date":"07.12.17:","desc":"Rebase to alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"10.02.17:","desc":"Rebase to alpine 3.5."},{"date":"26.11.16:","desc":"Update README to new standard and add icon and other small details."},{"date":"29.08.16:","desc":"Initial release."}]}},"setup":"Edit the `ddclient.conf` file found in your `/config` volume (also see official [ddclient documentation](https://ddclient.net)). This config file has many providers to choose from and you basically just have to uncomment your provider and add username/password where requested. If you modify ddclient.conf, ddclient will automaticcaly restart and read the config.\n\n### Get dynamic IP from Fritz.Box\nIf ddclient shall fetch the dynamic (public) IP-address from a fritz.box (AVM) add the following line to `/config/ddclient.conf`:\n````\nuse=cmd, cmd=/etc/ddclient/get-ip-from-fritzbox\n````\n"},{"id":"deluge","name":"deluge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a lightweight, Free Software, cross-platform BitTorrent client.\n\n* Full Encryption\n* WebUI\n* Plugin System\n* Much more...\n","icon":"https://avatars2.githubusercontent.com/u/6733935?v=3&s=200","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/deluge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-deluge"}],"containers":[{"name":"deluge","image":"linuxserver/deluge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use"},{"id":"DELUGE_LOGLEVEL","default":"error","description":"set the loglevel output when running Deluge, default is info for deluged and warning for delgued-web"}],"volumes":[{"container":"/config","description":"deluge configs","key":"config"},{"container":"/downloads","description":"torrent download directory"}],"ports":[{"container":"8112","description":"Port for webui","protocol":"tcp","web":false},{"container":"6881","description":"Inbound torrent traffic (See App Setup)","protocol":"tcp","web":false},{"container":"6881/udp","description":"Inbound torrent traffic (See App Setup)","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"deluge","project_url":"http://deluge-torrent.org/","project_logo":"https://avatars2.githubusercontent.com/u/6733935?v=3&s=200","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a lightweight, Free Software, cross-platform BitTorrent client.\n\n* Full Encryption\n* WebUI\n* Plugin System\n* Much more...\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/deluge/config","desc":"deluge configs"},{"vol_path":"/downloads","vol_host_path":"/path/to/your/downloads","desc":"torrent download directory"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8112","internal_port":"8112","port_desc":"Port for webui"},{"external_port":"6881","internal_port":"6881","port_desc":"Inbound torrent traffic (See App Setup)"},{"external_port":"6881","internal_port":"6881/udp","port_desc":"Inbound torrent traffic (See App Setup)"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DELUGE_LOGLEVEL","env_value":"error","desc":"set the loglevel output when running Deluge, default is info for deluged and warning for delgued-web"}],"app_setup_block_enabled":true,"app_setup_block":"The admin interface is available at `http://SERVER-IP:8112` with a default user/password of admin/deluge.\n\nTo change the password (recommended) log in to the web interface and go to Preferences->Interface->Password.\n\nChange the inbound port to 6881 (or whichever port you've mapped for the container) under Preferences->Network, otherwise random ports will be used.\n","changelogs":[{"date":"29.11.22:","desc":"Restore geoip using py3-geoip as an interim measure."},{"date":"24.11.22:","desc":"Remove GeoIP packages as geoip will not build under Py 3.11 and Deluge still doesn't support geoip2."},{"date":"22.11.22:","desc":"Update GeoIP URL for new IPFS domain."},{"date":"29.08.22:","desc":"Rebase to Alpine Edge again to follow latest releases."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"16.06.22:","desc":"Rebase to Alpine 3.16 from edge."},{"date":"22.02.22:","desc":"Rebase to Alpine, config on first startup, add GeoIP."},{"date":"15.01.22:","desc":"Rebase to Focal."},{"date":"07.06.21:","desc":"Remove host networking from readme examples"},{"date":"23.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"09.05.19:","desc":"Add python3 requests and future modules."},{"date":"24.08.19:","desc":"Add ability to set LogLevel for Deluge."},{"date":"09.06.19:","desc":"Update to 2.x using deluge ppa."},{"date":"02.05.19:","desc":"Install full version of 7zip."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"15.11.18:","desc":"Add deluge-console."},{"date":"11.11.18:","desc":"Rebase to Ubuntu Bionic, add pipeline multiarch logic."},{"date":"09.04.18:","desc":"update to libressl2.7-libssl."},{"date":"29.03.18:","desc":"Rebase to alpine edge."},{"date":"07.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.11.17:","desc":"Change libressl2.6-libssl repo."},{"date":"01.07.17:","desc":"Add curl package."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"29.04.17:","desc":"Add variable for user defined umask."},{"date":"28.04.17:","desc":"update to libressl2.5-libssl."},{"date":"28.12.16:","desc":"Rebase to alpine 3.5 baseimage."},{"date":"17.11.16:","desc":"Rebase to edge baseimage."},{"date":"13.10.16:","desc":"Switch to libressl as openssl deprecated from alpine linux and deluge dependency no longer installs"},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"30.08.16:","desc":"Use pip packages for some critical dependencies."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"15.08.16:","desc":"Rebase to alpine linux."},{"date":"09.11.15:","desc":"Add unrar and unzip"},{"date":"15.10.15:","desc":"Initial Release."}]}},"setup":"The admin interface is available at `http://SERVER-IP:8112` with a default user/password of admin/deluge.\n\nTo change the password (recommended) log in to the web interface and go to Preferences->Interface->Password.\n\nChange the inbound port to 6881 (or whichever port you've mapped for the container) under Preferences->Network, otherwise random ports will be used.\n"},{"id":"digikam","name":"digikam","description":"[digiKam]({{ project_url }}): Professional Photo Management with the Power of Open Source","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/digikam.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/digikam"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-digikam"}],"containers":[{"name":"digikam","image":"linuxserver/digikam","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York."},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores database.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"digikam","project_url":"https://www.digikam.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/digikam.png","project_blurb":"[digiKam]({{ project_url }}): Professional Photo Management with the Power of Open Source","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_usage_include_ports":false,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores database."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"digiKam desktop gui"}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n#### Mysql Internal\n\nWhen using mysql internal mode for the database you will need to click on \"Find\" Button for all the required binaries (mysql_install_db,mysqladmin,mysqld). Then select the binary file and press Open.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"20.01.23:","desc":"Added breeze-icons package for icon support."},{"date":"21.11.22:","desc":"Trigger upon baseimage updates (arch being a rolling distro has too many dependency breaks otherwise). Release version will be the baseimage build date going forward."},{"date":"20.10.22:","desc":"Migrate to s6v3."},{"date":"07.03.22:","desc":"Add Exiftool and firefox for image exports."},{"date":"20.02.22:","desc":"Add MariaDB, expand documentation."},{"date":"15.02.22:","desc":"Rebase to Arch."},{"date":"27.12.21:","desc":"Rebase to focal to resolve dependency issues."},{"date":"27.03.21:","desc":"Download link fixed."},{"date":"20.05.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n#### Mysql Internal\n\nWhen using mysql internal mode for the database you will need to click on \"Find\" Button for all the required binaries (mysql_install_db,mysqladmin,mysqld). Then select the binary file and press Open.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n"},{"id":"dillinger","name":"dillinger","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a cloud-enabled, mobile-ready, offline-storage, AngularJS powered HTML5 Markdown editor.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dillinger.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/dillinger"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-dillinger"}],"containers":[{"name":"dillinger","image":"linuxserver/dillinger","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Dillinger plugin config files","key":"config"}],"ports":[{"container":"8080","description":"The port for the Dillinger web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"dillinger","project_url":"https://github.com/joemccann/dillinger","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dillinger.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a cloud-enabled, mobile-ready, offline-storage, AngularJS powered HTML5 Markdown editor.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to configs>","desc":"Dillinger plugin config files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"The port for the Dillinger web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://your-ip:8080 , keep in mind that storage for this application is in your browser session not server side. Only plugin configurations will ever be stored server side. \n","changelogs":[{"date":"19.04.22:","desc":"Rebase to Alpine."},{"date":"31.05.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://your-ip:8080 , keep in mind that storage for this application is in your browser session not server side. Only plugin configurations will ever be stored server side. \n"},{"id":"diskover","name":"diskover","description":"[{{ project_name }}]({{ project_url }}) is an open source file system indexer that uses Elasticsearch to index and manage data across heterogeneous storage systems.","icon":"https://raw.githubusercontent.com/diskoverdata/diskover-community/master/diskover-web/public/images/diskover.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/diskover"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-diskover"}],"containers":[{"name":"diskover","image":"linuxserver/diskover","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"ES_HOST","default":"elasticsearch","description":"ElasticSearch host (optional)"},{"id":"ES_PORT","default":"9200","description":"ElasticSearch port (optional)"},{"id":"ES_USER","default":"elastic","description":"ElasticSearch username (optional)"},{"id":"ES_PASS","default":"changeme","description":"ElasticSearch password (optional)"}],"volumes":[{"container":"/config","description":"Persistent config files","key":"config"},{"container":"/data","description":"Default mount point to crawl"}],"ports":[{"container":"80","description":"diskover Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"diskover","project_url":"https://github.com/diskoverdata/diskover-community","project_logo":"https://raw.githubusercontent.com/diskoverdata/diskover-community/master/diskover-web/public/images/diskover.png","project_blurb":"[{{ project_name }}]({{ project_url }}) is an open source file system indexer that uses Elasticsearch to index and manage data across heterogeneous storage systems.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/{{ project_name }}/config","desc":"Persistent config files"},{"vol_path":"/data","vol_host_path":"/path/to/{{ project_name }}/data","desc":"Default mount point to crawl"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"diskover Web UI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"ES_HOST","env_value":"elasticsearch","desc":"ElasticSearch host (optional)"},{"env_var":"ES_PORT","env_value":"9200","desc":"ElasticSearch port (optional)"},{"env_var":"ES_USER","env_value":"elastic","desc":"ElasticSearch username (optional)"},{"env_var":"ES_PASS","env_value":"changeme","desc":"ElasticSearch password (optional)"}],"custom_compose":"version: '2'\nservices:\n  diskover:\n    image: lscr.io/linuxserver/diskover\n    container_name: diskover\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=America/New_York\n      - ES_HOST=elasticsearch\n      - ES_PORT=9200\n    volumes:\n      - /path/to/diskover/config:/config\n      - /path/to/diskover/data:/data\n    ports:\n      - 80:80\n    mem_limit: 4096m\n    restart: unless-stopped\n    depends_on:\n      - elasticsearch\n  elasticsearch:\n    container_name: elasticsearch\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=true\n      - bootstrap.memory_lock=true\n      - \"ES_JAVA_OPTS=-Xms1g -Xmx1g\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    volumes:\n      - /path/to/esdata:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n    depends_on:\n      - elasticsearch-helper\n    restart: unless-stopped\n  elasticsearch-helper:\n    image: alpine\n    command: sh -c \"sysctl -w vm.max_map_count=262144\"\n    privileged: true\n","app_setup_block_enabled":true,"app_setup_block":"This application is dependent on an ElasticSearch instance. Please see the example compose file for additional information.\n\nThe default username is diskover with the password of **darkdata**, access the container at `http://<host-ip>/`. The UI may be unusable until a valid index has been created.\n\nThe default diskover-web Constants.php file located at `/config/diskover-web.conf.d/Constants.php` will need to be edited to allow diskover-web to communicate with the ElasticSearch container. The following entries will need to be edited:\n* `const ES_HOST = elasticsearch`\n* `const ES_PORT = 9200`\n\nThe application doesn't start an index by default. A crontab is created inside of the `/config` directory and can be set up to run automated indexes of `/data`. Changes to this crontab file require a restart to apply. You can also manually run an index by executing `/app/diskover/diskover.py` either in interactive or detached mode:\n\n* `docker exec -u abc -d diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the background\n* `docker exec -u abc -it diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the foreground\n","changelogs":[{"date":"25.02.22:","desc":"Add php7-sqlite3 to support rc4 release."},{"date":"03.11.21:","desc":"Added more support for potential config files."},{"date":"31.10.21:","desc":"Added xpack.security variable to ElasticSearch; added instructions to edit Constants.php in diskover; corrected command needed to manually generate an index in diskover"},{"date":"11.10.21:","desc":"Updated to diskover-community v2."},{"date":"19.11.20:","desc":"Fix pip packages."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.11.18:","desc":"Initial Release."}]}},"setup":"This application is dependent on an ElasticSearch instance. Please see the example compose file for additional information.\n\nThe default username is diskover with the password of **darkdata**, access the container at `http://<host-ip>/`. The UI may be unusable until a valid index has been created.\n\nThe default diskover-web Constants.php file located at `/config/diskover-web.conf.d/Constants.php` will need to be edited to allow diskover-web to communicate with the ElasticSearch container. The following entries will need to be edited:\n* `const ES_HOST = elasticsearch`\n* `const ES_PORT = 9200`\n\nThe application doesn't start an index by default. A crontab is created inside of the `/config` directory and can be set up to run automated indexes of `/data`. Changes to this crontab file require a restart to apply. You can also manually run an index by executing `/app/diskover/diskover.py` either in interactive or detached mode:\n\n* `docker exec -u abc -d diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the background\n* `docker exec -u abc -it diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the foreground\n"},{"id":"docker-compose","name":"docker-compose","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/dockercompose.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/docker-compose"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-docker-compose"}],"containers":[{"name":"docker-compose","image":"linuxserver/docker-compose","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"docker-compose","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring:\n\n* regular and timely application updates\n* easy user mappings (PGID, PUID)\n* custom base image with s6 overlay\n* weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n* regular security updates\n\nFind us at:\n\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [GitHub](https://github.com/linuxserver) - view the source for all of our repositories.\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n# [linuxserver/docker-compose](https://github.com/linuxserver/docker-docker-compose)\n\n[![Scarf.io pulls](https://scarf.sh/installs-badge/linuxserver-ci/linuxserver%2Fdocker-compose?color=94398d&label-color=555555&logo-color=ffffff&style=for-the-badge&package-type=docker)](https://scarf.sh/gateway/linuxserver-ci/docker/linuxserver%2Fdocker-compose)\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-docker-compose)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github&include_prereleases)](https://github.com/linuxserver/docker-docker-compose/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-docker-compose/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/linuxserver.io/docker-docker-compose/container_registry)\n[![Quay.io](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Quay.io)](https://quay.io/repository/linuxserver.io/docker-compose)\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/docker-compose)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/docker-compose)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-docker-compose%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-docker-compose/job/master/)\n\n[docker-compose](https://github.com/docker/compose) is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application's services. Then, using a single command, you create and start all the services from your configuration.\n\n[![docker-compose](https://github.com/docker/compose/raw/master/logo.png)](https://github.com/docker/compose)\n\n## Supported Architectures\n\nWe utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `lscr.io/linuxserver/docker-compose:latest` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Available | Tag |\n| :----: | :----: | ---- |\n| x86-64 |  | amd64-\\<version tag\\> |\n| arm64 |  | arm64v8-\\<version tag\\> |\n| armhf|  | arm32v7-\\<version tag\\> |\n\n## Version Tags\n\nThis image provides various versions that are available via tags. Please read the descriptions carefully and exercise caution when using unstable or development tags.\n\n| Tag | Available | Description |\n| :----: | :----: |--- |\n| latest |  | docker-compose v1 releases |\n| alpine |  | docker-compose v1 releases with our alpine baseimage |\n| v2 |  | docker compose v2 releases |\n\n## Usage\n\n### Docker cli\n\n```\ndocker run --rm \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  lscr.io/linuxserver/docker-compose:latest \\\n  up\n```\nYou can replace the last line with any docker-compose command and argument, which will be passed to docker-compose inside the image.\n\n### Recommended method\n\nWe provide a very convenient script that allows the docker-compose container to run as if it was installed natively:\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n```\n\nRunning these two commands on your docker host once will let you issue commands such as `docker-compose up -d` and the docker-compose container will do its job behind the scenes.\n\n## Docker Mods\n\n[![Docker Mods](https://img.shields.io/badge/dynamic/yaml?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=docker-compose&query=%24.mods%5B%27docker-compose%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=docker-compose \"view available mods for this container.\") [![Docker Universal Mods](https://img.shields.io/badge/dynamic/yaml?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=universal&query=%24.mods%5B%27universal%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=universal \"view available universal mods.\")\n\nWe publish various [Docker Mods](https://github.com/linuxserver/docker-mods) to enable additional functionality within the containers. The list of Mods available for this image (if any) as well as universal mods that can be applied to any one of our images can be accessed via the dynamic badges above.\n\n## Support Info\n\n* Shell access whilst the container is running: `docker exec -it docker-compose /bin/bash`\n* To monitor the logs of the container in realtime: `docker logs -f docker-compose`\n* container version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' docker-compose`\n* image version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' lscr.io/linuxserver/docker-compose:latest`\n\n## Updating Info\n\nMost of our images are static, versioned, and require an image update and container recreation to update the app inside. With some exceptions (ie. nextcloud, plex), we do not recommend or support updating apps inside the container. Please consult the [Application Setup](#application-setup) section above to see if it is recommended for the image.\n\nBelow are the instructions for updating containers:\n\n### Via Docker Run\n\n* Update the image: `docker pull lscr.io/linuxserver/docker-compose:latest`\n* You can also remove the old dangling images: `docker image prune`\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n\n```bash\ngit clone https://github.com/linuxserver/docker-docker-compose.git\ncd docker-docker-compose\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t lscr.io/linuxserver/docker-compose:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **15.03.22:** - Add v2 branch. Change master to only fetch v1 releases. Change alpine to only fetch v1 releases. Rebase master to focal. Rebase alpine to 3.15.\n* **17.12.20:** - Update run.sh with formatting changes.\n* **04.10.20:** - Update run.sh with changes from upstream.\n* **31.08.20:** - Update tox and virtualenv.\n* **31.07.20:** - Add support for global env var `DOCKER_COMPOSE_IMAGE_TAG` in the `run.sh` script.\n* **06.07.20:** - Publish docker-compose and docker-cli binaries in Github releases.\n* **01.07.20:** - Release alpine based images at `alpine` tag.\n* **04.06.20:** - Bump docker-cli to 19.03.8, auto-detect python3 version.\n* **19.05.20:** - Initial Release.\n\n{%- endraw %}\n"}}},{"id":"dokuwiki","name":"dokuwiki","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple to use and highly versatile Open Source wiki software that doesn't require a database. It is loved by users for its clean and readable syntax. The ease of maintenance, backup and integration makes it an administrator's favorite. Built in access controls and authentication connectors make DokuWiki especially useful in the enterprise context and the large number of plugins contributed by its vibrant community allow for a broad range of use cases beyond a traditional wiki.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dokuwiki-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/dokuwiki"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-dokuwiki"}],"containers":[{"name":"dokuwiki","image":"linuxserver/dokuwiki","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"APP_URL","default":"/dokuwiki","description":"Specify an APP_URL to append to your root location, helpful for subfolder reverse proxy setups.  Does not take effect until after first restart following setup."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"80","description":"Application HTTP Port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"dokuwiki","project_url":"https://www.dokuwiki.org/dokuwiki/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dokuwiki-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple to use and highly versatile Open Source wiki software that doesn't require a database. It is loved by users for its clean and readable syntax. The ease of maintenance, backup and integration makes it an administrator's favorite. Built in access controls and authentication connectors make DokuWiki especially useful in the enterprise context and the large number of plugins contributed by its vibrant community allow for a broad range of use cases beyond a traditional wiki.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application HTTP Port"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"APP_URL","env_value":"/dokuwiki","desc":"Specify an APP_URL to append to your root location, helpful for subfolder reverse proxy setups.  Does not take effect until after first restart following setup."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"443","internal_port":"443","port_desc":"#optional Application HTTPS Port"}],"app_setup_block_enabled":true,"app_setup_block":"Upon first install go to `http://$IP:$PORT/install.php` once you have completed the setup, restart the container, login as admin and set \"Use nice URLs\" in the `admin/Configuration Settings` panel to `.htaccess` and tick `Use slash as namespace separator in URLs` to enable [nice URLs](https://www.dokuwiki.org/rewrite) you will find the webui at `http://$IP:$PORT/`, for more info see [{{ project_name|capitalize }}]({{ project_url }})\n","changelogs":[{"date":"28.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"11.13.22:","desc":"Move lib/images/smileys/local and lib/images/interwiki outside of the container for user defined smiley and interwiki icon support."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"20.07.21:","desc":"Add php7-dom, fixes minor issues in sprintdoc template."},{"date":"15.04.21:","desc":"Add `vendor` folder to deny list."},{"date":"21.02.21:","desc":"Store search index outside of container, set absolute (default) path for `savedir`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"28.09.20:","desc":"Add php7-pdo_sqlite and php7-sqlite3."},{"date":"23.09.20:","desc":"Fix php-local.ini bug introduced in the prior PR."},{"date":"14.09.20:","desc":"Rebase to alpine 3.12. Add php7-ctype, php7-curl, php7-pdo_mysql, php7-pdo_pgsql, php7-pecl-imagick and php7-iconv. Bump upload max filesize and post max size to 100MB. Remove deprecated APP_URL env var. Fix breaking addons."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"01.12.19:","desc":"Add php7-ldap package to support LDAP authentication."},{"date":"28.05.19:","desc":"Initial Release."}]}},"setup":"Upon first install go to `http://$IP:$PORT/install.php` once you have completed the setup, restart the container, login as admin and set \"Use nice URLs\" in the `admin/Configuration Settings` panel to `.htaccess` and tick `Use slash as namespace separator in URLs` to enable [nice URLs](https://www.dokuwiki.org/rewrite) you will find the webui at `http://$IP:$PORT/`, for more info see [{{ project_name|capitalize }}]({{ project_url }})\n"},{"id":"domoticz","name":"domoticz","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Home Automation System that lets you monitor and configure various devices like: Lights, Switches, various sensors/meters like Temperature, Rain, Wind, UV, Electra, Gas, Water and much more. Notifications/Alerts can be sent to any mobile device.","icon":"https://github.com/domoticz/domoticz/raw/master/www/images/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/domoticz"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-domoticz"}],"containers":[{"name":"domoticz","image":"linuxserver/domoticz","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"WEBROOT","default":"domoticz","description":"Sets webroot to domoticz for usage with subfolder reverse proxy. Not needed unless reverse proxying."},{"id":"DBASE","default":"<path to database>","description":"Sets path to database. Do not set unless you know what this does."}],"volumes":[{"container":"/config","description":"Where Domoticz stores config files and data.","key":"config"}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"6144","description":"Domoticz communication port.","protocol":"tcp","web":false},{"container":"1443","description":"Domoticz communication port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"domoticz","project_url":"https://www.domoticz.com","project_logo":"https://github.com/domoticz/domoticz/raw/master/www/images/logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Home Automation System that lets you monitor and configure various devices like: Lights, Switches, various sensors/meters like Temperature, Rain, Wind, UV, Electra, Gas, Water and much more. Notifications/Alerts can be sent to any mobile device.","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Current latest stable."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where Domoticz stores config files and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"6144","internal_port":"6144","port_desc":"Domoticz communication port."},{"external_port":"1443","internal_port":"1443","port_desc":"Domoticz communication port."}],"param_device_map":true,"param_devices":[{"device_path":"path to device","device_host_path":"path to device","desc":"For passing through USB devices."}],"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"WEBROOT","env_value":"domoticz","desc":"Sets webroot to domoticz for usage with subfolder reverse proxy. Not needed unless reverse proxying."},{"env_var":"DBASE","env_value":"<path to database>","desc":"Sets path to database. Do not set unless you know what this does."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Passing Through USB Devices\n\nTo get full use of Domoticz, you probably have a USB device you want to pass through. To figure out which device to pass through, you have to connect the device and look in dmesg for the device node created. Issue the command 'dmesg | tail' after you connected your device and you should see something like below.\n\n```\nusb 1-1.2: new full-speed USB device number 7 using ehci-pci\nftdi_sio 1-1.2:1.0: FTDI USB Serial Device converter detected\nusb 1-1.2: Detected FT232RL\nusb 1-1.2: FTDI USB Serial Device converter now attached to ttyUSB0\n```\nAs you can see above, the device node created is ttyUSB0. It does not say where, but it's almost always in /dev/. The correct tag for passing through this USB device is '--device /dev/ttyUSB0:/dev/ttyUSB0'\n"],"app_setup_block_enabled":true,"app_setup_block":"To configure Domoticz, go to the IP of your docker host on the port you configured (default 8080), and add your hardware in Setup > Hardware.\nThe user manual is available at [www.domoticz.com]({{ project_url }})\n","changelogs":[{"date":"15.10.22:","desc":"Remove deprecated legacy stable branches."},{"date":"05.02.22:","desc":"Set default webroot to /. Add env. variable for setting custom databas path."},{"date":"26.12.20:","desc":"Rebase to Ubuntu Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"24.11.19:","desc":"Change to using domoticz builtin Lua and MQTT."},{"date":"03.11.19:","desc":"Set capabilities for domoticz binary and move cmake from edge repo."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10. Add iputils for ping. Fix typo in readme. Fix permissions for custom icons."},{"date":"12.05.19:","desc":"Add boost dependencies and turn off static boost build. Bump to Alpine 3.9."},{"date":"30.03.19:","desc":"Add env variable to set webroot."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"19.02.19:","desc":"Fix branch for version logic."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"02.07.18:","desc":"Add openssh package."},{"date":"01.07.18:","desc":"Fix backup/restore in webgui."},{"date":"03.04.18:","desc":"Add dependencies for BroadlinkRM2 plugin."},{"date":"20.01.18:","desc":"Move telldus core to repo to prevent build fail when source site goes down."},{"date":"18.01.18:","desc":"Remove logging to syslog in the run command to prevent double logging."},{"date":"04.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"26.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"26.02.17:","desc":"Add curl and replace openssl with libressl."},{"date":"11.02.17:","desc":"Update README."},{"date":"03.01.17:","desc":"Initial Release."}]}},"setup":"To configure Domoticz, go to the IP of your docker host on the port you configured (default 8080), and add your hardware in Setup > Hardware.\nThe user manual is available at [www.domoticz.com]({{ project_url }})\n"},{"id":"doplarr","name":"doplarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an *arr request bot for Discord.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doplarr-logo_title.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/doplarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-doplarr"}],"containers":[{"name":"doplarr","image":"linuxserver/doplarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"DISCORD__TOKEN","default":"","description":"Specify your discord bot token."},{"id":"OVERSEERR__API","default":"","description":"Specify your Overseerr API key. Leave blank if using Radarr/Sonarr."},{"id":"OVERSEERR__URL","default":"http://localhost:5055","description":"Specify your Overseerr URL. Leave blank if using Radarr/Sonarr."},{"id":"RADARR__API","default":"","description":"Specify your Radarr API key. Leave blank if using Overseerr."},{"id":"RADARR__URL","default":"http://localhost:7878","description":"Specify your Radarr URL. Leave blank if using Overseerr."},{"id":"SONARR__API","default":"","description":"Specify your Sonarr API key. Leave blank if using Overseerr."},{"id":"SONARR__URL","default":"http://localhost:8989","description":"Specify your Sonarr URL. Leave blank if using Overseerr."},{"id":"DISCORD__MAX_RESULTS","default":"25","description":"Sets the maximum size of the search results selection"},{"id":"DISCORD__REQUESTED_MSG_STYLE","default":":plain","description":"Sets the style of the request alert message. One of `:plain` `:embed` `:none`"},{"id":"SONARR__QUALITY_PROFILE","default":"","description":"The name of the quality profile to use by default for Sonarr"},{"id":"RADARR__QUALITY_PROFILE","default":"","description":"The name of the quality profile to use by default for Radarr"},{"id":"SONARR__ROOTFOLDER","default":"","description":"The root folder to use by default for Sonarr"},{"id":"RADARR__ROOTFOLDER","default":"","description":"The root folder to use by default for Radarr"},{"id":"SONARR__LANGUAGE_PROFILE","default":"","description":"The name of the language profile to use by default for Sonarr"},{"id":"OVERSEERR__DEFAULT_ID","default":"","description":"The Overseerr user id to use by default if there is no associated discord account for the requester"},{"id":"PARTIAL_SEASONS","default":"true","description":"Sets whether users can request partial seasons."},{"id":"LOG_LEVEL","default":":info","description":"The log level for the logging backend. This can be changed for debugging purposes. One of trace `:debug` `:info` `:warn` `:error` `:fatal` `:report`"},{"id":"JAVA_OPTS","default":"","description":"For passing additional java options."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"doplarr","project_url":"https://github.com/kiranshila/Doplarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doplarr-logo_title.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an *arr request bot for Discord.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"DISCORD__TOKEN","env_value":"","desc":"Specify your discord bot token."},{"env_var":"OVERSEERR__API","env_value":"","desc":"Specify your Overseerr API key. Leave blank if using Radarr/Sonarr."},{"env_var":"OVERSEERR__URL","env_value":"http://localhost:5055","desc":"Specify your Overseerr URL. Leave blank if using Radarr/Sonarr."},{"env_var":"RADARR__API","env_value":"","desc":"Specify your Radarr API key. Leave blank if using Overseerr."},{"env_var":"RADARR__URL","env_value":"http://localhost:7878","desc":"Specify your Radarr URL. Leave blank if using Overseerr."},{"env_var":"SONARR__API","env_value":"","desc":"Specify your Sonarr API key. Leave blank if using Overseerr."},{"env_var":"SONARR__URL","env_value":"http://localhost:8989","desc":"Specify your Sonarr URL. Leave blank if using Overseerr."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DISCORD__MAX_RESULTS","env_value":"25","desc":"Sets the maximum size of the search results selection"},{"env_var":"DISCORD__REQUESTED_MSG_STYLE","env_value":":plain","desc":"Sets the style of the request alert message. One of `:plain` `:embed` `:none`"},{"env_var":"SONARR__QUALITY_PROFILE","env_value":"","desc":"The name of the quality profile to use by default for Sonarr"},{"env_var":"RADARR__QUALITY_PROFILE","env_value":"","desc":"The name of the quality profile to use by default for Radarr"},{"env_var":"SONARR__ROOTFOLDER","env_value":"","desc":"The root folder to use by default for Sonarr"},{"env_var":"RADARR__ROOTFOLDER","env_value":"","desc":"The root folder to use by default for Radarr"},{"env_var":"SONARR__LANGUAGE_PROFILE","env_value":"","desc":"The name of the language profile to use by default for Sonarr"},{"env_var":"OVERSEERR__DEFAULT_ID","env_value":"","desc":"The Overseerr user id to use by default if there is no associated discord account for the requester"},{"env_var":"PARTIAL_SEASONS","env_value":"true","desc":"Sets whether users can request partial seasons."},{"env_var":"LOG_LEVEL","env_value":":info","desc":"The log level for the logging backend. This can be changed for debugging purposes. One of trace `:debug` `:info` `:warn` `:error` `:fatal` `:report`"},{"env_var":"JAVA_OPTS","env_value":"","desc":"For passing additional java options."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Start by following the [Discord](https://github.com/kiranshila/Doplarr#discord) setup instructions from Doplarr's readme.\n\nNOTE: The `DISCORD__TOKEN` environment variable is required to run the container!\n\n- If you are using Overseerr, fill in the Overseerr API and URL variables, and leave the Radarr/Sonarr variables blank.\n- If you are using Radarr/Sonarr (and not using Overseerr), fill in the Radarr/Sonarr API and URL variables, and leave the Overseerr variables blank.\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`.\n\nReview and adjust any [Optional Settings](https://github.com/kiranshila/Doplarr#optional-settings) from Doplarr's readme.\n","changelogs":[{"date":"18.12.22:","desc":"Rebase to alpine 3.17, upgrade to openjdk17."},{"date":"01.05.22:","desc":"Remove `DISCORD__ROLE_ID` environment variable, see [Permissions Configuration](https://github.com/kiranshila/Doplarr/blob/main/docs/configuration.md#permissions)."},{"date":"30.01.22:","desc":"Variable adjustments."},{"date":"30.01.22:","desc":"Initial Release."}]}},"setup":"Start by following the [Discord](https://github.com/kiranshila/Doplarr#discord) setup instructions from Doplarr's readme.\n\nNOTE: The `DISCORD__TOKEN` environment variable is required to run the container!\n\n- If you are using Overseerr, fill in the Overseerr API and URL variables, and leave the Radarr/Sonarr variables blank.\n- If you are using Radarr/Sonarr (and not using Overseerr), fill in the Radarr/Sonarr API and URL variables, and leave the Overseerr variables blank.\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`.\n\nReview and adjust any [Optional Settings](https://github.com/kiranshila/Doplarr#optional-settings) from Doplarr's readme.\n"},{"id":"doublecommander","name":"doublecommander","description":"[Double Commander]({{ project_url }}) is a free cross platform open source file manager with two panels side by side. It is inspired by Total Commander and features some new ideas.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doublecommander-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/doublecommander"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-doublecommander"}],"containers":[{"name":"doublecommander","image":"linuxserver/doublecommander","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"},{"container":"/data","description":"Host data directories, mount as many as needed."}],"ports":[{"container":"3000","description":"Double Commander desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"doublecommander","project_url":"https://doublecmd.sourceforge.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doublecommander-icon.png","project_blurb":"[Double Commander]({{ project_url }}) is a free cross platform open source file manager with two panels side by side. It is inspired by Total Commander and features some new ideas.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Host data directories, mount as many as needed."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Double Commander desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.09.22:","desc":"Migrate to s6v3."},{"date":"15.02.21:","desc":"Rebase to Ubuntu Jammy."},{"date":"14.12.21:","desc":"Rebase to Ubuntu focal."},{"date":"25.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"duckdns","name":"duckdns","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/duckdns.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/duckdns"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-duckdns"}],"containers":[{"name":"duckdns","image":"linuxserver/duckdns","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBDOMAINS","default":"subdomain1,subdomain2","description":"multiple subdomains allowed, comma separated, no spaces"},{"id":"TOKEN","default":"token","description":"DuckDNS token"},{"id":"LOG_FILE","default":"false","description":"Set to `true` to log to file (also need to map /config)."}]}],"meta":{"readme-vars":{"project_name":"duckdns","project_url":"https://duckdns.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/duckdns.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":"","common_param_env_vars_enabled":"optional","param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"","param_net_desc":"","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"SUBDOMAINS","env_value":"subdomain1,subdomain2","desc":"multiple subdomains allowed, comma separated, no spaces"},{"env_var":"TOKEN","env_value":"token","desc":"DuckDNS token"}],"param_usage_include_vols":false,"param_volumes":"","param_usage_include_ports":false,"param_ports":"","param_device_map":false,"param_devices":"","cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"LOG_FILE","env_value":"false","desc":"Set to `true` to log to file (also need to map /config)."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Used in conjunction with logging to file."}],"opt_param_usage_include_ports":false,"opt_param_ports":"","opt_param_device_map":false,"opt_param_devices":"","opt_cap_add_param":false,"opt_cap_add_param_vars":"","optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"- Go to the [duckdns website]({{project_url}}), register your subdomain(s) and retrieve your token\n- Create a container with your subdomain(s) and token\n- It will update your IP with the DuckDNS service every 5 minutes (with a random jitter)\n","changelogs":[{"date":"23.09.22:","desc":"Rebase to alpine 3.16 and s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"17.05.22:","desc":"Don't allow insecure connections and add timeout."},{"date":"17.05.22:","desc":"Add random jitter to update time."},{"date":"23.02.22:","desc":"Append to log file instead of overwriting every time."},{"date":"03.05.21:","desc":"Re-adjust cron timings to prevent peak times, update code formatting."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.04.20:","desc":"Add donation links for DuckDNS."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"24.09.19:","desc":"Fix perms on github and remove chmod that can stall the container."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"08.02.19:","desc":"Update readme with optional parameters."},{"date":"10.12.18:","desc":"Fix docker compose example."},{"date":"15.10.18:","desc":"Multi-arch image."},{"date":"22.08.18:","desc":"Rebase to alpine 3.8."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"17.11.16:","desc":"Initial release."}]}},"setup":"- Go to the [duckdns website]({{project_url}}), register your subdomain(s) and retrieve your token\n- Create a container with your subdomain(s) and token\n- It will update your IP with the DuckDNS service every 5 minutes (with a random jitter)\n"},{"id":"duplicati","name":"duplicati","description":"[{{ project_name|capitalize }}]({{ project_url }}) works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/duplicati-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/duplicati"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-duplicati"}],"containers":[{"name":"duplicati","image":"linuxserver/duplicati","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"CLI_ARGS","default":"","description":"Optionally specify any [CLI variables](https://duplicati.readthedocs.io/en/latest/07-other-command-line-utilities/) you want to launch the app with"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/backups","description":"Path to store local backups."},{"container":"/source","description":"Path to source for files to backup."}],"ports":[{"container":"8200","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"duplicati","project_url":"https://www.duplicati.com/","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/duplicati-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Beta releases of Duplicati"},{"tag":"development","desc":"Canary releases of Duplicati"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains all relevant configuration files."},{"vol_path":"/backups","vol_host_path":"</path/to/backups>","desc":"Path to store local backups."},{"vol_path":"/source","vol_host_path":"</path/to/source>","desc":"Path to source for files to backup."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8200","internal_port":"8200","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CLI_ARGS","env_value":"","desc":"Optionally specify any [CLI variables](https://duplicati.readthedocs.io/en/latest/07-other-command-line-utilities/) you want to launch the app with"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The webui is at `<your ip>:8200` , create backup jobs etc via the webui, for local backups select `/backups` as the destination. For more information see [Duplicati]({{project_url}}).\n","changelogs":[{"date":"03.08.22:","desc":"Deprecate armhf."},{"date":"25.04.22:","desc":"Rebase to mono:focal."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"16.07.19:","desc":"Allow for additional command line arguments in an environment variable."},{"date":"28.06.19:","desc":"Rebase to bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"28.02.19:","desc":"Allow access from all hostnames, clarify info on image tags."},{"date":"13.01.19:","desc":"Use jq instead of awk in dockerfiles."},{"date":"11.01.19:","desc":"Multi-arch image."},{"date":"09.12.17:","desc":"Fix continuation lines."},{"date":"31.08.17:","desc":"Build only beta or release versions (thanks deasmi)."},{"date":"24.04.17:","desc":"Initial release."}]}},"setup":"The webui is at `<your ip>:8200` , create backup jobs etc via the webui, for local backups select `/backups` as the destination. For more information see [Duplicati]({{project_url}}).\n"},{"id":"emby","name":"emby","description":"[{{ project_name|capitalize }}]({{ project_url }}) organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emby-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/emby"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-emby"}],"containers":[{"name":"emby","image":"linuxserver/emby","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/opt/vc/lib","description":"Path for Raspberry Pi OpenMAX libs *optional*."},{"container":"/config","description":"Emby data storage location. *This can grow very large, 50gb+ is likely for a large collection.*","key":"config"},{"container":"/data/tvshows","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"container":"/data/movies","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"ports":[{"container":"8096","description":"Http webUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"emby","project_url":"https://emby.media/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emby-logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server.","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable emby releases"},{"tag":"beta","desc":"Beta emby releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/library","desc":"Emby data storage location. *This can grow very large, 50gb+ is likely for a large collection.*"},{"vol_path":"/data/tvshows","vol_host_path":"/path/to/tvshows","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"vol_path":"/data/movies","vol_host_path":"/path/to/movies","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8096","internal_port":"8096","port_desc":"Http webUI."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/opt/vc/lib","vol_host_path":"/opt/vc/lib","desc":"Path for Raspberry Pi OpenMAX libs *optional*."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel or AMD GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/vchiq","device_host_path":"/dev/vchiq","desc":"Only needed if you want to use your Raspberry Pi OpenMax video encoding (Bellagio)."},{"device_path":"/dev/video10","device_host_path":"/dev/video10","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video11","device_host_path":"/dev/video11","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video12","device_host_path":"/dev/video12","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8920","internal_port":"8920","port_desc":"Https webUI (you need to setup your own certificate)."}],"unraid_template_sync":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://<your-ip>:8096`\n\nEmby has very complete and verbose documentation located [here](https://github.com/MediaBrowser/Wiki/wiki) .\n\nHardware acceleration users for Intel Quicksync and AMD VAAPI will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n```--device=/dev/dri:/dev/dri```\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the emby docker.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi OpenMAX will need to mount their /dev/vchiq video device inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n```\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their /dev/video1X devices inside of the container by passing the following options when running or creating the container:\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","changelogs":[{"date":"26.09.22:","desc":"Update chown behavior."},{"date":"18.09.22:","desc":"Migrate to s6v3, rebase to Ubuntu Jammy."},{"date":"19.05.21:","desc":"Structural changes upstream."},{"date":"17.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information. Remove no longer used mapping for /transcode."},{"date":"21.12.20:","desc":"Rebase to Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"03.11.20:","desc":"Fix issue with missing samba folder."},{"date":"13.11.20:","desc":"Fix issue with samba and ffmpeg."},{"date":"03.07.20:","desc":"Add support for amd vaapi hw transcode."},{"date":"29.02.20:","desc":"Add v4l2 support on Raspberry Pi."},{"date":"26.02.20:","desc":"Add openmax support on Raspberry Pi."},{"date":"15.02.20:","desc":"Allow restarting emby from the gui (also allows for auto restarts after addon updates)."},{"date":"02.10.19:","desc":"Improve permission fixing for render and dvb devices."},{"date":"13.08.19:","desc":"Add umask environment variable."},{"date":"24.06.19:","desc":"Fix typos in readme."},{"date":"30.05.19:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://<your-ip>:8096`\n\nEmby has very complete and verbose documentation located [here](https://github.com/MediaBrowser/Wiki/wiki) .\n\nHardware acceleration users for Intel Quicksync and AMD VAAPI will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n```--device=/dev/dri:/dev/dri```\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the emby docker.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi OpenMAX will need to mount their /dev/vchiq video device inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n```\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their /dev/video1X devices inside of the container by passing the following options when running or creating the container:\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n"},{"id":"embystat","name":"embystat","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a personal web server that can calculate all kinds of statistics from your (local) Emby server. Just install this on your server and let him calculate all kinds of fun stuff.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/embystat-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/embystat"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-embystat"}],"containers":[{"name":"embystat","image":"linuxserver/embystat","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"/embystat","description":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"6555","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"embystat","project_url":"https://github.com/mregni/EmbyStat","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/embystat-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a personal web server that can calculate all kinds of statistics from your (local) Emby server. Just install this on your server and let him calculate all kinds of fun stuff.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"EmbyStat releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6555","internal_port":"6555","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"/embystat","desc":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:6555`. Follow the setup wizard on initial install.  Then configure the required services.\n","changelogs":[{"date":"11.06.22:","desc":"Rebase to focal, update disable updates flag."},{"date":"08.04.20:","desc":"Structural changes for beta18."},{"date":"04.12.19:","desc":"Disable in app updates."},{"date":"12.11.19:","desc":"Multi-arch builds."},{"date":"10.09.19:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:6555`. Follow the setup wizard on initial install.  Then configure the required services.\n"},{"id":"emulatorjs","name":"emulatorjs","description":"[{{ project_name|capitalize }}]({{ project_url }}) - In browser web based emulation portable to nearly any device for many retro consoles. A mix of emulators is used between Libretro and EmulatorJS.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emulatorjs-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/emulatorjs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-emulatorjs"}],"containers":[{"name":"emulatorjs","image":"linuxserver/emulatorjs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder for reverse proxies IE '/FOLDER/'"}],"volumes":[{"container":"/config","description":"Path to store user profiles","key":"config"},{"container":"/data","description":"Path to store roms/artwork"}],"ports":[{"container":"3000","description":"Rom/artwork management interface, used to generate/manage config files and download artwork","protocol":"tcp","web":false},{"container":"80","description":"Emulation frontend containing static web files used to browse and launch games","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"emulatorjs","project_url":"https://github.com/linuxserver/emulatorjs","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emulatorjs-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - In browser web based emulation portable to nearly any device for many retro consoles. A mix of emulators is used between Libretro and EmulatorJS.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Path to store user profiles"},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Path to store roms/artwork"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Rom/artwork management interface, used to generate/manage config files and download artwork"},{"external_port":"80","internal_port":"80","port_desc":"Emulation frontend containing static web files used to browse and launch games"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"4001","internal_port":"4001","port_desc":"IPFS peering port, if you want to participate in the P2P network to distribute frontend artwork please forward this to the Internet"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder for reverse proxies IE '/FOLDER/'"}],"app_setup_block_enabled":true,"app_setup_block":"The Backend can be accessed at:\n\n* http://yourhost:3000/\n\nThe first thing you will need to do is click to download the default art/configs from this interface, this will setup a skeleton directory in your `/data` mount. From there add roms to the respective `roms` directories and follow the on screen instructions to add them to your web frontend running on port 80.\n\nThe frontend application has been initially optimized around being used with a standard gamepad (more specifically for modern Xbox consoles that have chromium based Edge browsers). The navigation revolves around the up/down/left/right keys to browse the menus and launch games.\nMobile browsers will function, just keep in mind compatibility will be reduced especially for CD based games.\n\n**It is important to note that some of the current emulators used for this frontend are obfuscated code, efforts are being made to [reverse engineer it](https://github.com/ethanaobrien/emulatorjs/) but you should know it can potentially reach out to third party services if you manually enable features like netplay (this should never happen in a stock setup). The point of this message is that on top of the de-obfuscation effort there is also effort to stop using binary blobs and shift to built from source libretro emscripten blobs, for now this web based emulation stack is the best for useability and compatibility. We are in the process to transitioning to libretro cores for emulators, currently 27/30 emulators have been replaced.**\n\n**For Xbox users please click the select button a couple times after launching a game to ensure the B button does not trigger a \"back\" action in the browser. (official name \"view button\" it is the two small squares) Exiting the controller mode and back to browser controls can be triggered by holding the start button for 3 seconds. (official name \"menu button\" the three lines) You will be unable to use features like save states and modify controller layouts on the emulatorjs based emulators currently as I have not determined a methodology of re-entering controller mode once you exit it. All normal game saves will function given you exit the game play screen cleanly using the B button for back this includes multi disc games for psx. Your game saves are stored in browser storage by hostname so if you make any changes to your local hosted setup (port or IP) the saves will not follow with it. For libretro based emulators you can use the button combination start+select+L+R to access the libretro menu and change settings/save or load/etc.**\n\n**We know about most of the oddities like crackling sound for some emulators, rendering issues, and games unreliably auto launching to fullscreen. In general full CD games on the Xbox web browser do not seem to work due to their size if you have a chd/pbp less than 450 megs it will run. Edge on Xbox has some kind of undocumented ram limitation of about a gigabyte. Until all emulators are transitioned to libretro cores the oddities of using self hosted EmulatorJS will not be something that can or should be solved using hacky workarounds interacting with obfuscated code. Just keep in mind these are full blown machine emulators running in Javascript in a browser, do not expect bare metal performance.**\n\nMounting in existing rom directories can be achieved by pointing to the default folder structure, IE lets say you would like to mount your NES library:\n\n`-v /path/to/nes/roms:/data/nes/roms`\n\nThe folder names are:\n* 3do\n* arcade\n* atari2600\n* atari7800\n* colecovision\n* doom\n* gb\n* gba\n* gbc\n* jaguar\n* lynx\n* msx\n* n64\n* nds\n* nes\n* ngp\n* odyssey2\n* pce\n* psx\n* sega32x\n* segaCD\n* segaGG\n* segaMD\n* segaMS\n* segaSaturn\n* segaSG\n* snes\n* vb\n* vectrex\n* ws\n","changelogs":[{"date":"24.11.22:","desc":"Update IPFS links for chdman."},{"date":"04.04.22:","desc":"Ingest pre-built chdman bins during build time."},{"date":"23.02.22:","desc":"Update ingestion point for emulatorjs bins."},{"date":"25.01.22:","desc":"Allow users to mount in existing rom directories."},{"date":"14.01.22:","desc":"Add profile paths and rebase to Alpine 3.15."},{"date":"04.01.22:","desc":"Add headers needed for Threaded emulators."},{"date":"29.11.21:","desc":"Add wasm mime type to NGINX."},{"date":"26.11.21:","desc":"Configure IPFS in a lower power mode, use homebuilt blobs for emu cores."},{"date":"19.11.21:","desc":"Pin retroarch version."},{"date":"14.11.21:","desc":"Update default cores to ingest."},{"date":"23.10.21:","desc":"Initial release."}]}},"setup":"The Backend can be accessed at:\n\n* http://yourhost:3000/\n\nThe first thing you will need to do is click to download the default art/configs from this interface, this will setup a skeleton directory in your `/data` mount. From there add roms to the respective `roms` directories and follow the on screen instructions to add them to your web frontend running on port 80.\n\nThe frontend application has been initially optimized around being used with a standard gamepad (more specifically for modern Xbox consoles that have chromium based Edge browsers). The navigation revolves around the up/down/left/right keys to browse the menus and launch games.\nMobile browsers will function, just keep in mind compatibility will be reduced especially for CD based games.\n\n**It is important to note that some of the current emulators used for this frontend are obfuscated code, efforts are being made to [reverse engineer it](https://github.com/ethanaobrien/emulatorjs/) but you should know it can potentially reach out to third party services if you manually enable features like netplay (this should never happen in a stock setup). The point of this message is that on top of the de-obfuscation effort there is also effort to stop using binary blobs and shift to built from source libretro emscripten blobs, for now this web based emulation stack is the best for useability and compatibility. We are in the process to transitioning to libretro cores for emulators, currently 27/30 emulators have been replaced.**\n\n**For Xbox users please click the select button a couple times after launching a game to ensure the B button does not trigger a \"back\" action in the browser. (official name \"view button\" it is the two small squares) Exiting the controller mode and back to browser controls can be triggered by holding the start button for 3 seconds. (official name \"menu button\" the three lines) You will be unable to use features like save states and modify controller layouts on the emulatorjs based emulators currently as I have not determined a methodology of re-entering controller mode once you exit it. All normal game saves will function given you exit the game play screen cleanly using the B button for back this includes multi disc games for psx. Your game saves are stored in browser storage by hostname so if you make any changes to your local hosted setup (port or IP) the saves will not follow with it. For libretro based emulators you can use the button combination start+select+L+R to access the libretro menu and change settings/save or load/etc.**\n\n**We know about most of the oddities like crackling sound for some emulators, rendering issues, and games unreliably auto launching to fullscreen. In general full CD games on the Xbox web browser do not seem to work due to their size if you have a chd/pbp less than 450 megs it will run. Edge on Xbox has some kind of undocumented ram limitation of about a gigabyte. Until all emulators are transitioned to libretro cores the oddities of using self hosted EmulatorJS will not be something that can or should be solved using hacky workarounds interacting with obfuscated code. Just keep in mind these are full blown machine emulators running in Javascript in a browser, do not expect bare metal performance.**\n\nMounting in existing rom directories can be achieved by pointing to the default folder structure, IE lets say you would like to mount your NES library:\n\n`-v /path/to/nes/roms:/data/nes/roms`\n\nThe folder names are:\n* 3do\n* arcade\n* atari2600\n* atari7800\n* colecovision\n* doom\n* gb\n* gba\n* gbc\n* jaguar\n* lynx\n* msx\n* n64\n* nds\n* nes\n* ngp\n* odyssey2\n* pce\n* psx\n* sega32x\n* segaCD\n* segaGG\n* segaMD\n* segaMS\n* segaSaturn\n* segaSG\n* snes\n* vb\n* vectrex\n* ws\n"},{"id":"endlessh","name":"endlessh","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an SSH tarpit that very slowly sends an endless, random SSH banner. It keeps SSH clients locked up for hours or even days at a time. The purpose is to put your real SSH server on another port and then let the script kiddies get stuck in this tarpit instead of bothering a real server.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/openssh-server-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/endlessh"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-endlessh"}],"containers":[{"name":"endlessh","image":"linuxserver/endlessh","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"MSDELAY","default":"10000","description":"The endless banner is sent one line at a time. This is the delay in milliseconds between individual lines."},{"id":"MAXLINES","default":"32","description":"The length of each line is randomized. This controls the maximum length of each line. Shorter lines may keep clients on for longer if they give up after a certain number of bytes."},{"id":"MAXCLIENTS","default":"4096","description":"Maximum number of connections to accept at a time. Connections beyond this are not immediately rejected, but will wait in the queue."},{"id":"LOGFILE","default":"false","description":"By default, the app logs to container log. If this is set to `true`, the log will be output to file under `/config/logs/endlessh` (`/config` needs to be mapped)."},{"id":"BINDFAMILY","default":"","description":"By default, the app binds to IPv4 and IPv6 addresses. Set it to `4` or `6` to bind to IPv4 only or IPv6 only, respectively. Leave blank to bind to both."}],"ports":[{"container":"2222","description":"ssh port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"endlessh","project_url":"https://github.com/skeeto/endlessh","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/openssh-server-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an SSH tarpit that very slowly sends an endless, random SSH banner. It keeps SSH clients locked up for hours or even days at a time. The purpose is to put your real SSH server on another port and then let the script kiddies get stuck in this tarpit instead of bothering a real server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"22","internal_port":"2222","port_desc":"ssh port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MSDELAY","env_value":"10000","desc":"The endless banner is sent one line at a time. This is the delay in milliseconds between individual lines."},{"env_var":"MAXLINES","env_value":"32","desc":"The length of each line is randomized. This controls the maximum length of each line. Shorter lines may keep clients on for longer if they give up after a certain number of bytes."},{"env_var":"MAXCLIENTS","env_value":"4096","desc":"Maximum number of connections to accept at a time. Connections beyond this are not immediately rejected, but will wait in the queue."},{"env_var":"LOGFILE","env_value":"false","desc":"By default, the app logs to container log. If this is set to `true`, the log will be output to file under `/config/logs/endlessh` (`/config` needs to be mapped)."},{"env_var":"BINDFAMILY","env_value":"","desc":"By default, the app binds to IPv4 and IPv6 addresses. Set it to `4` or `6` to bind to IPv4 only or IPv6 only, respectively. Leave blank to bind to both."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Required if `LOGFILE` is set to `true`."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The app listens on the port mapped for ssh connections. To log to file, set the environment variable `LOGFILE` to `true` and map a volume for `/config`. The logs will be under `/config/logs/endlessh`.\n","changelogs":[{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"20.07.22:","desc":"Rebase to Alpine 3.16."},{"date":"16.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"07.10.21:","desc":"Fix typo on MAXLINES var."},{"date":"08.06.21:","desc":"Add BINDFAMILY option."},{"date":"16.04.21:","desc":"Initial Release."}]}},"setup":"The app listens on the port mapped for ssh connections. To log to file, set the environment variable `LOGFILE` to `true` and map a volume for `/config`. The logs will be under `/config/logs/endlessh`.\n"},{"id":"fail2ban","name":"fail2ban","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a daemon to ban hosts that cause multiple authentication errors.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/fail2ban-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/fail2ban"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-fail2ban"}],"containers":[{"name":"fail2ban","image":"linuxserver/fail2ban","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/remotelogs/airsonic:ro","description":"Optional path to airsonic log folder. Mounted as Read Only."},{"container":"/remotelogs/apache2:ro","description":"Optional path to apache2 log folder. Mounted as Read Only."},{"container":"/remotelogs/authelia:ro","description":"Optional path to authelia log folder. Mounted as Read Only."},{"container":"/remotelogs/emby:ro","description":"Optional path to emby log folder. Mounted as Read Only."},{"container":"/remotelogs/filebrowser:ro","description":"Optional path to filebrowser log folder. Mounted as Read Only."},{"container":"/remotelogs/homeassistant:ro","description":"Optional path to homeassistant log folder. Mounted as Read Only."},{"container":"/remotelogs/lighttpd:ro","description":"Optional path to lighttpd log folder. Mounted as Read Only."},{"container":"/remotelogs/nextcloud:ro","description":"Optional path to nextcloud log folder. Mounted as Read Only."},{"container":"/remotelogs/nginx:ro","description":"Optional path to nginx log folder. Mounted as Read Only."},{"container":"/remotelogs/nzbget:ro","description":"Optional path to nzbget log folder. Mounted as Read Only."},{"container":"/remotelogs/overseerr:ro","description":"Optional path to overseerr log folder. Mounted as Read Only."},{"container":"/remotelogs/prowlarr:ro","description":"Optional path to prowlarr log folder. Mounted as Read Only."},{"container":"/remotelogs/radarr:ro","description":"Optional path to radarr log folder. Mounted as Read Only."},{"container":"/remotelogs/sabnzbd:ro","description":"Optional path to sabnzbd log folder. Mounted as Read Only."},{"container":"/remotelogs/sonarr:ro","description":"Optional path to sonarr log folder. Mounted as Read Only."},{"container":"/remotelogs/unificontroller:ro","description":"Optional path to unificontroller log folder. Mounted as Read Only."},{"container":"/remotelogs/vaultwarden:ro","description":"Optional path to vaultwarden log folder. Mounted as Read Only."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/var/log:ro","description":"Host logs. Mounted as Read Only."}]}],"meta":{"readme-vars":{"project_name":"fail2ban","project_url":"http://www.fail2ban.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/fail2ban-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a daemon to ban hosts that cause multiple authentication errors.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."},{"vol_path":"/var/log:ro","vol_host_path":"/var/log","desc":"Host logs. Mounted as Read Only."}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"},{"cap_add_var":"NET_RAW"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/remotelogs/airsonic:ro","vol_host_path":"/path/to/airsonic/log","desc":"Optional path to airsonic log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/apache2:ro","vol_host_path":"/path/to/apache2/log","desc":"Optional path to apache2 log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/authelia:ro","vol_host_path":"/path/to/authelia/log","desc":"Optional path to authelia log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/emby:ro","vol_host_path":"/path/to/emby/log","desc":"Optional path to emby log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/filebrowser:ro","vol_host_path":"/path/to/filebrowser/log","desc":"Optional path to filebrowser log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/homeassistant:ro","vol_host_path":"/path/to/homeassistant/log","desc":"Optional path to homeassistant log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/lighttpd:ro","vol_host_path":"/path/to/lighttpd/log","desc":"Optional path to lighttpd log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nextcloud:ro","vol_host_path":"/path/to/nextcloud/log","desc":"Optional path to nextcloud log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nginx:ro","vol_host_path":"/path/to/nginx/log","desc":"Optional path to nginx log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nzbget:ro","vol_host_path":"/path/to/nzbget/log","desc":"Optional path to nzbget log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/overseerr:ro","vol_host_path":"/path/to/overseerr/log","desc":"Optional path to overseerr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/prowlarr:ro","vol_host_path":"/path/to/prowlarr/log","desc":"Optional path to prowlarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/radarr:ro","vol_host_path":"/path/to/radarr/log","desc":"Optional path to radarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/sabnzbd:ro","vol_host_path":"/path/to/sabnzbd/log","desc":"Optional path to sabnzbd log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/sonarr:ro","vol_host_path":"/path/to/sonarr/log","desc":"Optional path to sonarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/unificontroller:ro","vol_host_path":"/path/to/unificontroller/log","desc":"Optional path to unificontroller log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/vaultwarden:ro","vol_host_path":"/path/to/vaultwarden/log","desc":"Optional path to vaultwarden log folder. Mounted as Read Only."}],"app_setup_block_enabled":true,"app_setup_block":"This container is designed to allow fail2ban to function at the host level, as well as at the docker container level.\nIf you are running applications on the host, you will need to set the `chain` to `INPUT` in the jail for that application.\n\n### [Configuration Files](https://github.com/linuxserver/fail2ban-confs)\n\nOn first run, the container will create a number of folders and files in `/config`. The default configurations for fail2ban are all disabled by default.\n\nPlease refer to the [Configuration README](https://github.com/linuxserver/fail2ban-confs/blob/master/README.md), which can be viewed in our repository, or in your config folder at `/config/fail2ban/README.md`.\n\n### Remote Logs\n\nAll jails require the ability to read the application log files.\nWe recommend mounting each application's log folder as a volume to the container (illustrated by the optional volumes in our documentation).\nMounting individual log files can cause issues and is not recommended.\n\nThe `/remotelogs` path is designed to act as a parent for all log files you would like fail2ban to be able to use.\nEach log file should be mounted in a subfolder underneath `/remotelogs`, ex:\n- `/remotelogs/nginx/` would mount a folder containing the nginx logs to the container\n","changelogs":[{"date":"15.12.22:","desc":"Rebase to Alpine 3.17, Add ssmtp and whois packages. Symlink config to allow live reloading."},{"date":"25.08.22:","desc":"Update README to clarify remote log information."},{"date":"09.08.22:","desc":"Initial Release."}]}},"setup":"This container is designed to allow fail2ban to function at the host level, as well as at the docker container level.\nIf you are running applications on the host, you will need to set the `chain` to `INPUT` in the jail for that application.\n\n### [Configuration Files](https://github.com/linuxserver/fail2ban-confs)\n\nOn first run, the container will create a number of folders and files in `/config`. The default configurations for fail2ban are all disabled by default.\n\nPlease refer to the [Configuration README](https://github.com/linuxserver/fail2ban-confs/blob/master/README.md), which can be viewed in our repository, or in your config folder at `/config/fail2ban/README.md`.\n\n### Remote Logs\n\nAll jails require the ability to read the application log files.\nWe recommend mounting each application's log folder as a volume to the container (illustrated by the optional volumes in our documentation).\nMounting individual log files can cause issues and is not recommended.\n\nThe `/remotelogs` path is designed to act as a parent for all log files you would like fail2ban to be able to use.\nEach log file should be mounted in a subfolder underneath `/remotelogs`, ex:\n- `/remotelogs/nginx/` would mount a folder containing the nginx logs to the container\n"},{"id":"feed2toot","name":"feed2toot","description":"[{{ project_name|capitalize }}]({{ project_url }}) automatically parses rss feeds, identifies new posts and posts them on the Mastodon social network.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/feed2toot-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/feed2toot"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-feed2toot"}],"containers":[{"name":"feed2toot","image":"linuxserver/feed2toot","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"FEED_LIMIT","default":"5","description":"Limit number of RSS entries published at each execution."}],"volumes":[{"container":"/config","description":"Local path for feed2toot config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"feed2toot","project_url":"https://gitlab.com/chaica/feed2toot","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/feed2toot-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) automatically parses rss feeds, identifies new posts and posts them on the Mastodon social network.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local path for feed2toot config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"FEED_LIMIT","env_value":"5","desc":"Limit number of RSS entries published at each execution."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Run `docker run --rm -it -w /config -v /path/to/data:/config -e PUID=1000 -e PGID=1000 lscr.io/linuxserver/feed2toot /usr/bin/register_feed2toot_app` to generate credential files (be sure to set the correct volume path and PUID/PGID values).\n\nEdit the feed2toot.ini in /config to configure your instance name and RSS feeds.\n\nSee the [feed2toot docs](https://feed2toot.readthedocs.io/en/latest/) for more information.\n","changelogs":[{"date":"22.12.22:","desc":"Rebase to alpine 3.17."},{"date":"14.11.22:","desc":"Initial Release."}]}},"setup":"Run `docker run --rm -it -w /config -v /path/to/data:/config -e PUID=1000 -e PGID=1000 lscr.io/linuxserver/feed2toot /usr/bin/register_feed2toot_app` to generate credential files (be sure to set the correct volume path and PUID/PGID values).\n\nEdit the feed2toot.ini in /config to configure your instance name and RSS feeds.\n\nSee the [feed2toot docs](https://feed2toot.readthedocs.io/en/latest/) for more information.\n"},{"id":"ffmpeg","name":"ffmpeg","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/ffmpeg.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ffmpeg"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ffmpeg"}],"containers":[{"name":"ffmpeg","image":"linuxserver/ffmpeg","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"ffmpeg","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring :-\n\n * regular and timely application updates\n * easy user mappings (PGID, PUID)\n * custom base image with s6 overlay\n * weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n * regular security updates\n\nFind us at:\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [Podcast](https://anchor.fm/linuxserverio) - on hiatus. Coming back soon (late 2018).\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n[![Scarf.io pulls](https://scarf.sh/installs-badge/linuxserver-ci/linuxserver%2Fffmpeg?color=94398d&label-color=555555&logo-color=ffffff&style=for-the-badge&package-type=docker)](https://scarf.sh/gateway/linuxserver-ci/docker/linuxserver%2Fffmpeg)\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-ffmpeg)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-ffmpeg/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-ffmpeg/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/linuxserver.io/docker-ffmpeg/container_registry)\n[![Quay.io](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Quay.io)](https://quay.io/repository/linuxserver.io/ffmpeg)\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/ffmpeg)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/ffmpeg)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-ffmpeg%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-ffmpeg/job/master/)\n\n[FFmpeg](https://ffmpeg.org) - A complete, cross-platform solution to record, convert and stream audio and video.\n\n\n[![ffmpeg](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ffmpeg.png)](https://ffmpeg.org)\n\n## Supported Architectures\n\nWe utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `lscr.io/linuxserver/ffmpeg:latest` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Available | Tag |\n| :----: | :----: | ---- |\n| x86-64 |  | amd64-\\<version tag\\> |\n| arm64 |  | arm64v8-\\<version tag\\> |\n| armhf|  | arm32v7-\\<version tag\\> |\n\n## Usage\n\nUnlike most of our container library this image is meant to be run ephemerally from the command line parsing user input for a custom FFmpeg command. You will need to understand some Docker basics to use this image and be familiar with how to construct an FFmpeg command. In the commands below we will be bind mounting our current working directory from the CLI to /config, the assumption is that input.mkv is in your current working directory.\n\nIf an input file is detected we will run FFmpeg as that user/group so the output file will match it's permissions.\nThe image supports Hardware acceleration on x86 pay close attention to the variables for the examples below.\n\n### Basic Transcode\n\n```\ndocker run --rm -it \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -i /config/input.mkv \\\n  -c:v libx264 \\\n  -b:v 4M \\\n  -vf scale=1280:720 \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n### Hardware accelerated (VAAPI)\n\n```\ndocker run --rm -it \\\n  --device=/dev/dri:/dev/dri \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -vaapi_device /dev/dri/renderD128 \\\n  -i /config/input.mkv \\\n  -c:v h264_vaapi \\\n  -b:v 4M \\\n  -vf 'format=nv12|vaapi,hwupload,scale_vaapi=w=1280:h=720' \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n### Nvidia Hardware accelerated\n\n```\ndocker run --rm -it \\\n  --runtime=nvidia \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -hwaccel nvdec \\\n  -i /config/input.mkv \\\n  -c:v h264_nvenc \\\n  -b:v 4M \\\n  -vf scale=1280:720 \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n```\ngit clone https://github.com/linuxserver/docker-ffmpeg.git\ncd docker-ffmpeg\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t linuxserver/ffmpeg:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n```\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **14.12.22:** - Rebase to Jammy, bump to 5.1.2.\n* **19.06.22:** - Rebase to Focal.\n* **26.08.21:** - Add support for libOpenCL.\n* **01.07.21:** - Bump to 4.4.\n* **17.06.20:** - Bump to 4.3.\n* **16.06.20:** - Add support for libvmaf.\n* **01.08.19:** - Initial release.\n{%- endraw %}\n"}}},{"id":"filezilla","name":"filezilla","description":"[FIleZilla]({{ project_url }}) Client is a fast and reliable cross-platform FTP, FTPS and SFTP client with lots of useful features and an intuitive graphical user interface.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/filezilla-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/filezilla"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-filezilla"}],"containers":[{"name":"filezilla","image":"linuxserver/filezilla","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"FileZilla desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"filezilla","project_url":"https://filezilla-project.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/filezilla-logo.png","project_blurb":"[FIleZilla]({{ project_url }}) Client is a fast and reliable cross-platform FTP, FTPS and SFTP client with lots of useful features and an intuitive graphical user interface.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"FileZilla desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"18.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"firefox","name":"firefox","description":"[Firefox]({{ project_url }}) Browser, also known as Mozilla Firefox or simply Firefox, is a free and open-source web browser developed by the Mozilla Foundation and its subsidiary, the Mozilla Corporation. Firefox uses the Gecko layout engine to render web pages, which implements current and anticipated web standards.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/firefox-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/firefox"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-firefox"}],"containers":[{"name":"firefox","image":"linuxserver/firefox","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Firefox desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"firefox","project_url":"https://www.mozilla.org/en-US/firefox/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/firefox-logo.png","project_blurb":"[Firefox]({{ project_url }}) Browser, also known as Mozilla Firefox or simply Firefox, is a free and open-source web browser developed by the Mozilla Foundation and its subsidiary, the Mozilla Corporation. Firefox uses the Gecko layout engine to render web pages, which implements current and anticipated web standards.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Firefox desktop gui."}],"custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"This is needed for any modern website to function like youtube."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15, stop using ESR."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"19.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"fleet","name":"fleet","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides an online web interface which displays a set of maintained images from one or more owned repositories.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/fleet.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/fleet"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-fleet"}],"containers":[{"name":"fleet","image":"linuxserver/fleet","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"fleet_admin_authentication_type","default":"DATABASE","description":"A switch to define how Fleet manages user logins. If set to DATABASE, see the related optional params. Can be set to either DATABASE or PROPERTIES."},{"id":"fleet_database_url","default":"jdbc:mariadb://<url>:3306/fleet","description":"The full JDBC connection string to the Fleet database"},{"id":"fleet_database_username","default":"fleet_user","description":"The username with the relevant GRANT permissions for the database"},{"id":"fleet_database_password","default":"dbuserpassword","description":"The database user's password."},{"id":"fleet_admin_secret","default":"randomstring","description":"A string used as part of the password key derivation process."}],"volumes":[{"container":"/config","description":"The primary config file and rolling log files.","key":"config"}],"ports":[{"container":"8080","description":"Http port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"fleet","project_url":"https://github.com/linuxserver/fleet","project_logo":"","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides an online web interface which displays a set of maintained images from one or more owned repositories.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"fleet_admin_authentication_type","env_value":"DATABASE","desc":"A switch to define how Fleet manages user logins. If set to DATABASE, see the related optional params. Can be set to either DATABASE or PROPERTIES."},{"env_var":"fleet_database_url","env_value":"jdbc:mariadb://<url>:3306/fleet","desc":"The full JDBC connection string to the Fleet database"},{"env_var":"fleet_database_username","env_value":"fleet_user","desc":"The username with the relevant GRANT permissions for the database"},{"env_var":"fleet_database_password","env_value":"dbuserpassword","desc":"The database user's password."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"The primary config file and rolling log files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Http port"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"fleet_admin_secret","env_value":"randomstring","desc":"A string used as part of the password key derivation process."}],"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Navigate to `http://your_ip_here:8080` to display the home page. If `DATABASE` is selected as the preferred authentication process, ensure that you set up an\ninitial user via `http://your_ip_here:8080/setup`. Once done, that page will no longer be available. A restart is preferable as it will remove the page altogether.\nOnce complete, you can log into the app via `http://your_ip_here:8080/login` to manage your repositories.\n","changelogs":[{"date":"02.05.22:","desc":"Rebase to Alpine 3.15."},{"date":"13.12.21:","desc":"Add mitigations for CVE-2021-44228"},{"date":"26.04.20:","desc":"Updated to keep in line with v2.0.0 branch of Fleet"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"02.07.19:","desc":"Rebasing to alpine 3.10."},{"date":"02.07.19:","desc":"Stop container if fleet fails."},{"date":"19.05.19:","desc":"Use new base images for arm versions."},{"date":"01.04.19:","desc":"Initial Release"}]}},"setup":"Navigate to `http://your_ip_here:8080` to display the home page. If `DATABASE` is selected as the preferred authentication process, ensure that you set up an\ninitial user via `http://your_ip_here:8080/setup`. Once done, that page will no longer be available. A restart is preferable as it will remove the page altogether.\nOnce complete, you can log into the app via `http://your_ip_here:8080/login` to manage your repositories.\n"},{"id":"foldingathome","name":"foldingathome","description":"[Folding@home]({{ project_url }}) is a distributed computing project for simulating protein dynamics, including the process of protein folding and the movements of proteins implicated in a variety of diseases. It brings together citizen scientists who volunteer to run simulations of protein dynamics on their personal computers. Insights from this data are helping scientists to better understand biology, and providing new opportunities for developing therapeutics.","icon":"https://foldingathome.org/wp-content/uploads/2016/09/folding-at-home-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/foldingathome"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-foldingathome"}],"containers":[{"name":"foldingathome","image":"linuxserver/foldingathome","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Folding@home should store its database and config.","key":"config"}],"ports":[{"container":"7396","description":"Folding@home web gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"foldingathome","project_url":"https://foldingathome.org/","project_logo":"https://foldingathome.org/wp-content/uploads/2016/09/folding-at-home-logo.png","project_blurb":"[Folding@home]({{ project_url }}) is a distributed computing project for simulating protein dynamics, including the process of protein folding and the movements of proteins implicated in a variety of diseases. It brings together citizen scientists who volunteer to run simulations of protein dynamics on their personal computers. Insights from this data are helping scientists to better understand biology, and providing new opportunities for developing therapeutics.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where Folding@home should store its database and config."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"7396","internal_port":"7396","port_desc":"Folding@home web gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"36330","internal_port":"36330","port_desc":"Optional port for connecting remotely via FAHControl app (no password)."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU (vaapi)."}],"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"This image sets up the Folding@home client. The interface is available at `http://your-ip:7396`.\n\nThe built-in webserver provides very basic control (ie. GPUs are only active when set to `Medium` or higher). For more fine grained control of individual devices, you can use the FAHControl app on a different device and connect remotely via port `36330` (no password).\n\nThere are a couple of minor issues with the webgui:\n- If you get an \"ERR_EMPTY_RESPONSE\" error when trying to access via IP, it's most likely due to a clash of cookies/cache. Try opening in an incgnito window.\n- If you're getting a constant refresh of the window but no display of info, try a force refresh via `shft-F5` or `ctrl-F5`.\n\n## GPU Hardware Acceleration\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the foldingathome docker container.\n","changelogs":[{"date":"14.12.22:","desc":"Rebase to Ubuntu Jammy, migrate to s6v3."},{"date":"15.01.22:","desc":"Rebase to Ubuntu Focal. Add arm64v8 builds (cpu only). Increase verbosity about gpu driver permission settings."},{"date":"09.01.21:","desc":"Add nvidia.icd."},{"date":"14.04.20:","desc":"Add Folding@home donation links."},{"date":"20.03.20:","desc":"Initial release."}]}},"setup":"This image sets up the Folding@home client. The interface is available at `http://your-ip:7396`.\n\nThe built-in webserver provides very basic control (ie. GPUs are only active when set to `Medium` or higher). For more fine grained control of individual devices, you can use the FAHControl app on a different device and connect remotely via port `36330` (no password).\n\nThere are a couple of minor issues with the webgui:\n- If you get an \"ERR_EMPTY_RESPONSE\" error when trying to access via IP, it's most likely due to a clash of cookies/cache. Try opening in an incgnito window.\n- If you're getting a constant refresh of the window but no display of info, try a force refresh via `shft-F5` or `ctrl-F5`.\n\n## GPU Hardware Acceleration\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the foldingathome docker container.\n"},{"id":"freshrss","name":"freshrss","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, self-hostable aggregator for rss feeds.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/freshrss-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/freshrss"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-freshrss"}],"containers":[{"name":"freshrss","image":"linuxserver/freshrss","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Local storage for freshrss site files.","key":"config"}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"freshrss","project_url":"https://freshrss.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/freshrss-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, self-hostable aggregator for rss feeds.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local storage for freshrss site files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui set up wizard at `http://serverIP:port`\n\nFor external databases, create a user and database in your mysql/mariadb server (not root) and then follow the setup wizard in the webui. Use the IP address for \"host\" of your database server.  \n\nAdditional extensions can be dropped into `/config/www/freshrss/extensions` and will be active after container restart.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"21.10.22:","desc":"Fix cron init to properly migrate existing installations to new app location."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"31.03.20:","desc":"Internalize app and enable updates for existing users, allow user customized crontab."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Add multi arch and pipeline logic."},{"date":"05.09.18:","desc":"Rebase to alpine linux 3.8."},{"date":"17.03.18:","desc":"Update nginx config to resolve api not working."},{"date":"08.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"23.02.17:","desc":"Rebase to alpine linux 3.5 and nginx."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"08.10.16:","desc":"Add Sqlite support for standalone operation."},{"date":"27.09.16:","desc":"Fix for cron job."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"23.11.15:","desc":"Update dependencies to latest requirements."},{"date":"21.08.15:","desc":"Initial Release."}]}},"setup":"Access the webui set up wizard at `http://serverIP:port`\n\nFor external databases, create a user and database in your mysql/mariadb server (not root) and then follow the setup wizard in the webui. Use the IP address for \"host\" of your database server.  \n\nAdditional extensions can be dropped into `/config/www/freshrss/extensions` and will be active after container restart.\n"},{"id":"grav","name":"grav","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Fast, Simple, and Flexible, file-based Web-platform.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/grav-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/grav"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-grav"}],"containers":[{"name":"grav","image":"linuxserver/grav","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"grav","project_url":"https://github.com/getgrav/grav/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/grav-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Fast, Simple, and Flexible, file-based Web-platform.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"For more information check out the [Grav documentation](https://learn.getgrav.org/). Our image includes the [grav-admin](https://github.com/getgrav/grav-plugin-admin) plugin.\n\nTo use the CLI tools you need to pass the working directory as part of your exec command (or use an interactive shell), e.g. `docker exec -it -w /app/www/public grav bin/gpm`\n","changelogs":[{"date":"11.12.22:","desc":"Rebase to Alpine 3.17, PHP 8.1."},{"date":"05.09.22:","desc":"All php to read envs passed to container."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"03.09.21:","desc":"Added support for Redis caching."},{"date":"01.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"09.04.21:","desc":"Initial Release."}]}},"setup":"For more information check out the [Grav documentation](https://learn.getgrav.org/). Our image includes the [grav-admin](https://github.com/getgrav/grav-plugin-admin) plugin.\n\nTo use the CLI tools you need to pass the working directory as part of your exec command (or use an interactive shell), e.g. `docker exec -it -w /app/www/public grav bin/gpm`\n"},{"id":"grocy","name":"grocy","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an ERP system for your kitchen! Cut down on food waste, and manage your chores with this brilliant utility.\n\nKeep track of your purchases, how much food you are wasting, what chores need doing and what batteries need charging with this proudly Open Source tool\n\nFor more information on grocy visit their website and check it out: https://grocy.info\n","icon":"https://grocy.info/img/grocy_logo.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/grocy"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-grocy"}],"containers":[{"name":"grocy","image":"linuxserver/grocy","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"for specifying your timezone"}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"}],"ports":[{"container":"80","description":"will map the container's port 80 to port 9283 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"grocy","project_url":"https://github.com/grocy/grocy","project_logo":"https://grocy.info/img/grocy_logo.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an ERP system for your kitchen! Cut down on food waste, and manage your chores with this brilliant utility.\n\nKeep track of your purchases, how much food you are wasting, what chores need doing and what batteries need charging with this proudly Open Source tool\n\nFor more information on grocy visit their website and check it out: https://grocy.info\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"for specifying your timezone"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9283","internal_port":"80","port_desc":"will map the container's port 80 to port 9283 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Grocy is simple to get running. Configure the container with instructions below, start it, and you can then access it\nby visiting http://your.ip:9283 - once the page loads, you can log in with the default username and password of admin / admin\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.08.21:","desc":"Rebase to Alpine 3.14 and PHP 8."},{"date":"25.07.21:","desc":"Add 'int','json' and 'zlib' PHP extensions."},{"date":"10.05.21:","desc":"Reduce image size."},{"date":"08.04.21:","desc":"Update docs to reflect jenkins builder changes."},{"date":"17.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.01.21:","desc":"Add 'ldap' PHP extension."},{"date":"22.12.20:","desc":"Add 'ctype' PHP extension."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"22.09.19:","desc":"Add 'gd' PHP extension."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"27.12.18:","desc":"Initial Release."}]}},"setup":"Grocy is simple to get running. Configure the container with instructions below, start it, and you can then access it\nby visiting http://your.ip:9283 - once the page loads, you can log in with the default username and password of admin / admin\n"},{"id":"guacd","name":"guacd","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. This container is only the backend server component needed to use The official or 3rd party HTML5 frontends.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/guacd.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/guacd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-guacd"}],"containers":[{"name":"guacd","image":"linuxserver/guacd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"ports":[{"container":"4822","description":"Port Guacamole server listens on","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"guacd","project_url":"https://guacamole.apache.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/guacd.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. This container is only the backend server component needed to use The official or 3rd party HTML5 frontends.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","common_param_env_vars_enabled":false,"param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"4822","internal_port":"4822","port_desc":"Port Guacamole server listens on"}],"param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"This is a backend only service, to leverage Guacd server you need to use either the official Java frontend [guacamole-client](https://github.com/apache/guacamole-client) or an open source alternative like [guacamole-lite](https://github.com/vadimpronin/guacamole-lite). \n","changelogs":[{"date":"11.03.22:","desc":"Bump to 1.4.0."},{"date":"15.05.21:","desc":"Add terminus font for SSH support."},{"date":"08.05.21:","desc":"Bump to 1.3.0, rebase to Alpine."},{"date":"27.07.20:","desc":"Bump to 1.2.0."},{"date":"17.04.20:","desc":"Bump back 1.1.0, rebase to focal"},{"date":"08.02.20:","desc":"Bump to 1.1.0."},{"date":"25.05.19:","desc":"Initial Release."}]}},"setup":"This is a backend only service, to leverage Guacd server you need to use either the official Java frontend [guacamole-client](https://github.com/apache/guacamole-client) or an open source alternative like [guacamole-lite](https://github.com/vadimpronin/guacamole-lite). \n"},{"id":"habridge","name":"habridge","description":"[{{ project_name|capitalize }}]({{ project_url }}) emulates Philips Hue API to other home automation gateways such as an Amazon Echo/Dot Gen 1 (gen 2 has issues discovering ha-bridge) or other systems that support Philips Hue. The Bridge handles basic commands such as \"On\", \"Off\" and \"brightness\" commands of the hue protocol. This bridge can control most devices that have a distinct API.\n\nIn the cases of systems that require authorization and/or have APIs that cannot be handled in the current method, a module may need to be built. The Harmony Hub is such a module and so is the Nest module. The Bridge has helpers to build devices for the gateway for the Logitech Harmony Hub, Vera, Vera Lite or Vera Edge, Nest, Somfy Tahoma, Home Assistant, Domoticz, MQTT, HAL, Fibaro, HomeWizard, LIFX, OpenHAB, FHEM, Broadlink and the ability to proxy all of your real Hue bridges behind this bridge.\n\nThis bridge was built to help put the Internet of Things together.\n\nFor more information about how to use this software have a look at their Wiki [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","icon":"https://raw.githubusercontent.com/bwssytems/ha-bridge/master/src/main/resources/public/img/favicon.ico","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/habridge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-habridge"}],"containers":[{"name":"habridge","image":"linuxserver/habridge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"SEC_KEY","default":"<Your Key To Encrypt Security Data>","description":"Key used to secure communication."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where HABridge stores config files and data.","key":"config"}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"50000","description":"HABridge communication port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"habridge","project_url":"http://bwssystems.com/#/habridge","project_logo":"https://raw.githubusercontent.com/bwssytems/ha-bridge/master/src/main/resources/public/img/favicon.ico","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) emulates Philips Hue API to other home automation gateways such as an Amazon Echo/Dot Gen 1 (gen 2 has issues discovering ha-bridge) or other systems that support Philips Hue. The Bridge handles basic commands such as \"On\", \"Off\" and \"brightness\" commands of the hue protocol. This bridge can control most devices that have a distinct API.\n\nIn the cases of systems that require authorization and/or have APIs that cannot be handled in the current method, a module may need to be built. The Harmony Hub is such a module and so is the Nest module. The Bridge has helpers to build devices for the gateway for the Logitech Harmony Hub, Vera, Vera Lite or Vera Edge, Nest, Somfy Tahoma, Home Assistant, Domoticz, MQTT, HAL, Fibaro, HomeWizard, LIFX, OpenHAB, FHEM, Broadlink and the ability to proxy all of your real Hue bridges behind this bridge.\n\nThis bridge was built to help put the Internet of Things together.\n\nFor more information about how to use this software have a look at their Wiki [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"SEC_KEY","env_value":"<Your Key To Encrypt Security Data>","desc":"Key used to secure communication."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where HABridge stores config files and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"50000","internal_port":"50000","port_desc":"HABridge communication port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"To set up the ha-bridge simply go to http://localhost:8080. Once you are in the webui you can add devices and configure ha-bridge to your liking.\n\nFor information on how to configure ha-bridge, go to their wiki at [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","changelogs":[{"date":"11.12.22:","desc":"Rebasing to alpine 3.17."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"28.08.18:","desc":"Rebase to alpine 3.8."},{"date":"12.04.18:","desc":"Add workaround to bind to port 80 if needed."},{"date":"08.04.18:","desc":"Initial Release."}]}},"setup":"To set up the ha-bridge simply go to http://localhost:8080. Once you are in the webui you can add devices and configure ha-bridge to your liking.\n\nFor information on how to configure ha-bridge, go to their wiki at [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n"},{"id":"headphones","name":"headphones","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated music downloader for NZB and Torrent, written in Python. It supports SABnzbd, NZBget, Transmission, Torrent and Blackhole.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/headphones-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/headphones"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-headphones"}],"containers":[{"name":"headphones","image":"linuxserver/headphones","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"VERSION","default":"latest","description":"Supported values are LATEST, PLEXPASS or a specific version number."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/downloads","description":"ISOs."},{"container":"/music","description":"Your music directory."}],"ports":[{"container":"8181","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"headphones","project_url":"https://github.com/rembo10/headphones","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/headphones-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated music downloader for NZB and Torrent, written in Python. It supports SABnzbd, NZBget, Transmission, Torrent and Blackhole.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/downloads","vol_host_path":"</path/to/downloads>","desc":"ISOs."},{"vol_path":"/music","vol_host_path":"</path/to/music>","desc":"Your music directory."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8181","internal_port":"8181","port_desc":"Application WebUI"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":false,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"VERSION","env_value":"latest","desc":"Supported values are LATEST, PLEXPASS or a specific version number."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."}],"opt_param_usage_include_ports":false,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":["```","include optional stuff","```"],"app_setup_block_enabled":false,"app_setup_block":"","changelogs":[{"date":"02.02.22:","desc":"Rebasing to alpine 3.15. Updating to Python 3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"09.05.19:","desc":"Add default UTC timezone if user does not set it."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.08.18:","desc":"Rebase to alpine 3.8."},{"date":"03.04.18:","desc":"Remove forced port and update README."},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Add flac package to handle FLAC based .cue."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.05.17:","desc":"Reduce layer, replace broken source for shntool."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"23.12.16:","desc":"Fix capitalisation in README."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README, compile shntool."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"18.07.15:","desc":"Inital Release"}]}}},{"id":"healthchecks","name":"healthchecks","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.\n","icon":"https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/welcome.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/healthchecks"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-healthchecks"}],"containers":[{"name":"healthchecks","image":"linuxserver/healthchecks","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"SITE_ROOT","default":"","description":"The site's top-level URL and the port it listens to if differrent than 80 or 443 (e.g., https://healthchecks.example.com:8000)"},{"id":"SITE_NAME","default":"","description":"The site's name (e.g., \"Example Corp HealthChecks\")"},{"id":"DEFAULT_FROM_EMAIL","default":"","description":"From email for alerts"},{"id":"EMAIL_HOST","default":"","description":"SMTP host"},{"id":"EMAIL_PORT","default":"","description":"SMTP port"},{"id":"EMAIL_HOST_USER","default":"","description":"SMTP user"},{"id":"EMAIL_HOST_PASSWORD","default":"","description":"SMTP password"},{"id":"EMAIL_USE_TLS","default":"","description":"Use TLS for SMTP (`True` or `False`)"},{"id":"SUPERUSER_EMAIL","default":"","description":"Superuser email"},{"id":"SUPERUSER_PASSWORD","default":"","description":"Superuser password"},{"id":"REGENERATE_SETTINGS","default":"","description":"Defaults to False. Set to True to always override the `local_settings.py` file with values from environment variables. Do not set to True if you have made manual modifications to this file."},{"id":"ALLOWED_HOSTS","default":"","description":"Array of valid hostnames for the server `[\"test.com\",\"test2.com\"]` (default: `[\"*\"]`)"},{"id":"APPRISE_ENABLED","default":"","description":"Defaults to False. A boolean that turns on/off the Apprise integration (https://github.com/caronc/apprise)"},{"id":"DEBUG","default":"","description":"Defaults to True. Debug mode relaxes CSRF protections and increases logging verbosity but should be disabled for production instances as it will impact performance and security."},{"id":"INTEGRATIONS_ALLOW_PRIVATE_IPS","default":"","description":"Defaults to False. Set to True to allow integrations to connect to private IP addresses."},{"id":"PING_EMAIL_DOMAIN","default":"","description":"The domain to use for generating ping email addresses."},{"id":"SECRET_KEY","default":"","description":"A secret key used for cryptographic signing. Will generate a secure value if one is not supplied"},{"id":"SITE_LOGO_URL","default":"","description":"Full URL to custom site logo"}],"volumes":[{"container":"/config","description":"Database and healthchecks config directory","key":"config"}],"ports":[{"container":"8000","description":"Healthchecks Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"healthchecks","project_url":"https://github.com/healthchecks/healthchecks","project_logo":"https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/welcome.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and healthchecks config directory"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"SITE_ROOT","env_value":"","desc":"The site's top-level URL and the port it listens to if differrent than 80 or 443 (e.g., https://healthchecks.example.com:8000)"},{"env_var":"SITE_NAME","env_value":"","desc":"The site's name (e.g., \"Example Corp HealthChecks\")"},{"env_var":"DEFAULT_FROM_EMAIL","env_value":"","desc":"From email for alerts"},{"env_var":"EMAIL_HOST","env_value":"","desc":"SMTP host"},{"env_var":"EMAIL_PORT","env_value":"","desc":"SMTP port"},{"env_var":"EMAIL_HOST_USER","env_value":"","desc":"SMTP user"},{"env_var":"EMAIL_HOST_PASSWORD","env_value":"","desc":"SMTP password"},{"env_var":"EMAIL_USE_TLS","env_value":"","desc":"Use TLS for SMTP (`True` or `False`)"},{"env_var":"SUPERUSER_EMAIL","env_value":"","desc":"Superuser email"},{"env_var":"SUPERUSER_PASSWORD","env_value":"","desc":"Superuser password"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"REGENERATE_SETTINGS","env_value":"","desc":"Defaults to False. Set to True to always override the `local_settings.py` file with values from environment variables. Do not set to True if you have made manual modifications to this file."},{"env_var":"ALLOWED_HOSTS","env_value":"","desc":"Array of valid hostnames for the server `[\"test.com\",\"test2.com\"]` (default: `[\"*\"]`)"},{"env_var":"APPRISE_ENABLED","env_value":"","desc":"Defaults to False. A boolean that turns on/off the Apprise integration (https://github.com/caronc/apprise)"},{"env_var":"DEBUG","env_value":"","desc":"Defaults to True. Debug mode relaxes CSRF protections and increases logging verbosity but should be disabled for production instances as it will impact performance and security."},{"env_var":"INTEGRATIONS_ALLOW_PRIVATE_IPS","env_value":"","desc":"Defaults to False. Set to True to allow integrations to connect to private IP addresses."},{"env_var":"PING_EMAIL_DOMAIN","env_value":"","desc":"The domain to use for generating ping email addresses."},{"env_var":"SECRET_KEY","env_value":"","desc":"A secret key used for cryptographic signing. Will generate a secure value if one is not supplied"},{"env_var":"SITE_LOGO_URL","env_value":"","desc":"Full URL to custom site logo"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Healthchecks Web UI"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"2525","internal_port":"2525","port_desc":"Port for inbound SMTP pings"}],"app_setup_block_enabled":true,"app_setup_block":"Access the WebUI at <your-ip>:8000. For more information, check out [Healthchecks](https://github.com/healthchecks/healthchecks).\n","changelogs":[{"date":"22.12.22:","desc":"Rebase to Alpine 3.17. Add extra deps for pycurl. Add INTEGRATIONS_ALLOW_PRIVATE_IPS."},{"date":"18.10.22:","desc":"Add curl-dev to fix broken pip builds."},{"date":"11.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"27.09.22:","desc":"Fix sending of Email Reports"},{"date":"08.01.22:","desc":"Fix CSRF setting for Django 4.0 (introduced in v1.25.0)"},{"date":"11.11.21:","desc":"Add Apprise to Docker as in v1.24.0"},{"date":"10.09.21:","desc":"Fix creation of superuser"},{"date":"07.08.21:","desc":"Update custom logo handling to support changes in v1.22.0"},{"date":"11.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"18.05.21:","desc":"Add linuxserver wheel index."},{"date":"11.01.21:","desc":"Add libffi-dev to allow building of python cryptography lib."},{"date":"19.07.20:","desc":"Rebasing to alpine 3.12, fixed 'ALLOWED_HOSTS' bug, now defaults to wildcard"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"31.10.19:","desc":"Add postgres client and fix config for CSRF."},{"date":"23.10.19:","desc":"Allow to create superuser"},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.02.19:","desc":"Adding mysql libs needed for using a database."},{"date":"11.10.18:","desc":"adding pipeline logic and multi arching release"},{"date":"15.11.17:","desc":"`git pull` is now in Dockerfile so each tagged container contains the same code version"},{"date":"17.10.17:","desc":"Fixed `local_settings.py` output"},{"date":"27.09.17:","desc":"Initial Release."}]}},"setup":"Access the WebUI at <your-ip>:8000. For more information, check out [Healthchecks](https://github.com/healthchecks/healthchecks).\n"},{"id":"hedgedoc","name":"hedgedoc","description":"[HedgeDoc]({{ project_url }}) gives you access to all your files wherever you are.\n\nHedgeDoc is a real-time, multi-platform collaborative markdown note editor.  This means that you can write notes with other people on your desktop, tablet or even on the phone.  You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hedgedoc-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/hedgedoc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-hedgedoc"}],"containers":[{"name":"hedgedoc","image":"linuxserver/hedgedoc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"DB_HOST","default":"<hostname or ip>","description":"Host address of mysql database"},{"id":"DB_PORT","default":"3306","description":"Port to access mysql database default is 3306"},{"id":"DB_USER","default":"hedgedoc","description":"Database user"},{"id":"DB_PASS","default":"<secret password>","description":"Database password"},{"id":"DB_NAME","default":"hedgedoc","description":"Database name"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CMD_DOMAIN","default":"localhost","description":"The address the gui will be accessed at (ie. `192.168.1.1` or `hedgedoc.domain.com`)."},{"id":"CMD_URL_ADDPORT","default":"false","description":"Set to `true` if using a port other than `80` or `443`."},{"id":"CMD_PROTOCOL_USESSL","default":"false","description":"Set to `true` if accessing over https via reverse proxy."},{"id":"CMD_PORT","default":"3000","description":"If you wish to access hedgedoc at a port different than 80, 443 or 3000, you need to set this to that port (ie. `CMD_PORT=5000`) and change the port mapping accordingly (5000:5000)."},{"id":"CMD_ALLOW_ORIGIN","default":"['localhost']","description":"Comma-separated list of allowed hostnames"}],"volumes":[{"container":"/config","description":"HedgeDoc config and configurable files","key":"config"}],"ports":[{"container":"3000","description":"Web gui port (internal port also needs to be changed if accessing at port other than 80, 443 and 3000).","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"hedgedoc","project_url":"https://hedgedoc.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hedgedoc-banner.png","project_blurb":"[HedgeDoc]({{ project_url }}) gives you access to all your files wherever you are.\n\nHedgeDoc is a real-time, multi-platform collaborative markdown note editor.  This means that you can write notes with other people on your desktop, tablet or even on the phone.  You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"DB_HOST","env_value":"<hostname or ip>","desc":"Host address of mysql database"},{"env_var":"DB_PORT","env_value":"3306","desc":"Port to access mysql database default is 3306"},{"env_var":"DB_USER","env_value":"hedgedoc","desc":"Database user"},{"env_var":"DB_PASS","env_value":"<secret password>","desc":"Database password"},{"env_var":"DB_NAME","env_value":"hedgedoc","desc":"Database name"},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"CMD_DOMAIN","env_value":"localhost","desc":"The address the gui will be accessed at (ie. `192.168.1.1` or `hedgedoc.domain.com`)."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CMD_URL_ADDPORT","env_value":"false","desc":"Set to `true` if using a port other than `80` or `443`."},{"env_var":"CMD_PROTOCOL_USESSL","env_value":"false","desc":"Set to `true` if accessing over https via reverse proxy."},{"env_var":"CMD_PORT","env_value":"3000","desc":"If you wish to access hedgedoc at a port different than 80, 443 or 3000, you need to set this to that port (ie. `CMD_PORT=5000`) and change the port mapping accordingly (5000:5000)."},{"env_var":"CMD_ALLOW_ORIGIN","env_value":"['localhost']","desc":"Comma-separated list of allowed hostnames"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"HedgeDoc config and configurable files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web gui port (internal port also needs to be changed if accessing at port other than 80, 443 and 3000)."}],"app_setup_block_enabled":true,"app_setup_block":"HedgeDoc web interface can be accessed `http://${IP}:3000/`, if you want to use a custom domain or anything besides port 3000 you will need to leverage their env settings for callbacks: (specifically for CMD_DOMAIN, CMD_PORT and CMD_URL_ADDPORT)\n\n[Full list of HedgeDoc options](https://docs.hedgedoc.org/configuration/)\n\nFor convience we provide a working example using Mysql as a backend in this document, if you do not wish to use our custom environment values or a Mysql database backend feel free to leverage any of the settings laid out in the link above.\n\nTo run behind a reverse proxy we have a [preconfigured config](https://github.com/linuxserver/reverse-proxy-confs/blob/master/hedgedoc.subdomain.conf.sample) using docker networking included in our [SWAG](https://github.com/linuxserver/docker-swag) image and you can read how to use this in the [Reverse Proxy Confs repository](https://github.com/linuxserver/reverse-proxy-confs/#how-to-use-these-reverse-proxy-configs)\n","changelogs":[{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"10.04.22:","desc":"Use python3 to build node sqlite3."},{"date":"10.02.22:","desc":"Rebase to Alpine 3.15."},{"date":"09.02.22:","desc":"Add optional var `CMD_PORT` that is needed for accessing at port other than 80, 443 and 3000."},{"date":"09.12.21:","desc":"Add optional var `CMD_PROTOCOL_USESSL` that is needed for reverse proxy."},{"date":"07.12.21:","desc":"Rebase to ubuntu focal. Update to node 16. Make sure uploads are persistent."},{"date":"15.10.21:","desc":"Add required env var `CMD_DOMAIN`."},{"date":"05.05.21:","desc":"Remove symlinking some folders from config to /opt/hedgedoc/public."},{"date":"03.05.21:","desc":"Remove deprecated sequalizerc step."},{"date":"22.12.20:","desc":"Initial release"}]}},"setup":"HedgeDoc web interface can be accessed `http://${IP}:3000/`, if you want to use a custom domain or anything besides port 3000 you will need to leverage their env settings for callbacks: (specifically for CMD_DOMAIN, CMD_PORT and CMD_URL_ADDPORT)\n\n[Full list of HedgeDoc options](https://docs.hedgedoc.org/configuration/)\n\nFor convience we provide a working example using Mysql as a backend in this document, if you do not wish to use our custom environment values or a Mysql database backend feel free to leverage any of the settings laid out in the link above.\n\nTo run behind a reverse proxy we have a [preconfigured config](https://github.com/linuxserver/reverse-proxy-confs/blob/master/hedgedoc.subdomain.conf.sample) using docker networking included in our [SWAG](https://github.com/linuxserver/docker-swag) image and you can read how to use this in the [Reverse Proxy Confs repository](https://github.com/linuxserver/reverse-proxy-confs/#how-to-use-these-reverse-proxy-configs)\n"},{"id":"heimdall","name":"heimdall","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to organise all those links to your most used web sites and web applications in a simple way.\n\nSimplicity is the key to Heimdall.\n\nWhy not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/heimdall-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/heimdall"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-heimdall"}],"containers":[{"name":"heimdall","image":"linuxserver/heimdall","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"heimdall","project_url":"https://heimdall.site","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/heimdall-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to organise all those links to your most used web sites and web applications in a simple way.\n\nSimplicity is the key to Heimdall.\n\nWhy not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Heimdall releases."},{"tag":"development","desc":"Latest commit from the github 2.x branch."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the web gui at http://SERVERIP:PORT\n\n\n### Adding password protection\n\nThis image now supports password protection through htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it heimdall htpasswd -c /config/nginx/.htpasswd <username>`. Replace <username> with a username of your choice and you will be asked to enter a password. Uncomment the `basic auth` lines in `/config/nginx/site-confs/default.conf` and restart the container.\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"14.11.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"04.11.22:","desc":"Build commits to upstream branch 2.x for the `development` tag."},{"date":"13.03.21:","desc":"Make searchproviders.yaml user configurable."},{"date":"10.02.21:","desc":"Revert to alpine 3.12 as php 7.4 broke laravel."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"17.08.20:","desc":"Add php7-curl."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"17.01.20:","desc":"Use nginx from baseimage."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"16.07.19:","desc":"Save laravel.log to /config/log/heimdall."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"01.04.19:","desc":"Fix permission detect logic."},{"date":"26.03.19:","desc":"Install Heimdall during container start to prevent delayed start due to overlayfs bug with recursive chown."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"15.03.19:","desc":"Clarify docker image tags in readme."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.18:","desc":"Generate random app key in .env for new installs."},{"date":"20.11.18:","desc":"Upgrade baseimage packages during build."},{"date":"04.11.18:","desc":"Add php7-zip."},{"date":"31.10.18:","desc":"Add queue service."},{"date":"17.10.18:","desc":"Symlink avatars folder."},{"date":"16.10.18:","desc":"Updated fastcgi_params for user login support."},{"date":"07.10.18:","desc":"Symlink `.env` rather than copy. It now resides under `/config/www`"},{"date":"30.09.18:","desc":"Multi-arch image. Move `.env` to `/config`."},{"date":"05.09.18:","desc":"Rebase to alpine linux 3.8."},{"date":"06.03.18:","desc":"Use password protection if htpasswd is set. Existing users can delete their default site config at /config/nginx/site-confs/default.conf and restart the container, a new default site config with htpasswd support will be created in its place"},{"date":"12.02.18:","desc":"Initial Release."}]}},"setup":"Access the web gui at http://SERVERIP:PORT\n\n\n### Adding password protection\n\nThis image now supports password protection through htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it heimdall htpasswd -c /config/nginx/.htpasswd <username>`. Replace <username> with a username of your choice and you will be asked to enter a password. Uncomment the `basic auth` lines in `/config/nginx/site-confs/default.conf` and restart the container.\n"},{"id":"homeassistant","name":"homeassistant","description":"[Home Assistant Core]({{ project_url }}) - Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server. \n","icon":"https://github.com/home-assistant/home-assistant.io/raw/next/source/images/favicon-192x192-full.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/homeassistant"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-homeassistant"}],"containers":[{"name":"homeassistant","image":"linuxserver/homeassistant","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify your TimeZone e.g. Europe/London."}],"volumes":[{"container":"/config","description":"Home Assistant config storage path.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"homeassistant","project_url":"https://www.home-assistant.io/","project_logo":"https://github.com/home-assistant/home-assistant.io/raw/next/source/images/favicon-192x192-full.png","project_blurb":"[Home Assistant Core]({{ project_url }}) - Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server. \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"optional_block_1":true,"optional_block_1_items":["#### Host vs. Bridge\n\nHome Assistant can [discover][hb0] and automatically configure\n[zeroconf][hb1]/[mDNS][hb2] and [UPnP][hb3] devices on your network. In\norder for this to work you must create the container with `--net=host`.\n\n[hb0]: https://www.home-assistant.io/integrations/discovery/#mdns-and-upnp\n[hb1]: https://en.wikipedia.org/wiki/Zero-configuration_networking\n[hb2]: https://en.wikipedia.org/wiki/Multicast_DNS\n[hb3]: https://en.wikipedia.org/wiki/Universal_Plug_and_Play\n"],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Home Assistant config storage path."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify your TimeZone e.g. Europe/London."}],"param_usage_include_ports":false,"param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container. Required for some devices to be discovered by Home Assistant.","opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8123","internal_port":"8123","port_desc":"Application WebUI, only use this if you are not using host mode."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/path/to/device","device_host_path":"/path/to/device","desc":"For passing through USB, serial or gpio devices."}],"app_setup_block_enabled":true,"app_setup_block":"This image is based on Home Assistant Core.\n\nThe Webui can be found at `http://your-ip:8123`. Follow the wizard to set up Home Assistant.\n","unraid_template_sync":false,"changelogs":[{"date":"16.11.22:","desc":"Fix the dep conflict for google calendar."},{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"29.07.22:","desc":"Improve usb device permission fix."},{"date":"07.07.22:","desc":"Rebase to alpine 3.16, switch to cp310 wheels."},{"date":"07.05.22:","desc":"Build matplotlib with the same Numpy version as HA req."},{"date":"31.03.22:","desc":"Install pycups."},{"date":"07.03.22:","desc":"Install PySwitchbot."},{"date":"02.03.22:","desc":"Update pip and use legacy resolver, clean up temp python files, reduce image size."},{"date":"04.02.22:","desc":"Always compile grpcio on arm32v7 due to pypi pushing a glibc only wheel."},{"date":"12.12.21:","desc":"Use the new `build.yaml` to determine HA base version."},{"date":"25.09.21:","desc":"Use the new lsio homeassistant wheel repo, instead of the HA wheels."},{"date":"13.09.21:","desc":"Build psycopg locally as the HA provided wheel does not seem to work properly."},{"date":"13.09.21:","desc":"Fix setcap in service. Build CISO8601 locally as the HA provided wheel does not seem to work properly."},{"date":"12.09.21:","desc":"Rebase to alpine 3.14. Build on native armhf."},{"date":"09.08.21:","desc":"Fixed broken build caused by missing dependency."},{"date":"01.07.21:","desc":"Remove HACS dependencies as it caused a crash in Home-assistant."},{"date":"25.02.21:","desc":"Add python dependencies from homeassistant base image."},{"date":"07.02.21:","desc":"Fix building from the wrong requirement file. Add ssh client & external DB libs."},{"date":"06.02.21:","desc":"Add iputils so ping works as non root user."},{"date":"30.01.21:","desc":"Initial Release."}]}},"setup":"This image is based on Home Assistant Core.\n\nThe Webui can be found at `http://your-ip:8123`. Follow the wizard to set up Home Assistant.\n"},{"id":"htpcmanager","name":"htpcmanager","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a front end for many htpc related applications.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/htpcmanager-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/htpcmanager"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-htpcmanager"}],"containers":[{"name":"htpcmanager","image":"linuxserver/htpcmanager","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"8085","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"htpcmanager","project_url":"https://github.com/HTPC-Manager/HTPC-Manager","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/htpcmanager-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a front end for many htpc related applications.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8085","internal_port":"8085","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"The webui is found at port 8085. Smartmontools and psutil have not been included, you can safely ignore the warning error in the log.","changelogs":[{"date":"24.08.22:","desc":"Rebase to alpine 3.15, use linuxserver.io wheel repo."},{"date":"08.04.21:","desc":"Fix build."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.10.20:","desc":"Rebase to alpine 3.12, python3, change upstream project"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"26.09.16:","desc":"Add back cherrypy after removal from baseimage."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"14.01.15:","desc":"Remove hardcoded loglevel from the run command, set in webui"},{"date":"19.09.15:","desc":"Initial Release."}]}},"setup":"The webui is found at port 8085. Smartmontools and psutil have not been included, you can safely ignore the warning error in the log."},{"id":"ipfs","name":"ipfs","description":"[{{ project_name|capitalize }}]({{ project_url }}) - A peer-to-peer hypermedia protocol designed to make the web faster, safer, and more open.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Ipfs-logo-1024-ice-text.png/480px-Ipfs-logo-1024-ice-text.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ipfs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ipfs"}],"containers":[{"name":"ipfs","image":"linuxserver/ipfs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"IPFS storage and config files/logs","key":"config"}],"ports":[{"container":"80","description":"The port for the IPFS web UI","protocol":"tcp","web":false},{"container":"4001","description":"Peering port, this is the only port you should expose to the internet","protocol":"tcp","web":false},{"container":"5001","description":"API port, the clientside webUI needs to be able to talk to this from whatever machine your web browser is on","protocol":"tcp","web":false},{"container":"8080","description":"Gateway Port, actually serves IPFS content","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ipfs","project_url":"https://ipfs.io/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Ipfs-logo-1024-ice-text.png/480px-Ipfs-logo-1024-ice-text.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - A peer-to-peer hypermedia protocol designed to make the web faster, safer, and more open.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_deprecation_status":true,"project_deprecation_message":"Please use the official IPFS container here:\nhttps://hub.docker.com/r/ipfs/go-ipfs\nWhen this project started the web interface was not integrated well\nwith the default IPFS server. Now it is great and well maintained, hosting\nit on a static webserver does not make much sense anymore.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"IPFS storage and config files/logs"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"The port for the IPFS web UI"},{"external_port":"4001","internal_port":"4001","port_desc":"Peering port, this is the only port you should expose to the internet"},{"external_port":"5001","internal_port":"5001","port_desc":"API port, the clientside webUI needs to be able to talk to this from whatever machine your web browser is on"},{"external_port":"8080","internal_port":"8080","port_desc":"Gateway Port, actually serves IPFS content"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"443","internal_port":"443","port_desc":"HTTPS port for web UI"}],"app_setup_block_enabled":true,"app_setup_block":"In order to push files beyond your local gateway you have to make sure port 4001 is forwarded to the internet. This is required for IPFS peers to reach in and grab your files so public gateways can serve them.\n\nAccess the webui at http://localhost , if not using localhost scroll to the bottom of the page and set the API Address setting to IE http://192.168.1.10:5001 , from there you can upload and manage files you push to IPFS. Your gateway to access IPFS files is http://localhost:8080/ipfs/YOUR-FILE-HASH-HERE . You can also simply use public IPFS gateways like: \n* Cloudflare - https://cloudflare-ipfs.com/ipfs/YOUR-FILE-HASH-HERE\n* IPFS.io - https://ipfs.io/ipfs/YOUR-FILE-HASH-HERE\n* Eternum.io - https://ipfs.eternum.io/ipfs/YOUR-FILE-HASH-HERE\n\nCloudflare is a solid option as they actually edge cache the files on their CDN so even if your node pinning the item goes down for periods of time their cache will last up to a month. \n\nFor more on using IPFS please read the docs [here](https://docs.ipfs.io/)\n \n","changelogs":[{"date":"02.02.22:","desc":"Deprecate."},{"date":"19.09.21:","desc":"Build webui from source. Update code formatting. Rebase to Alpine 3.14."},{"date":"01.04.21:","desc":"Add migration bins to image to support upgrades."},{"date":"24.02.20:","desc":"Rebase to Alpine 3.13."},{"date":"09.07.19:","desc":"Initial version."}]}},"setup":"In order to push files beyond your local gateway you have to make sure port 4001 is forwarded to the internet. This is required for IPFS peers to reach in and grab your files so public gateways can serve them.\n\nAccess the webui at http://localhost , if not using localhost scroll to the bottom of the page and set the API Address setting to IE http://192.168.1.10:5001 , from there you can upload and manage files you push to IPFS. Your gateway to access IPFS files is http://localhost:8080/ipfs/YOUR-FILE-HASH-HERE . You can also simply use public IPFS gateways like: \n* Cloudflare - https://cloudflare-ipfs.com/ipfs/YOUR-FILE-HASH-HERE\n* IPFS.io - https://ipfs.io/ipfs/YOUR-FILE-HASH-HERE\n* Eternum.io - https://ipfs.eternum.io/ipfs/YOUR-FILE-HASH-HERE\n\nCloudflare is a solid option as they actually edge cache the files on their CDN so even if your node pinning the item goes down for periods of time their cache will last up to a month. \n\nFor more on using IPFS please read the docs [here](https://docs.ipfs.io/)\n \n"},{"id":"jackett","name":"jackett","description":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: it translates queries from apps (Sonarr, SickRage, CouchPotato, Mylar, etc) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/jackett-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jackett"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jackett"}],"containers":[{"name":"jackett","image":"linuxserver/jackett","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"AUTO_UPDATE","default":"true","description":"Allow Jackett to update inside of the container (currently recommended by Jackett and enabled by default)"},{"id":"RUN_OPTS","default":"<run options here>","description":"Optionally specify additional arguments to be passed."}],"volumes":[{"container":"/config","description":"Where Jackett should store its config file.","key":"config"},{"container":"/downloads","description":"Path to torrent blackhole."}],"ports":[{"container":"9117","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"jackett","project_url":"https://github.com/Jackett/Jackett","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/jackett-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: it translates queries from apps (Sonarr, SickRage, CouchPotato, Mylar, etc) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Jackett Releases"},{"tag":"development","desc":"Latest Jackett Releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where Jackett should store its config file."},{"vol_path":"/downloads","vol_host_path":"<path to blackhole>","desc":"Path to torrent blackhole."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9117","internal_port":"9117","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"AUTO_UPDATE","env_value":"true","desc":"Allow Jackett to update inside of the container (currently recommended by Jackett and enabled by default)"},{"env_var":"RUN_OPTS","env_value":"<run options here>","desc":"Optionally specify additional arguments to be passed."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"The web interface is at `<your-ip>:9117` , configure various trackers and connections to other apps there.\nMore info at [{{ project_name|capitalize }}]({{ project_url }}).\n\nDisable autoupdates in the webui to prevent jackett crashing, the image is refreshed when new versions are released.\n","changelogs":[{"date":"10.05.22:","desc":"Rebase to Ubuntu Focal."},{"date":"24.05.20:","desc":"Allow user to optionally enable auto updates."},{"date":"31.12.19:","desc":"Remove agressive startup chowning."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.03.19:","desc":"Switch to net-core builds of jackett, not dependant on mono and smaller images."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"11.06.18:","desc":"Ensure root ownership of Jackett files."},{"date":"13.12.17:","desc":"Fix continuation lines."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, ubuntu xenial based."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"29.10.16:","desc":"Call python2 from edge main to satisfy new mono dependency."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"22.09.16:","desc":"Remove autoupdate, tidy up Dockerfile."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"06.08.16:","desc":"Rebase to alpine linux for smaller image."},{"date":"25.01.16:","desc":"Initial Release."}]}},"setup":"The web interface is at `<your-ip>:9117` , configure various trackers and connections to other apps there.\nMore info at [{{ project_name|capitalize }}]({{ project_url }}).\n\nDisable autoupdates in the webui to prevent jackett crashing, the image is refreshed when new versions are released.\n"},{"id":"jellyfin","name":"jellyfin","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it.","icon":"https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jellyfin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jellyfin"}],"containers":[{"name":"jellyfin","image":"linuxserver/jellyfin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use (e.g. Europe/London)."},{"id":"JELLYFIN_PublishedServerUrl","default":"192.168.0.5","description":"Set the autodiscovery response domain or IP address."}],"volumes":[{"container":"/opt/vc/lib","description":"Path for Raspberry Pi OpenMAX libs *optional*."},{"container":"/config","description":"Jellyfin data storage location. *This can grow very large, 50gb+ is likely for a large collection.*","key":"config"},{"container":"/data/tvshows","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"container":"/data/movies","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"ports":[{"container":"8096","description":"Http webUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"jellyfin","project_url":"https://jellyfin.github.io/","project_logo":"https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it.","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Jellyfin releases"},{"tag":"nightly","desc":"Nightly Jellyfin releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/library","desc":"Jellyfin data storage location. *This can grow very large, 50gb+ is likely for a large collection.*"},{"vol_path":"/data/tvshows","vol_host_path":"/path/to/tvseries","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"vol_path":"/data/movies","vol_host_path":"/path/to/movies","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8096","internal_port":"8096","port_desc":"Http webUI."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use (e.g. Europe/London)."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"JELLYFIN_PublishedServerUrl","env_value":"192.168.0.5","desc":"Set the autodiscovery response domain or IP address."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/opt/vc/lib","vol_host_path":"/opt/vc/lib","desc":"Path for Raspberry Pi OpenMAX libs *optional*."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/vcsm","device_host_path":"/dev/vcsm","desc":"Only needed if you want to use your Raspberry Pi MMAL video decoding (Enabled as OpenMax H264 decode in gui settings)."},{"device_path":"/dev/vchiq","device_host_path":"/dev/vchiq","desc":"Only needed if you want to use your Raspberry Pi OpenMax video encoding."},{"device_path":"/dev/video10","device_host_path":"/dev/video10","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video11","device_host_path":"/dev/video11","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video12","device_host_path":"/dev/video12","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8920","internal_port":"8920","port_desc":"Optional - Https webUI (you need to set up your own certificate)."},{"external_port":"7359","internal_port":"7359/udp","port_desc":"Optional - Allows clients to discover Jellyfin on the local network."},{"external_port":"1900","internal_port":"1900/udp","port_desc":"Optional - Service discovery used by DNLA and clients."}],"optional_parameters":"The [official documentation for ports](https://jellyfin.org/docs/general/networking/index.html) has additional ports that can provide auto discovery.\n\nService Discovery (`1900/udp`) - Since client auto-discover would break if this option were configurable, you cannot change this in the settings at this time. DLNA also uses this port and is required to be in the local subnet.\n\nClient Discovery (`7359/udp`) - Allows clients to discover Jellyfin on the local network. A broadcast message to this port with \"Who is Jellyfin Server?\" will get a JSON response that includes the server address, ID, and name.\n\n```\n  -p 7359:7359/udp \\\n  -p 1900:1900/udp \\\n```\n\nThe [official documentation for environmentals](https://jellyfin.org/docs/general/administration/configuration.html) has additional environmentals that can provide additional configurability such as migrating to the native Jellyfin image.\n","app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://<your-ip>:8096`\n\nMore information can be found on the official documentation [here](https://jellyfin.org/docs/general/quick-start.html).\n\n## Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n`--device=/dev/dri:/dev/dri`\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nTo enable the OpenCL based DV, HDR10 and HLG tone-mapping, please refer to the OpenCL-Intel mod from here:\n\nhttps://mods.linuxserver.io/?mod=jellyfin\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the jellyfin docker container.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi MMAL/OpenMAX will need to mount their `/dev/vcsm` and `/dev/vchiq` video devices inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n\n```\n--device=/dev/vcsm:/dev/vcsm\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their `/dev/video1X` devices inside of the container by passing the following options when running or creating the container:\n\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","unraid_template_sync":false,"changelogs":[{"date":"07.12.22:","desc":"Rebase master to Jammy, migrate to s6v3."},{"date":"11.06.22:","desc":"Switch to upstream repo's ffmpeg5 build."},{"date":"05.01.22:","desc":"Specify Intel iHD driver versions to avoid mismatched libva errors."},{"date":"25.12.21:","desc":"Fix video device group perms error message."},{"date":"10.12.21:","desc":"Rework readme, disable template sync."},{"date":"22.09.21:","desc":"Pull only the server, web and ffmpeg packages instead of the wrapper."},{"date":"23.06.21:","desc":"Add log message if device permissions are incorrect. Pin jellyfin dependency versions to prevent upstream apt repo issues. Deprecate the `bionic` tag."},{"date":"21.05.21:","desc":"Add nvidia.icd file to fix missing tonemapping using Nvidia HW."},{"date":"20.01.21:","desc":"Add Jellyfin Binary Environmentals"},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.11.20:","desc":"Rebase to Focal, branch off Bionic."},{"date":"22.07.20:","desc":"Ingest releases from Jellyfin repo."},{"date":"28.04.20:","desc":"Replace MMAL/OMX dependency device `/dev/vc-mem` with `/dev/vcsm` as the former was not sufficient for raspbian."},{"date":"11.04.20:","desc":"Enable hw decode (mmal) on Raspberry Pi, update readme instructions, add donation info, create missing default transcodes folder."},{"date":"11.03.20:","desc":"Add Pi V4L2 support, remove optional transcode mapping (location is selected in the gui, defaults to path under `/config`)."},{"date":"30.01.20:","desc":"Add nightly tag."},{"date":"09.01.20:","desc":"Add Pi OpenMax support."},{"date":"02.10.19:","desc":"Improve permission fixing for render & dvb devices."},{"date":"31.07.19:","desc":"Add AMD drivers for vaapi support on x86."},{"date":"13.06.19:","desc":"Add Intel drivers for vaapi support on x86."},{"date":"07.06.19:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://<your-ip>:8096`\n\nMore information can be found on the official documentation [here](https://jellyfin.org/docs/general/quick-start.html).\n\n## Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n`--device=/dev/dri:/dev/dri`\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nTo enable the OpenCL based DV, HDR10 and HLG tone-mapping, please refer to the OpenCL-Intel mod from here:\n\nhttps://mods.linuxserver.io/?mod=jellyfin\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the jellyfin docker container.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi MMAL/OpenMAX will need to mount their `/dev/vcsm` and `/dev/vchiq` video devices inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n\n```\n--device=/dev/vcsm:/dev/vcsm\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their `/dev/video1X` devices inside of the container by passing the following options when running or creating the container:\n\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n"},{"id":"jenkins-builder","name":"jenkins-builder","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/jenkinsbuilder.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jenkins-builder"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jenkins-builder"}],"containers":[{"name":"jenkins-builder","image":"linuxserver/jenkins-builder","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"jenkins-builder","full_custom_readme":"{% raw -%}\n# linuxserver/jenkins-builder\n\nExpects to run as part of the LSIO CI process. Not for public consumption.\n\n## Running against remote project\n\n```bash\ndocker run --rm \\\n  -e CONTAINER_NAME=${CONTAINER_NAME} \\\n  -v ${TEMPDIR}:/ansible/jenkins \\\n  lscr.io/linuxserver/jenkins-builder:latest\n```\n\n## Running against local project\n\nIf you need to test functionality just navigate to the folder with the jenkins-vars.yml and run:\n\n```bash\ndocker pull lscr.io/linuxserver/jenkins-builder:latest && \\\ndocker run --rm \\\n  -v $(pwd):/tmp \\\n  -e LOCAL=true \\\n  -e PUID=$(id -u) -e PGID=$(id -g) \\\n  lscr.io/linuxserver/jenkins-builder:latest && \\\nrm -rf .jenkins-external\n```\n\nNewly generated files (including `README.md`, `Jenkinsfile`, issue templates, etc.) will overwrite the existing files in your current working directory.\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n\n```bash\ngit clone https://github.com/linuxserver/docker-jenkins-builder.git\ncd docker-jenkins-builder\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t lscr.io/linuxserver/jenkins-builder:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\nThe following line is only in this repo for loop testing:\n\n- { date: \"01.01.50:\", desc: \"I am the release message for this internal repo.\" }\n{%- endraw %}\n"}}},{"id":"kasm","name":"kasm","description":"[{{ project_name|capitalize }}]({{ project_url }}) Workspaces is a docker container streaming platform for delivering browser-based access to desktops, applications, and web services. Kasm uses devops-enabled Containerized Desktop Infrastructure (CDI) to create on-demand, disposable, docker containers that are accessible via web browser. Example use-cases include Remote Browser Isolation (RBI), Data Loss Prevention (DLP), Desktop as a Service (DaaS), Secure Remote Access Services (RAS), and Open Source Intelligence (OSINT) collections.\n\nThe rendering of the graphical-based containers is powered by the open-source project [KasmVNC](https://www.kasmweb.com/kasmvnc.html?utm_campaign=LinuxServer&utm_source=kasmvnc).\n","icon":"https://kasm-ci.s3.amazonaws.com/kasm_wide.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/kasm"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-kasm"}],"containers":[{"name":"kasm","image":"linuxserver/kasm","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"KASM_PORT","default":"443","description":"Specify the port you bind to the outside for Kasm Workspaces."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"DOCKER_HUB_USERNAME","default":"USER","description":"Optionally specify a DockerHub Username to pull private images."},{"id":"DOCKER_HUB_PASSWORD","default":"PASS","description":"Optionally specify a DockerHub password to pull private images."}],"volumes":[{"container":"/profiles","description":"Optionally specify a path for persistent profile storage."},{"container":"/dev/input","description":"Optional for gamepad support."},{"container":"/run/udev/data","description":"Optional for gamepad support."},{"container":"/opt","description":"Docker and installation storage."}],"ports":[{"container":"3000","description":"Kasm Installation wizard. (https)","protocol":"tcp","web":false},{"container":"443","description":"Kasm Workspaces interface. (https)","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"kasm","project_url":"https://www.kasmweb.com/?utm_campaign=LinuxServer&utm_source=listing","project_logo":"https://kasm-ci.s3.amazonaws.com/kasm_wide.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) Workspaces is a docker container streaming platform for delivering browser-based access to desktops, applications, and web services. Kasm uses devops-enabled Containerized Desktop Infrastructure (CDI) to create on-demand, disposable, docker containers that are accessible via web browser. Example use-cases include Remote Browser Isolation (RBI), Data Loss Prevention (DLP), Desktop as a Service (DaaS), Secure Remote Access Services (RAS), and Open Source Intelligence (OSINT) collections.\n\nThe rendering of the graphical-based containers is powered by the open-source project [KasmVNC](https://www.kasmweb.com/kasmvnc.html?utm_campaign=LinuxServer&utm_source=kasmvnc).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Kasm releases"},{"tag":"develop","desc":"Tip of develop"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"KASM_PORT","env_value":"443","desc":"Specify the port you bind to the outside for Kasm Workspaces."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/opt","vol_host_path":"/path/to/data","desc":"Docker and installation storage."}],"param_device_map":false,"param_devices":[],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Kasm Installation wizard. (https)"},{"external_port":"443","internal_port":"443","port_desc":"Kasm Workspaces interface. (https)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_HUB_USERNAME","env_value":"USER","desc":"Optionally specify a DockerHub Username to pull private images."},{"env_var":"DOCKER_HUB_PASSWORD","env_value":"PASS","desc":"Optionally specify a DockerHub password to pull private images."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/profiles","vol_host_path":"/path/to/profiles","desc":"Optionally specify a path for persistent profile storage."},{"vol_path":"/dev/input","vol_host_path":"/dev/input","desc":"Optional for gamepad support."},{"vol_path":"/run/udev/data","vol_host_path":"/run/udev/data","desc":"Optional for gamepad support."}],"opt_param_usage_include_ports":false,"opt_param_ports":[],"opt_param_device_map":false,"opt_param_devices":[],"cap_add_param":false,"cap_add_param_vars":[],"opt_cap_add_param":false,"opt_cap_add_param_vars":[],"optional_block_1":false,"optional_block_1_items":"","privileged":true,"app_setup_block_enabled":true,"app_setup_block":"This container uses [Docker in Docker](https://www.docker.com/blog/docker-can-now-run-within-docker/) and requires being run in `privileged` mode. This container also requires an initial setup that runs on port 3000.\n\n**Unlike other containers the web interface port (default 443) needs to be set for the env variable `KASM_PORT` and both the inside and outside port IE for 4443 `KASM_PORT=4443` `-p 4443:4443`**\n\n**Unraid users due to the DinD storage layer `/opt/` should be mounted directly to a disk IE `/mnt/disk1/appdata/path` or optimally with a cache disk at `/mnt/cache/appdata/path`**\n\nAccess the installation wizard at https://`your ip`:3000 and follow the instructions there. Once setup is complete access https://`your ip`:443 and login with the credentials you entered during setup. The default users are:\n\n* admin@kasm.local\n* user@kasm.local\n\nCurrently Synology systems are not supported due to them blocking CPU scheduling in their Kernel.\n\n### GPU Support\n\nDuring installation an option will be presented to force all Workspace containers to mount in and use a specific GPU. If using an NVIDIA GPU you will need to pass `-e NVIDIA_VISIBLE_DEVICES=all` or `--gpus all` and have the [NVIDIA Container Runtime](https://github.com/NVIDIA/nvidia-container-runtime) installed on the host. Also if using NVIDIA, Kasm Workspaces has [native NVIDIA support](https://www.kasmweb.com/docs/latest/how_to/gpu.html) so you can optionally opt to simply use that instead of he manual override during installation. \n\n### Gamepad support\n\nIn order to properly create virtual Gamepads you will need to mount from your host `/dev/input` and `/run/udev/data`. Please see [HERE](https://www.kasmweb.com/docs/develop/guide/gamepad_passthrough.html) for instructions on enabling gamepad support.\n\n### Persistant profiles\n\nIn order to use persistant profiles in Workspaces you will need to mount in a folder to use from your host to `/profiles`. From there when configuring a workspace you can set the `Persistant Profile Path` to IE `/profiles/ubuntu-focal/{username}/`, more infomation can be found [HERE](https://www.kasmweb.com/docs/latest/how_to/persistent_profiles.html).\n","changelogs":[{"date":"05.11.22:","desc":"Rebase to Jammy, add support for GPUs, add support for Gamepads."},{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"02.07.22:","desc":"Initial Release."}]}},"setup":"This container uses [Docker in Docker](https://www.docker.com/blog/docker-can-now-run-within-docker/) and requires being run in `privileged` mode. This container also requires an initial setup that runs on port 3000.\n\n**Unlike other containers the web interface port (default 443) needs to be set for the env variable `KASM_PORT` and both the inside and outside port IE for 4443 `KASM_PORT=4443` `-p 4443:4443`**\n\n**Unraid users due to the DinD storage layer `/opt/` should be mounted directly to a disk IE `/mnt/disk1/appdata/path` or optimally with a cache disk at `/mnt/cache/appdata/path`**\n\nAccess the installation wizard at https://`your ip`:3000 and follow the instructions there. Once setup is complete access https://`your ip`:443 and login with the credentials you entered during setup. The default users are:\n\n* admin@kasm.local\n* user@kasm.local\n\nCurrently Synology systems are not supported due to them blocking CPU scheduling in their Kernel.\n\n### GPU Support\n\nDuring installation an option will be presented to force all Workspace containers to mount in and use a specific GPU. If using an NVIDIA GPU you will need to pass `-e NVIDIA_VISIBLE_DEVICES=all` or `--gpus all` and have the [NVIDIA Container Runtime](https://github.com/NVIDIA/nvidia-container-runtime) installed on the host. Also if using NVIDIA, Kasm Workspaces has [native NVIDIA support](https://www.kasmweb.com/docs/latest/how_to/gpu.html) so you can optionally opt to simply use that instead of he manual override during installation. \n\n### Gamepad support\n\nIn order to properly create virtual Gamepads you will need to mount from your host `/dev/input` and `/run/udev/data`. Please see [HERE](https://www.kasmweb.com/docs/develop/guide/gamepad_passthrough.html) for instructions on enabling gamepad support.\n\n### Persistant profiles\n\nIn order to use persistant profiles in Workspaces you will need to mount in a folder to use from your host to `/profiles`. From there when configuring a workspace you can set the `Persistant Profile Path` to IE `/profiles/ubuntu-focal/{username}/`, more infomation can be found [HERE](https://www.kasmweb.com/docs/latest/how_to/persistent_profiles.html).\n"},{"id":"kdenlive","name":"kdenlive","description":"[Kdenlive]({{ project_url }}) is a powerful free and open source cross-platform video editing program made by the KDE community. Feature rich and production ready.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/kdenlive-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/kdenlive"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-kdenlive"}],"containers":[{"name":"kdenlive","image":"linuxserver/kdenlive","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Kdenlive desktop gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"kdenlive","project_url":"https://kdenlive.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/kdenlive-logo.png","project_blurb":"[Kdenlive]({{ project_url }}) is a powerful free and open source cross-platform video editing program made by the KDE community. Feature rich and production ready.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Kdenlive desktop gui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"This might be needed to prevent crashing"}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for hardware acceleration (Linux hosts only)"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, this may be required depending on your Docker and storage configuration."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration (x86_64 only)\n\nIn order to perform hardware transcoding you will need to mount a video device into the container. Some of the default hardware rendering/transcode profiles will point to devices in /dev/dri for `vaapi_device`. Make sure the profile you are using points to the correct device in the container. IE if you have intel integrated graphics along with an Nvdia or AMD video card you might have renderD128, renderD129, etc. To check which device is which use vainfo from inside the container: (right click the desktop and open xterm)\n\n```\nvainfo --display drm --device /dev/dri/renderD128\n```\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"16.09.22:","desc":"Migrate to s6v3."},{"date":"09.03.22:","desc":"Update seccomp explanation."},{"date":"07.03.22:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration (x86_64 only)\n\nIn order to perform hardware transcoding you will need to mount a video device into the container. Some of the default hardware rendering/transcode profiles will point to devices in /dev/dri for `vaapi_device`. Make sure the profile you are using points to the correct device in the container. IE if you have intel integrated graphics along with an Nvdia or AMD video card you might have renderD128, renderD129, etc. To check which device is which use vainfo from inside the container: (right click the desktop and open xterm)\n\n```\nvainfo --display drm --device /dev/dri/renderD128\n```\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n"},{"id":"lazylibrarian","name":"lazylibrarian","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a program to follow authors and grab metadata for all your digital reading needs. It uses a combination of Goodreads Librarything and optionally GoogleBooks as sources for author info and book info.  This container is based on the DobyTang fork.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lazylibrarian-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lazylibrarian"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lazylibrarian"}],"containers":[{"name":"lazylibrarian","image":"linuxserver/lazylibrarian","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"},{"id":"DOCKER_MODS","default":"linuxserver/calibre-web:calibre|linuxserver/mods:lazylibrarian-ffmpeg","description":"Allows additional functionality to be added, e.g. the Calibredb import program (optional, more info below)"}],"volumes":[{"container":"/books","description":"Books location"},{"container":"/config","description":"LazyLibrarian config","key":"config"},{"container":"/downloads","description":"Download location"}],"ports":[{"container":"5299","description":"The port for the LazyLibrarian webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lazylibrarian","project_url":"https://lazylibrarian.gitlab.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lazylibrarian-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a program to follow authors and grab metadata for all your digital reading needs. It uses a combination of Goodreads Librarything and optionally GoogleBooks as sources for author info and book info.  This container is based on the DobyTang fork.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"LazyLibrarian config"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads/","desc":"Download location"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/books","vol_host_path":"/path/to/data/","desc":"Books location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5299","internal_port":"5299","port_desc":"The port for the LazyLibrarian webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_MODS","env_value":"linuxserver/calibre-web:calibre|linuxserver/mods:lazylibrarian-ffmpeg","desc":"Allows additional functionality to be added, e.g. the Calibredb import program (optional, more info below)"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<your-ip>:5299/home`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n\n### Calibredb import\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable the Calibredb import program:, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as detailed in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the LazyLibrarian config page (Processing:Calibredb import program:) set the path to converter tool to `/usr/bin/calibredb`\n\n### ffmpeg\n\nBy adding `linuxserver/mods:lazylibrarian-ffmpeg` to your `DOCKER_MODS` environment variable you can install ffmpeg into your container on startup.\nThis allows you to use the audiobook conversion features of LazyLibrarian.\nYou can enable it in the Web UI under Settings > Processing > External Programs by setting the ffmpeg path to `ffmpeg`.\n\n### Media folders\n\nWe have set `/books` as ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional path if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"07.12.22:","desc":"Rebase to Ubuntu Jammy, migrate to s6v3. Use pyproject.toml for deps. Build unrar from source."},{"date":"27.09.22:","desc":"Switch to `Levenshtein`, add cmake as build dep on armhf."},{"date":"07.05.22:","desc":"Rebase to Ubuntu Focal."},{"date":"22.05.21:","desc":"Make the paths clearer to the user, remove optional volume."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.10.19:","desc":"Changed gitlab download link."},{"date":"23.10.19:","desc":"Add python module Pillow."},{"date":"31.07.19:","desc":"Add pyopenssl, remove git dependency during build time."},{"date":"09.07.19:","desc":"Rebase to Ubuntu Bionic, enables Calibre docker mod."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"05.03.19:","desc":"Added apprise python package."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"10.12.18:","desc":"Moved to Pipeline Building"},{"date":"16.08.18:","desc":"Rebase to alpine 3.8"},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling"},{"date":"12.12.17:","desc":"Rebase to alpine 3.7"},{"date":"21.07.17:","desc":"Internal git pull instead of at runtime"},{"date":"25.05.17:","desc":"Rebase to alpine 3.6"},{"date":"07.02.17:","desc":"Rebase to alpine 3.5"},{"date":"30.01.17:","desc":"Compile libunrar.so to allow reading of .cbr format files"},{"date":"12.01.17:","desc":"Add ghostscript package, allows magazine covers to be created etc"},{"date":"14.10.16:","desc":"Add version layer information"},{"date":"03.10.16:","desc":"Fix non-persistent settings and make log folder"},{"date":"28.09.16:","desc":"Inital Release"}]}},"setup":"Access the webui at `http://<your-ip>:5299/home`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n\n### Calibredb import\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable the Calibredb import program:, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as detailed in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the LazyLibrarian config page (Processing:Calibredb import program:) set the path to converter tool to `/usr/bin/calibredb`\n\n### ffmpeg\n\nBy adding `linuxserver/mods:lazylibrarian-ffmpeg` to your `DOCKER_MODS` environment variable you can install ffmpeg into your container on startup.\nThis allows you to use the audiobook conversion features of LazyLibrarian.\nYou can enable it in the Web UI under Settings > Processing > External Programs by setting the ffmpeg path to `ffmpeg`.\n\n### Media folders\n\nWe have set `/books` as ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional path if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n"},{"id":"ldap-auth","name":"ldap-auth","description":"[{{ project_name|capitalize }}]({{ project_url }}) software is for authenticating users who request protected resources from servers proxied by nginx. It includes a daemon (ldap-auth) that communicates with an authentication server, and a webserver daemon that generates an authentication cookie based on the users credentials. The daemons are written in Python for use with a Lightweight Directory Access Protocol (LDAP) authentication server (OpenLDAP or Microsoft Windows Active Directory 2003 and 2012).","icon":"https://jumpcloud.com/wp-content/uploads/2016/12/LDAP_Logo-1420591101.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ldap-auth"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ldap-auth"}],"containers":[{"name":"ldap-auth","image":"linuxserver/ldap-auth","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"FERNETKEY","default":"","description":"Optionally define a custom fernet key, has to be base64-encoded 32-byte (only needed if container is frequently recreated, or if using multi-node setups, invalidating previous authentications)"},{"id":"CERTFILE","default":"","description":"Point this to a certificate file to enable HTTP over SSL (HTTPS) for the ldap auth daemon"},{"id":"KEYFILE","default":"","description":"Point this to the private key file, matching the certificate file referred to in CERTFILE"}],"ports":[{"container":"8888","description":"the port for ldap auth daemon","protocol":"tcp","web":false},{"container":"9000","description":"the port for ldap login page","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ldap-auth","project_url":"https://github.com/nginxinc/nginx-ldap-auth","project_logo":"https://jumpcloud.com/wp-content/uploads/2016/12/LDAP_Logo-1420591101.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) software is for authenticating users who request protected resources from servers proxied by nginx. It includes a daemon (ldap-auth) that communicates with an authentication server, and a webserver daemon that generates an authentication cookie based on the users credentials. The daemons are written in Python for use with a Lightweight Directory Access Protocol (LDAP) authentication server (OpenLDAP or Microsoft Windows Active Directory 2003 and 2012).","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":"","param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"the port for ldap auth daemon"},{"external_port":"9000","internal_port":"9000","port_desc":"the port for ldap login page"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"FERNETKEY","env_value":"","desc":"Optionally define a custom fernet key, has to be base64-encoded 32-byte (only needed if container is frequently recreated, or if using multi-node setups, invalidating previous authentications)"},{"env_var":"CERTFILE","env_value":"","desc":"Point this to a certificate file to enable HTTP over SSL (HTTPS) for the ldap auth daemon"},{"env_var":"KEYFILE","env_value":"","desc":"Point this to the private key file, matching the certificate file referred to in CERTFILE"}],"app_setup_block_enabled":true,"app_setup_block":"- This container itself does not have any settings and it relies on the pertinent information passed through in http headers of incoming requests. Make sure that your webserver is set up with the right config.\n- Here's a sample config: [nginx-ldap-auth.conf](https://github.com/nginxinc/nginx-ldap-auth/blob/master/nginx-ldap-auth.conf).\n- Unlike the upstream project, this image encodes the cookie information with fernet, using a randomly generated key during container creation (or optionally user defined).\n- Also unlike the upstream project, this image serves the login page at `/ldaplogin` (as well as `/login`) to prevent clashes with reverse proxied apps that may also use `/login` for their internal auth.\n","changelogs":[{"date":"19.09.22:","desc":"Rebase to alpine 3.17."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"14.05.21:","desc":"Add linuxserver wheel index."},{"date":"12.02.21:","desc":"Clean up cargo/rust cache."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"08.09.20:","desc":"Set form action correctly."},{"date":"30.07.20:","desc":"Fix bug related to unset optional `CERTFILE` and `KEYFILE` vars."},{"date":"27.07.20:","desc":"Add support for HTTP over SSL (HTTPS)."},{"date":"21.07.20:","desc":"Add support for optional user defined fernet key."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12, serve login page at `/ldaplogin` as well as `/login`, to prevent clashes with reverese proxied apps."},{"date":"17.05.20:","desc":"Add support for self-signed CA certs."},{"date":"20.02.20:","desc":"Switch to python3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"01.07.19:","desc":"Fall back to base64 encoding when basic http auth is used."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.09.18:","desc":"Update pip"},{"date":"14.09.18:","desc":"Add TZ parameter, remove unnecessary PUID/PGID params"},{"date":"11.08.18:","desc":"Initial release."}]}},"setup":"- This container itself does not have any settings and it relies on the pertinent information passed through in http headers of incoming requests. Make sure that your webserver is set up with the right config.\n- Here's a sample config: [nginx-ldap-auth.conf](https://github.com/nginxinc/nginx-ldap-auth/blob/master/nginx-ldap-auth.conf).\n- Unlike the upstream project, this image encodes the cookie information with fernet, using a randomly generated key during container creation (or optionally user defined).\n- Also unlike the upstream project, this image serves the login page at `/ldaplogin` (as well as `/login`) to prevent clashes with reverse proxied apps that may also use `/login` for their internal auth.\n"},{"id":"libreoffice","name":"libreoffice","description":"[LibreOffice]({{ project_url }}) is a free and powerful office suite, and a successor to OpenOffice.org (commonly known as OpenOffice). Its clean interface and feature-rich tools help you unleash your creativity and enhance your productivity.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/libreoffice-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/libreoffice"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-libreoffice"}],"containers":[{"name":"libreoffice","image":"linuxserver/libreoffice","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and documents","key":"config"}],"ports":[{"container":"3000","description":"LibreOffice desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"libreoffice","project_url":"https://www.libreoffice.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/libreoffice-logo.png","project_blurb":"[LibreOffice]({{ project_url }}) is a free and powerful office suite, and a successor to OpenOffice.org (commonly known as OpenOffice). Its clean interface and feature-rich tools help you unleash your creativity and enhance your productivity.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and documents"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"LibreOffice desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"05.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"librespeed","name":"librespeed","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.\n\nNo Flash, No Java, No Websocket, No Bullshit.\n","icon":"https://raw.githubusercontent.com/librespeed/speedtest/master/.logo/logo3.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/librespeed"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-librespeed"}],"containers":[{"name":"librespeed","image":"linuxserver/librespeed","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PASSWORD","default":"PASSWORD","description":"Set the password for the results database."},{"id":"CUSTOM_RESULTS","default":"false","description":"(optional) set to `true` to enable custom results page in `/config/www/results/index.php`."},{"id":"DB_TYPE","default":"sqlite","description":"Defaults to `sqlite`, can also be set to `mysql` or `postgresql`."},{"id":"DB_NAME","default":"DB_NAME","description":"Database name. Required for mysql and pgsql."},{"id":"DB_HOSTNAME","default":"DB_HOSTNAME","description":"Database address. Required for mysql and pgsql."},{"id":"DB_USERNAME","default":"DB_USERNAME","description":"Database username. Required for mysql and pgsql."},{"id":"DB_PASSWORD","default":"DB_PASSWORD","description":"Database password. Required for mysql and pgsql."},{"id":"DB_PORT","default":"DB_PORT","description":"Database port. Required for mysql."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"librespeed","project_url":"https://github.com/librespeed/speedtest","project_logo":"https://raw.githubusercontent.com/librespeed/speedtest/master/.logo/logo3.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.\n\nNo Flash, No Java, No Websocket, No Bullshit.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"PASSWORD","env_value":"PASSWORD","desc":"Set the password for the results database."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CUSTOM_RESULTS","env_value":"false","desc":"(optional) set to `true` to enable custom results page in `/config/www/results/index.php`."},{"env_var":"DB_TYPE","env_value":"sqlite","desc":"Defaults to `sqlite`, can also be set to `mysql` or `postgresql`."},{"env_var":"DB_NAME","env_value":"DB_NAME","desc":"Database name. Required for mysql and pgsql."},{"env_var":"DB_HOSTNAME","env_value":"DB_HOSTNAME","desc":"Database address. Required for mysql and pgsql."},{"env_var":"DB_USERNAME","env_value":"DB_USERNAME","desc":"Database username. Required for mysql and pgsql."},{"env_var":"DB_PASSWORD","env_value":"DB_PASSWORD","desc":"Database password. Required for mysql and pgsql."},{"env_var":"DB_PORT","env_value":"DB_PORT","desc":"Database port. Required for mysql."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the speedtest webui at `http://SERVERIP`. The results database can be accessed at `http://SERVERIP/results/stats.php` with the password set.  \nThe default template used is based on `example-singleServer-full.html`. However, all templates are provided for reference at `/config/www/`. Feel free to customize `/config/www/index.html` as you like. Delete the file and restart to go back to the image default.  \n\nYou can optionally place customized `speedtest.js` and `speedtest_worker.js` files under `/config/www` and they will supersede the defaults after a container start. Keep in mind that once you do so, they will no longer be updated. You can delete them and recreate the container to go back to the image defaults.  \n\nIf you are setting up a mysql or postgresql database, you first need to import the tables into your database as described at the following link  \nhttps://github.com/librespeed/speedtest/blob/master/doc.md#creating-the-database\n\nTo enable a custom results page set the environment variable `CUSTOM_RESULTS=true` and start (or restart) the container at least once for `/config/www/results/index.php` to be created and modify this file to your liking.\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"01.03.21:","desc":"Fix up database settings. Make sure `index.html` is recreated."},{"date":"28.02.21:","desc":"Added php7-ctype."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"29.04.20:","desc":"Add donation links for LibreSpeed to Github sponsor button and container log."},{"date":"09.01.20:","desc":"Initial Release."}]}},"setup":"Access the speedtest webui at `http://SERVERIP`. The results database can be accessed at `http://SERVERIP/results/stats.php` with the password set.  \nThe default template used is based on `example-singleServer-full.html`. However, all templates are provided for reference at `/config/www/`. Feel free to customize `/config/www/index.html` as you like. Delete the file and restart to go back to the image default.  \n\nYou can optionally place customized `speedtest.js` and `speedtest_worker.js` files under `/config/www` and they will supersede the defaults after a container start. Keep in mind that once you do so, they will no longer be updated. You can delete them and recreate the container to go back to the image defaults.  \n\nIf you are setting up a mysql or postgresql database, you first need to import the tables into your database as described at the following link  \nhttps://github.com/librespeed/speedtest/blob/master/doc.md#creating-the-database\n\nTo enable a custom results page set the environment variable `CUSTOM_RESULTS=true` and start (or restart) the container at least once for `/config/www/results/index.php` to be created and modify this file to your liking.\n"},{"id":"lidarr","name":"lidarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","icon":"https://github.com/lidarr/Lidarr/raw/develop/Logo/400.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lidarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lidarr"}],"containers":[{"name":"lidarr","image":"linuxserver/lidarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/music","description":"Music files (See note in Application setup)."},{"container":"/downloads","description":"Path to your download folder for music (See note in Application setup)."},{"container":"/config","description":"Configuration files for Lidarr.","key":"config"}],"ports":[{"container":"8686","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lidarr","project_url":"https://github.com/lidarr/Lidarr","project_logo":"https://github.com/lidarr/Lidarr/raw/develop/Logo/400.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Lidarr releases."},{"tag":"develop","desc":"Develop Lidarr Releases."},{"tag":"nightly","desc":"Nightly Lidarr Releases."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"opt_param_usage_include_env":false,"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files for Lidarr."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/music","vol_host_path":"/path/to/music","desc":"Music files (See note in Application setup)."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Path to your download folder for music (See note in Application setup)."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8686","internal_port":"8686","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8686`, for more information check out [Lidarr]({{ project_url }}).\n\nSpecial Note: Following our current folder structure will result in an inability to hardlink from your downloads to your Music folder because they are on seperate volumes. To support hardlinking, simply ensure that the Music and downloads data are on a single volume. For example, if you have /mnt/storage/Music and /mnt/storage/downloads/completed/Music, you would want something like /mnt/storage:/media for your volume. Then you can hardlink from /media/downloads/completed to /media/Music.\n\nAnother item to keep in mind, is that within lidarr itself, you should then map your download client folder to your lidarr folder: Settings -> Download Client -> advanced -> remote path mappings. I input the host of my download client (matches the download client defined) remote path is /downloads/Music (relative to the internal container path) and local path is /media/downloads/completed/Music, assuming you have folders to seperate your downloaded data types.\n\n### Media folders\n\nWe have set `/music` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"17.01.23:","desc":"Rebase master branch to Alpine 3.17, migrate to s6v3."},{"date":"06.06.22:","desc":"Rebase master branch to Alpine 3.15."},{"date":"06.05.22:","desc":"Rebase master branch to Focal."},{"date":"06.05.22:","desc":"Rebase develop branch to Alpine."},{"date":"04.02.22:","desc":"Rebase nightly branch to Alpine, deprecate nightly-alpine branch."},{"date":"30.12.21:","desc":"Add nightly-alpine branch."},{"date":"01.08.21:","desc":"Add libchromaprint-tools."},{"date":"11.07.21:","desc":"Make the paths clearer to the user."},{"date":"18.04.21:","desc":"Switch `latest` tag to net core."},{"date":"25.01.21:","desc":"Publish `develop` tag."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"18.04.20:","desc":"Removed /downloads and /music volumes from Dockerfiles."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"08.03.19:","desc":"Rebase to Bionic, use proposed endpoint for libchromaprint."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"22.04.18:","desc":"Switch to beta builds."},{"date":"17.03.18:","desc":"Add ENV XDG_CONFIG_HOME=\"/config/xdg\" to Dockerfile for signalr fix."},{"date":"27.02.18:","desc":"Use json to query for new version."},{"date":"23.02.18:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:8686`, for more information check out [Lidarr]({{ project_url }}).\n\nSpecial Note: Following our current folder structure will result in an inability to hardlink from your downloads to your Music folder because they are on seperate volumes. To support hardlinking, simply ensure that the Music and downloads data are on a single volume. For example, if you have /mnt/storage/Music and /mnt/storage/downloads/completed/Music, you would want something like /mnt/storage:/media for your volume. Then you can hardlink from /media/downloads/completed to /media/Music.\n\nAnother item to keep in mind, is that within lidarr itself, you should then map your download client folder to your lidarr folder: Settings -> Download Client -> advanced -> remote path mappings. I input the host of my download client (matches the download client defined) remote path is /downloads/Music (relative to the internal container path) and local path is /media/downloads/completed/Music, assuming you have folders to seperate your downloaded data types.\n\n### Media folders\n\nWe have set `/music` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n"},{"id":"limnoria","name":"limnoria","description":"[{{ project_name|capitalize }}]({{ project_url }}) A robust, full-featured, and user/programmer-friendly Python IRC bot, with many existing plugins. Successor of the well-known Supybot.","icon":"https://raw.githubusercontent.com/linuxserver/docker-limnoria/master/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/limnoria"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-limnoria"}],"containers":[{"name":"limnoria","image":"linuxserver/limnoria","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Limnoria config is stored.","key":"config"}],"ports":[{"container":"8080","description":"Port for Limnoria's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"limnoria","project_url":"https://github.com/ProgVal/limnoria","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-limnoria/master/logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A robust, full-featured, and user/programmer-friendly Python IRC bot, with many existing plugins. Successor of the well-known Supybot.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"path/to/config","desc":"Where Limnoria config is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Port for Limnoria's web interface."}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"### New Configuration\n\nIf you do not have an existing config you will need to start the container and then run the following wizard command:\n\n`docker exec -it -w /config -u abc limnoria limnoria-wizard`\n\n### Existing Configuration\n\nIf you have an existing config, adjust the directory settings in your conf file as follows:\n\n```conf\nsupybot.directories.backup: /config/backup\nsupybot.directories.conf: /config/conf\nsupybot.directories.data: /config/data\nsupybot.directories.data.tmp: /config/data/tmp\nsupybot.directories.data.web: /config/web\nsupybot.directories.log: /config/logs\nsupybot.directories.plugins: /config/plugins\n```\n\nNOTE: These are not grouped together in the file. You will need to search your conf file for the variables.\n\nThen place your conf file and any of your existing directories in /config and start up the container.\n\n### Plugin Requirements\n\nThe container will pip install any requirements.txt it finds in the /config/plugins folder on startup.\n\nIf you install a plugin using the PluginDownloader that includes a requirements.txt you can \nexecute a shell into the container and then use `pip install /config/plugins/ThePlugin/requirements.txt`\nor restart the container and the requirements will be installed. \n","changelogs":[{"date":"22.12.22:","desc":"Rebase to alpine 3.17."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"25.05.21:","desc":"Install plugin requirements on container init."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"13.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.01.20:","desc":"Initial Release."}]}},"setup":"### New Configuration\n\nIf you do not have an existing config you will need to start the container and then run the following wizard command:\n\n`docker exec -it -w /config -u abc limnoria limnoria-wizard`\n\n### Existing Configuration\n\nIf you have an existing config, adjust the directory settings in your conf file as follows:\n\n```conf\nsupybot.directories.backup: /config/backup\nsupybot.directories.conf: /config/conf\nsupybot.directories.data: /config/data\nsupybot.directories.data.tmp: /config/data/tmp\nsupybot.directories.data.web: /config/web\nsupybot.directories.log: /config/logs\nsupybot.directories.plugins: /config/plugins\n```\n\nNOTE: These are not grouped together in the file. You will need to search your conf file for the variables.\n\nThen place your conf file and any of your existing directories in /config and start up the container.\n\n### Plugin Requirements\n\nThe container will pip install any requirements.txt it finds in the /config/plugins folder on startup.\n\nIf you install a plugin using the PluginDownloader that includes a requirements.txt you can \nexecute a shell into the container and then use `pip install /config/plugins/ThePlugin/requirements.txt`\nor restart the container and the requirements will be installed. \n"},{"id":"lychee","name":"lychee","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free photo-management tool, which runs on your server or web-space. Installing is a matter of seconds. Upload, manage and share photos like from a native application. Lychee comes with everything you need and all your photos are stored securely.\"\n\n### UPGRADE WARNING\n\nPlease note that the v4 upgrade process resets ALL password-protected albums. Any albums that were made public with a password will need to be re-secured.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lychee-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lychee"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lychee"}],"containers":[{"name":"lychee","image":"linuxserver/lychee","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"DB_HOST","default":"mariadb","description":"for specifying the database host"},{"id":"DB_PORT","default":"3306","description":"for specifying the database port"},{"id":"DB_USERNAME","default":"lychee","description":"for specifying the database user"},{"id":"DB_PASSWORD","default":"dbpassword","description":"for specifying the database password"},{"id":"DB_DATABASE","default":"lychee","description":"for specifying the database to be used"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/pictures","description":"Where lychee will store uploaded data."}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lychee","project_url":"https://lycheeorg.github.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lychee-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free photo-management tool, which runs on your server or web-space. Installing is a matter of seconds. Upload, manage and share photos like from a native application. Lychee comes with everything you need and all your photos are stored securely.\"\n\n### UPGRADE WARNING\n\nPlease note that the v4 upgrade process resets ALL password-protected albums. Any albums that were made public with a password will need to be re-secured.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Contains all relevant configuration files."},{"vol_path":"/pictures","vol_host_path":"/path/to/pictures","desc":"Where lychee will store uploaded data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"DB_HOST","env_value":"mariadb","desc":"for specifying the database host"},{"env_var":"DB_PORT","env_value":"3306","desc":"for specifying the database port"},{"env_var":"DB_USERNAME","env_value":"lychee","desc":"for specifying the database user"},{"env_var":"DB_PASSWORD","env_value":"dbpassword","desc":"for specifying the database password"},{"env_var":"DB_DATABASE","env_value":"lychee","desc":"for specifying the database to be used"}],"optional_block_1":false,"optional_block_1_items":"","custom_compose":"version: \"3\"\nservices:\n  mariadb:\n    image: lscr.io/linuxserver/mariadb:latest\n    container_name: lychee_mariadb\n    restart: always\n    volumes:\n      - /path/to/mariadb/data:/config\n    environment:\n      - MYSQL_ROOT_PASSWORD=rootpassword\n      - MYSQL_DATABASE=lychee\n      - MYSQL_USER=lychee\n      - MYSQL_PASSWORD=dbpassword\n      - PGID=1000\n      - PUID=1000\n      - TZ=Europe/London\n  lychee:\n    image: lscr.io/linuxserver/lychee:latest\n    container_name: lychee\n    restart: always\n    depends_on:\n      - mariadb\n    volumes:\n      - /path/to/config:/config\n      - /path/to/pictures:/pictures\n    environment:\n      - DB_HOST=mariadb\n      - DB_USERNAME=lychee\n      - DB_PASSWORD=dbpassword\n      - DB_DATABASE=lychee\n      - DB_PORT=3306\n      - PGID=1000\n      - PUID=1000\n      - TZ=Europe/London\n    ports:\n      - 80:80\n","app_setup_block_enabled":true,"app_setup_block":"**This image will not work with a prefilled `/pictures` mount, lychee wants total control over this folder**\n\nSetup mysql/mariadb and account via the webui, accessible at http://SERVERIP:PORT\nMore info at [lychee]({{ project_url }}).\n","changelogs":[{"date":"11.01.23:","desc":"Rebasing to alpine 3.17 with php8.1. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base)). Switch to git clone as builds fail with the release artifact."},{"date":"13.05.21:","desc":"Make readme clearer."},{"date":"18.04.21:","desc":"Add php-intl for v4.3."},{"date":"31.01.21:","desc":"Add jpegoptim."},{"date":"15.01.21:","desc":"Rebase to alpine 3.13, add php7-ctype."},{"date":"10.07.20:","desc":"Upgrade to Lychee v4 and rebased to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"23.10.19:","desc":"Increase fastcgi timeouts (existing users need to manually update)."},{"date":"19.09.19:","desc":"Update project website url."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"05.05.19:","desc":"Rebase to alpine 3.9, use new armv7 image format."},{"date":"21.01.18:","desc":"Added ffmpeg for video thumbnail creation, switched to installing zip release instead of source tarball, created small thumbnails folder, switched to dynamic readme."},{"date":"14.01.19:","desc":"Adding pipeline logic and multi arch.."},{"date":"04.09.18:","desc":"Rebase to alpine 3.8, switch to LycheeOrg repository."},{"date":"08.01.18:","desc":"Rebase to alpine 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.05.17:","desc":"Use repo pinning to better solve dependencies, use repo version of php7-imagick."},{"date":"12.02.17:","desc":"Initial Release."}]}},"setup":"**This image will not work with a prefilled `/pictures` mount, lychee wants total control over this folder**\n\nSetup mysql/mariadb and account via the webui, accessible at http://SERVERIP:PORT\nMore info at [lychee]({{ project_url }}).\n"},{"id":"mariadb","name":"mariadb","description":"[{{ project_name|capitalize }}]({{ project_url }}) is one of the most popular database servers. Made by the original developers of MySQL.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mariadb-git.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mariadb"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mariadb"}],"containers":[{"name":"mariadb","image":"linuxserver/mariadb","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"MYSQL_ROOT_PASSWORD","default":"ROOT_ACCESS_PASSWORD","description":"Set this to root password for installation (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MYSQL_DATABASE","default":"USER_DB_NAME","description":"Specify the name of a database to be created on image startup."},{"id":"MYSQL_USER","default":"MYSQL_USER","description":"This user will have superuser access to the database specified by MYSQL_DATABASE (do not use root here)."},{"id":"MYSQL_PASSWORD","default":"DATABASE_PASSWORD","description":"Set this to the password you want to use for you MYSQL_USER (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"id":"REMOTE_SQL","default":"http://URL1/your.sql,https://URL2/your.sql","description":"Set this to ingest sql files from an http/https endpoint (comma seperated array)."}],"volumes":[{"container":"/config","description":"Contains the db itself and all assorted settings.","key":"config"}],"ports":[{"container":"3306","description":"Mariadb listens on this port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mariadb","project_url":"https://mariadb.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mariadb-git.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is one of the most popular database servers. Made by the original developers of MySQL.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Latest mariadb release with an Alpine base."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"MYSQL_ROOT_PASSWORD","env_value":"ROOT_ACCESS_PASSWORD","desc":"Set this to root password for installation (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"path_to_data","desc":"Contains the db itself and all assorted settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3306","internal_port":"3306","port_desc":"Mariadb listens on this port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MYSQL_DATABASE","env_value":"USER_DB_NAME","desc":"Specify the name of a database to be created on image startup."},{"env_var":"MYSQL_USER","env_value":"MYSQL_USER","desc":"This user will have superuser access to the database specified by MYSQL_DATABASE (do not use root here)."},{"env_var":"MYSQL_PASSWORD","env_value":"DATABASE_PASSWORD","desc":"Set this to the password you want to use for you MYSQL_USER (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"env_var":"REMOTE_SQL","env_value":"http://URL1/your.sql,https://URL2/your.sql","desc":"Set this to ingest sql files from an http/https endpoint (comma seperated array)."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"If you didn't set a password during installation, (see logs for warning) use\n`mariadb-admin -u root -p<PASSWORD>`\nto set one at the docker prompt...\n\nNOTE changing the MYSQL_ROOT_PASSWORD variable after the container has set up the initial databases has no effect, use the mysqladmin tool to change your mariadb password.\n\nNOTE if you want to use (MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD) **all three** of these variables need to be set you cannot pick and choose.\n\nUnraid users, it is advisable to edit the template/webui after setup and remove reference to this variable.\n\nFind custom.cnf in /config for config changes (restart container for them to take effect)\n, the databases in /config/databases and the log in /config/log/myqsl\n\n### Loading passwords and users from files\n\nThe `MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD REMOTE_SQL` env values can be set in a file:\n\n```\n/config/env\n```\n\nUsing the following format:\n\n```\nMYSQL_ROOT_PASSWORD=\"ROOT_ACCESS_PASSWORD\"\nMYSQL_DATABASE=\"USER_DB_NAME\"\nMYSQL_USER=\"MYSQL_USER\"\nMYSQL_PASSWORD=\"DATABASE_PASSWORD\"\nREMOTE_SQL=\"http://URL1/your.sql,https://URL2/your.sql\"\n```\n\nThese settings can be mixed and matched with Docker ENV settings as you require, but the settings in the file will always take precedence.\n\n### Bootstrapping a new instance\n\nWe support a one time run of custom sql files on init. In order to use this place `*.sql` files in:\n\n```\n/config/initdb.d/\n```\nThis will have the same effect as setting the `REMOTE_SQL` environment variable. The sql will only be run on the containers first boot and setup.\n\n### Upgrading\n\nWhen this container initializes, if `MYSQL_ROOT_PASSWORD` is set an upgrade check will run. If an upgrade is required the log will indicate the need to run:\n\n```\nmariadb-upgrade -u root -p<PASSWORD>\n```\n","changelogs":[{"date":"09.12.22:","desc":"Add upgrade check warning."},{"date":"11.10.22:","desc":"Rebase master to Alpine 3.16, migrate to s6v3, remove password escape logic which caused problems for a small subset of users."},{"date":"06.07.21:","desc":"Rebase master to alpine."},{"date":"03.07.21:","desc":"Rebase to 3.14."},{"date":"08.02.21:","desc":"Fix new installs."},{"date":"08.02.21:","desc":"Rebase to alpine. Add mariadb-backup."},{"date":"08.02.21:","desc":"Release alpine tag. The alpine release will replace the latest tag in the near future."},{"date":"27.10.19:","desc":"Bump to 10.4, ability use custom sql on initial init ,defining root passwords via file."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"07.03.19:","desc":"Add ability to setup a database and default user on first spinup."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"10.09.18:","desc":"Rebase to ubuntu bionic and use 10.3 mariadb repository."},{"date":"09.12.17:","desc":"Fix continuation lines."},{"date":"12.09.17:","desc":"Gracefully shut down mariadb."},{"date":"27.10.16:","desc":"Implement linting suggestions on database init script."},{"date":"11.10.16:","desc":"Rebase to ubuntu xenial, add version labelling."},{"date":"09.03.16:","desc":"Update to mariadb 10.1. Change to use custom.cnf over my.cnf in /config. Restructured init files to change config options on startup, rather than in the dockerfile."},{"date":"26.01.16:","desc":"Change user of mysqld_safe script to abc, better unclean shutdown handling on restart."},{"date":"23.12.15:","desc":"Remove autoupdating, between some version updates the container breaks."},{"date":"12.08.15:","desc":"Initial Release."}]}},"setup":"If you didn't set a password during installation, (see logs for warning) use\n`mariadb-admin -u root -p<PASSWORD>`\nto set one at the docker prompt...\n\nNOTE changing the MYSQL_ROOT_PASSWORD variable after the container has set up the initial databases has no effect, use the mysqladmin tool to change your mariadb password.\n\nNOTE if you want to use (MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD) **all three** of these variables need to be set you cannot pick and choose.\n\nUnraid users, it is advisable to edit the template/webui after setup and remove reference to this variable.\n\nFind custom.cnf in /config for config changes (restart container for them to take effect)\n, the databases in /config/databases and the log in /config/log/myqsl\n\n### Loading passwords and users from files\n\nThe `MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD REMOTE_SQL` env values can be set in a file:\n\n```\n/config/env\n```\n\nUsing the following format:\n\n```\nMYSQL_ROOT_PASSWORD=\"ROOT_ACCESS_PASSWORD\"\nMYSQL_DATABASE=\"USER_DB_NAME\"\nMYSQL_USER=\"MYSQL_USER\"\nMYSQL_PASSWORD=\"DATABASE_PASSWORD\"\nREMOTE_SQL=\"http://URL1/your.sql,https://URL2/your.sql\"\n```\n\nThese settings can be mixed and matched with Docker ENV settings as you require, but the settings in the file will always take precedence.\n\n### Bootstrapping a new instance\n\nWe support a one time run of custom sql files on init. In order to use this place `*.sql` files in:\n\n```\n/config/initdb.d/\n```\nThis will have the same effect as setting the `REMOTE_SQL` environment variable. The sql will only be run on the containers first boot and setup.\n\n### Upgrading\n\nWhen this container initializes, if `MYSQL_ROOT_PASSWORD` is set an upgrade check will run. If an upgrade is required the log will indicate the need to run:\n\n```\nmariadb-upgrade -u root -p<PASSWORD>\n```\n"},{"id":"mastodon","name":"mastodon","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, open-source social network server based on ActivityPub where users can follow friends and discover new ones..\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mastodon-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mastodon"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mastodon"}],"containers":[{"name":"mastodon","image":"linuxserver/mastodon","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"LOCAL_DOMAIN","default":"example.com","description":"This is the unique identifier of your server in the network. It cannot be safely changed later."},{"id":"REDIS_HOST","default":"redis","description":"Redis server hostname"},{"id":"REDIS_PORT","default":"6379","description":"Redis port"},{"id":"DB_HOST","default":"db","description":"Postgres database hostname"},{"id":"DB_USER","default":"mastodon","description":"Postgres username"},{"id":"DB_NAME","default":"mastodon","description":"Postgres db name"},{"id":"DB_PASS","default":"mastodon","description":"Postgres password"},{"id":"DB_PORT","default":"5432","description":"Portgres port"},{"id":"ES_ENABLED","default":"false","description":"Enable or disable Elasticsearch (requires a separate ES instance)"},{"id":"SECRET_KEY_BASE","default":"","description":"Browser session secret. Changing it will break all active browser sessions."},{"id":"OTP_SECRET","default":"","description":"MFA secret. Changing it will break two-factor authentication."},{"id":"VAPID_PRIVATE_KEY","default":"","description":"Push notification private key. Changing it will break push notifications."},{"id":"VAPID_PUBLIC_KEY","default":"","description":"Push notification public key. Changing it will break push notifications."},{"id":"SMTP_SERVER","default":"mail.example.com","description":"SMTP server for email notifications"},{"id":"SMTP_PORT","default":"25","description":"SMTP server port"},{"id":"SMTP_LOGIN","default":"","description":"SMTP username"},{"id":"SMTP_PASSWORD","default":"","description":"SMTP password"},{"id":"SMTP_FROM_ADDRESS","default":"notifications@example.com","description":"From address for emails send from Mastodon"},{"id":"S3_ENABLED","default":"false","description":"Enable or disable S3 storage of uploaded files"},{"id":"WEB_DOMAIN","default":"mastodon.example.com","description":"This can be set if you want your server identifier to be different to the subdomain hosting Mastodon. See [https://docs.joinmastodon.org/admin/config/#basic](https://docs.joinmastodon.org/admin/config/#basic)"},{"id":"ES_HOST","default":"es","description":"Elasticsearch server hostname"},{"id":"ES_PORT","default":"9200","description":"Elasticsearch port"},{"id":"ES_USER","default":"elastic","description":"Elasticsearch username"},{"id":"ES_PASS","default":"elastic","description":"Elasticsearch password"},{"id":"S3_BUCKET","default":"","description":"S3 bucket hostname"},{"id":"AWS_ACCESS_KEY_ID","default":"","description":"S3 bucket access key ID"},{"id":"AWS_SECRET_ACCESS_KEY","default":"","description":"S3 bucket secret access key"},{"id":"S3_ALIAS_HOST","default":"","description":"Alternate hostname for object fetching if you are front the S3 connections."},{"id":"SIDEKIQ_ONLY","default":"false","description":"Only run the sidekiq service in this container instance. For large scale instances that need better queue handling."},{"id":"SIDEKIQ_QUEUE","default":"","description":"The name of the sidekiq queue to run in this container. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-queues)."},{"id":"SIDEKIQ_DEFAULT","default":"false","description":"Set to `true` on the main container if you're running additional sidekiq instances. It will run the `default` queue."},{"id":"SIDEKIQ_THREADS","default":"5","description":"The number of threads for sidekiq to use. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."},{"id":"DB_POOL","default":"5","description":"The size of the DB connection pool, must be *at least* the same as `SIDEKIQ_THREADS`. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false},{"container":"443","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mastodon","project_url":"https://github.com/mastodon/mastodon/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mastodon-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, open-source social network server based on ActivityPub where users can follow friends and discover new ones..\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"develop","desc":"Pre-releases *only*."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"LOCAL_DOMAIN","env_value":"example.com","desc":"This is the unique identifier of your server in the network. It cannot be safely changed later."},{"env_var":"REDIS_HOST","env_value":"redis","desc":"Redis server hostname"},{"env_var":"REDIS_PORT","env_value":"6379","desc":"Redis port"},{"env_var":"DB_HOST","env_value":"db","desc":"Postgres database hostname"},{"env_var":"DB_USER","env_value":"mastodon","desc":"Postgres username"},{"env_var":"DB_NAME","env_value":"mastodon","desc":"Postgres db name"},{"env_var":"DB_PASS","env_value":"mastodon","desc":"Postgres password"},{"env_var":"DB_PORT","env_value":"5432","desc":"Portgres port"},{"env_var":"ES_ENABLED","env_value":"false","desc":"Enable or disable Elasticsearch (requires a separate ES instance)"},{"env_var":"SECRET_KEY_BASE","env_value":"","desc":"Browser session secret. Changing it will break all active browser sessions."},{"env_var":"OTP_SECRET","env_value":"","desc":"MFA secret. Changing it will break two-factor authentication."},{"env_var":"VAPID_PRIVATE_KEY","env_value":"","desc":"Push notification private key. Changing it will break push notifications."},{"env_var":"VAPID_PUBLIC_KEY","env_value":"","desc":"Push notification public key. Changing it will break push notifications."},{"env_var":"SMTP_SERVER","env_value":"mail.example.com","desc":"SMTP server for email notifications"},{"env_var":"SMTP_PORT","env_value":"25","desc":"SMTP server port"},{"env_var":"SMTP_LOGIN","env_value":"","desc":"SMTP username"},{"env_var":"SMTP_PASSWORD","env_value":"","desc":"SMTP password"},{"env_var":"SMTP_FROM_ADDRESS","env_value":"notifications@example.com","desc":"From address for emails send from Mastodon"},{"env_var":"S3_ENABLED","env_value":"false","desc":"Enable or disable S3 storage of uploaded files"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"WEB_DOMAIN","env_value":"mastodon.example.com","desc":"This can be set if you want your server identifier to be different to the subdomain hosting Mastodon. See [https://docs.joinmastodon.org/admin/config/#basic](https://docs.joinmastodon.org/admin/config/#basic)"},{"env_var":"ES_HOST","env_value":"es","desc":"Elasticsearch server hostname"},{"env_var":"ES_PORT","env_value":"9200","desc":"Elasticsearch port"},{"env_var":"ES_USER","env_value":"elastic","desc":"Elasticsearch username"},{"env_var":"ES_PASS","env_value":"elastic","desc":"Elasticsearch password"},{"env_var":"S3_BUCKET","env_value":"","desc":"S3 bucket hostname"},{"env_var":"AWS_ACCESS_KEY_ID","env_value":"","desc":"S3 bucket access key ID"},{"env_var":"AWS_SECRET_ACCESS_KEY","env_value":"","desc":"S3 bucket secret access key"},{"env_var":"S3_ALIAS_HOST","env_value":"","desc":"Alternate hostname for object fetching if you are front the S3 connections."},{"env_var":"SIDEKIQ_ONLY","env_value":"false","desc":"Only run the sidekiq service in this container instance. For large scale instances that need better queue handling."},{"env_var":"SIDEKIQ_QUEUE","env_value":"","desc":"The name of the sidekiq queue to run in this container. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-queues)."},{"env_var":"SIDEKIQ_DEFAULT","env_value":"false","desc":"Set to `true` on the main container if you're running additional sidekiq instances. It will run the `default` queue."},{"env_var":"SIDEKIQ_THREADS","env_value":"5","desc":"The number of threads for sidekiq to use. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."},{"env_var":"DB_POOL","env_value":"5","desc":"The size of the DB connection pool, must be *at least* the same as `SIDEKIQ_THREADS`. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"},{"external_port":"443","internal_port":"443","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"We provide aliases for the common commands that execute in the correct context so that environment variables from secrets are available to them:\n\n* To generate keys for `SECRET_KEY_BASE` & `OTP_SECRET` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-secret` once for each.\n\n* To generate keys for `VAPID_PRIVATE_KEY` & `VAPID_PUBLIC_KEY` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-vapid`\n\nBoth of the secret generation aliases above can be run without any other setup having been carried out.\n\n* To use `tootctl` you can run something like `docker exec -it lscr.io/linuxserver/mastodon /tootctl <command>`\n\nUsing `tootctl` requires you to complete the initial Mastodon configuration first.\n\nThis container *requires* separate postgres and redis instances to run.\n\nWe support all of the official [environment variables](https://docs.joinmastodon.org/admin/config) for configuration. In place of adding them all to your run/compose you can use an env file such as [this example](https://github.com/mastodon/mastodon/blob/main/.env.production.sample) from the upstream project.\n\nFor more information check out the [mastodon documentation](https://docs.joinmastodon.org/).\n\n### Running separate sidekiq instances\n\nIt is currently only supported to run a single queue per container instance *or* all queues in a single container instance.\n\nAll containers must share the same `/config`` mount and be on a common docker network.\n\n### Strict reverse proxies\n\nThis image automatically redirects to https with a self-signed certificate. If you are using a reverse proxy which validates certificates, you need to [disable this check for the container](https://docs.linuxserver.io/faq#strict-proxy).\n","changelogs":[{"date":"09.01.23:","desc":"Updated nginx conf to fix bring inline with Mastodon configuration (fixes Elk integration)."},{"date":"19.12.22:","desc":"Support separate sidekiq queue instances."},{"date":"05.11.22:","desc":"Initial Release."}]}},"setup":"We provide aliases for the common commands that execute in the correct context so that environment variables from secrets are available to them:\n\n* To generate keys for `SECRET_KEY_BASE` & `OTP_SECRET` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-secret` once for each.\n\n* To generate keys for `VAPID_PRIVATE_KEY` & `VAPID_PUBLIC_KEY` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-vapid`\n\nBoth of the secret generation aliases above can be run without any other setup having been carried out.\n\n* To use `tootctl` you can run something like `docker exec -it lscr.io/linuxserver/mastodon /tootctl <command>`\n\nUsing `tootctl` requires you to complete the initial Mastodon configuration first.\n\nThis container *requires* separate postgres and redis instances to run.\n\nWe support all of the official [environment variables](https://docs.joinmastodon.org/admin/config) for configuration. In place of adding them all to your run/compose you can use an env file such as [this example](https://github.com/mastodon/mastodon/blob/main/.env.production.sample) from the upstream project.\n\nFor more information check out the [mastodon documentation](https://docs.joinmastodon.org/).\n\n### Running separate sidekiq instances\n\nIt is currently only supported to run a single queue per container instance *or* all queues in a single container instance.\n\nAll containers must share the same `/config`` mount and be on a common docker network.\n\n### Strict reverse proxies\n\nThis image automatically redirects to https with a self-signed certificate. If you are using a reverse proxy which validates certificates, you need to [disable this check for the container](https://docs.linuxserver.io/faq#strict-proxy).\n"},{"id":"medusa","name":"medusa","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/medusa-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/medusa"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-medusa"}],"containers":[{"name":"medusa","image":"linuxserver/medusa","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"Medusa config","key":"config"},{"container":"/downloads","description":"Download location"},{"container":"/tv","description":"TV Shows location"}],"ports":[{"container":"8081","description":"The port for the Medusa webui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"medusa","project_url":"https://pymedusa.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/medusa-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Medusa config"},{"vol_path":"/downloads","vol_host_path":"<path to downloads>","desc":"Download location"},{"vol_path":"/tv","vol_host_path":"<path to tv shows>","desc":"TV Shows location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"The port for the Medusa webui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Web interface is at `<your ip>:8081`. \n\nSet paths for downloads, tv-shows to match docker mappings via the webui, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n","changelogs":[{"date":"12.09.22:","desc":"Install ffmpeg for postprocessing."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"28.02.22:","desc":"Install python3 requirements for app."},{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"22.09.19:","desc":"Switch to python3."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Adding multi arch and pipeline logic"},{"date":"16.08.18:","desc":"Rebase to alpine 3.8"},{"date":"08.12.17:","desc":"Rebase to alpine 3.7"},{"date":"29.11.17:","desc":"Add py-gdbm for subtitles support"},{"date":"26.10.17:","desc":"Mediainfo moved from testing to community repo"},{"date":"10.10.17:","desc":"Use repo version of mediainfo to shorten build time"},{"date":"05.08.17:","desc":"Internal git pull instead of at runtime"},{"date":"25.05.17:","desc":"Rebase to alpine 3.6"},{"date":"07.02.17:","desc":"Rebase to alpine 3.5"},{"date":"02.01.17:","desc":"Initial Release"}]}},"setup":"Web interface is at `<your ip>:8081`. \n\nSet paths for downloads, tv-shows to match docker mappings via the webui, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n"},{"id":"minetest","name":"minetest","description":"[{{ project_name|capitalize }}]({{ project_url }}) (server) is a near-infinite-world block sandbox game and a game engine, inspired by InfiniMiner, Minecraft, and the like.","icon":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/minetest-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/minetest"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-minetest"}],"containers":[{"name":"minetest","image":"linuxserver/minetest","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CLI_ARGS","default":"\"--gameid minetest --port 30000\"","description":"Optionally specify any [CLI variables](https://wiki.minetest.net/Command_line) you want to launch the app with"}],"volumes":[{"container":"/config/.minetest","description":"Where minetest stores config files and maps etc."}],"ports":[{"container":"30000/udp","description":"Port Minetest listens on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"minetest","project_url":"http://www.minetest.net/","project_logo":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/minetest-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (server) is a near-infinite-world block sandbox game and a game engine, inspired by InfiniMiner, Minecraft, and the like.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config/.minetest","vol_host_path":"/path/to/data","desc":"Where minetest stores config files and maps etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"30000","internal_port":"30000/udp","port_desc":"Port Minetest listens on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CLI_ARGS","env_value":"\"--gameid minetest --port 30000\"","desc":"Optionally specify any [CLI variables](https://wiki.minetest.net/Command_line) you want to launch the app with"}],"app_setup_block_enabled":true,"app_setup_block":"You can find the world maps, mods folder and config files in /config/.minetest.\n\nIf you want to override the advertised port, ensure you add --port in your CLI_ARGS AND ensure the internal port reflects the change, ie;\nif you set your advertised port to 40000 with --port 40000 then your ports declaration should be 40000:40000/udp\n\n\nClient and server must be the same version, please browse the tags here to pull the appropriate version for your server:\n\nhttps://hub.docker.com/r/linuxserver/{{ project_name }}/tags\n","changelogs":[{"date":"06.08.22:","desc":"Update irrlicht deps."},{"date":"02.05.22:","desc":"Allow specifying the advertised port."},{"date":"17.03.22:","desc":"Install forked irrlicht, add zstd."},{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"12.07.19:","desc":"Bugfix to support multiple CLI variables."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"03.06.19:","desc":"Adding custom cli vars to options."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"04.03.19:","desc":"Rebase to alpine 3.9 to compile 5.0.0 minetest with new build args."},{"date":"14.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"08.08.18:","desc":"Rebase to alpine 3.8, build from latest release tag instead of master."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"30.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"14.02.17:","desc":"Rebase to alpine 3.5."},{"date":"25.11.16:","desc":"Rebase to alpine linux, move to main repo."},{"date":"27.02.16:","desc":"Bump to latest version."},{"date":"19.02.16:","desc":"Change port to UDP, thanks to slashopt for pointing this out."},{"date":"15.02.16:","desc":"Make minetest app a service."},{"date":"01.02.16:","desc":"Add lua-socket dependency."},{"date":"06.11.15:","desc":"Initial Release."}]}},"setup":"You can find the world maps, mods folder and config files in /config/.minetest.\n\nIf you want to override the advertised port, ensure you add --port in your CLI_ARGS AND ensure the internal port reflects the change, ie;\nif you set your advertised port to 40000 with --port 40000 then your ports declaration should be 40000:40000/udp\n\n\nClient and server must be the same version, please browse the tags here to pull the appropriate version for your server:\n\nhttps://hub.docker.com/r/linuxserver/{{ project_name }}/tags\n"},{"id":"minisatip","name":"minisatip","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-threaded satip server version 1.2 that runs under Linux and it was tested with DVB-S, DVB-S2, DVB-T, DVB-T2, DVB-C, DVB-C2, ATSC and ISDB-T cards.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/minisatip-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/minisatip"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-minisatip"}],"containers":[{"name":"minisatip","image":"linuxserver/minisatip","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"","description":"Specify specific run params for minisatip"},{"id":"VERSION","default":"latest","description":"Supported values are LATEST, PLEXPASS or a specific version number."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"Configuration files and minisatip data","key":"config"}],"ports":[{"container":"8875","description":"Status Page WebUI","protocol":"tcp","web":false},{"container":"554","description":"RTSP Port","protocol":"tcp","web":false},{"container":"1900/udp","description":"App Discovery","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"minisatip","project_url":"https://github.com/catalinii/minisatip","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/minisatip-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-threaded satip server version 1.2 that runs under Linux and it was tested with DVB-S, DVB-S2, DVB-T, DVB-T2, DVB-C, DVB-C2, ATSC and ISDB-T cards.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"RUN_OPTS","env_value":"","desc":"Specify specific run params for minisatip"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files and minisatip data"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8875","internal_port":"8875","port_desc":"Status Page WebUI"},{"external_port":"554","internal_port":"554","port_desc":"RTSP Port"},{"external_port":"1900","internal_port":"1900/udp","port_desc":"App Discovery"}],"param_device_map":true,"param_devices":[{"device_path":"/dev/dvb","device_host_path":"/dev/dvb","desc":"For passing through Tv-cards"}],"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"VERSION","env_value":"latest","desc":"Supported values are LATEST, PLEXPASS or a specific version number."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"opt_param_usage_include_ports":false,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Additional runtime parameters\n\nIn some cases it might be necessary to start minisatip with additional parameters, for example to configure a unicable LNB. Add the parameters you need and restart the container. Be sure to have the right parameters set as adding the wrong once might lead to the container not starting correctly.\nFor a list of minisatip parameters visit [{{ project_name|capitalize }}]({{ project_url }}) page.\n"],"app_setup_block_enabled":true,"app_setup_block":"Best used in conjunction with [tvheadend](https://github.com/linuxserver/docker-tvheadend)\n\nThere is no setup per se, other than adding your cards for passthrough.\n\nYou can then use your cards as DVB inputs in apps such as tvheadend.\n","changelogs":[{"date":"12.11.22:","desc":"Rebasing to alpine 3.137, upgrading to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"20.02.19:","desc":"Fix run options."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"28.08.18:","desc":"Rebase to Alpine 3.8."},{"date":"13.12.17:","desc":"Rebase to Alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to Alpine 3.6."},{"date":"08.02.17:","desc":"Rebase to Alpine 3.5 and only compile libs in dvb-apps."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"18.09.16:","desc":"Add support for Common Interface."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"15.08.16:","desc":"Initial Release."}]}},"setup":"Best used in conjunction with [tvheadend](https://github.com/linuxserver/docker-tvheadend)\n\nThere is no setup per se, other than adding your cards for passthrough.\n\nYou can then use your cards as DVB inputs in apps such as tvheadend.\n"},{"id":"mods","name":"mods","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/mods.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mods"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mods"}],"containers":[{"name":"mods","image":"linuxserver/mods","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"404":"Not Found"}}},{"id":"mstream","name":"mstream","description":"[{{ project_name }}]({{ project_url }}) is a personal music streaming server. You can use mStream to stream your music from your home computer to any device, anywhere.  There are mobile apps available for both Android and iPhone.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mstream-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mstream"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mstream"}],"containers":[{"name":"mstream","image":"linuxserver/mstream","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"mStream config","key":"config"},{"container":"/music","description":"Music location"}],"ports":[{"container":"3000","description":"The port for the mStream webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mstream","project_url":"https://mstream.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mstream-icon.png","project_blurb":"[{{ project_name }}]({{ project_url }}) is a personal music streaming server. You can use mStream to stream your music from your home computer to any device, anywhere.  There are mobile apps available for both Android and iPhone.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"mStream config"},{"vol_path":"/music","vol_host_path":"/path/to/music","desc":"Music location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"The port for the mStream webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<your-ip>:3000`\n\nSettings are adjusted through the web ui or via editing of `config.json`. For more information check out [{{ project_name|capitalize }}](https://github.com/IrosTheBeggar/mStream/blob/master/docs/json_config.md#json-config).\n\n## IMPORTANT NOTICE:\nmStream v5 no longer accepts cli arguments for setting the user and password and requires the use of `config.json`. Therefore, the environment variables `USER`, `PASSWORD` and `USE_JSON` are deprecated.\n\nv4's `config.json` is not compatible with v5. Existing `config.json` will be renamed to `config.json.v4-bak` for your reference and a new default `config.json` will be created upon upgrade from v4 to v5.\n","changelogs":[{"date":"05.04.22:","desc":"Move `sync` folder to `/config`."},{"date":"02.04.22:","desc":"Rebase to alpine 3.15. Fix ffmpeg download."},{"date":"17.05.21:","desc":"Deprecating the env vars `USER`, `PASSWORD` and `USE_JSON` as mStream v5 requires the use of `config.json`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"18.05.19:","desc":"Inital Release"}]}},"setup":"Access the webui at `http://<your-ip>:3000`\n\nSettings are adjusted through the web ui or via editing of `config.json`. For more information check out [{{ project_name|capitalize }}](https://github.com/IrosTheBeggar/mStream/blob/master/docs/json_config.md#json-config).\n\n## IMPORTANT NOTICE:\nmStream v5 no longer accepts cli arguments for setting the user and password and requires the use of `config.json`. Therefore, the environment variables `USER`, `PASSWORD` and `USE_JSON` are deprecated.\n\nv4's `config.json` is not compatible with v5. Existing `config.json` will be renamed to `config.json.v4-bak` for your reference and a new default `config.json` will be created upon upgrade from v4 to v5.\n"},{"id":"mylar3","name":"mylar3","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated Comic Book downloader (cbr/cbz) for use with NZB and torrents written in python. It supports SABnzbd, NZBGET, and many torrent clients in addition to DDL.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mylar-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mylar3"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mylar3"}],"containers":[{"name":"mylar3","image":"linuxserver/mylar3","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/config","description":"Where mylar should store config files.","key":"config"},{"container":"/comics","description":"Map to your comics folder."},{"container":"/downloads","description":"Map to your downloads folder."}],"ports":[{"container":"8090","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mylar3","project_url":"https://github.com/mylar3/mylar3","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mylar-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated Comic Book downloader (cbr/cbz) for use with NZB and torrents written in python. It supports SABnzbd, NZBGET, and many torrent clients in addition to DDL.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Mylar3 releases"},{"tag":"nightly","desc":"Commits to Mylar3 `python3-dev` branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where mylar should store config files."},{"vol_path":"/comics","vol_host_path":"/path/to/comics","desc":"Map to your comics folder."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Map to your downloads folder."}],"param_usage_include_env":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"8090","internal_port":"8090","port_desc":"WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"The web ui for settings etc, is on `http://SERVERIP:8090`\nFor more detailed setup options, refer to [{{ project_name|capitalize }}]({{ project_url }}).\n","changelogs":[{"date":"12.10.22:","desc":"Rebase to alpine 3.16 and upgrade to s6v3."},{"date":"01.02.22:","desc":"Rebase to alpine 3.15."},{"date":"02.11.21:","desc":"Rebase to alpine 3.14. Remove `pathlib.py`."},{"date":"25.05.21:","desc":"Add `libwebp` support."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"03.01.21:","desc":"Output mylar log to docker log."},{"date":"21.12.20:","desc":"Release `nightly` tag based on commits to upstream `python3-dev` branch."},{"date":"28.09.20:","desc":"Initial release."}]}},"setup":"The web ui for settings etc, is on `http://SERVERIP:8090`\nFor more detailed setup options, refer to [{{ project_name|capitalize }}]({{ project_url }}).\n"},{"id":"mysql-workbench","name":"mysql-workbench","description":"[MySQL Workbench]({{ project_url }}) is a unified visual tool for database architects, developers, and DBAs. MySQL Workbench provides data modeling, SQL development, and comprehensive administration tools for server configuration, user administration, backup, and much more.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mysql-workbench-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mysql-workbench"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mysql-workbench"}],"containers":[{"name":"mysql-workbench","image":"linuxserver/mysql-workbench","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"}],"ports":[{"container":"3000","description":"Mysql Workbench desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mysql-workbench","project_url":"https://www.mysql.com/products/workbench/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mysql-workbench-icon.png","project_blurb":"[MySQL Workbench]({{ project_url }}) is a unified visual tool for database architects, developers, and DBAs. MySQL Workbench provides data modeling, SQL development, and comprehensive administration tools for server configuration, user administration, backup, and much more.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Mysql Workbench desktop gui."}],"custom_params":[{"name":"cap-add","name_compose":"cap_add","value":["IPC_LOCK"],"desc":"Required for keyring functionality","array":"true"}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"15.09.22:","desc":"Migrate to s6v3."},{"date":"26.07.22:","desc":"Rebase on jammy."},{"date":"20.04.21:","desc":"Rebase on focal."},{"date":"18.01.21:","desc":"Update libpython dependency."},{"date":"26.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"nano","name":"nano","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nano"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nano"}],"containers":[{"name":"nano","image":"linuxserver/nano","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PEER_HOST","default":"localhost","description":"Default peer host (can be overidden with an array by command line options)"},{"id":"LIVE_GENESIS_PUB","default":"GENESIS_PUBLIC","description":"Genesis block public key"},{"id":"LIVE_GENESIS_ACCOUNT","default":"nano_xxxxxx","description":"Genesis block account"},{"id":"LIVE_GENESIS_WORK","default":"WORK_FOR_BLOCK","description":"Genesis block proof of work"},{"id":"LIVE_GENESIS_SIG","default":"BLOCK_SIGNATURE","description":"Genesis block signature"},{"id":"CLI_OPTIONS","default":"--config node.enable_voting=true","description":"Node run command cli args"},{"id":"LMDB_BOOTSTRAP_URL","default":"http://example.com/Nano_64_version_20.7z","description":"HTTP/HTTPS endpoint to download a 7z file with the data.ldb to bootstrap to this node"}],"volumes":[{"container":"/config","description":"Main storage for config and blockchain","key":"config"}],"ports":[{"container":"8075","description":"Nano communication port","protocol":"tcp","web":false},{"container":"3000","description":"RPC interface filtered through a proxy","protocol":"tcp","web":false},{"container":"3001","description":"Https RPC interface filtered through a proxy","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nano","project_url":"https://nano.org/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Nano releases"},{"tag":"beta","desc":"Beta Nano releases"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Main storage for config and blockchain"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8075","internal_port":"8075","port_desc":"Nano communication port"},{"external_port":"7076","internal_port":"3000","port_desc":"RPC interface filtered through a proxy"},{"external_port":"7077","internal_port":"3001","port_desc":"Https RPC interface filtered through a proxy"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PEER_HOST","env_value":"localhost","desc":"Default peer host (can be overidden with an array by command line options)"},{"env_var":"LIVE_GENESIS_PUB","env_value":"GENESIS_PUBLIC","desc":"Genesis block public key"},{"env_var":"LIVE_GENESIS_ACCOUNT","env_value":"nano_xxxxxx","desc":"Genesis block account"},{"env_var":"LIVE_GENESIS_WORK","env_value":"WORK_FOR_BLOCK","desc":"Genesis block proof of work"},{"env_var":"LIVE_GENESIS_SIG","env_value":"BLOCK_SIGNATURE","desc":"Genesis block signature"},{"env_var":"CLI_OPTIONS","env_value":"--config node.enable_voting=true","desc":"Node run command cli args"},{"env_var":"LMDB_BOOTSTRAP_URL","env_value":"http://example.com/Nano_64_version_20.7z","desc":"HTTP/HTTPS endpoint to download a 7z file with the data.ldb to bootstrap to this node"}],"app_setup_block_enabled":true,"app_setup_block":"### Your Genesis account\nBy default this container will launch with a genesis block based on the private key `0000000000000000000000000000000000000000000000000000000000000000`, this should obviously only ever be used for testing purposes. Before you run your node you should use a script baked into this image to determine your private key and required environment variables: \n\n```\ndocker run --rm --entrypoint /genesis.sh linuxserver/nano\nGenerating Genesis block\n!!!!!!! ACCOUNT INFO SAVE THIS INFORMATION IT WILL NOT BE SHOWN AGAIN !!!!!!!!\nPrivate Key: CD4CD6B1E5523D4B5AEDD2B1E5A447C6C6797E729A531A95F9AD7937FC7CD9EA\nPublic Key:  2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D\nAccount:     nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nContainer Environment Values:\n -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n```\n\nThese environment variables will be used for all of the peers in your payment network, but if you are running what you would consider a public or live network never share your private key even if you have drained the funds from that account it can be potentionally used to create valid forks.\n**Even Better**, you should never even trust our Docker image for generating a private key and open block. Do it on an airgapped machine and keep it on a paper wallet.\n\n### RPC Proxy settings\nBy default this container will enable RPC control and publish a custom service that acts as an RPC firewall giving you the ability to whitelist specific RPC calls and overide/add default values.\n\nThe default proxy config is stored in `/config/rpc-proxy.json`: \n\n```\n{\n  \"port\":3000,\n  \"httpsport\":3001,\n  \"rpchost\":\"127.0.0.1\",\n  \"rpcport\":7076,\n  \"certfile\":\"/config/ssl/cert.crt\",\n  \"keyfile\":\"/config/ssl/cert.key\",\n  \"whitelist\":[\n    \"account_info\",\n    \"account_history\",\n    \"block_count\",\n    \"block_info\",\n    \"pending\",\n    \"process\"\n  ],\n  \"overrides\":{\n    \"account-history\":{\n      \"count\":\"64\"\n    },\n    \"pending\":{\n      \"count\":\"8\"\n    }\n  }\n}\n```\n\nThis should be a minimal amount of RPC access needed to run a local light wallet against this endpoint. If you plan on having your network users only run clientside light wallets (local blake2b block generation and block `process` call publishing) you should publically publish this port for access for both port 7076 and 7077. For functional light wallets on Https endpoints we will generate a self signed cert/key combo but you should add the ones associated with your domain. This will allow yours and other https hosted light wallets to hit your RPC endpoint clientside from the users web browser.\n\nOutside of potential https tunneling and actual object parsing (will remove duplicate keys) this is not a conventional API, it simply acts as a firewall and will send and return data just like a local RPC server would. The goal is to be compatible with any existing Nano software if the developers decide to add the ability to connect to alternative network endpoints. \n\n**Our Proxy has not been audited by any security team and is provided as is, though we make the best effort to keep it simple and secure**\n\n### Node configuration via environment\nBefore you get started please review the configuration docs [here](https://docs.nano.org/running-a-node/configuration/)\n\nWe will pass the `CLI_OPTIONS` to the node, here is a run command example:\n\n```\n-e CLI_OPTIONS='--config node.preconfigured_peers=[\"peering.yourhost.com\",\"peering.yourhost2.com\"] \\\n                --config node.enable_voting=true'\n```\n\nThere are many options to know here to run an actual live node especially peering and voting, again please review the docs if you plan to run something outside of a local setup.\n\n### Quickstart Guide\n\nHere we are going to cover the bare minimum commands needed to spinup a local payment network and wallet. \n\nFirst spinup your containers:\n```\ndocker run -d \\\n--name node \\\n-e CLI_OPTIONS='--config node.enable_voting=true' \\\n-p 7076:3000 \\\n--restart unless-stopped \\\nlinuxserver/nano\n```\n```\ndocker run -d \\\n--name=wallet \\\n-p 80:80 \\\n--restart unless-stopped \\\nlinuxserver/nano-wallet\n```\nThen unlock the Genesis funds on the local node to allow it to confirm transactions: \n```\ndocker exec -it node bash\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_create\" }' localhost:7076\n{\n    \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\"\n}\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_add\", \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\", \"key\": \"0000000000000000000000000000000000000000000000000000000000000000\" }' localhost:7076\n{\n    \"account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\"\n}\n```\n\nHere we are using the default private key of `0000000000000000000000000000000000000000000000000000000000000000` for the image.\nNavigate to http://localhost/#/localhost and enter this key. You should be greeted by the genesis account wallet with 340.28 Million Nano.\n\nFrom here you can generate new wallets from the home screen and send/receive funds on your local network. Now you will be running an insecure centralized network with a single voting representative and a zero security private key using the commands above. To spinup a standard private or even public network you should read up on Nano's documentation [HERE](https://docs.nano.org/) and continue reading the network design section below.\n\n### Network design\nThere are 4 main concepts to grasp from a network standpoint as far as types of endpoints. Before we get started here is a basic network diagram:\n\n![image](https://raw.githubusercontent.com/linuxserver/image-docs/master/img/nano-network.png)\n\n#### Principle nodes and voting representatives\nPrinciple nodes are network representatives with the ability to vote due to having a certain threshold of funds unlocked on that node or pointed to that unlocked address. These nodes should be as airgapped as possible while still being an active 24/7 peer of the network. From a tecnical perspective this is a node with an account private key that either has the funds it needs itself or enough users have pointed their accounts to it as a representative. In a live and secure configuration to protect the funds of this account you would use an inactive private key account with the funds in it and locally sign a change of representative block to point to the always online representative.\n\nThese nodes should never process external RPC calls even on a local network, the same rules go for any node with a local unlocked wallet.\n\nKeep in mind the key to the security of the network is that 51% of the funds are pointed to trusted representatives that will generally not argue about chain forks. \n\nIn most deployments the best bet is to heavily centralize your voting nodes, this is unless you are intentionally trying to build a distributed ledger and security model like the main Nano live net. Achieving that will be a long and difficult task.\n\n#### Network peers\n\nTo a normal user simply transacting on the network using off the shelf tools like a web wallet and web based block explorers is generally all that is required. They get a number in a ledger somewhere and are able to locally sign and publish blocks using their private key using your published RPC endpoints.\n\nFor advanced users and just to generally make the network more robust, network operators should promote people running their own nodes. Using this image a network peer simply needs to run a docker run command with your pre-configured variables. IE given the generation example from above in the `Your Genesis account` section:\n\n```\ndocker create \\\n  --name=nano \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.mydomain.com \\\n  -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n  -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n  -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n\nWhen the container spins up it will reach out to the node to bootstrap it's local ledger from peering.mydomain.com . This node once fully synced will be able to run local RPC commands to plug into a wallet and default Nano node wallet commands for automated pocketing of transactions etc. It will also get a list of other peers on the network from it's initial network peering and start participating in your distributed cryptocurrency network.\n\n#### Public RPC endpoints\nThe key to users going to a webpage and managing the funds on your network is the ability to get blockchain information and publish new blocks to theirs. As mentioned earlier we bundle a basic firewall with a core set of RPC functions whitelisted that should be safe to expose publically. \n\nFrom a network design perspective these nodes should be purely what you would consider client peers and never have any wallets registered or private keys stored on them. Also for redundancy optmimally these peers should be run in a cluster behind a load balancer. For standard nodes you are building out a large P2P network, but in the case of the RPC endpoint and specifically the URL the end user is going to pass when accessing their wallet it is up to you to make that resilient.\n\n#### Clientside javascript wallet\nCurrently we publish a pure javascript clientside wallet located here:  \n\nhttps://github.com/linuxserver/nano-wallet\n\nIt is designed to be run 100% clientside in any web browser and use public RPC endpoints to hook into any network and conduct transactions by locally signing then publishing the result.\nThis can be hosted locally with any simple webserver and pointed to a locally run peer, but for full functionality we reccomend providing a public Https URL with these files along with plugging in legitamite SSL certificates into your RPC endpoints running on 7077.\n\n# Running a node on the LinuxServer network\n\nWe maintain our own network which users can get funds to transact on from our [Discord](https://discord.gg/YWrKVTn) server. If you would like to run a node on our network here is our Docker run command:\n```\ndocker create \\\n  --name=lsio-node \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.linuxserver.io \\\n  -e LIVE_GENESIS_PUB=79F2E157B5667F1C8B6CCB6DF691DAC032B85DEC39E231D29976DCED05F5B1BE \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1yhkw7ducsmz5k7pskufytaxoi3kq3gyrgh489bbkxpwxn4zdefyn4rmrrkk \\\n  -e LIVE_GENESIS_WORK=c51204c6b69384cb \\\n  -e LIVE_GENESIS_SIG=90DDE7B4DC038811180FF5DDE8594F1774542A7AADE3DB71A57AA38A5AED42672E1E8D7ACFAC315BDB0EB5DCB542C610B9C49B2560AE575073855259AF065509 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n","changelogs":[{"date":"02.06.20:","desc":"Rebase to Alpine 3.12."},{"date":"28.05.20:","desc":"Add beta tag."},{"date":"17.05.20:","desc":"Initial Release."}]}},"setup":"### Your Genesis account\nBy default this container will launch with a genesis block based on the private key `0000000000000000000000000000000000000000000000000000000000000000`, this should obviously only ever be used for testing purposes. Before you run your node you should use a script baked into this image to determine your private key and required environment variables: \n\n```\ndocker run --rm --entrypoint /genesis.sh linuxserver/nano\nGenerating Genesis block\n!!!!!!! ACCOUNT INFO SAVE THIS INFORMATION IT WILL NOT BE SHOWN AGAIN !!!!!!!!\nPrivate Key: CD4CD6B1E5523D4B5AEDD2B1E5A447C6C6797E729A531A95F9AD7937FC7CD9EA\nPublic Key:  2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D\nAccount:     nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nContainer Environment Values:\n -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n```\n\nThese environment variables will be used for all of the peers in your payment network, but if you are running what you would consider a public or live network never share your private key even if you have drained the funds from that account it can be potentionally used to create valid forks.\n**Even Better**, you should never even trust our Docker image for generating a private key and open block. Do it on an airgapped machine and keep it on a paper wallet.\n\n### RPC Proxy settings\nBy default this container will enable RPC control and publish a custom service that acts as an RPC firewall giving you the ability to whitelist specific RPC calls and overide/add default values.\n\nThe default proxy config is stored in `/config/rpc-proxy.json`: \n\n```\n{\n  \"port\":3000,\n  \"httpsport\":3001,\n  \"rpchost\":\"127.0.0.1\",\n  \"rpcport\":7076,\n  \"certfile\":\"/config/ssl/cert.crt\",\n  \"keyfile\":\"/config/ssl/cert.key\",\n  \"whitelist\":[\n    \"account_info\",\n    \"account_history\",\n    \"block_count\",\n    \"block_info\",\n    \"pending\",\n    \"process\"\n  ],\n  \"overrides\":{\n    \"account-history\":{\n      \"count\":\"64\"\n    },\n    \"pending\":{\n      \"count\":\"8\"\n    }\n  }\n}\n```\n\nThis should be a minimal amount of RPC access needed to run a local light wallet against this endpoint. If you plan on having your network users only run clientside light wallets (local blake2b block generation and block `process` call publishing) you should publically publish this port for access for both port 7076 and 7077. For functional light wallets on Https endpoints we will generate a self signed cert/key combo but you should add the ones associated with your domain. This will allow yours and other https hosted light wallets to hit your RPC endpoint clientside from the users web browser.\n\nOutside of potential https tunneling and actual object parsing (will remove duplicate keys) this is not a conventional API, it simply acts as a firewall and will send and return data just like a local RPC server would. The goal is to be compatible with any existing Nano software if the developers decide to add the ability to connect to alternative network endpoints. \n\n**Our Proxy has not been audited by any security team and is provided as is, though we make the best effort to keep it simple and secure**\n\n### Node configuration via environment\nBefore you get started please review the configuration docs [here](https://docs.nano.org/running-a-node/configuration/)\n\nWe will pass the `CLI_OPTIONS` to the node, here is a run command example:\n\n```\n-e CLI_OPTIONS='--config node.preconfigured_peers=[\"peering.yourhost.com\",\"peering.yourhost2.com\"] \\\n                --config node.enable_voting=true'\n```\n\nThere are many options to know here to run an actual live node especially peering and voting, again please review the docs if you plan to run something outside of a local setup.\n\n### Quickstart Guide\n\nHere we are going to cover the bare minimum commands needed to spinup a local payment network and wallet. \n\nFirst spinup your containers:\n```\ndocker run -d \\\n--name node \\\n-e CLI_OPTIONS='--config node.enable_voting=true' \\\n-p 7076:3000 \\\n--restart unless-stopped \\\nlinuxserver/nano\n```\n```\ndocker run -d \\\n--name=wallet \\\n-p 80:80 \\\n--restart unless-stopped \\\nlinuxserver/nano-wallet\n```\nThen unlock the Genesis funds on the local node to allow it to confirm transactions: \n```\ndocker exec -it node bash\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_create\" }' localhost:7076\n{\n    \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\"\n}\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_add\", \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\", \"key\": \"0000000000000000000000000000000000000000000000000000000000000000\" }' localhost:7076\n{\n    \"account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\"\n}\n```\n\nHere we are using the default private key of `0000000000000000000000000000000000000000000000000000000000000000` for the image.\nNavigate to http://localhost/#/localhost and enter this key. You should be greeted by the genesis account wallet with 340.28 Million Nano.\n\nFrom here you can generate new wallets from the home screen and send/receive funds on your local network. Now you will be running an insecure centralized network with a single voting representative and a zero security private key using the commands above. To spinup a standard private or even public network you should read up on Nano's documentation [HERE](https://docs.nano.org/) and continue reading the network design section below.\n\n### Network design\nThere are 4 main concepts to grasp from a network standpoint as far as types of endpoints. Before we get started here is a basic network diagram:\n\n![image](https://raw.githubusercontent.com/linuxserver/image-docs/master/img/nano-network.png)\n\n#### Principle nodes and voting representatives\nPrinciple nodes are network representatives with the ability to vote due to having a certain threshold of funds unlocked on that node or pointed to that unlocked address. These nodes should be as airgapped as possible while still being an active 24/7 peer of the network. From a tecnical perspective this is a node with an account private key that either has the funds it needs itself or enough users have pointed their accounts to it as a representative. In a live and secure configuration to protect the funds of this account you would use an inactive private key account with the funds in it and locally sign a change of representative block to point to the always online representative.\n\nThese nodes should never process external RPC calls even on a local network, the same rules go for any node with a local unlocked wallet.\n\nKeep in mind the key to the security of the network is that 51% of the funds are pointed to trusted representatives that will generally not argue about chain forks. \n\nIn most deployments the best bet is to heavily centralize your voting nodes, this is unless you are intentionally trying to build a distributed ledger and security model like the main Nano live net. Achieving that will be a long and difficult task.\n\n#### Network peers\n\nTo a normal user simply transacting on the network using off the shelf tools like a web wallet and web based block explorers is generally all that is required. They get a number in a ledger somewhere and are able to locally sign and publish blocks using their private key using your published RPC endpoints.\n\nFor advanced users and just to generally make the network more robust, network operators should promote people running their own nodes. Using this image a network peer simply needs to run a docker run command with your pre-configured variables. IE given the generation example from above in the `Your Genesis account` section:\n\n```\ndocker create \\\n  --name=nano \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.mydomain.com \\\n  -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n  -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n  -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n\nWhen the container spins up it will reach out to the node to bootstrap it's local ledger from peering.mydomain.com . This node once fully synced will be able to run local RPC commands to plug into a wallet and default Nano node wallet commands for automated pocketing of transactions etc. It will also get a list of other peers on the network from it's initial network peering and start participating in your distributed cryptocurrency network.\n\n#### Public RPC endpoints\nThe key to users going to a webpage and managing the funds on your network is the ability to get blockchain information and publish new blocks to theirs. As mentioned earlier we bundle a basic firewall with a core set of RPC functions whitelisted that should be safe to expose publically. \n\nFrom a network design perspective these nodes should be purely what you would consider client peers and never have any wallets registered or private keys stored on them. Also for redundancy optmimally these peers should be run in a cluster behind a load balancer. For standard nodes you are building out a large P2P network, but in the case of the RPC endpoint and specifically the URL the end user is going to pass when accessing their wallet it is up to you to make that resilient.\n\n#### Clientside javascript wallet\nCurrently we publish a pure javascript clientside wallet located here:  \n\nhttps://github.com/linuxserver/nano-wallet\n\nIt is designed to be run 100% clientside in any web browser and use public RPC endpoints to hook into any network and conduct transactions by locally signing then publishing the result.\nThis can be hosted locally with any simple webserver and pointed to a locally run peer, but for full functionality we reccomend providing a public Https URL with these files along with plugging in legitamite SSL certificates into your RPC endpoints running on 7077.\n\n# Running a node on the LinuxServer network\n\nWe maintain our own network which users can get funds to transact on from our [Discord](https://discord.gg/YWrKVTn) server. If you would like to run a node on our network here is our Docker run command:\n```\ndocker create \\\n  --name=lsio-node \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.linuxserver.io \\\n  -e LIVE_GENESIS_PUB=79F2E157B5667F1C8B6CCB6DF691DAC032B85DEC39E231D29976DCED05F5B1BE \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1yhkw7ducsmz5k7pskufytaxoi3kq3gyrgh489bbkxpwxn4zdefyn4rmrrkk \\\n  -e LIVE_GENESIS_WORK=c51204c6b69384cb \\\n  -e LIVE_GENESIS_SIG=90DDE7B4DC038811180FF5DDE8594F1774542A7AADE3DB71A57AA38A5AED42672E1E8D7ACFAC315BDB0EB5DCB542C610B9C49B2560AE575073855259AF065509 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n"},{"id":"nano-wallet","name":"nano-wallet","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n\nThis container is a simple nginx wrapper for the light wallet located [here](https://github.com/linuxserver/nano-wallet). You will need to pass a valid RPC host when accessing this container.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nano-wallet"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nano-wallet"}],"containers":[{"name":"nano-wallet","image":"linuxserver/nano-wallet","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"ports":[{"container":"80","description":"Webserver port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nano-wallet","project_url":"https://nano.org/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n\nThis container is a simple nginx wrapper for the light wallet located [here](https://github.com/linuxserver/nano-wallet). You will need to pass a valid RPC host when accessing this container.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Webserver port"}],"param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"\nThis container requires a Nano RPC endpoint to communicate with whether a public network or your own, see [here](https://hub.docker.com/r/linuxserver/nano) for more information.\n\nSimply access the container at the URL:\n\nhttp://localhost/#/THE_IP_OR_HOSTNAME_OF_RPC_ENDPOINT\n","changelogs":[{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"23.05.20:","desc":"Initial Release."}]}},"setup":"\nThis container requires a Nano RPC endpoint to communicate with whether a public network or your own, see [here](https://hub.docker.com/r/linuxserver/nano) for more information.\n\nSimply access the container at the URL:\n\nhttp://localhost/#/THE_IP_OR_HOSTNAME_OF_RPC_ENDPOINT\n"},{"id":"netbootxyz","name":"netbootxyz","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to PXE boot various operating system installers or utilities from one place within the BIOS without the need of having to go retrieve the media to run the tool. iPXE is used to provide a user friendly menu from within the BIOS that lets you easily choose the operating system you want along with any specific types of versions or bootable flags.","icon":"https://netboot.xyz/images/netboot.xyz.gif","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/netbootxyz"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-netbootxyz"}],"containers":[{"name":"netbootxyz","image":"linuxserver/netbootxyz","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/assets","description":"Storage for NETBOOT.XYZ bootable assets (live CDs and other files)"},{"container":"/config","description":"Storage for boot menu files and web application config","key":"config"}],"ports":[{"container":"3000","description":"Web configuration interface.","protocol":"tcp","web":false},{"container":"69/udp","description":"TFTP Port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"netbootxyz","project_url":"https://netboot.xyz","project_logo":"https://netboot.xyz/images/netboot.xyz.gif","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to PXE boot various operating system installers or utilities from one place within the BIOS without the need of having to go retrieve the media to run the tool. iPXE is used to provide a user friendly menu from within the BIOS that lets you easily choose the operating system you want along with any specific types of versions or bootable flags.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Web application for full self hosting"},{"tag":"tftp","desc":"TFTP server only with NETBOOT.XYZ boot files"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Storage for boot menu files and web application config"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web configuration interface."},{"external_port":"69","internal_port":"69/udp","port_desc":"TFTP Port."}],"param_usage_include_env":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MENU_VERSION","env_value":"1.9.9","desc":"Specify a specific version of boot files you want to use from NETBOOT.XYZ (unset pulls latest)"},{"env_var":"PORT_RANGE","env_value":"30000:30010","desc":"Specify the port range tftp will use for data transfers [(see Wikipedia)](https://en.wikipedia.org/wiki/Trivial_File_Transfer_Protocol#Details)"},{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a sobfolder if running this behind a reverse proxy (IE /proxy/)"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8080","internal_port":"80","port_desc":"NGINX server for hosting assets."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/assets","vol_host_path":"/path/to/assets","desc":"Storage for NETBOOT.XYZ bootable assets (live CDs and other files)"}],"app_setup_block_enabled":true,"app_setup_block":"To use this image you need an existing DHCP server where you can set this TFTP server as your DHCP boot destination. This image does not contain a DHCP server nor do we aim to support one in the future. This is simply a TFTP server hosting the latest IPXE kernel builds from [netboot.xyz]({{ project_url }}). If you are interested in their project and lack the ability to setup a DHCP server to boot this payload they also have USB stick images you can use available on their [downloads page]({{ project_url }}/downloads/).\n\n### Router Setup Examples\n\n#### PFSense\nServices -> DHCP Server\n\nSet both the option for \"TFTP Server\" and the options under the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP used for TFTP Server\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### OPNsense\nServices -> DHCP Server\n\nUnder the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP of docker host\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### Unifi Security Gateway (with the controller)\nNetworks -> LAN (or the network you want to boot from) -> ADVANCED DHCP OPTIONS\n* tick Enable network boot\n* Server-  YOURSERVERIP\n* Filename- `netboot.xyz.kpxe`\n\n#### EdgeOS/VyOS\nConnect via SSH\n```\nconfigure\nset service dhcp-server use-dnsmasq enable\nset service dns forwarding options \"dhcp-match=set:bios,60,PXEClient:Arch:00000\"\nset service dns forwarding options \"dhcp-boot=tag:bios,netboot.xyz.kpxe,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32,60,PXEClient:Arch:00002\"\nset service dns forwarding options \"dhcp-boot=tag:efi32,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32-1,60,PXEClient:Arch:00006\"\nset service dns forwarding options \"dhcp-boot=tag:efi32-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64,60,PXEClient:Arch:00007\"\nset service dns forwarding options \"dhcp-boot=tag:efi64,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-1,60,PXEClient:Arch:00008\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-2,60,PXEClient:Arch:00009\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-2,netboot.xyz.efi,,SERVERIP\"\ncommit; save\n```\n\n#### DD-WRT\nAdministration -> Services -> Additional DNSMasq Options\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### Tomato\nAdvanced -> DHCP/DNS -> Dnsmasq Custom configuration\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### OpenWRT\n```\nuci set dhcp.@dnsmasq[0].dhcp_match=set:bios,60,PXEClient:Arch:00000\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32,60,PXEClient:Arch:00002\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32-1,60,PXEClient:Arch:00006\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64,60,PXEClient:Arch:00007\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-1,60,PXEClient:Arch:00008\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-2,60,PXEClient:Arch:00009\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\nuci commit\n/etc/init.d/dnsmasq restart\n```\n#### Microsoft Server DHCP\n\n* Run the DHCP program\n* Under Scope/Scope Options\n* check option 066 and enter the FQDN or IP of your TFTP boot server\n* check option 067 and enter one of the following bootfile names:\n   * Default BIOS file name- netboot.xyz.kpxe\n   * UEFI 32 bit file name- netboot.xyz.efi\n   * UEFI 64 bit file name- netboot.xyz.efi\n\nAnything else from a router standpoint is a crapshoot for supporting Dnsmasq options or proprietary PXE boot options, check Google for support (try your exact router model number with 'pxe boot') or look into setting up your own DHCP server in Linux.\n\nThis image also contains `netboot.xyz.efi` which can be used to boot using UEFI network boot. The UEFI boot and menu will have limited functionality if you choose to use it. \n","changelogs":[{"date":"12.10.22:","desc":"Rebasing to Alpine 3.16, migrate to s6v3."},{"date":"29.04.21:","desc":"Rebasing to alpine 3.13, add SUBFOLDER env variable."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"13.12.19:","desc":"Swapping latest tag over to webapp stack for management."},{"date":"10.12.19:","desc":"Adding tftp branch to provide tftp only option to latest users."},{"date":"22.10.19:","desc":"Initial release."}]}},"setup":"To use this image you need an existing DHCP server where you can set this TFTP server as your DHCP boot destination. This image does not contain a DHCP server nor do we aim to support one in the future. This is simply a TFTP server hosting the latest IPXE kernel builds from [netboot.xyz]({{ project_url }}). If you are interested in their project and lack the ability to setup a DHCP server to boot this payload they also have USB stick images you can use available on their [downloads page]({{ project_url }}/downloads/).\n\n### Router Setup Examples\n\n#### PFSense\nServices -> DHCP Server\n\nSet both the option for \"TFTP Server\" and the options under the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP used for TFTP Server\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### OPNsense\nServices -> DHCP Server\n\nUnder the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP of docker host\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### Unifi Security Gateway (with the controller)\nNetworks -> LAN (or the network you want to boot from) -> ADVANCED DHCP OPTIONS\n* tick Enable network boot\n* Server-  YOURSERVERIP\n* Filename- `netboot.xyz.kpxe`\n\n#### EdgeOS/VyOS\nConnect via SSH\n```\nconfigure\nset service dhcp-server use-dnsmasq enable\nset service dns forwarding options \"dhcp-match=set:bios,60,PXEClient:Arch:00000\"\nset service dns forwarding options \"dhcp-boot=tag:bios,netboot.xyz.kpxe,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32,60,PXEClient:Arch:00002\"\nset service dns forwarding options \"dhcp-boot=tag:efi32,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32-1,60,PXEClient:Arch:00006\"\nset service dns forwarding options \"dhcp-boot=tag:efi32-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64,60,PXEClient:Arch:00007\"\nset service dns forwarding options \"dhcp-boot=tag:efi64,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-1,60,PXEClient:Arch:00008\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-2,60,PXEClient:Arch:00009\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-2,netboot.xyz.efi,,SERVERIP\"\ncommit; save\n```\n\n#### DD-WRT\nAdministration -> Services -> Additional DNSMasq Options\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### Tomato\nAdvanced -> DHCP/DNS -> Dnsmasq Custom configuration\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### OpenWRT\n```\nuci set dhcp.@dnsmasq[0].dhcp_match=set:bios,60,PXEClient:Arch:00000\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32,60,PXEClient:Arch:00002\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32-1,60,PXEClient:Arch:00006\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64,60,PXEClient:Arch:00007\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-1,60,PXEClient:Arch:00008\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-2,60,PXEClient:Arch:00009\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\nuci commit\n/etc/init.d/dnsmasq restart\n```\n#### Microsoft Server DHCP\n\n* Run the DHCP program\n* Under Scope/Scope Options\n* check option 066 and enter the FQDN or IP of your TFTP boot server\n* check option 067 and enter one of the following bootfile names:\n   * Default BIOS file name- netboot.xyz.kpxe\n   * UEFI 32 bit file name- netboot.xyz.efi\n   * UEFI 64 bit file name- netboot.xyz.efi\n\nAnything else from a router standpoint is a crapshoot for supporting Dnsmasq options or proprietary PXE boot options, check Google for support (try your exact router model number with 'pxe boot') or look into setting up your own DHCP server in Linux.\n\nThis image also contains `netboot.xyz.efi` which can be used to boot using UEFI network boot. The UEFI boot and menu will have limited functionality if you choose to use it. \n"},{"id":"netbox","name":"netbox","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an IP address management (IPAM) and data center infrastructure management (DCIM) tool. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It is intended to function as a domain-specific source of truth for network operations.\n","icon":"https://raw.githubusercontent.com/netbox-community/netbox/develop/docs/netbox_logo.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/netbox"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-netbox"}],"containers":[{"name":"netbox","image":"linuxserver/netbox","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"<TZ>","description":"Timezone (i.e., America/New_York)"},{"id":"SUPERUSER_EMAIL","default":"<SUPERUSER_EMAIL>","description":"Email address for `admin` account"},{"id":"SUPERUSER_PASSWORD","default":"<SUPERUSER_PASSWORD>","description":"Password for `admin` account"},{"id":"ALLOWED_HOST","default":"<ALLOWED_HOST>","description":"The hostname you will use to access the app (i.e., netbox.example.com)"},{"id":"DB_NAME","default":"<DB_NAME>","description":"Database name (default: netbox)"},{"id":"DB_USER","default":"<DB_USER>","description":"Database user"},{"id":"DB_PASSWORD","default":"<DB_PASSWORD>","description":"Database password"},{"id":"DB_HOST","default":"<DB_HOST>","description":"Database host (default: postgres)"},{"id":"DB_PORT","default":"<DB_PORT>","description":"Database port (defaul: 5432)"},{"id":"REDIS_HOST","default":"<REDIS_HOST>","description":"Redis host (default: redis)"},{"id":"REDIS_PORT","default":"<REDIS_PORT>","description":"Redis port number (default: 6379)"},{"id":"REDIS_PASSWORD","default":"<REDIS_PASSWORD>","description":"Redis password (default: none)"},{"id":"REDIS_DB_TASK","default":"<REDIS_DB_TASK>","description":"Redis database ID for tasks (default: 0)"},{"id":"REDIS_DB_CACHE","default":"<REDIS_DB_CACHE>","description":"Redis database ID for caching (default: 1)"},{"id":"BASE_PATH","default":"<BASE_PATH>","description":"The path you will use to access the app (i.e., /netbox, optional, default: none)"},{"id":"REMOTE_AUTH_ENABLED","default":"<REMOTE_AUTH_ENABLED>","description":"Enable remote authentication (optional, default: False)"},{"id":"REMOTE_AUTH_BACKEND","default":"<REMOTE_AUTH_BACKEND>","description":"Python path to the custom Django authentication backend to use for external user authentication (optional, default: netbox.authentication.RemoteUserBackend)"},{"id":"REMOTE_AUTH_HEADER","default":"<REMOTE_AUTH_HEADER>","description":"Name of the HTTP header which informs NetBox of the currently authenticated user. (optional, default: HTTP_REMOTE_USER)"},{"id":"REMOTE_AUTH_AUTO_CREATE_USER","default":"<REMOTE_AUTH_AUTO_CREATE_USER>","description":"If true, NetBox will automatically create local accounts for users authenticated via a remote service (optional, default: False)"},{"id":"REMOTE_AUTH_DEFAULT_GROUPS","default":"<REMOTE_AUTH_DEFAULT_GROUPS>","description":"The list of groups to assign a new user account when created using remote authentication (optional, default: [])"},{"id":"REMOTE_AUTH_DEFAULT_PERMISSIONS","default":"<REMOTE_AUTH_DEFAULT_PERMISSIONS>","description":"A mapping of permissions to assign a new user account when created using remote authentication (optional, default: {})"}],"volumes":[{"container":"/config","description":"config directory volume mapping","key":"config"}],"ports":[{"container":"8000","description":"will map the container's port 8000 to port 8000 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"netbox","project_url":"https://github.com/netbox-community/netbox","project_logo":"https://raw.githubusercontent.com/netbox-community/netbox/develop/docs/netbox_logo.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an IP address management (IPAM) and data center infrastructure management (DCIM) tool. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It is intended to function as a domain-specific source of truth for network operations.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data on host>","desc":"config directory volume mapping"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"<TZ>","desc":"Timezone (i.e., America/New_York)"},{"env_var":"SUPERUSER_EMAIL","env_value":"<SUPERUSER_EMAIL>","desc":"Email address for `admin` account"},{"env_var":"SUPERUSER_PASSWORD","env_value":"<SUPERUSER_PASSWORD>","desc":"Password for `admin` account"},{"env_var":"ALLOWED_HOST","env_value":"<ALLOWED_HOST>","desc":"The hostname you will use to access the app (i.e., netbox.example.com)"},{"env_var":"DB_NAME","env_value":"<DB_NAME>","desc":"Database name (default: netbox)"},{"env_var":"DB_USER","env_value":"<DB_USER>","desc":"Database user"},{"env_var":"DB_PASSWORD","env_value":"<DB_PASSWORD>","desc":"Database password"},{"env_var":"DB_HOST","env_value":"<DB_HOST>","desc":"Database host (default: postgres)"},{"env_var":"DB_PORT","env_value":"<DB_PORT>","desc":"Database port (defaul: 5432)"},{"env_var":"REDIS_HOST","env_value":"<REDIS_HOST>","desc":"Redis host (default: redis)"},{"env_var":"REDIS_PORT","env_value":"<REDIS_PORT>","desc":"Redis port number (default: 6379)"},{"env_var":"REDIS_PASSWORD","env_value":"<REDIS_PASSWORD>","desc":"Redis password (default: none)"},{"env_var":"REDIS_DB_TASK","env_value":"<REDIS_DB_TASK>","desc":"Redis database ID for tasks (default: 0)"},{"env_var":"REDIS_DB_CACHE","env_value":"<REDIS_DB_CACHE>","desc":"Redis database ID for caching (default: 1)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_PATH","env_value":"<BASE_PATH>","desc":"The path you will use to access the app (i.e., /netbox, optional, default: none)"},{"env_var":"REMOTE_AUTH_ENABLED","env_value":"<REMOTE_AUTH_ENABLED>","desc":"Enable remote authentication (optional, default: False)"},{"env_var":"REMOTE_AUTH_BACKEND","env_value":"<REMOTE_AUTH_BACKEND>","desc":"Python path to the custom Django authentication backend to use for external user authentication (optional, default: netbox.authentication.RemoteUserBackend)"},{"env_var":"REMOTE_AUTH_HEADER","env_value":"<REMOTE_AUTH_HEADER>","desc":"Name of the HTTP header which informs NetBox of the currently authenticated user. (optional, default: HTTP_REMOTE_USER)"},{"env_var":"REMOTE_AUTH_AUTO_CREATE_USER","env_value":"<REMOTE_AUTH_AUTO_CREATE_USER>","desc":"If true, NetBox will automatically create local accounts for users authenticated via a remote service (optional, default: False)"},{"env_var":"REMOTE_AUTH_DEFAULT_GROUPS","env_value":"<REMOTE_AUTH_DEFAULT_GROUPS>","desc":"The list of groups to assign a new user account when created using remote authentication (optional, default: [])"},{"env_var":"REMOTE_AUTH_DEFAULT_PERMISSIONS","env_value":"<REMOTE_AUTH_DEFAULT_PERMISSIONS>","desc":"A mapping of permissions to assign a new user account when created using remote authentication (optional, default: {})"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"will map the container's port 8000 to port 8000 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Netbox requires a postgres database and a redis instance.\n\nAccess the WebUI at <your-ip>:8000. For more information, check out [NetBox](https://github.com/netbox-community/netbox).\n","changelogs":[{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"01.08.22:","desc":"Remove py3-pillow, add tiff to fix deps."},{"date":"26.07.22:","desc":"Add py3-pillow package back on arm to fix build issue."},{"date":"10.12.21:","desc":"Remove py3-pillow package to fix dependency issue with 3.2.0."},{"date":"10.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.04.21:","desc":"Added Redis database environment variables."},{"date":"03.02.21:","desc":"Added remote authentication environment variables."},{"date":"02.01.21:","desc":"Added BASE_PATH environment variable."},{"date":"23.08.20:","desc":"Initial Release."}]}},"setup":"Netbox requires a postgres database and a redis instance.\n\nAccess the WebUI at <your-ip>:8000. For more information, check out [NetBox](https://github.com/netbox-community/netbox).\n"},{"id":"nextcloud","name":"nextcloud","description":"[{{ project_name|capitalize }}]({{ project_url }}) gives you access to all your files wherever you are.\n\nWhere are your photos and documents? With Nextcloud you pick a server of your choice, at home, in a data center or at a provider. And that is where your files will be. Nextcloud runs on that server, protecting your data and giving you access from your desktop or mobile devices. Through Nextcloud you also access, sync and share your existing data on that FTP drive at the office, a Dropbox or a NAS you have at home.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nextcloud-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nextcloud"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nextcloud"}],"containers":[{"name":"nextcloud","image":"linuxserver/nextcloud","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Nextcloud configs.","key":"config"},{"container":"/data","description":"Your personal data."}],"ports":[{"container":"443","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nextcloud","project_url":"https://nextcloud.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nextcloud-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) gives you access to all your files wherever you are.\n\nWhere are your photos and documents? With Nextcloud you pick a server of your choice, at home, in a data center or at a provider. And that is where your files will be. Nextcloud runs on that server, protecting your data and giving you access from your desktop or mobile devices. Through Nextcloud you also access, sync and share your existing data on that FTP drive at the office, a Dropbox or a NAS you have at home.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Nextcloud releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Nextcloud configs."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Your personal data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"443","internal_port":"443","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `https://<your-ip>:443`, for more information check out [Nextcloud]({{ project_url }}).\n\nDocker image update and recreation of container alone won't update nextcloud version. \n\nIn order to update nextcloud version, you have two options, firstly make sure you are using the latest docker image,then either \n\n1.  Perform the in app gui update. \n2.  Use the CLI version by running `docker exec -it nextcloud updater.phar`\n (Both of these are described [here](https://docs.nextcloud.com/server/latest/admin_manual/maintenance/update.html))\n\nNote:  Both `occ` and `updater.phar` can be run without prepending with `sudo -u abc php` or `sudo -u www-data php`\n\nIf you are not customizing our default nginx configuration you will need to remove the file:\n```\n/config/nginx/site-confs/default.conf\n```\nThen restart the container to replace it with the latest one. \n\n### Collaborative Editing\n\nNextcloud's built-in collaborative editing packages (Collabora/CODE and OnlyOffice) only work on x86_64 systems with glibc, and therefore they are not compatible with our images. You should create separate containers for them and set them up in Nextcloud with their respective connector addons.\n\nIf (auto) installed, those built-in packages may cause instability and should be removed.\n","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"30.09.22:","desc":"Disabled `output_buffering` as per [nextcloud docs](https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/big_file_upload_configuration.html"},{"date":"21.05.22:","desc":"Update version check endpoint."},{"date":"28.04.22:","desc":"Increase OPCache interned strings buffered setting to 16."},{"date":"14.04.22:","desc":"Nginx default site config updated for v23 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container). Fix LDAP connection."},{"date":"11.09.21:","desc":"Rebasing to alpine 3.14"},{"date":"21.03.21:","desc":"Publish `php8` tag for testing."},{"date":"25.02.21:","desc":"Nginx default site config updated for v21 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"21.01.21:","desc":"Fix php iconv (was breaking the mail addon). If installed, attempt to remove broken CODE Server app during startup."},{"date":"20.01.21:","desc":"Increase php fcgi timeout to prevent 504 Gateway timeout errors (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"16.01.21:","desc":"Rebasing to alpine 3.13. Users with issues on 32-bit arm, [see this article](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal-and-alpine-3-13)."},{"date":"12.08.20:","desc":"Various updates to default site config, including added support for webfinger (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"03.06.20:","desc":"Rebasing to alpine 3.12"},{"date":"03.06.20:","desc":"Add php7-bcmath and php7-fileinfo"},{"date":"31.05.20:","desc":"Add aliases for occ and updater.phar"},{"date":"31.03.20:","desc":"Allow crontab to be user customized, fix logrotate."},{"date":"17.01.20:","desc":"Updated php.ini defaults and site config, including an optional HSTS directive (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"18.11.19:","desc":"Nginx default site config updated for v17 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"28.10.19:","desc":"Change cronjob to run every 5 minutes."},{"date":"24.10.19:","desc":"Nginx default site config updated due to CVE-2019-11043 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"14.07.19:","desc":"Download nextcloud during build time."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"27.02.19:","desc":"Updating base nginx config to sync up with v15 requirements."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"25.01.19:","desc":"Add php7-phar for occ upgrades."},{"date":"05.09.18:","desc":"Rebase to alpine 3.8."},{"date":"11.06.18:","desc":"Use latest rather than specific version for initial install."},{"date":"26.04.18:","desc":"Bump default install to 13.0.1."},{"date":"06.02.18:","desc":"Bump default install to 13.0.0."},{"date":"26.01.18:","desc":"Rebase to alpine 3.7, bump default install to 12.0.5."},{"date":"12.12.17:","desc":"Bump default install to 12.0.4, fix continuation lines."},{"date":"15.10.17:","desc":"Sed php.ini for opcache requirements in newer nextcloud versions."},{"date":"20.09.17:","desc":"Bump default install to 12.0.3."},{"date":"19.08.17:","desc":"Bump default install to 12.0.2."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"22.05.17:","desc":"Update to nextcloud 12.0, adding required dependecies and note about commenting out SAMEORIGIN; line."},{"date":"03.05.17:","desc":"Use community repo of memcache."},{"date":"07.03.17:","desc":"Release into main repository and upgrade to php7 and Alpine 3.5."}]}},"setup":"Access the webui at `https://<your-ip>:443`, for more information check out [Nextcloud]({{ project_url }}).\n\nDocker image update and recreation of container alone won't update nextcloud version. \n\nIn order to update nextcloud version, you have two options, firstly make sure you are using the latest docker image,then either \n\n1.  Perform the in app gui update. \n2.  Use the CLI version by running `docker exec -it nextcloud updater.phar`\n (Both of these are described [here](https://docs.nextcloud.com/server/latest/admin_manual/maintenance/update.html))\n\nNote:  Both `occ` and `updater.phar` can be run without prepending with `sudo -u abc php` or `sudo -u www-data php`\n\nIf you are not customizing our default nginx configuration you will need to remove the file:\n```\n/config/nginx/site-confs/default.conf\n```\nThen restart the container to replace it with the latest one. \n\n### Collaborative Editing\n\nNextcloud's built-in collaborative editing packages (Collabora/CODE and OnlyOffice) only work on x86_64 systems with glibc, and therefore they are not compatible with our images. You should create separate containers for them and set them up in Nextcloud with their respective connector addons.\n\nIf (auto) installed, those built-in packages may cause instability and should be removed.\n"},{"id":"nginx","name":"nginx","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple webserver with php support. The config files reside in `/config` for easy user customization.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nginx-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nginx"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nginx"}],"containers":[{"name":"nginx","image":"linuxserver/nginx","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains your www content and all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"http","protocol":"tcp","web":false},{"container":"443","description":"https","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nginx","project_url":"https://nginx.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nginx-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple webserver with php support. The config files reside in `/config` for easy user customization.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains your www content and all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http"},{"external_port":"443","internal_port":"443","port_desc":"https"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Add your web files to `/config/www` for hosting.  \nModify the nginx, php and site config files under `/config` as needed  \n*Protip: This container is best combined with a sql server, e.g. [mariadb](https://hub.docker.com/r/linuxserver/mariadb/)*\n","changelogs":[{"date":"16.01.23:","desc":"Remove nchan module because it keeps causing crashes."},{"date":"22.12.22:","desc":"Rebase to Alpine 3.17 with PHP 8.1, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.05.22:","desc":"Install nginx version from 3.14."},{"date":"01.07.21:","desc":"Rebasing to alpine 3.14."},{"date":"24.06.21:","desc":"Update default nginx conf folder."},{"date":"12.04.21:","desc":"Add php7-gmp and php7-pecl-mailparse."},{"date":"13.02.21:","desc":"Remove php7-pecl-imagick (it now installs the full imagemagick with too much crud). Users can install it via [this docker mod](https://github.com/linuxserver/docker-mods/tree/swag-imagemagick)."},{"date":"09.02.21:","desc":"Rebasing to alpine 3.13. Add nginx mods brotli and dav-ext. Remove nginx mods lua and lua-upstream (due to regression over the last couple of years)."},{"date":"08.09.20:","desc":"Add php7-xsl."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.04.20:","desc":"Fix unwanted shutdown of the container."},{"date":"11.03.20:","desc":"Add php7-sodium."},{"date":"18.02.20:","desc":"Add geoip2, suppress lua warning."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"18.12.19:","desc":"Add php7-imap and php7-pecl-apcu."},{"date":"13.11.19:","desc":"Add php7-pdo_odbc."},{"date":"24.10.19:","desc":"Add php7-pecl-imagick."},{"date":"06.08.19:","desc":"Add php7-bcmath, ph7-pear, php7-xmlrpc and php7-ftp."},{"date":"02.08.19:","desc":"Add php7-ldap."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"08.05.19:","desc":"Remove default.conf when nginx is upgraded in downstream image."},{"date":"30.04.19:","desc":"Add php-redis."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"02.03.19:","desc":"Add php intl and posix modules."},{"date":"28.02.19:","desc":"Add php7-opcache, remove memcached service due to issues on aarch64 (let us know if you need to enable it)."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.11.18:","desc":"Attempt to upgrade packages during build."},{"date":"28.09.18:","desc":"Multi-arch image."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8, inherit nginx.conf from nginx baseimage."},{"date":"11.05.18:","desc":"Add php pgsql support."},{"date":"19.04.18:","desc":"Bind memcached to localhost only, add php7-sqlite3."},{"date":"05.01.18:","desc":"Rebase to alpine 3.7."},{"date":"08.11.17:","desc":"Add php7 soap module."},{"date":"31.10.17:","desc":"Add php7 exif and xmlreader modules."},{"date":"30.09.17:","desc":"Copy additional root files into image."},{"date":"24.09.17:","desc":"Add memcached service."},{"date":"31.08.17:","desc":"Add php7-phar."},{"date":"14.07.17:","desc":"Enable modules dynamically in nginx.conf."},{"date":"22.06.17:","desc":"Add various nginx modules and enable all modules in the default nginx.conf."},{"date":"05.06.17:","desc":"Add php7-bz2."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"18.04.17:","desc":"Add php7-sockets."},{"date":"27.02.17:","desc":"Rebase to alpine 3.5, update to nginx 1.10.2 and php7."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"10.09.16:","desc":"Add badges to README."},{"date":"05.12.15:","desc":"Intial Release."}]}},"setup":"Add your web files to `/config/www` for hosting.  \nModify the nginx, php and site config files under `/config` as needed  \n*Protip: This container is best combined with a sql server, e.g. [mariadb](https://hub.docker.com/r/linuxserver/mariadb/)*\n"},{"id":"ngircd","name":"ngircd","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, portable and lightweight Internet Relay Chat server for small or private networks, developed under the GNU General Public License (GPL). It is easy to configure, can cope with dynamic IP addresses, and supports IPv6, SSL-protected connections as well as PAM for authentication. It is written from scratch and not based on the original IRCd.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ngircd-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ngircd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ngircd"}],"containers":[{"name":"ngircd","image":"linuxserver/ngircd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"Where `ngircd.conf` is stored","key":"config"}],"ports":[{"container":"6667","description":"ngircd port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ngircd","project_url":"https://ngircd.barton.de/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ngircd-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, portable and lightweight Internet Relay Chat server for small or private networks, developed under the GNU General Public License (GPL). It is easy to configure, can cope with dynamic IP addresses, and supports IPv6, SSL-protected connections as well as PAM for authentication. It is written from scratch and not based on the original IRCd.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/ngircd/config","desc":"Where `ngircd.conf` is stored"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6667","internal_port":"6667","port_desc":"ngircd port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"- To setup ngircd you will need to edit `/config/ngircd.conf` which is created the first time the container is run, edit the file and restart the container to implement any config changes.  \n- For information see the ngircd site [here.](https://github.com/ngircd/ngircd/blob/master/doc/sample-ngircd.conf.tmpl)\n","changelogs":[{"date":"11.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"04.07.19:","desc":"Initial release."}]}},"setup":"- To setup ngircd you will need to edit `/config/ngircd.conf` which is created the first time the container is run, edit the file and restart the container to implement any config changes.  \n- For information see the ngircd site [here.](https://github.com/ngircd/ngircd/blob/master/doc/sample-ngircd.conf.tmpl)\n"},{"id":"nntp2nntp","name":"nntp2nntp","description":"[{{ project_name|capitalize }}]({{ project_url }}) proxy allow you to use your NNTP Account from multiple systems, each with own user name and password. It fully supports SSL and you can also limit the access to proxy with SSL certificates. nntp2nntp proxy is very simple and pretty fast.\n## Warning\n\nWhilst we know of no nntp2nntp security issues the [upstream code](https://github.com/linuxserver/nntp2nntp) for this project has received no changes since 06.08.15 and is likely abandoned permanently.  For this reason we strongly recommend you do not make this application public facing and if you must do so other layers of security and SSL should be considered an absolute bare minimum requirement.  We see this proxy being used primarily on a LAN so that all the users NNTP applications can share a common set of internal credentials allowing for central managment of the upstream account e.g change provider, server, thread limits for all applications with one global config change.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nntp2nntp.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nntp2nntp"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nntp2nntp"}],"containers":[{"name":"nntp2nntp","image":"linuxserver/nntp2nntp","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"PUID","default":"<yourUID>","description":"specify your UID"},{"id":"PGID","default":"<yourGID>","description":"specify your GID"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"}],"ports":[{"container":"1563","description":"will map the container's port 1563 to port 1563 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nntp2nntp","project_url":"https://github.com/linuxserver/nntp2nntp","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nntp2nntp.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) proxy allow you to use your NNTP Account from multiple systems, each with own user name and password. It fully supports SSL and you can also limit the access to proxy with SSL certificates. nntp2nntp proxy is very simple and pretty fast.\n## Warning\n\nWhilst we know of no nntp2nntp security issues the [upstream code](https://github.com/linuxserver/nntp2nntp) for this project has received no changes since 06.08.15 and is likely abandoned permanently.  For this reason we strongly recommend you do not make this application public facing and if you must do so other layers of security and SSL should be considered an absolute bare minimum requirement.  We see this proxy being used primarily on a LAN so that all the users NNTP applications can share a common set of internal credentials allowing for central managment of the upstream account e.g change provider, server, thread limits for all applications with one global config change.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v6-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"this will store config on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"PUID","env_value":"<yourUID>","desc":"specify your UID"},{"env_var":"PGID","env_value":"<yourGID>","desc":"specify your GID"},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"1563","internal_port":"1563","port_desc":"will map the container's port 1563 to port 1563 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Edit sample config file `config/nntp2nntp.conf` with upstream provider details and rename the local users.\n\nNew user passwords can be created by running the password hash generator\n```\ndocker exec -it nntp2nntp /usr/bin/nntp2nntp.py pass\n```\nentering the desired password and copying the resulting string to the relevant user line in `/config/nntp2nntp.conf`\n\nExample with a user called `Dave` and with a password of `password`\n```\nDave    = 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8\n```\n","changelogs":[{"date":"10.10.22:","desc":"Rebase to Alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.04.19:","desc":"Multiarch builds and build from Github fork."},{"date":"15.05.18:","desc":"Initial Release."}]}},"setup":"Edit sample config file `config/nntp2nntp.conf` with upstream provider details and rename the local users.\n\nNew user passwords can be created by running the password hash generator\n```\ndocker exec -it nntp2nntp /usr/bin/nntp2nntp.py pass\n```\nentering the desired password and copying the resulting string to the relevant user line in `/config/nntp2nntp.conf`\n\nExample with a user called `Dave` and with a password of `password`\n```\nDave    = 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8\n```\n"},{"id":"nzbget","name":"nzbget","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a usenet downloader, written in C++ and designed with performance in mind to achieve maximum download speed by using very little system resources.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nzbget-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nzbget"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nzbget"}],"containers":[{"name":"nzbget","image":"linuxserver/nzbget","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"NZBGET_USER","default":"nzbget","description":"Specify the user for web authentication."},{"id":"NZBGET_PASS","default":"tegbzn6789","description":"Specify the password for web authentication."}],"volumes":[{"container":"/downloads","description":"Location of downloads on disk."},{"container":"/config","description":"NZBGet App data.","key":"config"}],"ports":[{"container":"6789","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nzbget","project_url":"http://nzbget.net/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nzbget-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a usenet downloader, written in C++ and designed with performance in mind to achieve maximum download speed by using very little system resources.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_deprecation_status":true,"project_deprecation_message":"nzbget has been deprecated by its developers. Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable nzbget releases"},{"tag":"testing","desc":"nzbget pre-releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"NZBGet App data."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Location of downloads on disk."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6789","internal_port":"6789","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"NZBGET_USER","env_value":"nzbget","desc":"Specify the user for web authentication."},{"env_var":"NZBGET_PASS","env_value":"tegbzn6789","desc":"Specify the password for web authentication."}],"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at  `<your-ip>:6789` and the default login details (change ASAP) are\n\n`login:nzbget, password:tegbzn6789`\n\nTo allow scheduling, from the webui set the time correction value in settings/logging.\n\nTo change umask settings.\n\n![](http://i.imgur.com/A4VMbwE.png)\n\nscroll to bottom, set umask like this (example shown for unraid)\n\n![](http://i.imgur.com/mIqDEJJ.png)\n\nYou can add an additional mount point for intermediate unpacking folder with:-\n\n`-v </path/to/intermedia_unpacking_folder>:/intermediate`\n\nfor example, and changing the setting for InterDir in the PATHS tab of settings to `/intermediate`\n\n### Media folders\n\nWe have set `/downloads` as a ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"31.12.22:","desc":"Deprecate image.  Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd"},{"date":"27.11.22:","desc":"Advanced notice: This image will be deprecated on 2022-12-31. Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd"},{"date":"13.11.22:","desc":"Rebase master to 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"22.02.22:","desc":"Rebase to alpine 3.15, add six and python 7zip tools, allow env variables for credentials."},{"date":"04.07.21:","desc":"Rebase to alpine 3.14."},{"date":"28.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.10.20:","desc":"Fix python dependencies."},{"date":"24.08.20:","desc":"Fix ignored umask environment variable."},{"date":"08.06.20:","desc":"Symlink python3 bin to python."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12. Removing python2."},{"date":"13.05.20:","desc":"Add rarfile python package (for DeepUnrar)."},{"date":"01.01.20:","desc":"Add python3 alongside python2 during transition."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"13.06.19:","desc":"Add apprise, chardet & pynzbget packages."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"25.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"20.01.19:","desc":"Add pipeline logic and multi arch, build from source."},{"date":"21.08.18:","desc":"Rebase to alpine 3.8."},{"date":"20.02.18:","desc":"Add note about supplemental mount point for intermediate unpacking."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"02.09.17:","desc":"Place app in subfolder rather than /app."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"20.04.17:","desc":"Add testing branch."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README, perms fix on /app to allow updates."},{"date":"19.08.16:","desc":"Rebase to alpine linux."},{"date":"18.08.15:","desc":"Now useing latest version of unrar beta and implements the universal installer method."}]}},"setup":"Webui can be found at  `<your-ip>:6789` and the default login details (change ASAP) are\n\n`login:nzbget, password:tegbzn6789`\n\nTo allow scheduling, from the webui set the time correction value in settings/logging.\n\nTo change umask settings.\n\n![](http://i.imgur.com/A4VMbwE.png)\n\nscroll to bottom, set umask like this (example shown for unraid)\n\n![](http://i.imgur.com/mIqDEJJ.png)\n\nYou can add an additional mount point for intermediate unpacking folder with:-\n\n`-v </path/to/intermedia_unpacking_folder>:/intermediate`\n\nfor example, and changing the setting for InterDir in the PATHS tab of settings to `/intermediate`\n\n### Media folders\n\nWe have set `/downloads` as a ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n"},{"id":"nzbhydra2","name":"nzbhydra2","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a meta search application for NZB indexers, the \"spiritual successor\" to NZBmegasearcH, and an evolution of the original application [NZBHydra](https://github.com/theotherp/nzbhydra).\n\nIt provides easy access to a number of raw and newznab based indexers. The application NZBHydra 2 is replacing NZBHydra 1 and supports migrating from V1. Be wary that there may be some compatibility issues for those migrating from V1 to V2, so ensure you back up your old configuration before moving over to the new version. **NOTE:** The last version that supports migration is `linuxserver/nzbhydra2:v2.10.2-ls49`\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hydra-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nzbhydra2"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nzbhydra2"}],"containers":[{"name":"nzbhydra2","image":"linuxserver/nzbhydra2","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where nzbhydra2 should store config files.","key":"config"},{"container":"/downloads","description":"NZB download folder."}],"ports":[{"container":"5076","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nzbhydra2","project_url":"https://github.com/theotherp/nzbhydra2","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hydra-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a meta search application for NZB indexers, the \"spiritual successor\" to NZBmegasearcH, and an evolution of the original application [NZBHydra](https://github.com/theotherp/nzbhydra).\n\nIt provides easy access to a number of raw and newznab based indexers. The application NZBHydra 2 is replacing NZBHydra 1 and supports migrating from V1. Be wary that there may be some compatibility issues for those migrating from V1 to V2, so ensure you back up your old configuration before moving over to the new version. **NOTE:** The last version that supports migration is `linuxserver/nzbhydra2:v2.10.2-ls49`\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"dev","desc":"Prereleases from their GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where nzbhydra2 should store config files."},{"vol_path":"/downloads","vol_host_path":"/nzb/download","desc":"NZB download folder."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5076","internal_port":"5076","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"The web interface is at `<your ip>:5076` , to set up indexers and connections to your nzb download applications.\n","changelogs":[{"date":"22.01.23:","desc":"Update release URL for arch-specific packages."},{"date":"20.01.23:","desc":"Update dependencies for v5."},{"date":"10.12.22:","desc":"Bump master JRE to v17. Default mapIpToHost to false."},{"date":"11.09.22:","desc":"Migrate to s6v3."},{"date":"03.05.22:","desc":"Rebase to Jammy."},{"date":"18.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"01.05.20:","desc":"Reorganize container, Relocate app to /app/nzbhydra2/bin, Create /app/nzbhydra2/package_info, Use nzbhydra2wrapperPy3.py from zip."},{"date":"14.04.20:","desc":"Correct Name, Hydra2 -> NZBHydra2."},{"date":"08.01.20:","desc":"Switch to python3."},{"date":"05.01.20:","desc":"Add dev tag for prereleases."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.08.18:","desc":"Bump java version to 10, (bionic currently refers to it as version 11)."},{"date":"10.08.18:","desc":"Rebase to ubuntu bionic."},{"date":"15.04.18:","desc":"Change to port 5076 in the Dockerfile."},{"date":"11.01.18:","desc":"Initial Release."}]}},"setup":"The web interface is at `<your ip>:5076` , to set up indexers and connections to your nzb download applications.\n"},{"id":"ombi","name":"ombi","description":"[{{ project_name|capitalize }}]({{ project_url }}) allows you to host your own Plex Request and user management system.\nIf you are sharing your Plex server with other users, allow them to request new content using an easy to manage interface!\nManage all your requests for Movies and TV with ease, leave notes for the user and get notification when a user requests something.\nAllow your users to post issues against their requests so you know there is a problem with the audio etc.\nEven automatically send them weekly newsletters of new content that has been added to your Plex server!","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ombi.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ombi"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ombi"}],"containers":[{"name":"ombi","image":"linuxserver/ombi","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"/ombi","description":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"3579","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ombi","project_url":"https://ombi.io","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ombi.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) allows you to host your own Plex Request and user management system.\nIf you are sharing your Plex server with other users, allow them to request new content using an easy to manage interface!\nManage all your requests for Movies and TV with ease, leave notes for the user and get notification when a user requests something.\nAllow your users to post issues against their requests so you know there is a problem with the audio etc.\nEven automatically send them weekly newsletters of new content that has been added to your Plex server!","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3579","internal_port":"3579","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"/ombi","desc":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:3579`. Follow the setup wizard on initial install.  Then configure the required services.\n","changelogs":[{"date":"11.09.22:","desc":"Migrate to s6v3."},{"date":"01.05.22:","desc":"Rebase to Jammy."},{"date":"26.04.21:","desc":"Update tarball name, allow for v4 builds in stable."},{"date":"18.01.21:","desc":"Update upstream repo. Deprecate `v4-preview` tag, which is merged to `development` tag upstream."},{"date":"14.04.20:","desc":"Add Ombi donate links."},{"date":"10.05.19:","desc":"Added an optional env variable for base url setting."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Clarify info on tags and development builds."},{"date":"25.01.19:","desc":"Add info on tags and development builds."},{"date":"09.01.19:","desc":"Switch to multi-arch builds and add aarch64 image."},{"date":"11.03.18:","desc":"Add HOME env to Dockerfile."},{"date":"05.03.18:","desc":"Switch to Ombi v3 stable based on .net core."},{"date":"26.01.18:","desc":"Fix continuation lines."},{"date":"16.04.17:","desc":"Switch to using inhouse mono baseimage."},{"date":"17.02.17:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:3579`. Follow the setup wizard on initial install.  Then configure the required services.\n"},{"id":"openssh-server","name":"openssh-server","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a sandboxed environment that allows ssh access without giving keys to the entire server.\nGiving ssh access via private key often means giving full access to the server. This container creates a limited and sandboxed environment that others can ssh into.\nThe users only have access to the folders mapped and the processes running inside this container.","icon":"https://upload.wikimedia.org/wikipedia/en/6/65/OpenSSH_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/openssh-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-openssh-server"}],"containers":[{"name":"openssh-server","image":"linuxserver/openssh-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PUBLIC_KEY","default":"yourpublickey","description":"Optional ssh public key, which will automatically be added to authorized_keys."},{"id":"PUBLIC_KEY_FILE","default":"/path/to/file","description":"Optionally specify a file containing the public key (works with docker secrets)."},{"id":"PUBLIC_KEY_DIR","default":"/path/to/directory/containing/_only_/pubkeys","description":"Optionally specify a directory containing the public keys (works with docker secrets)."},{"id":"PUBLIC_KEY_URL","default":"https://github.com/username.keys","description":"Optionally specify a URL containing the public key."},{"id":"SUDO_ACCESS","default":"false","description":"Set to `true` to allow `linuxserver.io`, the ssh user, sudo access. Without `USER_PASSWORD` set, this will allow passwordless sudo access."},{"id":"PASSWORD_ACCESS","default":"false","description":"Set to `true` to allow user/password ssh access. You will want to set `USER_PASSWORD` or `USER_PASSWORD_FILE` as well."},{"id":"USER_PASSWORD","default":"password","description":"Optionally set a sudo password for `linuxserver.io`, the ssh user. If this or `USER_PASSWORD_FILE` are not set but `SUDO_ACCESS` is set to true, the user will have passwordless sudo access."},{"id":"USER_PASSWORD_FILE","default":"/path/to/file","description":"Optionally specify a file that contains the password. This setting supersedes the `USER_PASSWORD` option (works with docker secrets)."},{"id":"USER_NAME","default":"linuxserver.io","description":"Optionally specify a user name (Default:`linuxserver.io`)"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"2222","description":"ssh port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"openssh-server","project_url":"https://www.openssh.com/","project_logo":"https://upload.wikimedia.org/wikipedia/en/6/65/OpenSSH_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a sandboxed environment that allows ssh access without giving keys to the entire server.\nGiving ssh access via private key often means giving full access to the server. This container creates a limited and sandboxed environment that others can ssh into.\nThe users only have access to the folders mapped and the processes running inside this container.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":"optional","param_hostname":"{{ project_name }}","param_hostname_desc":"Optionally the hostname can be defined.","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"2222","internal_port":"2222","port_desc":"ssh port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PUBLIC_KEY","env_value":"yourpublickey","desc":"Optional ssh public key, which will automatically be added to authorized_keys."},{"env_var":"PUBLIC_KEY_FILE","env_value":"/path/to/file","desc":"Optionally specify a file containing the public key (works with docker secrets)."},{"env_var":"PUBLIC_KEY_DIR","env_value":"/path/to/directory/containing/_only_/pubkeys","desc":"Optionally specify a directory containing the public keys (works with docker secrets)."},{"env_var":"PUBLIC_KEY_URL","env_value":"https://github.com/username.keys","desc":"Optionally specify a URL containing the public key."},{"env_var":"SUDO_ACCESS","env_value":"false","desc":"Set to `true` to allow `linuxserver.io`, the ssh user, sudo access. Without `USER_PASSWORD` set, this will allow passwordless sudo access."},{"env_var":"PASSWORD_ACCESS","env_value":"false","desc":"Set to `true` to allow user/password ssh access. You will want to set `USER_PASSWORD` or `USER_PASSWORD_FILE` as well."},{"env_var":"USER_PASSWORD","env_value":"password","desc":"Optionally set a sudo password for `linuxserver.io`, the ssh user. If this or `USER_PASSWORD_FILE` are not set but `SUDO_ACCESS` is set to true, the user will have passwordless sudo access."},{"env_var":"USER_PASSWORD_FILE","env_value":"/path/to/file","desc":"Optionally specify a file that contains the password. This setting supersedes the `USER_PASSWORD` option (works with docker secrets)."},{"env_var":"USER_NAME","env_value":"linuxserver.io","desc":"Optionally specify a user name (Default:`linuxserver.io`)"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"If `PUBLIC_KEY` or `PUBLIC_KEY_FILE`, or `PUBLIC_KEY_DIR` variables are set, the specified keys will automatically be added to `authorized_keys`. If not, the keys can manually be added to `/config/.ssh/authorized_keys` and the container should be restarted.\nRemoving `PUBLIC_KEY` or `PUBLIC_KEY_FILE` variables from docker run environment variables will not remove the keys from `authorized_keys`. `PUBLIC_KEY_FILE` and `PUBLIC_KEY_DIR` can be used with docker secrets.\n\nWe provide the ability to set and allow password based access via the `PASSWORD_ACCESS` and `USER_PASSWORD` variables, though we as an organization discourage using password auth for public facing ssh endpoints.\n\nConnect to server via `ssh -i /path/to/private/key -p PORT USER_NAME@SERVERIP`\n\nSetting `SUDO_ACCESS` to `true` by itself will allow passwordless sudo. `USER_PASSWORD` and `USER_PASSWORD_FILE` allow setting an optional sudo password.\n\nThe users only have access to the folders mapped and the processes running inside this container.\nAdd any volume mappings you like for the users to have access to.\nTo install packages or services for users to access, use the LinuxServer container customization methods described [in this blog article](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/).\n\nSample use case is when a server admin would like to have automated incoming backups from a remote server to the local server, but they might not want all the other admins of the remote server to have full access to the local server.\nThis container can be set up with a mounted folder for incoming backups, and rsync installed via LinuxServer container customization described above, so that the incoming backups can proceed, but remote server and its admins' access would be limited to the backup folder.\n\nIt is also possible to run multiple copies of this container with different ports mapped, different folders mounted and access to different private keys for compartmentalized access.\n\n#### TIPS\nYou can volume map your own text file to `/etc/motd` to override the message displayed upon connection.\nYou can optionally set the docker argument `hostname`\n\n## Key Generation\n\nThis container has a helper script to generate an ssh private/public key. In order to generate a key please run:\n```\ndocker run --rm -it --entrypoint /keygen.sh linuxserver/openssh-server\n```\n\nThen simply follow the prompts.\nThe keys generated by this script are only displayed on your console output, so make sure to save them somewhere after generation.\n","changelogs":[{"date":"18.10.22:","desc":"Fix wrong behavior of password/passwordless sudo"},{"date":"11.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"15.09.22:","desc":"add netcat-openbsd with support for proxies."},{"date":"18.07.22:","desc":"Fix service perms to comply with upgrade to s6 v3."},{"date":"16.04.22:","desc":"Rebase to alpine 3.15."},{"date":"16.11.21:","desc":"Add PUBLIC_KEY_URL option"},{"date":"28.06.21:","desc":"Rebasing to alpine 3.14. Add support for PAM."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13. Add openssh-client for scp."},{"date":"21.10.20:","desc":"Implement s6-log for openssh, which adds local timestamps to logs and can be used with a log parser like fail2ban."},{"date":"20.10.20:","desc":"Set umask for sftp."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.01.20:","desc":"Add key generation script."},{"date":"13.01.20:","desc":"Add openssh-sftp-server."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"17.10.19:","desc":"Initial Release."}]}},"setup":"If `PUBLIC_KEY` or `PUBLIC_KEY_FILE`, or `PUBLIC_KEY_DIR` variables are set, the specified keys will automatically be added to `authorized_keys`. If not, the keys can manually be added to `/config/.ssh/authorized_keys` and the container should be restarted.\nRemoving `PUBLIC_KEY` or `PUBLIC_KEY_FILE` variables from docker run environment variables will not remove the keys from `authorized_keys`. `PUBLIC_KEY_FILE` and `PUBLIC_KEY_DIR` can be used with docker secrets.\n\nWe provide the ability to set and allow password based access via the `PASSWORD_ACCESS` and `USER_PASSWORD` variables, though we as an organization discourage using password auth for public facing ssh endpoints.\n\nConnect to server via `ssh -i /path/to/private/key -p PORT USER_NAME@SERVERIP`\n\nSetting `SUDO_ACCESS` to `true` by itself will allow passwordless sudo. `USER_PASSWORD` and `USER_PASSWORD_FILE` allow setting an optional sudo password.\n\nThe users only have access to the folders mapped and the processes running inside this container.\nAdd any volume mappings you like for the users to have access to.\nTo install packages or services for users to access, use the LinuxServer container customization methods described [in this blog article](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/).\n\nSample use case is when a server admin would like to have automated incoming backups from a remote server to the local server, but they might not want all the other admins of the remote server to have full access to the local server.\nThis container can be set up with a mounted folder for incoming backups, and rsync installed via LinuxServer container customization described above, so that the incoming backups can proceed, but remote server and its admins' access would be limited to the backup folder.\n\nIt is also possible to run multiple copies of this container with different ports mapped, different folders mounted and access to different private keys for compartmentalized access.\n\n#### TIPS\nYou can volume map your own text file to `/etc/motd` to override the message displayed upon connection.\nYou can optionally set the docker argument `hostname`\n\n## Key Generation\n\nThis container has a helper script to generate an ssh private/public key. In order to generate a key please run:\n```\ndocker run --rm -it --entrypoint /keygen.sh linuxserver/openssh-server\n```\n\nThen simply follow the prompts.\nThe keys generated by this script are only displayed on your console output, so make sure to save them somewhere after generation.\n"},{"id":"openvscode-server","name":"openvscode-server","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides a version of VS Code that runs a server on a remote machine and allows access through a modern web browser.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/openvscode-server-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/openvscode-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-openvscode-server"}],"containers":[{"name":"openvscode-server","image":"linuxserver/openvscode-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use."},{"id":"CONNECTION_TOKEN","default":"","description":"Optional security token for accessing the Web UI (ie. `supersecrettoken`)."},{"id":"CONNECTION_SECRET","default":"","description":"Optional path to a file inside the container that contains the security token for accessing the Web UI (ie. `/path/to/file`). Overrides `CONNECTION_TOKEN`."},{"id":"SUDO_PASSWORD","default":"password","description":"If this optional variable is set, user will have sudo access in the openvscode-server terminal with the specified password."},{"id":"SUDO_PASSWORD_HASH","default":"","description":"Optionally set sudo password via hash (takes priority over `SUDO_PASSWORD` var). Format is `$type$salt$hashed`."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"3000","description":"Web UI port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"openvscode-server","project_url":"https://github.com/gitpod-io/openvscode-server","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/openvscode-server-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides a version of VS Code that runs a server on a remote machine and allows access through a modern web browser.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"insiders","desc":"Insiders releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web UI port."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONNECTION_TOKEN","env_value":"","desc":"Optional security token for accessing the Web UI (ie. `supersecrettoken`)."},{"env_var":"CONNECTION_SECRET","env_value":"","desc":"Optional path to a file inside the container that contains the security token for accessing the Web UI (ie. `/path/to/file`). Overrides `CONNECTION_TOKEN`."},{"env_var":"SUDO_PASSWORD","env_value":"password","desc":"If this optional variable is set, user will have sudo access in the openvscode-server terminal with the specified password."},{"env_var":"SUDO_PASSWORD_HASH","env_value":"","desc":"Optionally set sudo password via hash (takes priority over `SUDO_PASSWORD` var). Format is `$type$salt$hashed`."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"If `CONNECTION_TOKEN` or `CONNECTION_SECRET` env vars are set, you can access the webui at `http://<your-ip>:3000/?tkn=supersecrettoken` (replace `supersecrettoken` with the value set). If not, you can access the webui at `http://<your-ip>:3000`.\n\nFor github integration, drop your ssh key in to `/config/.ssh`.\nThen open a terminal from the top menu and set your github username and email via the following commands\n\n```bash\ngit config --global user.name \"username\"\ngit config --global user.email \"email address\"\n```\n\nWhen reverse proxied through SWAG, custom services running on specific ports inside openvscode-server can be accessed at `https://PORT.openvscode-server.domain.com` very much like how code-server's port proxy function is handled. For that, a wildcard CNAME `*.openvscode-server.domain.com` needs to be created and the SWAG cert needs to cover those subdomains.\n","changelogs":[{"date":"29.09.22:","desc":"Rebase to jammy, switch to s6v3. Fix chown logic to skip `/config/workspace` contents."},{"date":"12.02.22:","desc":"Update `install-extension` helper to compensate for upstream changes."},{"date":"04.02.22:","desc":"Update binary for 1.64.0+. Allow for no token set when both toekn env vars are unset. Add libsecret for keytar."},{"date":"29.12.21:","desc":"Add `install-extension` as a helper for mods to install extensions."},{"date":"10.12.21:","desc":"Update deprecated connectionToken arg."},{"date":"30.11.21:","desc":"Fix app folder permissions, add the optional sudo password vars."},{"date":"29.11.21:","desc":"Create `.profile` and `.bashrc` for the user."},{"date":"29.11.21:","desc":"Release `insiders` tag."},{"date":"28.11.21:","desc":"Initial Release."}]}},"setup":"If `CONNECTION_TOKEN` or `CONNECTION_SECRET` env vars are set, you can access the webui at `http://<your-ip>:3000/?tkn=supersecrettoken` (replace `supersecrettoken` with the value set). If not, you can access the webui at `http://<your-ip>:3000`.\n\nFor github integration, drop your ssh key in to `/config/.ssh`.\nThen open a terminal from the top menu and set your github username and email via the following commands\n\n```bash\ngit config --global user.name \"username\"\ngit config --global user.email \"email address\"\n```\n\nWhen reverse proxied through SWAG, custom services running on specific ports inside openvscode-server can be accessed at `https://PORT.openvscode-server.domain.com` very much like how code-server's port proxy function is handled. For that, a wildcard CNAME `*.openvscode-server.domain.com` needs to be created and the SWAG cert needs to cover those subdomains.\n"},{"id":"oscam","name":"oscam","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an Open Source Conditional Access Module software used for descrambling DVB transmissions using smart cards. It's both a server and a client.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/oscam-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/oscam"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-oscam"}],"containers":[{"name":"oscam","image":"linuxserver/oscam","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where oscam should store config files and logs.","key":"config"}],"ports":[{"container":"8888","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"oscam","project_url":"http://www.streamboard.tv/oscam/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/oscam-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an Open Source Conditional Access Module software used for descrambling DVB transmissions using smart cards. It's both a server and a client.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where oscam should store config files and logs."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"WebUI"}],"param_device_map":true,"param_devices":[{"device_path":"/dev/ttyUSB0","device_host_path":"/dev/ttyUSB0","desc":"For passing through smart card readers."}],"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Passing through Smart Card Readers\n\nIf you want to pass through a smart card reader, you need to specify the reader with the `--device=` tag. The method used depends on how the reader is recognized.\nThe first is /dev/ttyUSBX. To find the correct device, connect the reader and run `dmesg | tail` on the host. In the output you will find /dev/ttyUSBX, where X is the number of the device. If this is the first reader you connect to your host, it will be /dev/ttyUSB0. If you add one more it will be /dev/ttyUSB1.\n\nIf there are no /dev/ttyUSBX device in `dmesg | tail`, you have to use the USB bus path. It will look similar to the below.\n\n`/dev/bus/usb/001/001`\n\nThe important parts are the two numbers in the end. The first one is the Bus number, the second is the Device number. To find the Bus and Device number you have to run `lsusb` on the host, then find your USB device in the list and note the Bus and Device numbers.\n\nHere is an example of how to find the Bus and Device. The output of the lsusb command is below.\n\n`Bus 002 Device 005: ID 076b:6622 OmniKey AG CardMan 6121`\n\nThe first number, the Bus, is 002. The second number, the Device, is 005. This will look like below in the `--device=` tag.\n\n`--device=/dev/bus/usb/002/005`\n\nIf you have multiple smart card readers, you add one `--device=` tag for each reader.\n"],"app_setup_block_enabled":true,"app_setup_block":"To set up oscam there are numerous guides on the internet. There are too many scenarios to make a quick guide.\nThe web interface is at port 8888.\n","changelogs":[{"date":"03.11.22:","desc":"Rebasing to alpine 3.16 and s6v3. Update pcsd driver link."},{"date":"13.02.22:","desc":"Rebasing to alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"29.04.19:","desc":"Add revision check, so pipeline can build new revisions."},{"date":"28.04.19:","desc":"Switch back to streamboard svn to fix version not showing in UI."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"19.02.19:","desc":"Add pipeline logic and multi arch, rebase to Alpine 3.8."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"19.10.17:","desc":"Add ccid package for usb card readers."},{"date":"17.10.17:","desc":"Switch to using bzr for source code, streamboard awol."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"02.10.16:","desc":"Add info on passing through devices to README."},{"date":"25.09.16:","desc":"Initial release."}]}},"setup":"To set up oscam there are numerous guides on the internet. There are too many scenarios to make a quick guide.\nThe web interface is at port 8888.\n"},{"id":"overseerr","name":"overseerr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a request management and media discovery tool built to work with your existing Plex ecosystem.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/overseerr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/overseerr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-overseerr"}],"containers":[{"name":"overseerr","image":"linuxserver/overseerr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"5055","description":"Port for Overseerr's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"overseerr","project_url":"https://overseerr.dev/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/overseerr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a request management and media discovery tool built to work with your existing Plex ecosystem.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from GitHub"},{"tag":"develop","desc":"Development releases from commits in upstream develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5055","internal_port":"5055","port_desc":"Port for Overseerr's web interface."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_vols":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:5055`, for more information check out [Overseerr](https://overseerr.dev/).\n","changelogs":[{"date":"18.12.22:","desc":"Rebase main to 3.17."},{"date":"27.10.22:","desc":"Rebase main to 3.16, migrate to s6v3."},{"date":"20.08.22:","desc":"Don't install cypress."},{"date":"01.04.22:","desc":"Rebase main branch to Alpine 3.15."},{"date":"27.01.22:","desc":"Rebase develop branch to Alpine 3.15."},{"date":"04.01.22:","desc":"Remove cached files."},{"date":"10.10.21:","desc":"Add additional post-build cleanup."},{"date":"19.09.21:","desc":"Rebase to alpine 3.14. Update code formatting. Increase js mem limit."},{"date":"05.04.21:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:5055`, for more information check out [Overseerr](https://overseerr.dev/).\n"},{"id":"papermerge","name":"papermerge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an open source document management system (DMS) primarily designed for archiving and retrieving your digital documents. Instead of having piles of paper documents all over your desk, office or drawers - you can quickly scan them and configure your scanner to directly upload to Papermerge DMS.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/papermerge-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/papermerge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-papermerge"}],"containers":[{"name":"papermerge","image":"linuxserver/papermerge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"REDIS_URL","default":"","description":"Specify an external redis instance to use. Can optionally include a port (`redis:6379`) and/or db (`redis/foo`). If left blank or not included, will use a built-in redis instance. If changed after initial setup will also require manual modification of /config/settings.py"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/data","description":"Storage location for all papermerge data files."}],"ports":[{"container":"8000","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"papermerge","project_url":"https://www.papermerge.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/papermerge-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an open source document management system (DMS) primarily designed for archiving and retrieving your digital documents. Instead of having piles of paper documents all over your desk, office or drawers - you can quickly scan them and configure your scanner to directly upload to Papermerge DMS.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains all relevant configuration files."},{"vol_path":"/data","vol_host_path":"</path/to/appdata/data>","desc":"Storage location for all papermerge data files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"REDIS_URL","env_value":"","desc":"Specify an external redis instance to use. Can optionally include a port (`redis:6379`) and/or db (`redis/foo`). If left blank or not included, will use a built-in redis instance. If changed after initial setup will also require manual modification of /config/settings.py"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Default login is admin:admin via the webui, accessible at http://SERVERIP:PORT\nMore info at [papermerge]({{ project_url }}).\n\nIf you need non-English OCR language support, you can use [this mod](https://github.com/linuxserver/docker-mods/tree/papermerge-multilangocr).\n","changelogs":[{"date":"15.07.22:","desc":"Don't install development python packages"},{"date":"13.04.21:","desc":"Handle upstream stapler change"},{"date":"13.03.21:","desc":"Fixed mglib dependency per issue 32"},{"date":"25.02.21:","desc":"Updated dependencies for v2"},{"date":"07.02.21:","desc":"Support external MySQL/PSQL DBs."},{"date":"01.02.21:","desc":"Add redis."},{"date":"09.12.20:","desc":"Fix locales."},{"date":"08.08.20:","desc":"Initial Release."}]}},"setup":"Default login is admin:admin via the webui, accessible at http://SERVERIP:PORT\nMore info at [papermerge]({{ project_url }}).\n\nIf you need non-English OCR language support, you can use [this mod](https://github.com/linuxserver/docker-mods/tree/papermerge-multilangocr).\n"},{"id":"phpmyadmin","name":"phpmyadmin","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/phpmyadmin-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/phpmyadmin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-phpmyadmin"}],"containers":[{"name":"phpmyadmin","image":"linuxserver/phpmyadmin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"PMA_ARBITRARY","default":"1","description":"Set to `1` to allow you to connect to any server. Setting to `0` will only allow you to connect to specified hosts (See Application Setup)"},{"id":"PMA_ABSOLUTE_URI","default":"https://phpmyadmin.example.com","description":"Set the URL you will use to access the web frontend"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"phpmyadmin","project_url":"https://github.com/phpmyadmin/phpmyadmin/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/phpmyadmin-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PMA_ARBITRARY","env_value":"1","desc":"Set to `1` to allow you to connect to any server. Setting to `0` will only allow you to connect to specified hosts (See Application Setup)"},{"env_var":"PMA_ABSOLUTE_URI","env_value":"https://phpmyadmin.example.com","desc":"Set the URL you will use to access the web frontend"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"This image uses nginx, in contrast to the official images which offer fpm-only or Apache variants.\n\nWe support all of the official [environment variables](https://docs.phpmyadmin.net/en/latest/setup.html#docker-environment-variables) for configuration as well as directly editing the config files.\n\nFor more information check out the [phpmyadmin documentation](https://www.phpmyadmin.net/docs/).\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"18.11.22:","desc":"Rebasing to Alpine 3.16, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to Alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"23.01.22:","desc":"Pin versions to 5.x.x."},{"date":"14.06.21:","desc":"Initial Release."}]}},"setup":"This image uses nginx, in contrast to the official images which offer fpm-only or Apache variants.\n\nWe support all of the official [environment variables](https://docs.phpmyadmin.net/en/latest/setup.html#docker-environment-variables) for configuration as well as directly editing the config files.\n\nFor more information check out the [phpmyadmin documentation](https://www.phpmyadmin.net/docs/).\n"},{"id":"pidgin","name":"pidgin","description":"[Pidgin]({{ project_url }}) is a chat program which lets you log into accounts on multiple chat networks simultaneously. This means that you can be chatting with friends on XMPP and sitting in an IRC channel at the same time.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/pidgin-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pidgin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pidgin"}],"containers":[{"name":"pidgin","image":"linuxserver/pidgin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Pidgin desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pidgin","project_url":"https://pidgin.im/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/pidgin-logo.png","project_blurb":"[Pidgin]({{ project_url }}) is a chat program which lets you log into accounts on multiple chat networks simultaneously. This means that you can be chatting with friends on XMPP and sitting in an IRC channel at the same time.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Pidgin desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nThis Pidgin installation comes with default chat plugins plus a series of third party ones. **Please note that the third party plugins for the most part are not simply plug and play, you will need to reference their documentation and possibly generate oauth tokens along with other workarounds**. Third party plugins are always in a state of constant development do not expect every single native feature to work flawlessly. To ease integration with some third party plugins we include Firefox in this image to allow you to fill out captchas or pre-auth before loading your credentials into the program, simply right click the desktop to launch it. \n\n* Bonjour- Default XMPP style plugin\n* Discord- Provided by [purple-discord](https://github.com/EionRobb/purple-discord)\n* Facebook- Provided by [purple-facebook](https://github.com/dequis/purple-facebook)\n* Gadu-Gadu- Default libgadu plugin\n* Google Talk- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* GroupWise- Default GroupWise plugin\n* Hangouts- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* ICQ (WIM)- Provided by [icyque](https://github.com/EionRobb/icyque)\n* IRC- Default IRC plugin\n* Instagram- Provided by [purple-instagram](https://github.com/EionRobb/purple-instagram)\n* Office Comminicator (SIPE)- Provided by [SIPE Project](https://sipe.sourceforge.io/)\n* Rocket.chat- Provided by [purple-rocketchat](https://github.com/EionRobb/purple-rocketchat)\n* SIMPLE- Default plugin\n* Skype (HTTP)- Provided by [skype4pidgin](https://github.com/EionRobb/skype4pidgin)\n* Slack- Provided by [slack-libpurple](https://github.com/EionRobb/slack-libpurple)\n* Telegram- Provided by [telegram-purple](https://github.com/majn/telegram-purple)\n* XMPP- Default XMPP plugin\n* Zephyr- Default project Athena plugin\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"15.02.22:","desc":"Add build deps for discord."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"14.05.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nThis Pidgin installation comes with default chat plugins plus a series of third party ones. **Please note that the third party plugins for the most part are not simply plug and play, you will need to reference their documentation and possibly generate oauth tokens along with other workarounds**. Third party plugins are always in a state of constant development do not expect every single native feature to work flawlessly. To ease integration with some third party plugins we include Firefox in this image to allow you to fill out captchas or pre-auth before loading your credentials into the program, simply right click the desktop to launch it. \n\n* Bonjour- Default XMPP style plugin\n* Discord- Provided by [purple-discord](https://github.com/EionRobb/purple-discord)\n* Facebook- Provided by [purple-facebook](https://github.com/dequis/purple-facebook)\n* Gadu-Gadu- Default libgadu plugin\n* Google Talk- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* GroupWise- Default GroupWise plugin\n* Hangouts- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* ICQ (WIM)- Provided by [icyque](https://github.com/EionRobb/icyque)\n* IRC- Default IRC plugin\n* Instagram- Provided by [purple-instagram](https://github.com/EionRobb/purple-instagram)\n* Office Comminicator (SIPE)- Provided by [SIPE Project](https://sipe.sourceforge.io/)\n* Rocket.chat- Provided by [purple-rocketchat](https://github.com/EionRobb/purple-rocketchat)\n* SIMPLE- Default plugin\n* Skype (HTTP)- Provided by [skype4pidgin](https://github.com/EionRobb/skype4pidgin)\n* Slack- Provided by [slack-libpurple](https://github.com/EionRobb/slack-libpurple)\n* Telegram- Provided by [telegram-purple](https://github.com/majn/telegram-purple)\n* XMPP- Default XMPP plugin\n* Zephyr- Default project Athena plugin\n"},{"id":"piwigo","name":"piwigo","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a photo gallery software for the web that comes with powerful features to publish and manage your collection of pictures.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/piwigo-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/piwigo"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-piwigo"}],"containers":[{"name":"piwigo","image":"linuxserver/piwigo","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/gallery","description":"Image storage for Piwigo"}],"ports":[{"container":"80","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"piwigo","project_url":"http://piwigo.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/piwigo-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a photo gallery software for the web that comes with powerful features to publish and manage your collection of pictures.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."},{"vol_path":"/gallery","vol_host_path":"/path/to/appdata/gallery","desc":"Image storage for Piwigo"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"* You must create a user and database for piwigo to use in a mysql/mariadb server. \n\n* Self-signed keys are generated the first time you run the container and can be found in `/config/keys`, if needed, you can replace them with your own.\n\n* The easiest way to edit the configuration file is to enable local files editor from the plugins page and use it to configure email settings etc.\"\n","changelogs":[{"date":"16.01.23:","desc":"Fix broken custom template persistence."},{"date":"08.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3. Move application install to /app/www/public, add migration for existing users. Container updates should now update the application correctly."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"29.06.21:","desc":"Rebase to 3.14, Add php7-zip package"},{"date":"20.05.21:","desc":"Create separate volume for image data"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"12.12.20:","desc":"Increased upload_max_filesize in php.ini"},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.06.19:","desc":"Add ffmpeg and other deps as needed by popular plugins."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.03.19:","desc":"Add php-ctype & php-curl."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9, add php-ldap."},{"date":"28.01.19:","desc":"Rebase to alpine linux 3.8 , add pipeline logic and multi arch."},{"date":"25.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"03.05.17:","desc":"Use repo pinning to better solve dependencies, use repo version of php7-imagick."},{"date":"20.04.17:","desc":"Add php7-exif package, thanks iiska"},{"date":"23.02.17:","desc":"Rebase to alpine linux 3.5 and nginx."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"29.08.15:","desc":"Initial Release."}]}},"setup":"* You must create a user and database for piwigo to use in a mysql/mariadb server. \n\n* Self-signed keys are generated the first time you run the container and can be found in `/config/keys`, if needed, you can replace them with your own.\n\n* The easiest way to edit the configuration file is to enable local files editor from the plugins page and use it to configure email settings etc.\"\n"},{"id":"plex","name":"plex","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/plex.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/plex"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-plex"}],"containers":[{"name":"plex","image":"linuxserver/plex","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"param_usage_include_ports":false,"param_usage_include_vols":false,"param_usage_include_env":false,"param_volumes":[],"param_ports":[],"param_env_vars":[]}}},{"id":"plex-meta-manager","name":"plex-meta-manager","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Python 3 script that can be continuously run using YAML configuration files to update on a schedule the metadata of the movies, shows, and collections in your libraries as well as automatically build collections based on various methods all detailed in the wiki.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/plex-meta-manager-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/plex-meta-manager"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-plex-meta-manager"}],"containers":[{"name":"plex-meta-manager","image":"linuxserver/plex-meta-manager","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PMM_CONFIG","default":"/config/config.yml","description":"Specify a custom config file to use."},{"id":"PMM_TIME","default":"03:00","description":"Comma-separated list of times to update each day. Format: `HH:MM`."},{"id":"PMM_RUN","default":"False","description":"Set to `True` to run without the scheduler."},{"id":"PMM_TEST","default":"False","description":"Set to `True` to run in debug mode with only collections that have `test: true`."},{"id":"PMM_NO_MISSING","default":"False","description":"Set to `True` to run without any of the missing movie/show functions."}],"volumes":[{"container":"/config","description":"Local path for plex-meta-manager config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"plex-meta-manager","project_url":"https://github.com/meisnate12/Plex-Meta-Manager","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/plex-meta-manager-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Python 3 script that can be continuously run using YAML configuration files to update on a schedule the metadata of the movies, shows, and collections in your libraries as well as automatically build collections based on various methods all detailed in the wiki.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"develop","desc":"Latest commits from the develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Local path for plex-meta-manager config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PMM_CONFIG","env_value":"/config/config.yml","desc":"Specify a custom config file to use."},{"env_var":"PMM_TIME","env_value":"03:00","desc":"Comma-separated list of times to update each day. Format: `HH:MM`."},{"env_var":"PMM_RUN","env_value":"False","desc":"Set to `True` to run without the scheduler."},{"env_var":"PMM_TEST","env_value":"False","desc":"Set to `True` to run in debug mode with only collections that have `test: true`."},{"env_var":"PMM_NO_MISSING","env_value":"False","desc":"Set to `True` to run without any of the missing movie/show functions."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"There is a [walkthrough](https://metamanager.wiki/en/latest/home/guides/docker.html#setting-up-the-initial-config-file) available to help get you up and running.\n\nThis image supports all of the environment variables listed [here](https://metamanager.wiki/en/latest/home/environmental.html) and all commandline arguments.\n\nTo perform a one-time run use `docker run` (or `docker-compose run`) with the `--rm` and `-e PMM_RUN=True` arguments. This will cause the container to process your config immediately instead of waiting for the scheduled time, and delete the old container after completion.\n\nFor more information see the [official wiki](https://metamanager.wiki).\n","changelogs":[{"date":"11.12.22:","desc":"Rebase master to Alpine 3.17."},{"date":"08.11.22:","desc":"Add develop branch."},{"date":"25.10.22:","desc":"Support commandline args and relative paths."},{"date":"03.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"30.01.22:","desc":"Initial Release."}]}},"setup":"There is a [walkthrough](https://metamanager.wiki/en/latest/home/guides/docker.html#setting-up-the-initial-config-file) available to help get you up and running.\n\nThis image supports all of the environment variables listed [here](https://metamanager.wiki/en/latest/home/environmental.html) and all commandline arguments.\n\nTo perform a one-time run use `docker run` (or `docker-compose run`) with the `--rm` and `-e PMM_RUN=True` arguments. This will cause the container to process your config immediately instead of waiting for the scheduled time, and delete the old container after completion.\n\nFor more information see the [official wiki](https://metamanager.wiki).\n"},{"id":"projectsend","name":"projectsend","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-hosted application that lets you upload files and assign them to specific clients that you create yourself. Secure, private and easy. No more depending on external services or e-mail to send those files.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/projectsend.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/projectsend"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-projectsend"}],"containers":[{"name":"projectsend","image":"linuxserver/projectsend","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MAX_UPLOAD","default":"5000","description":"To set maximum upload size (in MB), default if unset is 5000."}],"volumes":[{"container":"/config","description":"Where to store projectsend config files.","key":"config"},{"container":"/data","description":"Where to store files to share."}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"projectsend","project_url":"http://www.projectsend.org","project_logo":"http://www.projectsend.org/wp-content/themes/projectsend/img/screenshots.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-hosted application that lets you upload files and assign them to specific clients that you create yourself. Secure, private and easy. No more depending on external services or e-mail to send those files.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"MAX_UPLOAD","env_value":"5000","desc":"To set maximum upload size (in MB), default if unset is 5000."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where to store projectsend config files."},{"vol_path":"/data","vol_host_path":"<path to data>","desc":"Where to store files to share."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"*IMPORTANT* This image no longer supports MSSQL since being migrated to PHP7, if you want MSSQL support please use the tag `linuxserver/projectsend:r1053-ls27`\n\nRequires a user and database in either mysql or mariadb.\n\nTo use translations, follow the instructions [here](https://www.projectsend.org/how-to-use-translation-files/). The necessary paths are symlinked under `/config/translations` (note that the \"templates\" paths don't need `lang` subdirectories).\n\nMore info at [ProjectSend]({{ project_url }}).\n","changelogs":[{"date":"23.08.22:","desc":"Add translation support"},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"24.06.21:","desc":"Rebasing to alpine 3.14, switch to nginx"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"31.12.19:","desc":"Rebase to Alpine 3.11 and upgrade to PHP7."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"11.06.17:","desc":"Fetch version from github."},{"date":"09.12.17:","desc":"Rebase to alpine 3.7."},{"date":"13.06.17:","desc":"Initial Release."}]}},"setup":"*IMPORTANT* This image no longer supports MSSQL since being migrated to PHP7, if you want MSSQL support please use the tag `linuxserver/projectsend:r1053-ls27`\n\nRequires a user and database in either mysql or mariadb.\n\nTo use translations, follow the instructions [here](https://www.projectsend.org/how-to-use-translation-files/). The necessary paths are symlinked under `/config/translations` (note that the \"templates\" paths don't need `lang` subdirectories).\n\nMore info at [ProjectSend]({{ project_url }}).\n"},{"id":"prowlarr","name":"prowlarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Sonarr, Radarr, Lidarr, and Readarr offering complete management of your indexers with no per app Indexer setup required (we do it all).\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/prowlarr-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/prowlarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-prowlarr"}],"containers":[{"name":"prowlarr","image":"linuxserver/prowlarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Prowlarr"}],"volumes":[{"container":"/config","description":"Database and Prowlarr configs","key":"config"}],"ports":[{"container":"9696","description":"The port for the Prowlarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"prowlarr","project_url":"https://github.com/Prowlarr/Prowlarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/prowlarr-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Sonarr, Radarr, Lidarr, and Readarr offering complete management of your indexers with no per app Indexer setup required (we do it all).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Prowlarr stable releases"},{"tag":"develop","desc":"Prowlarr releases from their develop branch"},{"tag":"nightly","desc":"Prowlarr releases from their nightly branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and Prowlarr configs"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9696","internal_port":"9696","port_desc":"The port for the Prowlarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Prowlarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:9696`, for more information check out [Prowlarr](https://github.com/Prowlarr/Prowlarr).\n\nSetup info can be found [here](https://wikijs.servarr.com/prowlarr/quick-start-guide).\n","changelogs":[{"date":"03.01.23:","desc":"Publish stable release."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine."},{"date":"06.06.21:","desc":"Initial realease."}]}},"setup":"Access the webui at `<your-ip>:9696`, for more information check out [Prowlarr](https://github.com/Prowlarr/Prowlarr).\n\nSetup info can be found [here](https://wikijs.servarr.com/prowlarr/quick-start-guide).\n"},{"id":"pwndrop","name":"pwndrop","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-deployable file hosting service for sending out red teaming payloads or securely sharing your private files over HTTP and WebDAV.","icon":"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-logo-512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pwndrop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pwndrop"}],"containers":[{"name":"pwndrop","image":"linuxserver/pwndrop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SECRET_PATH","default":"/pwndrop","description":"Secret path for admin access. Defaults to `/pwndrop`. This parameter only takes effect during initial install; it can later be changed in the web gui."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration and data.","key":"config"}],"ports":[{"container":"8080","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pwndrop","project_url":"https://github.com/kgretzky/pwndrop","project_logo":"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-logo-512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-deployable file hosting service for sending out red teaming payloads or securely sharing your private files over HTTP and WebDAV.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"development","desc":"Prereleases from their GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SECRET_PATH","env_value":"/pwndrop","desc":"Secret path for admin access. Defaults to `/pwndrop`. This parameter only takes effect during initial install; it can later be changed in the web gui."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the web gui at `http://<your-ip>:8080/pwndrop` (replace `/pwndrop` with your SECRET_PATH if you set one).\n","changelogs":[{"date":"19.09.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"17.04.20:","desc":"Initial Release."}]}},"setup":"Access the web gui at `http://<your-ip>:8080/pwndrop` (replace `/pwndrop` with your SECRET_PATH if you set one).\n"},{"id":"pydio-cells","name":"pydio-cells","description":"[{{ project_name|capitalize }}]({{ project_url }}) is the nextgen file sharing platform for organizations. It is a full rewrite of the Pydio project using the Go language following a micro-service architecture.","icon":"https://raw.githubusercontent.com/wiki/pydio/cells/images/PydioCellsColor.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pydio-cells"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pydio-cells"}],"containers":[{"name":"pydio-cells","image":"linuxserver/pydio-cells","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"EXTERNALURL","default":"yourdomain.url","description":"The external url you would like to use to access Pydio Cells (Can be https://domain.url or https://IP:PORT)."},{"id":"SERVER_IP","default":"0.0.0.0","description":"Enter the LAN IP of the docker server. Required for local access by IP, added to self signed cert as SAN (not required if accessing only through reverse proxy)."}],"volumes":[{"container":"/config","description":"Folder where configuration and data files reside.","key":"config"},{"container":"/config","description":"All the config files reside here.","key":"config"}],"ports":[{"container":"8080","description":"Http port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pydio-cells","project_url":"https://pydio.com/","project_logo":"https://raw.githubusercontent.com/wiki/pydio/cells/images/PydioCellsColor.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is the nextgen file sharing platform for organizations. It is a full rewrite of the Pydio project using the Go language following a micro-service architecture.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Pydio Cells releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":true,"param_hostname":"{{ project_name }}","param_hostname_desc":"Pydio Cells uses the hostname to verify local files. This setting is required and should not be changed after it has been set.","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"EXTERNALURL","env_value":"yourdomain.url","desc":"The external url you would like to use to access Pydio Cells (Can be https://domain.url or https://IP:PORT)."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"All the config files reside here."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Http port"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":false,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SERVER_IP","env_value":"0.0.0.0","desc":"Enter the LAN IP of the docker server. Required for local access by IP, added to self signed cert as SAN (not required if accessing only through reverse proxy)."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Folder where configuration and data files reside."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"33060","internal_port":"33060","port_desc":"gRPC port (required for CellsSync)."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"You must first create a mysql database for Pydio Cells. Using our [mariadb image](https://hub.docker.com/r/linuxserver/mariadb) is recommended.  \n\nThen access the web gui setup wizard at `https://SERVER_IP:8080` if accessing locally (must set `SERVER_IP` env var), or at `https://pydio-cells.domain.com` if reverse proxying.\n","changelogs":[{"date":"01.12.22:","desc":"Rebasing to alpine 3.17. Adding multi-arch support. Updating cli arguments for v4 compatibility."},{"date":"19.10.22:","desc":"Rebasing to alpine 3.16. Upgrading to s6v3. Updating build instructions for v4."},{"date":"19.09.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.04.20:","desc":"Switch to https as default (only affects new installs). Add self signed cert, add `SERVER_IP` var for adding to cert as SAN. Add optional gRPC port mapping for CellsSync."},{"date":"17.04.20:","desc":"Update compile options, previous release was broken for new installs."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"12.12.19:","desc":"Initial Release"}]}},"setup":"You must first create a mysql database for Pydio Cells. Using our [mariadb image](https://hub.docker.com/r/linuxserver/mariadb) is recommended.  \n\nThen access the web gui setup wizard at `https://SERVER_IP:8080` if accessing locally (must set `SERVER_IP` env var), or at `https://pydio-cells.domain.com` if reverse proxying.\n"},{"id":"pyload-ng","name":"pyload-ng","description":"[pyLoad]({{ project_url }}) is a Free and Open Source download manager written in Python and designed to be extremely lightweight, easily extensible and fully manageable via web.","icon":"https://pyload.net/img/banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pyload-ng"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pyload-ng"}],"containers":[{"name":"pyload-ng","image":"linuxserver/pyload-ng","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"pyLoad Configuration and files database","key":"config"},{"container":"/downloads","description":"Destination of pyLoad downloads"}],"ports":[{"container":"8000","description":"Allows HTTP access to the application","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pyload-ng","project_url":"https://pyload.net/","project_logo":"https://pyload.net/img/banner.png","project_blurb":"[pyLoad]({{ project_url }}) is a Free and Open Source download manager written in Python and designed to be extremely lightweight, easily extensible and fully manageable via web.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from pyLoad Next"},{"tag":"develop","desc":"Releases from pyload Next develop branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"pyLoad Configuration and files database"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Destination of pyLoad downloads"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Allows HTTP access to the application"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"9666","internal_port":"9666","port_desc":"Click'n'Load port."}],"app_setup_block_enabled":true,"app_setup_block":"Access the web interface at `http://your-ip:8000` the default login is: \nusername - **pyload**\npassword - **pyload**\n\nFor general usage please see the pyLoad wiki [here](https://github.com/pyload/pyload/wiki) .\n","changelogs":[{"date":"02.02.22:","desc":"Rebase master to alpine 3.17."},{"date":"02.02.22:","desc":"Add ffmpeg for the Youtube plugin."},{"date":"24.01.22:","desc":"Replace unrar with p7zip."},{"date":"24.01.22:","desc":"Initial release."}]}},"setup":"Access the web interface at `http://your-ip:8000` the default login is: \nusername - **pyload**\npassword - **pyload**\n\nFor general usage please see the pyLoad wiki [here](https://github.com/pyload/pyload/wiki) .\n"},{"id":"pylon","name":"pylon","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web based integrated development environment built with Node.js as a backend and with a supercharged JavaScript/HTML5 frontend, licensed under GPL version 3. This project originates from Cloud9 v2 project.\n","icon":"https://raw.githubusercontent.com/pylonide/pylon/master/doc/screenshot02.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pylon"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pylon"}],"containers":[{"name":"pylon","image":"linuxserver/pylon","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"GITURL","default":"https://github.com/linuxserver/docker-pylon.git","description":"Specify a git repo to checkout on first startup"},{"id":"PYUSER","default":"myuser","description":"Specify a basic auth user."},{"id":"PYPASS","default":"mypass","description":"Specify a basic auth password."}],"ports":[{"container":"3131","description":"The port for the Pylon web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pylon","project_url":"https://github.com/pylonide/pylon","project_logo":"https://raw.githubusercontent.com/pylonide/pylon/master/doc/screenshot02.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web based integrated development environment built with Node.js as a backend and with a supercharged JavaScript/HTML5 frontend, licensed under GPL version 3. This project originates from Cloud9 v2 project.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_ports":true,"param_ports":[{"external_port":"3131","internal_port":"3131","port_desc":"The port for the Pylon web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/code","vol_host_path":"<path to your code>","desc":"Optionally if you want the bind mount your own code and have changes survive container upgrades."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"GITURL","env_value":"https://github.com/linuxserver/docker-pylon.git","desc":"Specify a git repo to checkout on first startup"},{"env_var":"PYUSER","env_value":"myuser","desc":"Specify a basic auth user."},{"env_var":"PYPASS","env_value":"mypass","desc":"Specify a basic auth password."}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://your-ip:3131, more information [here](https://github.com/pylonide/pylon).\n","changelogs":[{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"19.09.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://your-ip:3131, more information [here](https://github.com/pylonide/pylon).\n"},{"id":"qbittorrent","name":"qbittorrent","description":"The [{{ project_name|capitalize }}]({{ project_url }}) project aims to provide an open-source software alternative to Torrent. qBittorrent is based on the Qt toolkit and libtorrent-rasterbar library.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/qbittorrent-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/qbittorrent"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-qbittorrent"}],"containers":[{"name":"qbittorrent","image":"linuxserver/qbittorrent","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"WEBUI_PORT","default":"8080","description":"for changing the port of the webui, see below for explanation"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/downloads","description":"Location of downloads on disk."}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"6881","description":"tcp connection port","protocol":"tcp","web":false},{"container":"6881/udp","description":"udp connection port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"qbittorrent","project_url":"https://www.qbittorrent.org/","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/qbittorrent-icon.png","project_blurb":"The [{{ project_name|capitalize }}]({{ project_url }}) project aims to provide an open-source software alternative to Torrent. qBittorrent is based on the Qt toolkit and libtorrent-rasterbar library.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable qbittorrent releases"},{"tag":"libtorrentv1","desc":"Static qbittorrent builds using libtorrent v1"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Location of downloads on disk."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"6881","internal_port":"6881","port_desc":"tcp connection port"},{"external_port":"6881","internal_port":"6881/udp","port_desc":"udp connection port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"WEBUI_PORT","env_value":"8080","desc":"for changing the port of the webui, see below for explanation"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The webui is at `<your-ip>:8080` and the default username/password is `admin/adminadmin`.  \n\nChange username/password via the webui in the webui section of settings.  \n\n### WEBUI_PORT variable\n\nDue to issues with CSRF and port mapping, should you require to alter the port for the webui you need to change both sides of the -p 8080 switch AND set the WEBUI_PORT variable to the new port.  \n\nFor example, to set the port to 8090 you need to set -p 8090:8090 and -e WEBUI_PORT=8090  \n\nThis should alleviate the \"white screen\" issue.  \n\nIf you have no webui , check the file /config/qBittorrent/qBittorrent.conf  \n\nedit or add the following lines  \n\n```text\nWebUI\\Address=*\n\nWebUI\\ServerDomains=*\n```\n\nIf you are running a very old (3.x) kernel you may run into [this issue](https://github.com/linuxserver/docker-qbittorrent/issues/103) which can be worked around using [this method](https://github.com/linuxserver/docker-qbittorrent/issues/103#issuecomment-831238484)\n","changelogs":[{"date":"29.11.22:","desc":"Add openssl1.1-compat for qbittorrent-cli."},{"date":"31.10.22:","desc":"Add libtorrentv1 branch."},{"date":"31.08.22:","desc":"Rebase to Alpine Edge again to follow latest releases."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"16.06.22:","desc":"Rebase to Alpine 3.16 from edge."},{"date":"25.05.22:","desc":"Fetch qbitorrent-cli from upstream repo."},{"date":"02.03.22:","desc":"Add unrar, 7zip, and qbitorrent-cli."},{"date":"01.03.22:","desc":"Add python for search plugin support."},{"date":"23.02.22:","desc":"Rebase to Alpine Edge, install from Alpine repos."},{"date":"19.02.22:","desc":"Add jq to build-stage"},{"date":"07.01.22:","desc":"Rebase to Alpine, build from source."},{"date":"06.01.22:","desc":"Deprecate unstable branch."},{"date":"10.02.21:","desc":"Rebase to focal."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"12.11.20:","desc":"Stop creating /config/data directory on startup"},{"date":"03.04.20:","desc":"Fix adding search engine plugin"},{"date":"02.08.19:","desc":"Add qbitorrent-cli for processing scripts."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.01.19:","desc":"Rebase to Ubuntu, add multi arch and pipeline logic."},{"date":"25.09.18:","desc":"Use buildstage type build, bump qbitorrent to 4.1.3."},{"date":"14.08.18:","desc":"Rebase to alpine 3.8, bump libtorrent to 1.1.9 and qbitorrent to 4.1.2."},{"date":"08.06.18:","desc":"Bump qbitorrent to 4.1.1."},{"date":"26.04.18:","desc":"Bump libtorrent to 1.1.7."},{"date":"02.03.18:","desc":"Bump qbitorrent to 4.0.4 and libtorrent to 1.1.6."},{"date":"02.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"19.12.17:","desc":"Update to v4.0.3."},{"date":"09.02.17:","desc":"Rebase to alpine 3.7"},{"date":"01.12.17:","desc":"Update to v4.0.2."},{"date":"27.11.17:","desc":"Update to v4 and use cpu_core routine to speed up builds."},{"date":"16.09.17:","desc":"Bump to 3.3.16, Add WEBUI_PORT variable and notes to README to allow changing port of webui."},{"date":"01.08.17:","desc":"Initial Release."},{"date":"12.02.18:","desc":"Initial Release."}]}},"setup":"The webui is at `<your-ip>:8080` and the default username/password is `admin/adminadmin`.  \n\nChange username/password via the webui in the webui section of settings.  \n\n### WEBUI_PORT variable\n\nDue to issues with CSRF and port mapping, should you require to alter the port for the webui you need to change both sides of the -p 8080 switch AND set the WEBUI_PORT variable to the new port.  \n\nFor example, to set the port to 8090 you need to set -p 8090:8090 and -e WEBUI_PORT=8090  \n\nThis should alleviate the \"white screen\" issue.  \n\nIf you have no webui , check the file /config/qBittorrent/qBittorrent.conf  \n\nedit or add the following lines  \n\n```text\nWebUI\\Address=*\n\nWebUI\\ServerDomains=*\n```\n\nIf you are running a very old (3.x) kernel you may run into [this issue](https://github.com/linuxserver/docker-qbittorrent/issues/103) which can be worked around using [this method](https://github.com/linuxserver/docker-qbittorrent/issues/103#issuecomment-831238484)\n"},{"id":"qdirstat","name":"qdirstat","description":"[QDirStat]({{ project_url }}) Qt-based directory statistics: KDirStat without any KDE -- from the author of the original KDirStat.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/qdirstat-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/qdirstat"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-qdirstat"}],"containers":[{"name":"qdirstat","image":"linuxserver/qdirstat","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores qdirstat settings and scans.","key":"config"},{"container":"/data","description":"Data you want to analyze disk usage information of."}],"ports":[{"container":"3000","description":"QdirStat desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"qdirstat","project_url":"https://github.com/shundhammer/qdirstat","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/qdirstat-logo.png","project_blurb":"[QDirStat]({{ project_url }}) Qt-based directory statistics: KDirStat without any KDE -- from the author of the original KDirStat.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores qdirstat settings and scans."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Data you want to analyze disk usage information of."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"QdirStat desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.12.22:","desc":"Rebase to Jammy."},{"date":"06.04.22:","desc":"Add xfce terminal."},{"date":"13.01.22:","desc":"Compile from source."},{"date":"11.01.22:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"quassel-core","name":"quassel-core","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a modern, cross-platform, distributed IRC client, meaning that one (or multiple) client(s) can attach to and detach from a central core.\n\nThis container handles the IRC connection (quasselcore) and requires a desktop client (quasselclient) to be used and configured. It is designed to be always on and will keep your identity present in IRC even when your clients cannot be online. Backlog (history) is downloaded by your client upon reconnection allowing infinite scrollback through time.\n","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/quasselcore.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/quassel-core"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-quassel-core"}],"containers":[{"name":"quassel-core","image":"linuxserver/quassel-core","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"--config-from-environment","description":"Custom CLI options for Quassel"}],"volumes":[{"container":"/config","description":"Database and quassel-core configuration storage.","key":"config"}],"ports":[{"container":"4242","description":"The port quassel-core listens for connections on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"quassel-core","project_url":"http://quassel-irc.org/","project_logo":"http://icons.iconarchive.com/icons/oxygen-icons.org/oxygen/256/Apps-quassel-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a modern, cross-platform, distributed IRC client, meaning that one (or multiple) client(s) can attach to and detach from a central core.\n\nThis container handles the IRC connection (quasselcore) and requires a desktop client (quasselclient) to be used and configured. It is designed to be always on and will keep your identity present in IRC even when your clients cannot be online. Backlog (history) is downloaded by your client upon reconnection allowing infinite scrollback through time.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Database and quassel-core configuration storage."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4242","internal_port":"4242","port_desc":"The port quassel-core listens for connections on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"RUN_OPTS","env_value":"--config-from-environment","desc":"Custom CLI options for Quassel"}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"113","internal_port":"10113","port_desc":"Optional Ident Port"}],"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Quassel wiki: [quassel](http://bugs.quassel-irc.org/projects/quassel-irc/wiki)\n\nA great place to host a quassel instance is a VPS, such as [DigitalOcean](https://www.digitalocean.com/?refcode=501c48b34b8c). For $5 a month you can have a 24/7 IRC connection and be up and running in under 55 seconds (or so they claim).\n\nOnce you have the container running, fire up a quassel desktop client and connect to your new core instance using your droplets public IP address and the port you specified in your `docker run` command *default: 4242*. Create an admin user, select SQLite as your storage backend (Quassel limitation). Setup your real name and nick, then press `Save & Connect`.\n\nYou're now connected to IRC. Let's add you to our [IRC](http://www.linuxserver.io/index.php/irc/) `#linuxserver.io` room on Freenode. Click 'File' > 'Networks' > 'Configure Networks' > 'Add' (under Networks section, not Servers) > 'Use preset' > Select 'Freenode' and then configure your identity using the tabs in the 'Network details' section. Once connected to Freenode, click `#join` and enter `#linuxserver.io`. That's it, you're done.\n\n## Stateless usage\n\nTo use Quassel in stateless mode, where it needs to be configured through\nenvironment arguments, run it with the `--config-from-environment` RUN_OPTS environment setting.\n\n| Env | Usage |\n| :----: | --- |\n| DB_BACKEND | `SQLite` or `PostgreSQL` |\n| DB_PGSQL_USERNAME | PostgreSQL User |\n| DB_PGSQL_PASSWORD | PostgreSQL Password |\n| DB_PGSQL_HOSTNAME | PostgreSQL Host |\n| DB_PGSQL_PORT | PostgreSQL Port |\n| AUTH_AUTHENTICATOR | `Database` or `LDAP` |\n| AUTH_LDAP_HOSTNAME | LDAP Host |\n| AUTH_LDAP_PORT | LDAP Port |\n| AUTH_LDAP_BIND_DN | LDAP Bind Domain |\n| AUTH_LDAP_BIND_PASSWORD | LDAP Password |\n| AUTH_LDAP_FILTER | LDAP Authentication Filters |\n| AUTH_LDAP_UID_ATTRIBUTE | LDAP UID |\n\nAdditionally you have RUN_OPTS that can be used to customize pathing and behvior.\n\n| Option | Example |\n| :----: | --- |\n| --strict-ident | strictly bool `--strict-ident` |\n| --ident-daemon | strictly bool `--ident-daemon` |\n| --ident-port | `--ident-port \"10113\"` |\n| --ident-listen | `--ident-listen \"::,0.0.0.0\"` |\n| --ssl-cert | `--ssl-cert /config/keys/cert.crt` |\n| --ssl-key | `--ssl-key /config/keys/cert.key` |\n| --require-ssl | strictly bool `--require-ssl` |\n\nMinimal example with SQLite:\n\n```\ndocker create \\\n  --name=quassel-core \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e RUN_OPTS='--config-from-environment' \\\n  -e DB_BACKEND=SQLite \\\n  -e AUTH_AUTHENTICATOR=Database \\\n  -p 4242:4242 \\\n  -v <path to data>:/config \\\n  --restart unless-stopped \\\n  linuxserver/quassel-core\n```\n","changelogs":[{"date":"03.01.22:","desc":"Rebase to alpine 3.15. Add new build deps and apply other fixes for 0.14."},{"date":"07.08.21:","desc":"Fixing incorrect database password variable operator."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"20.03.19:","desc":"Make stateless operation an option, with input from one of the quassel team."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"08.01.19:","desc":"Rebase to Ubuntu Bionic and upgrade to Quassel`0.13.0` See [here.](https://quassel-irc.org/node/134)."},{"date":"30.07.18:","desc":"Rebase to alpine:3.8 and use buildstage."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"09.12.17:","desc":"Rebase to alpine:3.7."},{"date":"26.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"27.05.17:","desc":"Rebase to alpine:3.6."},{"date":"13.05.17:","desc":"Switch to git source."},{"date":"28.12.16:","desc":"Rebase to alpine:3.5."},{"date":"23.11.16:","desc":"Rebase to alpine:edge."},{"date":"23.09.16:","desc":"Use QT5 dependencies (thanks bauerj)."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"10.08.16:","desc":"Rebase to xenial."},{"date":"14.10.15:","desc":"Removed the webui, turned out to be to unstable for most usecases."},{"date":"01.09.15:","desc":"Fixed mistake in README."},{"date":"30.07.15:","desc":"Switched to internal baseimage, and fixed a bug with updating the webinterface."},{"date":"06.07.15:","desc":"Enabled BLOWFISH encryption and added a (optional) webinterface, for the times you dont have access to your client."}]}},"setup":"Quassel wiki: [quassel](http://bugs.quassel-irc.org/projects/quassel-irc/wiki)\n\nA great place to host a quassel instance is a VPS, such as [DigitalOcean](https://www.digitalocean.com/?refcode=501c48b34b8c). For $5 a month you can have a 24/7 IRC connection and be up and running in under 55 seconds (or so they claim).\n\nOnce you have the container running, fire up a quassel desktop client and connect to your new core instance using your droplets public IP address and the port you specified in your `docker run` command *default: 4242*. Create an admin user, select SQLite as your storage backend (Quassel limitation). Setup your real name and nick, then press `Save & Connect`.\n\nYou're now connected to IRC. Let's add you to our [IRC](http://www.linuxserver.io/index.php/irc/) `#linuxserver.io` room on Freenode. Click 'File' > 'Networks' > 'Configure Networks' > 'Add' (under Networks section, not Servers) > 'Use preset' > Select 'Freenode' and then configure your identity using the tabs in the 'Network details' section. Once connected to Freenode, click `#join` and enter `#linuxserver.io`. That's it, you're done.\n\n## Stateless usage\n\nTo use Quassel in stateless mode, where it needs to be configured through\nenvironment arguments, run it with the `--config-from-environment` RUN_OPTS environment setting.\n\n| Env | Usage |\n| :----: | --- |\n| DB_BACKEND | `SQLite` or `PostgreSQL` |\n| DB_PGSQL_USERNAME | PostgreSQL User |\n| DB_PGSQL_PASSWORD | PostgreSQL Password |\n| DB_PGSQL_HOSTNAME | PostgreSQL Host |\n| DB_PGSQL_PORT | PostgreSQL Port |\n| AUTH_AUTHENTICATOR | `Database` or `LDAP` |\n| AUTH_LDAP_HOSTNAME | LDAP Host |\n| AUTH_LDAP_PORT | LDAP Port |\n| AUTH_LDAP_BIND_DN | LDAP Bind Domain |\n| AUTH_LDAP_BIND_PASSWORD | LDAP Password |\n| AUTH_LDAP_FILTER | LDAP Authentication Filters |\n| AUTH_LDAP_UID_ATTRIBUTE | LDAP UID |\n\nAdditionally you have RUN_OPTS that can be used to customize pathing and behvior.\n\n| Option | Example |\n| :----: | --- |\n| --strict-ident | strictly bool `--strict-ident` |\n| --ident-daemon | strictly bool `--ident-daemon` |\n| --ident-port | `--ident-port \"10113\"` |\n| --ident-listen | `--ident-listen \"::,0.0.0.0\"` |\n| --ssl-cert | `--ssl-cert /config/keys/cert.crt` |\n| --ssl-key | `--ssl-key /config/keys/cert.key` |\n| --require-ssl | strictly bool `--require-ssl` |\n\nMinimal example with SQLite:\n\n```\ndocker create \\\n  --name=quassel-core \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e RUN_OPTS='--config-from-environment' \\\n  -e DB_BACKEND=SQLite \\\n  -e AUTH_AUTHENTICATOR=Database \\\n  -p 4242:4242 \\\n  -v <path to data>:/config \\\n  --restart unless-stopped \\\n  linuxserver/quassel-core\n```\n"},{"id":"quassel-web","name":"quassel-web","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web client for Quassel.  Note that a Quassel-Core instance is required, we have a container available [here.](https://hub.docker.com/r/linuxserver/quassel-core/) \n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/quassel-web-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/quassel-web"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-quassel-web"}],"containers":[{"name":"quassel-web","image":"linuxserver/quassel-web","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"QUASSEL_CORE","default":"192.168.1.10","description":"specify the URL or IP address of your Quassel Core instance"},{"id":"QUASSEL_PORT","default":"4242","description":"specify the port of your Quassel Core instance"},{"id":"URL_BASE","default":"/quassel","description":"Specify a url-base in reverse proxy setups ie. `/quassel`"}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"}],"ports":[{"container":"64443","description":"Quassel-web https webui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"quassel-web","project_url":"https://github.com/magne4000/quassel-webserver","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/quassel-web-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web client for Quassel.  Note that a Quassel-Core instance is required, we have a container available [here.](https://hub.docker.com/r/linuxserver/quassel-core/) \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v6-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store config on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"QUASSEL_CORE","env_value":"192.168.1.10","desc":"specify the URL or IP address of your Quassel Core instance"},{"env_var":"QUASSEL_PORT","env_value":"4242","desc":"specify the port of your Quassel Core instance"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"64443","internal_port":"64443","port_desc":"Quassel-web https webui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"URL_BASE","env_value":"/quassel","desc":"Specify a url-base in reverse proxy setups ie. `/quassel`"}],"app_setup_block_enabled":true,"app_setup_block":"By default this container webui will be available on `https://$SERVER_IP:64443`. To setup this container you can either use the envrionment variables we recommend or manually setup the configuration file by leaving out the `QUASSEL_CORE` environment variable among others. \nThe configuration file using this method can be found at:\n```\n/config/settings-user.js\n```\n","changelogs":[{"date":"12.02.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"18.05.19:","desc":"Reconfigure environmental variable setup."},{"date":"28.04.19:","desc":"Initial Release."}]}},"setup":"By default this container webui will be available on `https://$SERVER_IP:64443`. To setup this container you can either use the envrionment variables we recommend or manually setup the configuration file by leaving out the `QUASSEL_CORE` environment variable among others. \nThe configuration file using this method can be found at:\n```\n/config/settings-user.js\n```\n"},{"id":"radarr","name":"radarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) - A fork of Sonarr to work with movies  la Couchpotato.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/radarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/radarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-radarr"}],"containers":[{"name":"radarr","image":"linuxserver/radarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Radarr"}],"volumes":[{"container":"/movies","description":"Location of Movie library on disk (See note in Application setup)"},{"container":"/downloads","description":"Location of download managers output directory (See note in Application setup)"},{"container":"/config","description":"Database and Radarr configs","key":"config"}],"ports":[{"container":"7878","description":"The port for the Radarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"radarr","project_url":"https://github.com/Radarr/Radarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/radarr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - A fork of Sonarr to work with movies  la Couchpotato.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Radarr releases"},{"tag":"develop","desc":"Radarr releases from their develop branch"},{"tag":"nightly","desc":"Radarr releases from their nightly branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and Radarr configs"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/movies","vol_host_path":"/path/to/movies","desc":"Location of Movie library on disk (See note in Application setup)"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloadclient-downloads","desc":"Location of download managers output directory (See note in Application setup)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"7878","internal_port":"7878","port_desc":"The port for the Radarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Radarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:7878`, for more information check out [Radarr](https://github.com/Radarr/Radarr).\n\n### Media folders\n\nWe have set `/movies` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"17.01.23:","desc":"Rebase master branch to Alpine 3.17, migrate to s6v3."},{"date":"06.06.22:","desc":"Rebase master branch to Alpine 3.15."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine."},{"date":"04.02.22:","desc":"Rebase nightly branch to Alpine and deprecate nightly-alpine branch."},{"date":"27.12.21:","desc":"Add nightly-alpine branch."},{"date":"17.10.21:","desc":"Remove `UMASK_SET`."},{"date":"08.05.21:","desc":"Make the paths clearer to the user"},{"date":"17.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"11.30.20:","desc":"Publish `develop` tag."},{"date":"11.28.20:","desc":"Switch to v3 .NET CORE builds (no more mono, `5.14` tag is deprecated). Rebase to Focal (for issues on arm32v7, [see here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal))."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"10.05.19:","desc":"Rebase to Bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"09.09.18:","desc":"Add pipeline build process."},{"date":"24.02.18:","desc":"Add nightly branch."},{"date":"06.02.18:","desc":"Radarr repo changed owner."},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, adds python also."},{"date":"13.04.17:","desc":"Switch to official mono repository."},{"date":"10.01.17:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:7878`, for more information check out [Radarr](https://github.com/Radarr/Radarr).\n\n### Media folders\n\nWe have set `/movies` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n"},{"id":"raneto","name":"raneto","description":"[{{ project_name|capitalize }}]({{ project_url }}) - is an open source Knowledgebase platform that uses static Markdown files to power your Knowledgebase.","icon":"https://raw.githubusercontent.com/gilbitron/Raneto/master/logo/logo_readme.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/raneto"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-raneto"}],"containers":[{"name":"raneto","image":"linuxserver/raneto","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Raneto config and Markdown files","key":"config"}],"ports":[{"container":"3000","description":"The port for the Raneto web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"raneto","project_url":"http://raneto.com/","project_logo":"https://raw.githubusercontent.com/gilbitron/Raneto/master/logo/logo_readme.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - is an open source Knowledgebase platform that uses static Markdown files to power your Knowledgebase.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Raneto config and Markdown files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"The port for the Raneto web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://<your-ip>:3000\n\nThe default username and password is *admin/password*\n\nThis application can only be configured through file storage the web interface is only for editing Markdown files.\nYou need to understand the following paths and the role they play for the application:\n\n* /config/config.default.js - Main configuration file to setup your user, site name, etc.\n* /config/content - All of your Markdown files go here [more info](http://docs.raneto.com/usage/creating-pages).\n* /config/images - This folder will serve content on http://<your-ip>:3000/images/<image name>.png you can put anything in here but it is specifically for image files so you can embed them in your Markdown files without using external hosting.\n","changelogs":[{"date":"18.01.23:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"10.08.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.11."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"01.06.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://<your-ip>:3000\n\nThe default username and password is *admin/password*\n\nThis application can only be configured through file storage the web interface is only for editing Markdown files.\nYou need to understand the following paths and the role they play for the application:\n\n* /config/config.default.js - Main configuration file to setup your user, site name, etc.\n* /config/content - All of your Markdown files go here [more info](http://docs.raneto.com/usage/creating-pages).\n* /config/images - This folder will serve content on http://<your-ip>:3000/images/<image name>.png you can put anything in here but it is specifically for image files so you can embed them in your Markdown files without using external hosting.\n"},{"id":"rdesktop","name":"rdesktop","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Containers containing full desktop environments in many popular flavors for Alpine, Ubuntu, Arch, and Fedora accessible via RDP.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rdesktop.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/rdesktop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-rdesktop"}],"containers":[{"name":"rdesktop","image":"linuxserver/rdesktop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"ports":[{"container":"3389","description":"RDP access port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"rdesktop","project_url":"http://xrdp.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rdesktop.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Containers containing full desktop environments in many popular flavors for Alpine, Ubuntu, Arch, and Fedora accessible via RDP.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"XFCE Alpine"},{"tag":"ubuntu-xfce","desc":"XFCE Ubuntu"},{"tag":"fedora-xfce","desc":"XFCE Fedora"},{"tag":"arch-xfce","desc":"XFCE Arch"},{"tag":"alpine-kde","desc":"KDE Alpine"},{"tag":"ubuntu-kde","desc":"KDE Ubuntu"},{"tag":"fedora-kde","desc":"KDE Fedora"},{"tag":"arch-kde","desc":"KDE Arch"},{"tag":"alpine-mate","desc":"MATE Alpine"},{"tag":"ubuntu-mate","desc":"MATE Ubuntu"},{"tag":"fedora-mate","desc":"MATE Fedora"},{"tag":"arch-mate","desc":"MATE Arch"},{"tag":"alpine-i3","desc":"i3 Alpine"},{"tag":"ubuntu-i3","desc":"i3 Ubuntu"},{"tag":"fedora-i3","desc":"i3 Fedora"},{"tag":"arch-i3","desc":"i3 Arch"},{"tag":"alpine-openbox","desc":"Openbox Alpine"},{"tag":"ubuntu-openbox","desc":"Openbox Ubuntu"},{"tag":"fedora-openbox","desc":"Openbox Fedora"},{"tag":"arch-openbox","desc":"Openbox Arch"},{"tag":"alpine-icewm","desc":"IceWM Alpine"},{"tag":"ubuntu-icewm","desc":"IceWM Ubuntu"},{"tag":"fedora-icewm","desc":"IceWM Fedora"},{"tag":"arch-icewm","desc":"IceWM Arch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"3389","internal_port":"3389","port_desc":"RDP access port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/run/docker.sock","vol_host_path":"/var/run/docker.sock","desc":"Docker Socket on the system, if you want to use Docker in the container"},{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"abc users home directory"}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"We set this to 1 gig to prevent modern web browsers from crashing"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker"}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for GL support (Linux hosts only)"}],"app_setup_block_enabled":true,"app_setup_block":"**The Default USERNAME and PASSWORD is: abc/abc**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\nYou will need a Remote Desktop client to access this container [Wikipedia List](https://en.wikipedia.org/wiki/Comparison_of_remote_desktop_software), by default it listens on 3389, but you can change that port to whatever you wish on the host side IE `3390:3389`.\nThe first thing you should do when you login to the container is to change the abc users password by issuing the `passwd` command.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it rdesktop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt.\n","changelogs":[{"date":"27.10.22:","desc":"Rebase all Ubuntu images to Jammy 22.04."},{"date":"26.10.22:","desc":"Rebase Alpine xfce to 3.16, migrate to s6v3."},{"date":"05.03.22:","desc":"Organize tags differently to run Ubuntu at latest LTS, make Alpine latest, add docs about GPU accel."},{"date":"05.05.21:","desc":"Reduce default packages to their flavor specific basics."},{"date":"05.04.21:","desc":"Add Alpine flavor."},{"date":"06.04.20:","desc":"Start PulseAudio in images to support audio"},{"date":"28.02.20:","desc":"Initial Releases"}]}},"setup":"**The Default USERNAME and PASSWORD is: abc/abc**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\nYou will need a Remote Desktop client to access this container [Wikipedia List](https://en.wikipedia.org/wiki/Comparison_of_remote_desktop_software), by default it listens on 3389, but you can change that port to whatever you wish on the host side IE `3390:3389`.\nThe first thing you should do when you login to the container is to change the abc users password by issuing the `passwd` command.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it rdesktop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt.\n"},{"id":"readarr","name":"readarr","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/readarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/readarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-readarr"}],"containers":[{"name":"readarr","image":"linuxserver/readarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"404":"Not Found"}}},{"id":"remmina","name":"remmina","description":"[Remmina]({{ project_url }}) is a remote desktop client written in GTK, aiming to be useful for system administrators and travellers, who need to work with lots of remote computers in front of either large or tiny screens. Remmina supports multiple network protocols, in an integrated and consistent user interface. Currently RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC are supported.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/remmina-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/remmina"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-remmina"}],"containers":[{"name":"remmina","image":"linuxserver/remmina","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"}],"ports":[{"container":"3000","description":"Remmina desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"remmina","project_url":"https://remmina.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/remmina-icon.png","project_blurb":"[Remmina]({{ project_url }}) is a remote desktop client written in GTK, aiming to be useful for system administrators and travellers, who need to work with lots of remote computers in front of either large or tiny screens. Remmina supports multiple network protocols, in an integrated and consistent user interface. Currently RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC are supported.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Remmina desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.12.22:","desc":"Rebase to Jammy. Drop nx, xdmcp plugins due to lack of packages. Add Kiosk, Secret, x2go plugins."},{"date":"19.06.22:","desc":"Rebase to Focal. Drop Telepathy plugin due to lack of packages."},{"date":"27.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n"},{"id":"requestrr","name":"requestrr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat.","icon":"https://github.com/darkalfx/requestrr/raw/master/Logos/requestrr_discord_Icon_512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/requestrr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-requestrr"}],"containers":[{"name":"requestrr","image":"linuxserver/requestrr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"4545","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"requestrr","project_url":"https://github.com/darkalfx/requestrr","project_logo":"https://github.com/darkalfx/requestrr/raw/master/Logos/requestrr_discord_Icon_512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_deprecation_status":true,"project_deprecation_message":"The upstream dev has ended development.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Requestrr releases."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4545","internal_port":"4545","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"\nAccess the webui at `<your-ip>:4545`, for more information check out [Requestrr]({{ project_url }}).\n","changelogs":[{"date":"20.12.21:","desc":"Deprecate."},{"date":"27.09.21:","desc":"Allow app to write to tmp folder."},{"date":"21.02.21:","desc":"Initial Release."}]}},"setup":"\nAccess the webui at `<your-ip>:4545`, for more information check out [Requestrr]({{ project_url }}).\n"},{"id":"resilio-sync","name":"resilio-sync","description":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly BitTorrent Sync) uses the BitTorrent protocol to sync files and folders between all of your devices. There are both free and paid versions, this container supports both. There is an official sync image but we created this one as it supports user mapping to simplify permissions for volumes.","icon":"https://www.resilio.com/img/individual/freeproduct.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/resilio-sync"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-resilio-sync"}],"containers":[{"name":"resilio-sync","image":"linuxserver/resilio-sync","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where resilio-sync should store its config file.","key":"config"},{"container":"/downloads","description":"Folder for downloads/cache."},{"container":"/sync","description":"Sync folders root."}],"ports":[{"container":"8888","description":"WebUI","protocol":"tcp","web":false},{"container":"55555","description":"Sync Port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"resilio-sync","project_url":"https://www.resilio.com/individuals/","project_logo":"https://www.resilio.com/img/individual/freeproduct.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly BitTorrent Sync) uses the BitTorrent protocol to sync files and folders between all of your devices. There are both free and paid versions, this container supports both. There is an official sync image but we created this one as it supports user mapping to simplify permissions for volumes.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"opt_param_usage_include_env":false,"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where resilio-sync should store its config file."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Folder for downloads/cache."},{"vol_path":"/sync","vol_host_path":"/path/to/data","desc":"Sync folders root."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"WebUI"},{"external_port":"55555","internal_port":"55555","port_desc":"Sync Port."}],"param_device_map":false,"cap_add_param":false,"app_setup_block_enabled":true,"app_setup_block":"* Webui is at `<your-ip>:8888`, for account creation and configuration.\n* More info on setup at [Resilio Sync]({{ project_url }})\n","changelogs":[{"date":"14.12.22:","desc":"Rebase to Jammy, migrate to s6v3."},{"date":"03.10.21:","desc":"Use upstream apt repo to install. Rebase to focal."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Rebase to bionic, add pipeline logic and multi arch."},{"date":"05.02.18:","desc":"Add downloads volume mount."},{"date":"28.01.18:","desc":"Add /sync to dir whitelist."},{"date":"26.01.18:","desc":"Use variable for arch to bring in line with armhf arch repo."},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"02.06.17:","desc":"Rebase to ubuntu xenial, alpine linux no longer works with resilio."},{"date":"22.05.17:","desc":"Add variable for user defined umask."},{"date":"14.05.17:","desc":"Use fixed version instead of latest, while 2.5.0 is broken on non glibc (alpine)."},{"date":"08.02.17:","desc":"Rebase to alpine 3.5."},{"date":"02.11.16:","desc":"Initial Release."}]}},"setup":"* Webui is at `<your-ip>:8888`, for account creation and configuration.\n* More info on setup at [Resilio Sync]({{ project_url }})\n"},{"id":"rsnapshot","name":"rsnapshot","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rsnapshot.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/rsnapshot"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-rsnapshot"}],"containers":[{"name":"rsnapshot","image":"linuxserver/rsnapshot","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/.snapshots","description":"Storage location for all snapshots."},{"container":"/data","description":"Storage location for data to be backed up."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"rsnapshot","project_url":"http://www.rsnapshot.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rsnapshot.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration files."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/.snapshots","vol_host_path":"/path/to/snapshots","desc":"Storage location for all snapshots."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Storage location for data to be backed up."}],"app_setup_block_enabled":true,"app_setup_block":"### IMPORTANT NOTES:\nAfter starting the container you will need to edit `/config/rsnapshot.conf`.\n\n#### SNAPSHOT ROOT DIRECTORY\n\nrsnapshot is configured to backup data to the `/.snapshots` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n#### BACKUP LEVELS / INTERVALS\n\nrsnapshot retains backups based on configurations in this section.\nPlease see the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration) for more information.\n\n#### BACKUP POINTS\n\nrsnapshot is configured to backup data from the `/data` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n### cron\n\nYou will then need to edit `/config/crontabs/root` to set cron jobs to run rsnapshot.\nBy default no cron jobs are enabled. Examples are includes based on information from the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration).\n","changelogs":[{"date":"15.12.22:","desc":"Rebase to alpine 3.17."},{"date":"11.10.22:","desc":"Rebase to alpine 3.16, migrate to s6v3."},{"date":"10.10.21:","desc":"Rebase to alpine 3.14."},{"date":"20.08.20:","desc":"Initial Release."}]}},"setup":"### IMPORTANT NOTES:\nAfter starting the container you will need to edit `/config/rsnapshot.conf`.\n\n#### SNAPSHOT ROOT DIRECTORY\n\nrsnapshot is configured to backup data to the `/.snapshots` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n#### BACKUP LEVELS / INTERVALS\n\nrsnapshot retains backups based on configurations in this section.\nPlease see the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration) for more information.\n\n#### BACKUP POINTS\n\nrsnapshot is configured to backup data from the `/data` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n### cron\n\nYou will then need to edit `/config/crontabs/root` to set cron jobs to run rsnapshot.\nBy default no cron jobs are enabled. Examples are includes based on information from the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration).\n"},{"id":"sabnzbd","name":"sabnzbd","description":"[{{ project_name|capitalize }}]({{ project_url }}) makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sabnzbd-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sabnzbd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sabnzbd"}],"containers":[{"name":"sabnzbd","image":"linuxserver/sabnzbd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/downloads","description":"Local path for finished downloads."},{"container":"/incomplete-downloads","description":"Local path for incomplete-downloads."},{"container":"/config","description":"Local path for sabnzbd config files.","key":"config"}],"ports":[{"container":"8080","description":"HTTP port for the WebUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sabnzbd","project_url":"http://sabnzbd.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sabnzbd-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable SABnzbd releases"},{"tag":"unstable","desc":"Pre-releases from the develop branch"},{"tag":"nightly","desc":"Latest commits from the develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local path for sabnzbd config files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"HTTP port for the WebUI."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Local path for finished downloads."},{"vol_path":"/incomplete-downloads","vol_host_path":"/path/to/incomplete/downloads","desc":"Local path for incomplete-downloads."}],"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Initial setup is done from the http port.\n\nSee the [SABnzbd wiki](https://sabnzbd.org/wiki/) for more information.\n\n### nzb-notify\n\nnzb-notify is included with this image as a convenience script. To use it set the Scripts folder in the Folder settings to /app/nzbnotify and then configure it under Notifications. See [nzb-notify](https://github.com/caronc/nzb-notify/) for more information.\n\n### Download folders\n\nIn Sabnzbd gui settings, under `Folders`, make sure to set the `Completed Download Folder` as `/downloads` and the `Temporary Download Folder` as `/incomplete-downloads`\n\nWe have set `/incomplete-downloads` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves. \n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"03.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"31.07.22:","desc":"Add nightly tag."},{"date":"10.03.22:","desc":"Add nzb-notify."},{"date":"22.02.22:","desc":"Rebase master branch to Alpine, build unrar from source, deprecate Alpine branch."},{"date":"25.01.22:","desc":"Rebase Unstable branch to Alpine."},{"date":"13.01.22:","desc":"Add alpine branch"},{"date":"08.08.21:","desc":"Bump to focal, dont enforce binding to ipv4 port 8080"},{"date":"24.07.21:","desc":"Add python3-setuptools."},{"date":"14.05.21:","desc":"Use linuxserver.io wheel index for pip packages."},{"date":"12.02.21:","desc":"Clean up rust/cargo and pip cache."},{"date":"17.08.20:","desc":"Run from source with python3 instead of ppa, remove python2 completely, symlink `python` to `python3`."},{"date":"02.01.20:","desc":"Add python3 on top of python2 to image during transition."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"25.02.19:","desc":"Rebase to Bionic, add python deps for scripts."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"13.12.17:","desc":"Fix continuation lines."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"10.04.17:","desc":"Bump to 2.0 Release."},{"date":"25.02.17:","desc":"Switch to nobetas repo for master/latest branch and add unstable branch."},{"date":"08.02.17:","desc":"Add pythonioenconding=utf8 as env."},{"date":"15.09.16:","desc":"Compile par2 multicore as per latest info sabnzbd git [readme](https://github.com/sabnzbd/sabnzbd#resolving-dependencies)."},{"date":"11.09.16:","desc":"Bump to release of 1.10."},{"date":"09.09.16:","desc":"Rebase back to xenial, issues with alpine version of python and 1.10 branch of sab."},{"date":"28.08.16:","desc":"Rebase to alpine, using git version of sab."},{"date":"17.03.16:","desc":"Bump to install 1.0 final at startup."},{"date":"14.03.16:","desc":"Refresh image to pick up latest RC."},{"date":"23.01.15:","desc":"Refresh image."},{"date":"14.12.15:","desc":"Refresh image to pick up latest beta."},{"date":"21.08.15:","desc":"Initial Release."}]}},"setup":"Initial setup is done from the http port.\n\nSee the [SABnzbd wiki](https://sabnzbd.org/wiki/) for more information.\n\n### nzb-notify\n\nnzb-notify is included with this image as a convenience script. To use it set the Scripts folder in the Folder settings to /app/nzbnotify and then configure it under Notifications. See [nzb-notify](https://github.com/caronc/nzb-notify/) for more information.\n\n### Download folders\n\nIn Sabnzbd gui settings, under `Folders`, make sure to set the `Completed Download Folder` as `/downloads` and the `Temporary Download Folder` as `/incomplete-downloads`\n\nWe have set `/incomplete-downloads` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves. \n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n"},{"id":"sickchill","name":"sickchill","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an Automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. \n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sickchill-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sickchill"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sickchill"}],"containers":[{"name":"sickchill","image":"linuxserver/sickchill","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"specify your TimeZone e.g. Europe/London"}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"},{"container":"/downloads","description":"this will store any downloaded data on the docker host"},{"container":"/tv","description":"this will allow sickchill to view what you already have"}],"ports":[{"container":"8081","description":"will map the container's port 8081 to port 8081 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sickchill","project_url":"https://github.com/SickChill/SickChill","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sickchill-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an Automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store config on the docker host"},{"vol_path":"/downloads","vol_host_path":"/path/to/data","desc":"this will store any downloaded data on the docker host"},{"vol_path":"/tv","vol_host_path":"/path/to/data","desc":"this will allow sickchill to view what you already have"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"specify your TimeZone e.g. Europe/London"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"will map the container's port 8081 to port 8081 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Web interface is at `<your ip>:8081` , set paths for downloads, tv-shows to match docker mappings via the webui.\n","changelogs":[{"date":"17.02.22:","desc":"Rebase to alpine 3.17."},{"date":"17.02.22:","desc":"Rebase to alpine 3.15."},{"date":"20.11.21:","desc":"Modify binary usage from SickChill.py to SickChill."},{"date":"14.05.21:","desc":"Add linuxserver wheel index."},{"date":"12.02.21:","desc":"Rebasing to alpine 3.13. Add python certifi."},{"date":"17.09.20:","desc":"Update dependencies."},{"date":"06.09.20:","desc":"Switch to python3, install pip package."},{"date":"22.04.20:","desc":"Switch to git clone and using git tags for versioning."},{"date":"09.01.20:","desc":"Remove creating data volumes, fix build args for armhf and aarch64."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"17.04.19:","desc":"Adding Nodejs dependancy."},{"date":"31.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.10.18:","desc":"Initial Release."}]}},"setup":"Web interface is at `<your ip>:8081` , set paths for downloads, tv-shows to match docker mappings via the webui.\n"},{"id":"sickgear","name":"sickgear","description":"[SickGear]({{ project_url }}) provides management of TV shows and/or Anime, it detects new episodes, links downloader apps, and more..\n\nFor more information on SickGear visit their website and check it out: https://github.com/SickGear/SickGear\n","icon":"https://raw.githubusercontent.com/wiki/SickGear/SickGear.Wiki/images/SickGearLogo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sickgear"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sickgear"}],"containers":[{"name":"sickgear","image":"linuxserver/sickgear","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"},{"container":"/tv","description":"where you store your tv shows"},{"container":"/downloads","description":"your downloads folder for post processing (must not be download in progress)"}],"ports":[{"container":"8081","description":"will map the container's port 8081 to port 8081 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sickgear","project_url":"https://github.com/sickgear/sickgear","project_logo":"https://raw.githubusercontent.com/wiki/SickGear/SickGear.Wiki/images/SickGearLogo.png","project_blurb":"[SickGear]({{ project_url }}) provides management of TV shows and/or Anime, it detects new episodes, links downloader apps, and more..\n\nFor more information on SickGear visit their website and check it out: https://github.com/SickGear/SickGear\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"},{"vol_path":"/tv","vol_host_path":"/path/to/data","desc":"where you store your tv shows"},{"vol_path":"/downloads","vol_host_path":"/path/to/data","desc":"your downloads folder for post processing (must not be download in progress)"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"will map the container's port 8081 to port 8081 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"## Setting up the application\n\nAccess the webui at `<your-ip>:8081`, for more information check out [SickGear]({{ project_url }}).\n\n## Migration\n\nNon linuxserver.io containers are known to have the following configuration differences and may need SickGear or docker changes to migrate an existing setup\n\n* The post processing directory which is volume mounted as `downloads` within this container may be `incoming` in other versions.\n\n* The permissions environmental variables which are defined as `PGID` and `PUID` within this container may have been `APP_UID` and `APP_UID` in other versions.\n\n* The configuration file directory which is volume mounted as `config` within this container may be set as the environmetal variable `APP_DATA` in other versions.\n\n* The cache directory which is set in `config.ini` may be configured as a fixed path `cache_dir = /data/cache`.\nSymptoms of this issue include port usage problems and a failure to start the web server log entries.\nWhilst the container is stopped alter this directive to `cache_dir = cache` which will allow SickGear to look for the folder relative to the volume mounted `/config` directory.\n\nIt is recommended that a clean install be completed, rather than a migration, however if migration is necessary:\n\n* start a new instance of this image\n\n* compare and align SickGear version numbers bewteen old and new. Ideally they should match but at a minumum the old vesion should be a lower version number to allow SickGear itself to try and migrate\n\n* stop both containers\n\n* notice the configuration difference and migrate copies of the old settings into the new app\n\n* start the new container and test\n","changelogs":[{"date":"18.11.22:","desc":"Update service file from legacy SickBeard.py to sickgear.py."},{"date":"10.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15. Build unrar from source."},{"date":"31.01.21:","desc":"Add unrar."},{"date":"29.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"03.06.20:","desc":"Rebasing to alpine 3.12, switch to python3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"07.11.18:","desc":"Pipeline prep"},{"date":"07.07.18:","desc":"Initial draft release"}]}},"setup":"## Setting up the application\n\nAccess the webui at `<your-ip>:8081`, for more information check out [SickGear]({{ project_url }}).\n\n## Migration\n\nNon linuxserver.io containers are known to have the following configuration differences and may need SickGear or docker changes to migrate an existing setup\n\n* The post processing directory which is volume mounted as `downloads` within this container may be `incoming` in other versions.\n\n* The permissions environmental variables which are defined as `PGID` and `PUID` within this container may have been `APP_UID` and `APP_UID` in other versions.\n\n* The configuration file directory which is volume mounted as `config` within this container may be set as the environmetal variable `APP_DATA` in other versions.\n\n* The cache directory which is set in `config.ini` may be configured as a fixed path `cache_dir = /data/cache`.\nSymptoms of this issue include port usage problems and a failure to start the web server log entries.\nWhilst the container is stopped alter this directive to `cache_dir = cache` which will allow SickGear to look for the folder relative to the volume mounted `/config` directory.\n\nIt is recommended that a clean install be completed, rather than a migration, however if migration is necessary:\n\n* start a new instance of this image\n\n* compare and align SickGear version numbers bewteen old and new. Ideally they should match but at a minumum the old vesion should be a lower version number to allow SickGear itself to try and migrate\n\n* stop both containers\n\n* notice the configuration difference and migrate copies of the old settings into the new app\n\n* start the new container and test\n"},{"id":"smokeping","name":"smokeping","description":"[{{ project_name|capitalize }}]({{ project_url }}) keeps track of your network latency. For a full example of what this application is capable of visit [UCDavis](http://smokeping.ucdavis.edu/cgi-bin/smokeping.fcgi).","icon":"https://camo.githubusercontent.com/e0694ef783e3fd1d74e6776b28822ced01c7cc17/687474703a2f2f6f73732e6f6574696b65722e63682f736d6f6b6570696e672f696e632f736d6f6b6570696e672d6c6f676f2e706e67","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/smokeping"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-smokeping"}],"containers":[{"name":"smokeping","image":"linuxserver/smokeping","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Configure the `Targets` file here","key":"config"},{"container":"/data","description":"Storage location for db and application data (graphs etc)"}],"ports":[{"container":"80","description":"Allows HTTP access to the internal webserver.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"smokeping","project_url":"https://oss.oetiker.ch/smokeping/","project_logo":"https://camo.githubusercontent.com/e0694ef783e3fd1d74e6776b28822ced01c7cc17/687474703a2f2f6f73732e6f6574696b65722e63682f736d6f6b6570696e672f696e632f736d6f6b6570696e672d6c6f676f2e706e67","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) keeps track of your network latency. For a full example of what this application is capable of visit [UCDavis](http://smokeping.ucdavis.edu/cgi-bin/smokeping.fcgi).","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/smokeping/config","desc":"Configure the `Targets` file here"},{"vol_path":"/data","vol_host_path":"/path/to/{{ project_name }}/data","desc":"Storage location for db and application data (graphs etc)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Allows HTTP access to the internal webserver."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"* Once running the URL will be `http://<host-ip>/smokeping/smokeping.cgi`. For example a full URL might look like `https://smokeping.yourdomain.com/smokeping/smokeping.cgi`.\n* Basics are, edit the `Targets` file to ping the hosts you're interested in to match the format found there.\n* Wait 10 minutes.\n","changelogs":[{"date":"22.01.23:","desc":"Revert to using Apache due to latency issues with nginx and fcgiwrap."},{"date":"12.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3, switch to nginx and fcgiwrap."},{"date":"29.03.21:","desc":"Dockerfile: Install curl before we call it"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.11.18:","desc":"Allow access without /smokeping in URL."},{"date":"28.04.18:","desc":"Rebase to alpine 3.8."},{"date":"09.04.18:","desc":"Add bc package."},{"date":"08.04.18:","desc":"Add tccping script and tcptraceroute package (thanks rcarmo)."},{"date":"13.12.17:","desc":"Expose httpd_conf to /config."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"24.07.17:","desc":"Add :unraid tag for hosts without ipv6."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"07.05.17:","desc":"Expose smokeping.conf in /config/site-confs to allow user customisations"},{"date":"12.04.17:","desc":"Fix cropper.js path, thanks nibbledeez."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"17.10.16:","desc":"Add ttf-dejavu package as per [LT forum](http://lime-technology.com/forum/index.php?topic=43602.msg507875#msg507875)."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.09.16:","desc":"Add curl package."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"25.07.16:","desc":"Rebase to alpine linux."},{"date":"23.07.16:","desc":"Fix apt script confusion."},{"date":"29.06.15:","desc":"This is the first release, it is mostly stable, but may contain minor defects. (thus a beta tag)"}]}},"setup":"* Once running the URL will be `http://<host-ip>/smokeping/smokeping.cgi`. For example a full URL might look like `https://smokeping.yourdomain.com/smokeping/smokeping.cgi`.\n* Basics are, edit the `Targets` file to ping the hosts you're interested in to match the format found there.\n* Wait 10 minutes.\n"},{"id":"snapdrop","name":"snapdrop","description":"[{{ project_name|capitalize }}]({{ project_url }}) A local file sharing in your browser. Inspired by Apple's Airdrop.","icon":"https://raw.githubusercontent.com/RobinLinus/snapdrop/master/client/images/logo_transparent_512x512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/snapdrop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-snapdrop"}],"containers":[{"name":"snapdrop","image":"linuxserver/snapdrop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Persistent configs and logs.","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"snapdrop","project_url":"https://github.com/RobinLinus/snapdrop","project_logo":"https://raw.githubusercontent.com/RobinLinus/snapdrop/master/client/images/logo_transparent_512x512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A local file sharing in your browser. Inspired by Apple's Airdrop.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to config>","desc":"Persistent configs and logs."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Webui is accessible at http://SERVERIP:PORT\n\nIf you intend to expose Snapdrop to the internet, edit /config/nginx/site-confs/default.conf and uncomment the real_ip settings\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"09.08.21:","desc":"Rebase to Alpine 3.14. Add real_ip block to nginx default site config."},{"date":"15.09.20:","desc":"Initial Release."}]}},"setup":"Webui is accessible at http://SERVERIP:PORT\n\nIf you intend to expose Snapdrop to the internet, edit /config/nginx/site-confs/default.conf and uncomment the real_ip settings\n"},{"id":"snipe-it","name":"snipe-it","description":"[{{ project_name|capitalize }}]({{ project_url }}) makes asset management easy. It was built by people solving real-world IT and asset management problems, and a solid UX has always been a top priority. Straightforward design and bulk actions mean getting things done faster.","icon":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/snipe-it-logo500x500.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/snipe-it"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-snipe-it"}],"containers":[{"name":"snipe-it","image":"linuxserver/snipe-it","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"APP_URL","default":"http://localhost:8080","description":"Hostname or IP and port if applicable, be sure to define https/http"},{"id":"MYSQL_PORT_3306_TCP_ADDR","default":"","description":"Mysql hostname or IP to use"},{"id":"MYSQL_PORT_3306_TCP_PORT","default":"","description":"Mysql port to use"},{"id":"MYSQL_DATABASE","default":"","description":"Mysql database to use"},{"id":"MYSQL_USER","default":"","description":"Mysql user to use"},{"id":"MYSQL_PASSWORD","default":"","description":"Mysql password to use"},{"id":"TZ","default":"US/Pacific","description":"Specify a timezone to use EG Europe/London, this is required to run snipe-it"}],"volumes":[{"container":"/config","description":"Contains your config files and data storage for Snipe-IT","key":"config"}],"ports":[{"container":"80","description":"Snipe-IT Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"snipe-it","project_url":"https://github.com/snipe/snipe-it","project_logo":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/snipe-it-logo500x500.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) makes asset management easy. It was built by people solving real-world IT and asset management problems, and a solid UX has always been a top priority. Straightforward design and bulk actions mean getting things done faster.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Contains your config files and data storage for Snipe-IT"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"80","port_desc":"Snipe-IT Web UI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"APP_URL","env_value":"http://localhost:8080","desc":"Hostname or IP and port if applicable, be sure to define https/http"},{"env_var":"MYSQL_PORT_3306_TCP_ADDR","env_value":"","desc":"Mysql hostname or IP to use"},{"env_var":"MYSQL_PORT_3306_TCP_PORT","env_value":"","desc":"Mysql port to use"},{"env_var":"MYSQL_DATABASE","env_value":"","desc":"Mysql database to use"},{"env_var":"MYSQL_USER","env_value":"","desc":"Mysql user to use"},{"env_var":"MYSQL_PASSWORD","env_value":"","desc":"Mysql password to use"},{"env_var":"TZ","env_value":"US/Pacific","desc":"Specify a timezone to use EG Europe/London, this is required to run snipe-it"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8080`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n**This container requires a MySQL or MariaDB server to connect to, we reccomend [ours](https://github.com/linuxserver/docker-mariadb)**\n\nThis container also generates an SSL certificate and stores it in\n```\n/config/keys/cert.crt\n/config/keys/cert.key\n```\nTo use your own certificate swap these files with yours. To use SSL forward your port to 443 inside the container IE:\n\n```\n-p 443:443\n```\n\nThe application accepts a series of environment variables to further customize itself on boot:\n\n| Parameter | Function |\n| :---: | --- |\n| `-e APP_ENV=` | Default is production but can use testing or develop|\n| `-e APP_DEBUG=` | Set to true to see debugging output in the web UI|\n| `-e APP_LOCALE=` | Default is en set to the language preferred full list [here](https://snipe-it.readme.io/docs/configuration#section-setting-a-language)|\n| `-e MAIL_PORT_587_TCP_ADDR=` | SMTP mailserver ip or hostname|\n| `-e MAIL_PORT_587_TCP_PORT=` | SMTP mailserver port|\n| `-e MAIL_ENV_FROM_ADDR=` | The email address mail should be replied to and listed when sent|\n| `-e MAIL_ENV_FROM_NAME=` | The name listed on email sent from the default account on the system|\n| `-e MAIL_ENV_ENCRYPTION=` | Mail encryption to use IE tls |\n| `-e MAIL_ENV_USERNAME=` | SMTP server login username|\n| `-e MAIL_ENV_PASSWORD=` | SMTP server login password|\n\n### PHP customization\n\nThis image uses our NGINX base image all configuration files for PHP and NGINX are located in `/config/php`. To overide any defaults please modify `/config/php/php-local.ini` IE for upload size: \n\n```\nupload_max_filesize = 16\npost_max_size = 16M\n```\n","changelogs":[{"date":"28.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"14.05.22:","desc":"Add php7-sodium for v6."},{"date":"12.04.22:","desc":"Don't build development elements."},{"date":"02.03.22:","desc":"Rework init logic, do not show default compose."},{"date":"29.06.21:","desc":"Rebasing to alpine 3.14."},{"date":"30.04.21:","desc":"Rebasing to alpine 3.13, add artisan migrate on spinup."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"10.04.19:","desc":"Add php deps for V4.7.0, ensure framework directories are available at build time."},{"date":"10.04.19:","desc":"Fix permissions for new bootstrap cache directory."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"31.10.18:","desc":"Rebasing to alpine 3.8"},{"date":"05.08.18:","desc":"Migration to live build server."},{"date":"13.06.18:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:8080`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n**This container requires a MySQL or MariaDB server to connect to, we reccomend [ours](https://github.com/linuxserver/docker-mariadb)**\n\nThis container also generates an SSL certificate and stores it in\n```\n/config/keys/cert.crt\n/config/keys/cert.key\n```\nTo use your own certificate swap these files with yours. To use SSL forward your port to 443 inside the container IE:\n\n```\n-p 443:443\n```\n\nThe application accepts a series of environment variables to further customize itself on boot:\n\n| Parameter | Function |\n| :---: | --- |\n| `-e APP_ENV=` | Default is production but can use testing or develop|\n| `-e APP_DEBUG=` | Set to true to see debugging output in the web UI|\n| `-e APP_LOCALE=` | Default is en set to the language preferred full list [here](https://snipe-it.readme.io/docs/configuration#section-setting-a-language)|\n| `-e MAIL_PORT_587_TCP_ADDR=` | SMTP mailserver ip or hostname|\n| `-e MAIL_PORT_587_TCP_PORT=` | SMTP mailserver port|\n| `-e MAIL_ENV_FROM_ADDR=` | The email address mail should be replied to and listed when sent|\n| `-e MAIL_ENV_FROM_NAME=` | The name listed on email sent from the default account on the system|\n| `-e MAIL_ENV_ENCRYPTION=` | Mail encryption to use IE tls |\n| `-e MAIL_ENV_USERNAME=` | SMTP server login username|\n| `-e MAIL_ENV_PASSWORD=` | SMTP server login password|\n\n### PHP customization\n\nThis image uses our NGINX base image all configuration files for PHP and NGINX are located in `/config/php`. To overide any defaults please modify `/config/php/php-local.ini` IE for upload size: \n\n```\nupload_max_filesize = 16\npost_max_size = 16M\n```\n"},{"id":"sonarr","name":"sonarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly NZBdrone) is a PVR for usenet and bittorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sonarr-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sonarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sonarr"}],"containers":[{"name":"sonarr","image":"linuxserver/sonarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Sonarr"}],"volumes":[{"container":"/tv","description":"Location of TV library on disk (See note in Application setup)"},{"container":"/downloads","description":"Location of download managers output directory (See note in Application setup)"},{"container":"/config","description":"Database and sonarr configs","key":"config"}],"ports":[{"container":"8989","description":"The port for the Sonarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sonarr","project_url":"https://sonarr.tv/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sonarr-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly NZBdrone) is a PVR for usenet and bittorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from Sonarr (currently v3)"},{"tag":"develop","desc":"Development releases from Sonarr (currently v4)"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and sonarr configs"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/tv","vol_host_path":"/path/to/tvseries","desc":"Location of TV library on disk (See note in Application setup)"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloadclient-downloads","desc":"Location of download managers output directory (See note in Application setup)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8989","internal_port":"8989","port_desc":"The port for the Sonarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Sonarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8989`, for more information check out [Sonarr](https://sonarr.tv/).\n\n### Media folders\n\nWe have set `/tv` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/Docker_Guide#Consistent_and_well_planned_paths) on how to get started with this.\n","changelogs":[{"date":"24.11.22:","desc":"Bump develop branch to v4, rebase to Alpine 3.16."},{"date":"03.08.22:","desc":"Deprecate armhf."},{"date":"02.08.22:","desc":"Add armhf deprecation warning."},{"date":"28.04.22:","desc":"Rebase master branch to mono 6.12 base (focal)."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine, deprecate develop-alpine branch."},{"date":"28.12.21:","desc":"Add develop-alpine branch."},{"date":"11.05.21:","desc":"Make the paths clearer to the user."},{"date":"10.03.21:","desc":"Upgrade to Sonarr v3. Existing users are highly recommended to make a backup prior to update."},{"date":"18.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"10.05.19:","desc":"Rebase to Bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.02.19:","desc":"Multi arch images and pipeline build logic"},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, adds python also."},{"date":"14.04.17:","desc":"Change to mount /etc/localtime in README, thanks cbgj."},{"date":"13.04.17:","desc":"Switch to official mono repository."},{"date":"30.09.16:","desc":"Fix umask"},{"date":"23.09.16:","desc":"Add cd to /opt fixes redirects with althub (issue #25), make XDG config environment variable"},{"date":"15.09.16:","desc":"Add libcurl3 package."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README."},{"date":"20.07.16:","desc":"Rebase to xenial."},{"date":"31.08.15:","desc":"Cleanup, changed sources to fetch binarys from. also a new baseimage."}]}},"setup":"Access the webui at `<your-ip>:8989`, for more information check out [Sonarr](https://sonarr.tv/).\n\n### Media folders\n\nWe have set `/tv` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/Docker_Guide#Consistent_and_well_planned_paths) on how to get started with this.\n"},{"id":"sqlitebrowser","name":"sqlitebrowser","description":"[DB Browser for SQLite]({{ project_url }}) is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sqlitebrowser-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sqlitebrowser"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sqlitebrowser"}],"containers":[{"name":"sqlitebrowser","image":"linuxserver/sqlitebrowser","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and potentially dump files.","key":"config"}],"ports":[{"container":"3000","description":"Sqlitebrowser desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sqlitebrowser","project_url":"https://sqlitebrowser.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sqlitebrowser-banner.png","project_blurb":"[DB Browser for SQLite]({{ project_url }}) is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and potentially dump files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Sqlitebrowser desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"16.02.22:","desc":"Rebase to Alpine."},{"date":"20.01.21:","desc":"Remove Wireshark reference."},{"date":"29.07.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n"},{"id":"swag","name":"swag","description":"SWAG - Secure Web Application Gateway (formerly known as letsencrypt, no relation to Let's Encrypt) sets up an Nginx webserver and reverse proxy with php support and a built-in certbot client that automates free SSL server certificate generation and renewal processes (Let's Encrypt and ZeroSSL). It also contains fail2ban for intrusion prevention.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/swag.gif","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/swag"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-swag"}],"containers":[{"name":"swag","image":"linuxserver/swag","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"URL","default":"yourdomain.url","description":"Top url you have control over (`customdomain.com` if you own it, or `customsubdomain.ddnsprovider.com` if dynamic dns)."},{"id":"VALIDATION","default":"http","description":"Certbot validation method to use, options are `http` or `dns` (`dns` method also requires `DNSPLUGIN` variable set)."},{"id":"SUBDOMAINS","default":"www,","description":"Subdomains you'd like the cert to cover (comma separated, no spaces) ie. `www,ftp,cloud`. For a wildcard cert, set this *exactly* to `wildcard` (wildcard cert is available via `dns` validation only)"},{"id":"CERTPROVIDER","default":"","description":"Optionally define the cert provider. Set to `zerossl` for ZeroSSL certs (requires existing [ZeroSSL account](https://app.zerossl.com/signup) and the e-mail address entered in `EMAIL` env var). Otherwise defaults to Let's Encrypt."},{"id":"DNSPLUGIN","default":"cloudflare","description":"Required if `VALIDATION` is set to `dns`. Options are `acmedns`, `aliyun`, `azure`, `cloudflare`, `cpanel`, `desec`, `digitalocean`, `directadmin`, `dnsimple`, `dnsmadeeasy`, `dnspod`, `do`, `domeneshop`, `duckdns`, `dynu`, `gandi`, `gehirn`, `godaddy`, `google`, `he`, `hetzner`, `infomaniak`, `inwx`, `ionos`, `linode`, `loopia`, `luadns`, `netcup`, `njalla`, `nsone`, `ovh`, `porkbun`, `rfc2136`, `route53`, `sakuracloud`, `standalone`, `transip`, and `vultr`. Also need to enter the credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`."},{"id":"PROPAGATION","default":"","description":"Optionally override (in seconds) the default propagation time for the dns plugins."},{"id":"EMAIL","default":"","description":"Optional e-mail address used for cert expiration notifications (Required for ZeroSSL)."},{"id":"ONLY_SUBDOMAINS","default":"false","description":"If you wish to get certs only for certain subdomains, but not the main domain (main domain may be hosted on another machine and cannot be validated), set this to `true`"},{"id":"EXTRA_DOMAINS","default":"","description":"Additional fully qualified domain names (comma separated, no spaces) ie. `extradomain.com,subdomain.anotherdomain.org,*.anotherdomain.org`"},{"id":"STAGING","default":"false","description":"Set to `true` to retrieve certs in staging mode. Rate limits will be much higher, but the resulting cert will not pass the browser's security test. Only to be used for testing purposes."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"All the config files including the webroot reside here.","key":"config"}],"ports":[{"container":"443","description":"Https port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"swag","project_url":"https://linuxserver.io","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/swag.gif","project_blurb":"SWAG - Secure Web Application Gateway (formerly known as letsencrypt, no relation to Let's Encrypt) sets up an Nginx webserver and reverse proxy with php support and a built-in certbot client that automates free SSL server certificate generation and renewal processes (Let's Encrypt and ZeroSSL). It also contains fail2ban for intrusion prevention.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"URL","env_value":"yourdomain.url","desc":"Top url you have control over (`customdomain.com` if you own it, or `customsubdomain.ddnsprovider.com` if dynamic dns)."},{"env_var":"VALIDATION","env_value":"http","desc":"Certbot validation method to use, options are `http` or `dns` (`dns` method also requires `DNSPLUGIN` variable set)."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"All the config files including the webroot reside here."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"443","internal_port":"443","port_desc":"Https port"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBDOMAINS","env_value":"www,","desc":"Subdomains you'd like the cert to cover (comma separated, no spaces) ie. `www,ftp,cloud`. For a wildcard cert, set this *exactly* to `wildcard` (wildcard cert is available via `dns` validation only)"},{"env_var":"CERTPROVIDER","env_value":"","desc":"Optionally define the cert provider. Set to `zerossl` for ZeroSSL certs (requires existing [ZeroSSL account](https://app.zerossl.com/signup) and the e-mail address entered in `EMAIL` env var). Otherwise defaults to Let's Encrypt."},{"env_var":"DNSPLUGIN","env_value":"cloudflare","desc":"Required if `VALIDATION` is set to `dns`. Options are `acmedns`, `aliyun`, `azure`, `cloudflare`, `cpanel`, `desec`, `digitalocean`, `directadmin`, `dnsimple`, `dnsmadeeasy`, `dnspod`, `do`, `domeneshop`, `duckdns`, `dynu`, `gandi`, `gehirn`, `godaddy`, `google`, `he`, `hetzner`, `infomaniak`, `inwx`, `ionos`, `linode`, `loopia`, `luadns`, `netcup`, `njalla`, `nsone`, `ovh`, `porkbun`, `rfc2136`, `route53`, `sakuracloud`, `standalone`, `transip`, and `vultr`. Also need to enter the credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`."},{"env_var":"PROPAGATION","env_value":"","desc":"Optionally override (in seconds) the default propagation time for the dns plugins."},{"env_var":"EMAIL","env_value":"","desc":"Optional e-mail address used for cert expiration notifications (Required for ZeroSSL)."},{"env_var":"ONLY_SUBDOMAINS","env_value":"false","desc":"If you wish to get certs only for certain subdomains, but not the main domain (main domain may be hosted on another machine and cannot be validated), set this to `true`"},{"env_var":"EXTRA_DOMAINS","env_value":"","desc":"Additional fully qualified domain names (comma separated, no spaces) ie. `extradomain.com,subdomain.anotherdomain.org,*.anotherdomain.org`"},{"env_var":"STAGING","env_value":"false","desc":"Set to `true` to retrieve certs in staging mode. Rate limits will be much higher, but the resulting cert will not pass the browser's security test. Only to be used for testing purposes."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Http port (required for http validation and http -> https redirect)"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"### Validation and initial setup\n\n* Before running this container, make sure that the url and subdomains are properly forwarded to this container's host, and that port 443 (and/or 80) is not being used by another service on the host (NAS gui, another webserver, etc.).\n* If you need a dynamic dns provider, you can use the free provider duckdns.org where the `URL` will be `yoursubdomain.duckdns.org` and the `SUBDOMAINS` can be `www,ftp,cloud` with http validation, or `wildcard` with dns validation. You can use our [duckdns image](https://hub.docker.com/r/linuxserver/duckdns/) to update your IP on duckdns.org.\n* For `http` validation, port 80 on the internet side of the router should be forwarded to this container's port 80\n* For `dns` validation, make sure to enter your credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`\n  * Cloudflare provides free accounts for managing dns and is very easy to use with this image. Make sure that it is set up for \"dns only\" instead of \"dns + proxy\"\n  * Google dns plugin is meant to be used with \"Google Cloud DNS\", a paid enterprise product, and not for \"Google Domains DNS\"\n  * DuckDNS only supoprts two types of DNS validated certificates (not both at the same time):\n    1. Certs that only cover your main subdomain (ie. `yoursubdomain.duckdns.org`, leave the `SUBDOMAINS` variable empty)\n    2. Certs that cover sub-subdomains of your main subdomain (ie. `*.yoursubdomain.duckdns.org`, set the `SUBDOMAINS` variable to `wildcard`)\n* `--cap-add=NET_ADMIN` is required for fail2ban to modify iptables\n* After setup, navigate to `https://yourdomain.url` to access the default homepage (http access through port 80 is disabled by default, you can enable it by editing the default site config at `/config/nginx/site-confs/default.conf`).\n* Certs are checked nightly and if expiration is within 30 days, renewal is attempted. If your cert is about to expire in less than 30 days, check the logs under `/config/log/letsencrypt` to see why the renewals have been failing. It is recommended to input your e-mail in docker parameters so you receive expiration notices from Let's Encrypt in those circumstances.\n\n### Security and password protection\n\n* The container detects changes to url and subdomains, revokes existing certs and generates new ones during start.\n* Per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919), the container is shipping [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) as the `dhparams.pem`.\n* If you'd like to password protect your sites, you can use htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it swag htpasswd -c /config/nginx/.htpasswd <username>`\n* You can add multiple user:pass to `.htpasswd`. For the first user, use the above command, for others, use the above command without the `-c` flag, as it will force deletion of the existing `.htpasswd` and creation of a new one\n* You can also use ldap auth for security and access control. A sample, user configurable ldap.conf is provided, and it requires the separate image [linuxserver/ldap-auth](https://hub.docker.com/r/linuxserver/ldap-auth/) to communicate with an ldap server.\n\n### Site config and reverse proxy\n\n* The default site config resides at `/config/nginx/site-confs/default.conf`. Feel free to modify this file, and you can add other conf files to this directory. However, if you delete the `default` file, a new default will be created on container start.\n* Preset reverse proxy config files are added for popular apps. See the `README.md` file under `/config/nginx/proxy_confs` for instructions on how to enable them. The preset confs reside in and get imported from [this repo](https://github.com/linuxserver/reverse-proxy-confs).\n* If you wish to hide your site from search engine crawlers, you may find it useful to add this configuration line to your site config, within the server block, above the line where ssl.conf is included\n`add_header X-Robots-Tag \"noindex, nofollow, nosnippet, noarchive\";`\nThis will *ask* Google et al not to index and list your site. Be careful with this, as you will eventually be de-listed if you leave this line in on a site you wish to be present on search engines\n* If you wish to redirect http to https, you must expose port 80\n\n### Using certs in other containers\n\n* This container includes auto-generated pfx and private-fullchain-bundle pem certs that are needed by other apps like Emby and Znc.\n  * To use these certs in other containers, do either of the following:\n  1. *(Easier)* Mount the container's config folder in other containers (ie. `-v /path-to-swag-config:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/keys/letsencrypt/`\n  2. *(More secure)* Mount the SWAG folder `etc` that resides under `/config` in other containers (ie. `-v /path-to-swag-config/etc:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/letsencrypt/live/<your.domain.url>/` (This is more secure because the first method shares the entire SWAG config folder with other containers, including the www files, whereas the second method only shares the ssl certs)\n  * These certs include:\n  1. `cert.pem`, `chain.pem`, `fullchain.pem` and `privkey.pem`, which are generated by Certbot and used by nginx and various other apps\n  2. `privkey.pfx`, a format supported by Microsoft and commonly used by dotnet apps such as Emby Server (no password)\n  3. `priv-fullchain-bundle.pem`, a pem cert that bundles the private key and the fullchain, used by apps like ZNC\n\n### Using fail2ban\n\n* This container includes fail2ban set up with 5 jails by default:\n  1. nginx-http-auth\n  2. nginx-badbots\n  3. nginx-botsearch\n  4. nginx-deny\n  5. nginx-unauthorized\n* To enable or disable other jails, modify the file `/config/fail2ban/jail.local`\n* To modify filters and actions, instead of editing the `.conf` files, create `.local` files with the same name and edit those because .conf files get overwritten when the actions and filters are updated. `.local` files will append whatever's in the `.conf` files (ie. `nginx-http-auth.conf` --> `nginx-http-auth.local`)\n* You can check which jails are active via `docker exec -it swag fail2ban-client status`\n* You can check the status of a specific jail via `docker exec -it swag fail2ban-client status <jail name>`\n* You can unban an IP via `docker exec -it swag fail2ban-client set <jail name> unbanip <IP>`\n* A list of commands can be found here: <https://www.fail2ban.org/wiki/index.php/Commands>\n\n### Updating configs\n\n* This container creates a number of configs for nginx, proxy samples, etc.\n* Config updates are noted in the changelog but not automatically applied to your files.\n* If you have modified a file with noted changes in the changelog:\n  1. Keep your existing configs as is (not broken, don't fix)\n  2. Review our repository commits and apply the new changes yourself\n  3. Delete the modified config file with listed updates, restart the container, reapply your changes\n* If you have NOT modified a file with noted changes in the changelog:\n  1. Delete the config file with listed updates, restart the container\n* Proxy sample updates are not listed in the changelog. See the changes here: [https://github.com/linuxserver/reverse-proxy-confs/commits/master](https://github.com/linuxserver/reverse-proxy-confs/commits/master)\n* Proxy sample files WILL be updated, however your renamed (enabled) proxy files will not.\n* You can check the new sample and adjust your active config as needed.\n\n### Migration from the old `linuxserver/letsencrypt` image\n\nPlease follow the instructions [on this blog post](https://www.linuxserver.io/blog/2020-08-21-introducing-swag#migrate).\n","changelogs":[{"date":"21.01.23:","desc":"Unpin certbot version (allow certbot 2.x). !!BREAKING CHANGE!! We are temporarily removing the certbot porkbun plugin until a new version is released that is compatible with certbot 2.x."},{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"16.01.23:","desc":"Remove nchan module because it keeps causing crashes."},{"date":"08.12.22:","desc":"Revamp certbot init."},{"date":"03.12.22:","desc":"Remove defunct cloudxns plugin."},{"date":"22.11.22:","desc":"Pin acme to the same version as certbot."},{"date":"22.11.22:","desc":"Pin certbot to 1.32.0 until plugin compatibility improves."},{"date":"05.11.22:","desc":"Update acmedns plugin handling."},{"date":"06.10.22:","desc":"Switch to certbot-dns-duckdns. Update cpanel and gandi dns plugin handling. Minor adjustments to init logic."},{"date":"05.10.22:","desc":"Use certbot file hooks instead of command line hooks"},{"date":"04.10.22:","desc":"Add godaddy and porkbun dns plugins."},{"date":"03.10.22:","desc":"Add default_server back to default site conf's https listen."},{"date":"22.09.22:","desc":"Added support for DO DNS validation."},{"date":"22.09.22:","desc":"Added certbot-dns-acmedns for DNS01 validation."},{"date":"20.08.22:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf - Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"10.08.22:","desc":"Added support for Dynu DNS validation."},{"date":"18.05.22:","desc":"Added support for Azure DNS validation."},{"date":"09.04.22:","desc":"Added certbot-dns-loopia for DNS01 validation."},{"date":"05.04.22:","desc":"Added support for standalone DNS validation."},{"date":"28.03.22:","desc":"created a logfile for fail2ban nginx-unauthorized in /etc/cont-init.d/50-config"},{"date":"09.01.22:","desc":"Added a fail2ban jail for nginx unauthorized"},{"date":"21.12.21:","desc":"Fixed issue with iptables not working as expected"},{"date":"30.11.21:","desc":"Move maxmind to a [new mod](https://github.com/linuxserver/docker-mods/tree/swag-maxmind)"},{"date":"22.11.21:","desc":"Added support for Infomaniak DNS for certificate generation."},{"date":"20.11.21:","desc":"Added support for dnspod validation."},{"date":"15.11.21:","desc":"Added support for deSEC DNS for wildcard certificate generation."},{"date":"26.10.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) proxy.conf - Mitigate <https://httpoxy.org/> vulnerabilities. Ref: <https://www.nginx.com/blog/mitigating-the-httpoxy-vulnerability-with-nginx#Defeating-the-Attack-using-NGINX-and-NGINX-Plus>"},{"date":"23.10.21:","desc":"Fix Hurricane Electric (HE) DNS validation."},{"date":"12.10.21:","desc":"Fix deprecated LE root cert check to fix failures when using `STAGING=true`, and failures in revoking."},{"date":"06.10.21:","desc":"Added support for Hurricane Electric (HE) DNS validation. Added lxml build deps."},{"date":"01.10.21:","desc":"Check if the cert uses the old LE root cert, revoke and regenerate if necessary. [Here's more info](https://twitter.com/letsencrypt/status/1443621997288767491) on LE root cert expiration"},{"date":"19.09.21:","desc":"Add an optional header to opt out of Google FLoC in `ssl.conf`."},{"date":"17.09.21:","desc":"Mark `SUBDOMAINS` var as optional."},{"date":"01.08.21:","desc":"Add support for ionos dns validation."},{"date":"15.07.21:","desc":"Fix libmaxminddb issue due to upstream change."},{"date":"07.07.21:","desc":"Rebase to alpine 3.14."},{"date":"24.06.21:","desc":"Update default nginx conf folder."},{"date":"28.05.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) authelia-server.conf - Use `resolver.conf` and patch for `CVE-2021-32637`."},{"date":"20.05.21:","desc":"Modify resolver.conf generation to detect and ignore ipv6."},{"date":"14.05.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, ssl.conf, proxy.conf, and the default site-conf - Rework nginx.conf to be inline with alpine upstream and relocate lines from other files. Use linuxserver.io wheel index for pip packages. Switch to using [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) for `dhparams.pem` per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919). Added `worker_processes.conf`, which sets the number of nginx workers, and `resolver.conf`, which sets the dns resolver. Both conf files are auto-generated only on first start and can be user modified later."},{"date":"21.04.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) authelia-server.conf and authelia-location.conf - Add remote name/email headers and pass http method."},{"date":"12.04.21:","desc":"Add php7-gmp and php7-pecl-mailparse."},{"date":"12.04.21:","desc":"Add support for vultr dns validation."},{"date":"14.03.21:","desc":"Add support for directadmin dns validation."},{"date":"12.02.21:","desc":"Clean up rust/cargo cache, which ballooned the image size in the last couple of builds."},{"date":"10.02.21:","desc":"Fix aliyun, domeneshop, inwx and transip dns confs for existing users."},{"date":"09.02.21:","desc":"Rebasing to alpine 3.13. Add nginx mods brotli and dav-ext. Remove nginx mods lua and lua-upstream (due to regression over the last couple of years)."},{"date":"26.01.21:","desc":"Add support for hetzner dns validation."},{"date":"20.01.21:","desc":"Add check for ZeroSSL EAB retrieval."},{"date":"08.01.21:","desc":"Add support for getting certs from [ZeroSSL](https://zerossl.com/) via optional `CERTPROVIDER` env var. Update aliyun, domeneshop, inwx and transip dns plugins with the new plugin names. Hide `donoteditthisfile.conf` because users were editing it despite its name. Suppress harmless error when no proxy confs are enabled."},{"date":"03.01.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) /config/nginx/site-confs/default.conf - Add helper pages to aid troubleshooting"},{"date":"10.12.20:","desc":"Add support for njalla dns validation"},{"date":"09.12.20:","desc":"Check for template/conf updates and notify in the log. Add support for gehirn and sakuracloud dns validation."},{"date":"01.11.20:","desc":"Add support for netcup dns validation"},{"date":"29.10.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) ssl.conf - Add frame-ancestors to Content-Security-Policy."},{"date":"04.10.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, proxy.conf, and ssl.conf - Minor cleanups and reordering."},{"date":"20.09.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf - Added geoip2 configs. Added MAXMINDDB_LICENSE_KEY variable to readme."},{"date":"08.09.20:","desc":"Add php7-xsl."},{"date":"01.09.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, proxy.conf, and various proxy samples - Global websockets across all configs."},{"date":"03.08.20:","desc":"Initial release."}]}},"setup":"### Validation and initial setup\n\n* Before running this container, make sure that the url and subdomains are properly forwarded to this container's host, and that port 443 (and/or 80) is not being used by another service on the host (NAS gui, another webserver, etc.).\n* If you need a dynamic dns provider, you can use the free provider duckdns.org where the `URL` will be `yoursubdomain.duckdns.org` and the `SUBDOMAINS` can be `www,ftp,cloud` with http validation, or `wildcard` with dns validation. You can use our [duckdns image](https://hub.docker.com/r/linuxserver/duckdns/) to update your IP on duckdns.org.\n* For `http` validation, port 80 on the internet side of the router should be forwarded to this container's port 80\n* For `dns` validation, make sure to enter your credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`\n  * Cloudflare provides free accounts for managing dns and is very easy to use with this image. Make sure that it is set up for \"dns only\" instead of \"dns + proxy\"\n  * Google dns plugin is meant to be used with \"Google Cloud DNS\", a paid enterprise product, and not for \"Google Domains DNS\"\n  * DuckDNS only supoprts two types of DNS validated certificates (not both at the same time):\n    1. Certs that only cover your main subdomain (ie. `yoursubdomain.duckdns.org`, leave the `SUBDOMAINS` variable empty)\n    2. Certs that cover sub-subdomains of your main subdomain (ie. `*.yoursubdomain.duckdns.org`, set the `SUBDOMAINS` variable to `wildcard`)\n* `--cap-add=NET_ADMIN` is required for fail2ban to modify iptables\n* After setup, navigate to `https://yourdomain.url` to access the default homepage (http access through port 80 is disabled by default, you can enable it by editing the default site config at `/config/nginx/site-confs/default.conf`).\n* Certs are checked nightly and if expiration is within 30 days, renewal is attempted. If your cert is about to expire in less than 30 days, check the logs under `/config/log/letsencrypt` to see why the renewals have been failing. It is recommended to input your e-mail in docker parameters so you receive expiration notices from Let's Encrypt in those circumstances.\n\n### Security and password protection\n\n* The container detects changes to url and subdomains, revokes existing certs and generates new ones during start.\n* Per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919), the container is shipping [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) as the `dhparams.pem`.\n* If you'd like to password protect your sites, you can use htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it swag htpasswd -c /config/nginx/.htpasswd <username>`\n* You can add multiple user:pass to `.htpasswd`. For the first user, use the above command, for others, use the above command without the `-c` flag, as it will force deletion of the existing `.htpasswd` and creation of a new one\n* You can also use ldap auth for security and access control. A sample, user configurable ldap.conf is provided, and it requires the separate image [linuxserver/ldap-auth](https://hub.docker.com/r/linuxserver/ldap-auth/) to communicate with an ldap server.\n\n### Site config and reverse proxy\n\n* The default site config resides at `/config/nginx/site-confs/default.conf`. Feel free to modify this file, and you can add other conf files to this directory. However, if you delete the `default` file, a new default will be created on container start.\n* Preset reverse proxy config files are added for popular apps. See the `README.md` file under `/config/nginx/proxy_confs` for instructions on how to enable them. The preset confs reside in and get imported from [this repo](https://github.com/linuxserver/reverse-proxy-confs).\n* If you wish to hide your site from search engine crawlers, you may find it useful to add this configuration line to your site config, within the server block, above the line where ssl.conf is included\n`add_header X-Robots-Tag \"noindex, nofollow, nosnippet, noarchive\";`\nThis will *ask* Google et al not to index and list your site. Be careful with this, as you will eventually be de-listed if you leave this line in on a site you wish to be present on search engines\n* If you wish to redirect http to https, you must expose port 80\n\n### Using certs in other containers\n\n* This container includes auto-generated pfx and private-fullchain-bundle pem certs that are needed by other apps like Emby and Znc.\n  * To use these certs in other containers, do either of the following:\n  1. *(Easier)* Mount the container's config folder in other containers (ie. `-v /path-to-swag-config:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/keys/letsencrypt/`\n  2. *(More secure)* Mount the SWAG folder `etc` that resides under `/config` in other containers (ie. `-v /path-to-swag-config/etc:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/letsencrypt/live/<your.domain.url>/` (This is more secure because the first method shares the entire SWAG config folder with other containers, including the www files, whereas the second method only shares the ssl certs)\n  * These certs include:\n  1. `cert.pem`, `chain.pem`, `fullchain.pem` and `privkey.pem`, which are generated by Certbot and used by nginx and various other apps\n  2. `privkey.pfx`, a format supported by Microsoft and commonly used by dotnet apps such as Emby Server (no password)\n  3. `priv-fullchain-bundle.pem`, a pem cert that bundles the private key and the fullchain, used by apps like ZNC\n\n### Using fail2ban\n\n* This container includes fail2ban set up with 5 jails by default:\n  1. nginx-http-auth\n  2. nginx-badbots\n  3. nginx-botsearch\n  4. nginx-deny\n  5. nginx-unauthorized\n* To enable or disable other jails, modify the file `/config/fail2ban/jail.local`\n* To modify filters and actions, instead of editing the `.conf` files, create `.local` files with the same name and edit those because .conf files get overwritten when the actions and filters are updated. `.local` files will append whatever's in the `.conf` files (ie. `nginx-http-auth.conf` --> `nginx-http-auth.local`)\n* You can check which jails are active via `docker exec -it swag fail2ban-client status`\n* You can check the status of a specific jail via `docker exec -it swag fail2ban-client status <jail name>`\n* You can unban an IP via `docker exec -it swag fail2ban-client set <jail name> unbanip <IP>`\n* A list of commands can be found here: <https://www.fail2ban.org/wiki/index.php/Commands>\n\n### Updating configs\n\n* This container creates a number of configs for nginx, proxy samples, etc.\n* Config updates are noted in the changelog but not automatically applied to your files.\n* If you have modified a file with noted changes in the changelog:\n  1. Keep your existing configs as is (not broken, don't fix)\n  2. Review our repository commits and apply the new changes yourself\n  3. Delete the modified config file with listed updates, restart the container, reapply your changes\n* If you have NOT modified a file with noted changes in the changelog:\n  1. Delete the config file with listed updates, restart the container\n* Proxy sample updates are not listed in the changelog. See the changes here: [https://github.com/linuxserver/reverse-proxy-confs/commits/master](https://github.com/linuxserver/reverse-proxy-confs/commits/master)\n* Proxy sample files WILL be updated, however your renamed (enabled) proxy files will not.\n* You can check the new sample and adjust your active config as needed.\n\n### Migration from the old `linuxserver/letsencrypt` image\n\nPlease follow the instructions [on this blog post](https://www.linuxserver.io/blog/2020-08-21-introducing-swag#migrate).\n"},{"id":"synclounge","name":"synclounge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a third party tool that allows you to watch Plex in sync with your friends/family, wherever you are.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/synclounge-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/synclounge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-synclounge"}],"containers":[{"name":"synclounge","image":"linuxserver/synclounge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"AUTH_LIST","default":"plexuser1,plexuser2,email1,machineid1","description":"If set, only the users defined here and the users of the plex servers defined here will be able to access the server. Use e-mails, plex usernames and/or plex server machine ids, comma separated, no spaces."},{"id":"AUTOJOIN_ENABLED","default":"false","description":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set to `true` to let users autojoin the server and a room (specified by the `AUTOJOIN_ROOM` var)."},{"id":"AUTOJOIN_ROOM","default":"roomname","description":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set the room name for auto joining (requires `AUTOJOIN_ENABLED` set to `true`)."}],"ports":[{"container":"8088","description":"Web app and server port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"synclounge","project_url":"https://github.com/samcm/synclounge","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/synclounge-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a third party tool that allows you to watch Plex in sync with your friends/family, wherever you are.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":null,"param_usage_include_ports":true,"param_ports":[{"external_port":"8088","internal_port":"8088","port_desc":"Web app and server port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"AUTH_LIST","env_value":"plexuser1,plexuser2,email1,machineid1","desc":"If set, only the users defined here and the users of the plex servers defined here will be able to access the server. Use e-mails, plex usernames and/or plex server machine ids, comma separated, no spaces."},{"env_var":"AUTOJOIN_ENABLED","env_value":"false","desc":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set to `true` to let users autojoin the server and a room (specified by the `AUTOJOIN_ROOM` var)."},{"env_var":"AUTOJOIN_ROOM","env_value":"roomname","desc":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set the room name for auto joining (requires `AUTOJOIN_ENABLED` set to `true`)."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The web app and the server are both accessible at `http://SERVERIP:8088`.\n\nNote: It is recommended to use `http` as the external proto with a reverse proxy due to `https` not working with external plex clients.\n","changelogs":[{"date":"29.11.22:","desc":"Rebase to alpine 3.17, upgrade to s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"12.02.21:","desc":"Fix optional dependency builds in aarch64 image."},{"date":"12.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"28.10.20:","desc":"Update to v4. Env vars `EXTERNAL_URL`, `EXTERNAL_SERVER_PORT` and `AUTOJOIN_PASSWORD` are deprecated and no longer have any effect. Env vars `AUTOJOIN_ENABLED` and `AUTOJOIN_ROOM` are still working but will be removed in the future in favor of synclounge's built-in var `autojoin__room`. If you are reverse proxying, do not forget to update your proxy settings ([here](https://github.com/linuxserver/reverse-proxy-confs/blob/master/synclounge.subdomain.conf.sample) and [here](https://github.com/linuxserver/reverse-proxy-confs/blob/master/synclounge.subfolder.conf.sample)) as the server port and addresses are changed."},{"date":"11.10.20:","desc":"Pin builds to upstream commit `6aecc9bd` while evaluating the breaking changes upstream."},{"date":"27.09.20:","desc":"Updating the external repo endpoint."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"11.05.20:","desc":"Initial Release."}]}},"setup":"The web app and the server are both accessible at `http://SERVERIP:8088`.\n\nNote: It is recommended to use `http` as the external proto with a reverse proxy due to `https` not working with external plex clients.\n"},{"id":"syncthing","name":"syncthing","description":"[{{ project_name|capitalize }}]({{ project_url }}) replaces proprietary sync and cloud services with something open, trustworthy and decentralized. Your data is your data alone and you deserve to choose where it is stored, if it is shared with some third party and how it's transmitted over the Internet.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syncthing-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/syncthing"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-syncthing"}],"containers":[{"name":"syncthing","image":"linuxserver/syncthing","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/data1","description":"Data1"},{"container":"/data2","description":"Data2"}],"ports":[{"container":"8384","description":"Application WebUI","protocol":"tcp","web":false},{"container":"22000/tcp","description":"Listening port (TCP)","protocol":"tcp","web":false},{"container":"22000/udp","description":"Listening port (UDP)","protocol":"tcp","web":false},{"container":"21027/udp","description":"Protocol discovery","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"syncthing","project_url":"https://syncthing.net","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syncthing-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) replaces proprietary sync and cloud services with something open, trustworthy and decentralized. Your data is your data alone and you deserve to choose where it is stored, if it is shared with some third party and how it's transmitted over the Internet.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":"optional","param_hostname":"{{ project_name }}","param_hostname_desc":"Optionally the hostname can be defined.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."},{"vol_path":"/data1","vol_host_path":"/path/to/data1","desc":"Data1"},{"vol_path":"/data2","vol_host_path":"/path/to/data2","desc":"Data2"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8384","internal_port":"8384","port_desc":"Application WebUI"},{"external_port":"22000","internal_port":"22000/tcp","port_desc":"Listening port (TCP)"},{"external_port":"22000","internal_port":"22000/udp","port_desc":"Listening port (UDP)"},{"external_port":"21027","internal_port":"21027/udp","port_desc":"Protocol discovery"}],"app_setup_block_enabled":true,"app_setup_block":"**Note: ** The Syncthing devs highly suggest setting a password for this container as it listens on 0.0.0.0. To do this go to `Actions -> Settings -> set user/password` for the webUI.","changelogs":[{"date":"17.08.22:","desc":"Build on alpine 3.16 for go 1.18)."},{"date":"03.05.22:","desc":"Rebase to alpine 3.15 (builds on edge for go 1.18)."},{"date":"05.10.21:","desc":"Rebase to alpine 3.14."},{"date":"12.05.21:","desc":"Remove sysctl parameter again"},{"date":"03.05.21:","desc":"Raise maximum UDP buffer size."},{"date":"03.05.21:","desc":"Add port mapping for 22000/udp."},{"date":"29.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"15.09.20:","desc":"Use go from alpine edge repo to compile. Remove duplicate UMASK env var. Add hostname setting."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"05.03.19:","desc":"Update Build process for v1.1.0 release."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"30.07.18:","desc":"Rebase to alpine 3.8 and use buildstage."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"25.10.17:","desc":"Add env for manual setting of umask."},{"date":"29.07.17:","desc":"Simplify build structure as symlinks failing on > 0.14.32"},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"08.02.17:","desc":"Rebase to alpine 3.5."},{"date":"01.11.16:","desc":"Switch to compiling latest version from git source."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"11.08.16:","desc":"Rebase to alpine linux."},{"date":"18.12.15:","desc":"Initial testing / release (IronicBadger)"},{"date":"24.09.15:","desc":"Inital dev complete (Lonix)"}]}},"setup":"**Note: ** The Syncthing devs highly suggest setting a password for this container as it listens on 0.0.0.0. To do this go to `Actions -> Settings -> set user/password` for the webUI."},{"id":"syslog-ng","name":"syslog-ng","description":"[syslog-ng]({{ project_url }}) allows you to flexibly collect, parse, classify, rewrite and correlate logs from across your infrastructure and store or route them to log analysis tools.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syslog-ng-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/syslog-ng"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-syslog-ng"}],"containers":[{"name":"syslog-ng","image":"linuxserver/syslog-ng","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/var/log","description":"Stores logs collected by the syslog-ng service"},{"container":"/config","description":"Stores config and application files","key":"config"}],"ports":[{"container":"5514/udp","description":"Syslog UDP","protocol":"tcp","web":false},{"container":"6601/tcp","description":"Syslog TCP","protocol":"tcp","web":false},{"container":"6514/tcp","description":"Syslog TLS","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"syslog-ng","project_url":"https://www.syslog-ng.com/products/open-source-log-management/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syslog-ng-logo.png","project_blurb":"[syslog-ng]({{ project_url }}) allows you to flexibly collect, parse, classify, rewrite and correlate logs from across your infrastructure and store or route them to log analysis tools.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Stores config and application files"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/log","vol_host_path":"/path/to/log","desc":"Stores logs collected by the syslog-ng service"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"514","internal_port":"5514/udp","port_desc":"Syslog UDP"},{"external_port":"601","internal_port":"6601/tcp","port_desc":"Syslog TCP"},{"external_port":"6514","internal_port":"6514/tcp","port_desc":"Syslog TLS"}],"app_setup_block_enabled":true,"app_setup_block":"Edit `/config/syslog-ng.conf` to configure your logging sources and destinations. Note: As the application does not run as root you cannot listen on ports < 1024.\n\nThe application pid, control file, etc. are all kept in /config so when using tools such as `syslog-ng-ctl` you need to specify the path e.g. `syslog-ng-ctl reload -c /config/syslog-ng.ctl`\n\nMore info at [syslog-ng](https://www.syslog-ng.com/technical-documents/list/syslog-ng-open-source-edition).\n","changelogs":[{"date":"10.01.23:","desc":"Add paho-mqtt-c library as required by the syslog-ng documentation"},{"date":"30.12.22:","desc":"Rebase to Alpine 3.17, add libdbi-drivers for SQL support."},{"date":"01.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"18.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"01.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"26.05.21:","desc":"Initial release."}]}},"setup":"Edit `/config/syslog-ng.conf` to configure your logging sources and destinations. Note: As the application does not run as root you cannot listen on ports < 1024.\n\nThe application pid, control file, etc. are all kept in /config so when using tools such as `syslog-ng-ctl` you need to specify the path e.g. `syslog-ng-ctl reload -c /config/syslog-ng.ctl`\n\nMore info at [syslog-ng](https://www.syslog-ng.com/technical-documents/list/syslog-ng-open-source-edition).\n"},{"id":"tautulli","name":"tautulli","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a python based web application for monitoring, analytics and notifications for Plex Media Server.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tautulli-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/tautulli"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-tautulli"}],"containers":[{"name":"tautulli","image":"linuxserver/tautulli","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Contains tautulli config and database.","key":"config"}],"ports":[{"container":"8181","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"tautulli","project_url":"http://tautulli.com","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tautulli-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a python based web application for monitoring, analytics and notifications for Plex Media Server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Tautulli releases"},{"tag":"develop","desc":"Built at head of Tautulli nightly branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Contains tautulli config and database."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8181","internal_port":"8181","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8181`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\nTo use the build-in Plex LogViewer you have to add a volume, preferably ReadOnly. Then in tautulli gui settings, under `Plex Media Server`, turn on `Show Advanced` and set the `Logs Folder` to the folder you mapped.\n","changelogs":[{"date":"15.12.22:","desc":"Rebase master branch to Alpine 3.17."},{"date":"04.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"10.01.22:","desc":"Rebase to Alpine 3.15."},{"date":"11.07.21:","desc":"Add curl package."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"11.07.20:","desc":"Add py3-openssl."},{"date":"05.06.20:","desc":"Rebasing to alpine 3.12. Rework to python3."},{"date":"12.04.20:","desc":"Added mock from pip and donate links."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"23.10.18:","desc":"Update plex logs info in readm."},{"date":"16.08.18:","desc":"Rebase to alpine 3.8."},{"date":"10.03.18:","desc":"Rebrand to tautulli."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"21.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"20.04.17:","desc":"Add pycryptodomex pip package."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"16.07.15:","desc":"Inital Release."}]}},"setup":"Access the webui at `<your-ip>:8181`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\nTo use the build-in Plex LogViewer you have to add a volume, preferably ReadOnly. Then in tautulli gui settings, under `Plex Media Server`, turn on `Show Advanced` and set the `Logs Folder` to the folder you mapped.\n"},{"id":"thelounge","name":"thelounge","description":"[{{ project_name|capitalize }}]({{ project_url }}) (a fork of shoutIRC) is a web IRC client that you host on your own server.","icon":"https://raw.githubusercontent.com/thelounge/thelounge/master/client/img/logo-vertical-transparent-bg.svg?sanitize=true","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/thelounge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-thelounge"}],"containers":[{"name":"thelounge","image":"linuxserver/thelounge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"9000","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"thelounge","project_url":"https://thelounge.github.io/","project_logo":"https://raw.githubusercontent.com/thelounge/thelounge/master/client/img/logo-vertical-transparent-bg.svg?sanitize=true","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (a fork of shoutIRC) is a web IRC client that you host on your own server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"next","desc":"Next Pre-Releases."},{"tag":"nightly","desc":"Nightly images from commits in master."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9000","internal_port":"9000","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"* When the application first runs, it will populate its /config\n\n* Stop the container\n\n* Now from the host, edit `/config/config.js`, wherever you've mapped it\n\n* In most cases you want the value `public: false` to allow named users only\n\n* Setting the two prefetch values to true improves usability, but uses more storage\n\n* Once you have the configuration you want, save it and start the container again\n\n* For each user, run the command\n\n* `docker exec -it thelounge s6-setuidgid abc thelounge add <user>`\n\n* You will be prompted to enter a password that will not be echoed.\n\n* Saving logs to disk is the default, this consumes more space but allows scrollback.\n\n* To log in to the application, browse to `http://<hostip>:9000`\n\n* You should now be prompted for a username and password on the webinterface.\n\n* Once logged in, you can add an IRC network. Some defaults are preset for Freenode\n","changelogs":[{"date":"18.12.22:","desc":"Rebasing master to alpine 3.17."},{"date":"24.10.22:","desc":"Fix sqlite3 build."},{"date":"12.04.22:","desc":"Install from source using yarn."},{"date":"11.04.22:","desc":"Rebasing to alpine 3.15 and switching from python2-dev to python3-dev for building node sqlite on arm."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"15.05.19:","desc":"Update Arm variant images to build sqlite3 module."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"25.08.18:","desc":"Use global install, simplifies adding users."},{"date":"20.08.18:","desc":"Rebase to alpine 3.8."},{"date":"06.01.18:","desc":"Rebase to alpine 3.7."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Bump to pickup 2.10 release."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"31.08.16:","desc":"Initial Release."}]}},"setup":"* When the application first runs, it will populate its /config\n\n* Stop the container\n\n* Now from the host, edit `/config/config.js`, wherever you've mapped it\n\n* In most cases you want the value `public: false` to allow named users only\n\n* Setting the two prefetch values to true improves usability, but uses more storage\n\n* Once you have the configuration you want, save it and start the container again\n\n* For each user, run the command\n\n* `docker exec -it thelounge s6-setuidgid abc thelounge add <user>`\n\n* You will be prompted to enter a password that will not be echoed.\n\n* Saving logs to disk is the default, this consumes more space but allows scrollback.\n\n* To log in to the application, browse to `http://<hostip>:9000`\n\n* You should now be prompted for a username and password on the webinterface.\n\n* Once logged in, you can add an IRC network. Some defaults are preset for Freenode\n"},{"id":"transmission","name":"transmission","description":"[{{ project_name|capitalize }}]({{ project_url }}) is designed for easy, powerful use. Transmission has the features you want from a BitTorrent client: encryption, a web interface, peer exchange, magnet links, DHT, TP, UPnP and NAT-PMP port forwarding, webseed support, watch directories, tracker editing, global and per-torrent speed limits, and more.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/transmission.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/transmission"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-transmission"}],"containers":[{"name":"transmission","image":"linuxserver/transmission","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"TRANSMISSION_WEB_HOME","default":"/combustion-release/","description":"Specify an alternative UI options are [`/combustion-release/`](https://github.com/Secretmapper/combustion), [`/transmission-web-control/`](https://github.com/ronggang/transmission-web-control), [`/kettu/`](https://github.com/endor/kettu), [`/flood-for-transmission/`](https://github.com/johman10/flood-for-transmission), and [`/transmissionic/`](https://github.com/6c65726f79/Transmissionic)."},{"id":"USER","default":"username","description":"Specify an optional username for the interface"},{"id":"PASS","default":"password","description":"Specify an optional password for the interface"},{"id":"WHITELIST","default":"iplist","description":"Specify an optional list of comma separated ip whitelist. Fills rpc-whitelist setting."},{"id":"PEERPORT","default":"peerport","description":"Specify an optional port for torrent TCP/UDP connections. Fills peer-port setting."},{"id":"HOST_WHITELIST","default":"dnsname list","description":"Specify an optional list of comma separated dns name whitelist. Fills rpc-host-whitelist setting."}],"volumes":[{"container":"/config","description":"Where transmission should store config files and logs.","key":"config"},{"container":"/downloads","description":"Local path for downloads."},{"container":"/watch","description":"Watch folder for torrent files."}],"ports":[{"container":"9091","description":"WebUI","protocol":"tcp","web":false},{"container":"51413","description":"Torrent Port TCP","protocol":"tcp","web":false},{"container":"51413/udp","description":"Torrent Port UDP","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"transmission","project_url":"https://www.transmissionbt.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/transmission.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is designed for easy, powerful use. Transmission has the features you want from a BitTorrent client: encryption, a web interface, peer exchange, magnet links, DHT, TP, UPnP and NAT-PMP port forwarding, webseed support, watch directories, tracker editing, global and per-torrent speed limits, and more.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where transmission should store config files and logs."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Local path for downloads."},{"vol_path":"/watch","vol_host_path":"/path/to/watch/folder","desc":"Watch folder for torrent files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9091","internal_port":"9091","port_desc":"WebUI"},{"external_port":"51413","internal_port":"51413","port_desc":"Torrent Port TCP"},{"external_port":"51413","internal_port":"51413/udp","port_desc":"Torrent Port UDP"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"TRANSMISSION_WEB_HOME","env_value":"/combustion-release/","desc":"Specify an alternative UI options are [`/combustion-release/`](https://github.com/Secretmapper/combustion), [`/transmission-web-control/`](https://github.com/ronggang/transmission-web-control), [`/kettu/`](https://github.com/endor/kettu), [`/flood-for-transmission/`](https://github.com/johman10/flood-for-transmission), and [`/transmissionic/`](https://github.com/6c65726f79/Transmissionic)."},{"env_var":"USER","env_value":"username","desc":"Specify an optional username for the interface"},{"env_var":"PASS","env_value":"password","desc":"Specify an optional password for the interface"},{"env_var":"WHITELIST","env_value":"iplist","desc":"Specify an optional list of comma separated ip whitelist. Fills rpc-whitelist setting."},{"env_var":"PEERPORT","env_value":"peerport","desc":"Specify an optional port for torrent TCP/UDP connections. Fills peer-port setting."},{"env_var":"HOST_WHITELIST","env_value":"dnsname list","desc":"Specify an optional list of comma separated dns name whitelist. Fills rpc-host-whitelist setting."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui is on port 9091, the settings.json file in /config has extra settings not available in the webui. Stop the container before editing it or any changes won't be saved.\n\nIf you choose to use transmission-web-control as your default UI, just note that the origional Web UI will not be available to you despite the button being present.\n\n## Securing the webui with a username/password.\n\nUse the `USER` and `PASS` variables in docker run/create/compose to set authentication. Do not manually edit the `settings.json` to input user/pass, otherwise transmission cannot be stopped cleanly by the s6 supervisor.\n\n## Updating Blocklists Automatically\n\nThis requires `\"blocklist-enabled\": true,` to be set. By setting this to true, it is assumed you have also populated `blocklist-url` with a valid block list.\n\nThe automatic update is a shell script that downloads a blocklist from the url stored in the settings.json, gunzips it, and restarts the transmission daemon.\n\nThe automatic update will run once a day at 3am local server time.\n\n## Using whitelist\n\nUse `WHITELIST` to enable a list of ip as whitelist. This enable support for `rpc-whitelist`. When `WHITELIST` is empty support for whitelist is disabled.\n\nUse `HOST_WHITELIST` to enable an list of dns names as host-whitelist. This enable support for `rpc-host-whitelist`. When `HOST_WHITELIST` is empty support for host-whitelist is disabled.\n\n## Use alternative Transmission torrent ports\n\nUse `PEERPORT` to specify the port(s) Transmission should listen on.  This disables random port selection.  This should be the same as the port mapped in your docker configuration.\n","changelogs":[{"date":"05.01.23:","desc":"Rebase to Alpine 3.17, restore GNU findutils package."},{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"03.04.22:","desc":"Add Transmissionic as a UI option."},{"date":"21.02.22:","desc":"Build unrar from source, rebase to Alpine 3.15, add symlinks neeeded for TWC. Credit @alexbelgium"},{"date":"09.07.21:","desc":"Wait for the transmission-daemon termination after a caught sigterm."},{"date":"06.03.21:","desc":"Add Flood for Transmission as a UI option."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.11.20:","desc":"Add ca-certificates package to allow connecting to https trackers."},{"date":"02.06.20:","desc":"Rebase to alpine 3.12, update to transmission 3.0, remove python2, add python3."},{"date":"11.05.20:","desc":"Remove unnecessary chmod (remnant of previous change)."},{"date":"28.04.20:","desc":"Use transmission-remote to update blocklist."},{"date":"30.03.20:","desc":"Internalize blocklist-update.sh."},{"date":"29.03.20:","desc":"Update auth info in readme."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"04.10.19:","desc":"Update package label."},{"date":"21.08.19:","desc":"Add optional user/pass environment variables, fix transmission shut down if user/pass are set."},{"date":"19.07.19:","desc":"Send SIGTERM in blocklist update to properly close pid."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebase to Alpine 3.9, add themes to baseimage, add python and findutils."},{"date":"22.02.19:","desc":"Catch term and clean exit."},{"date":"07.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.08.18:","desc":"Rebase to alpine linux 3.8."},{"date":"12.02.18:","desc":"Pull transmission from edge repo."},{"date":"10.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.07.17:","desc":"Add rsync package."},{"date":"27.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"15.01.17:","desc":"Add p7zip, tar, unrar, and unzip packages."},{"date":"16.10.16:","desc":"Blocklist autoupdate with optional authentication."},{"date":"14.10.16:","desc":"Add version layer informationE."},{"date":"23.09.16:","desc":"Add information about securing the webui to README."},{"date":"21.09.16:","desc":"Add curl package."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"09.08.16:","desc":"Rebase to alpine linux."},{"date":"06.12.15:","desc":"Separate mapping for watch folder."},{"date":"16.11.15:","desc":"Initial Release."}]}},"setup":"Webui is on port 9091, the settings.json file in /config has extra settings not available in the webui. Stop the container before editing it or any changes won't be saved.\n\nIf you choose to use transmission-web-control as your default UI, just note that the origional Web UI will not be available to you despite the button being present.\n\n## Securing the webui with a username/password.\n\nUse the `USER` and `PASS` variables in docker run/create/compose to set authentication. Do not manually edit the `settings.json` to input user/pass, otherwise transmission cannot be stopped cleanly by the s6 supervisor.\n\n## Updating Blocklists Automatically\n\nThis requires `\"blocklist-enabled\": true,` to be set. By setting this to true, it is assumed you have also populated `blocklist-url` with a valid block list.\n\nThe automatic update is a shell script that downloads a blocklist from the url stored in the settings.json, gunzips it, and restarts the transmission daemon.\n\nThe automatic update will run once a day at 3am local server time.\n\n## Using whitelist\n\nUse `WHITELIST` to enable a list of ip as whitelist. This enable support for `rpc-whitelist`. When `WHITELIST` is empty support for whitelist is disabled.\n\nUse `HOST_WHITELIST` to enable an list of dns names as host-whitelist. This enable support for `rpc-host-whitelist`. When `HOST_WHITELIST` is empty support for host-whitelist is disabled.\n\n## Use alternative Transmission torrent ports\n\nUse `PEERPORT` to specify the port(s) Transmission should listen on.  This disables random port selection.  This should be the same as the port mapped in your docker configuration.\n"},{"id":"tvheadend","name":"tvheadend","description":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: is a TV streaming server and recorder for Linux, FreeBSD and Android supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, ISDB-T, IPTV, SAT>IP and HDHomeRun as input sources.\nTvheadend offers the HTTP (VLC, MPlayer), HTSP (Kodi, Movian) and SAT>IP streaming.\nMultiple EPG sources are supported (over-the-air DVB and ATSC including OpenTV DVB extensions, XMLTV, PyXML).\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tvheadend-big.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/tvheadend"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-tvheadend"}],"containers":[{"name":"tvheadend","image":"linuxserver/tvheadend","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"","description":"Optionally specify additional arguments to be passed. See Additional runtime parameters."}],"volumes":[{"container":"/config","description":"Where TVHeadend show store it's config files.","key":"config"},{"container":"/recordings","description":"Where you want the PVR to store recordings."}],"ports":[{"container":"9981","description":"WebUI","protocol":"tcp","web":false},{"container":"9982","description":"HTSP server port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"tvheadend","project_url":"https://www.tvheadend.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tvheadend-big.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: is a TV streaming server and recorder for Linux, FreeBSD and Android supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, ISDB-T, IPTV, SAT>IP and HDHomeRun as input sources.\nTvheadend offers the HTTP (VLC, MPlayer), HTSP (Kodi, Movian) and SAT>IP streaming.\nMultiple EPG sources are supported (over-the-air DVB and ATSC including OpenTV DVB extensions, XMLTV, PyXML).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Current latest release."},{"tag":"release-4.2","desc":"Latest release from 4.2 branch."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where TVHeadend show store it's config files."},{"vol_path":"/recordings","vol_host_path":"/path/to/recordings","desc":"Where you want the PVR to store recordings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9981","internal_port":"9981","port_desc":"WebUI"},{"external_port":"9982","internal_port":"9982","port_desc":"HTSP server port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"RUN_OPTS","env_value":"","desc":"Optionally specify additional arguments to be passed. See Additional runtime parameters."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your AMD/Intel GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/dvb","device_host_path":"/dev/dvb","desc":"Only needed if you want to pass through a DVB card to the container. If you use IPTV or HDHomeRun you can leave it out."}],"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["#### Host vs. Bridge\n\nIf you use IPTV, SAT>IP or HDHomeRun, you need to create the container with --net=host and remove the -p flags. This is because to work with these services Tvheadend requires a multicast address of `239.255.255.250` and a UDP port of `1900` which at this time is not possible with docker bridge mode.\nIf you have other host services which also use multicast such as SSDP/DLNA/Emby you may experience stabilty problems. These can be solved by giving tvheadend its own IP using macvlan.\n"],"app_setup_block_enabled":true,"app_setup_block":"The setup depends if you run the one of the stable tags or use latest. Running latest is the easiest as it has a setup wizard.\n\n**Stable**\n\nFirst thing to do is to go to Configuration --> DVB Inputs --> TV adapters and add your LNB/switch info. Then create a new network in the Networks tab and set the correct pre-defined muxes and orbital position.\nGo back to the TV adapters tab and add the newly created network under universal LNB. Go back to the Networks tab and mark the network you created earlier and press the Force Scan button. Tvheadend will now scan the muxes for services.\n\nAfter the scan is done, head to the Services tab and find the services you want as channels, mark them, and press map services. They should now appear under Configuration --> Channel/EPG.\n\n**Latest**\n\nThe first thing to do is to run the setup wizard. If it doesn't pop up at first login, you can find it in Configuration --> General --> Base and click Start Wizard. This will guide you to set up the basic parts of tvheadend.\n\n**Configuring XMLTV grabber**\n\nTo configure the XMLTV grabber, first check if your grabber is listed in Configuration --> Channel/EPG --> EPG Grabber Modules. If it's listed, you will have to configure the grabber before enabling.\nFind the path in the path field of your grabber. We will use the last part. It starts with tv_grab_. Add it after /usr/bin/ in the below command. There should be no space between Usr/bin/ and the part you added.\n\n```\ndocker exec -it -u abc tvheadend /usr/bin/for_you_to_fill_out --configure\n```\n\nNow follow the onscreen progress. If you get asked about cache, just accept the default. After you have configured your grabber, you can go back and enable your grabber.\n\nIf you allready have a configuration file, you can add it in the .xmltv folder where you mapped the /config volume. If it's not created, create it.\n\n**Comskip**\nThis container comes with Comskip for commercial flagging of recordings. This you have to add in the recording config of tvheadend.\nGo to Configuration --> Recording. Change the view level to advanced in the top right corner, and add the below in the Post-processor command field.\n\n```\n/usr/bin/comskip --ini=/config/comskip/comskip.ini \"%f\"\n```\n\nNow comskip will run after each recording is finished. You will find comskip.ini in the comskip folder of your /config volume mapping. See the [Comskip](http://www.kaashoek.com/comskip/) homepage for tuning of the ini file.\n\n\n**FFmpeg**\n\nFFmpeg is installed in /usr/bin/ in case you need to use it with pipe.\n\n**EPG XML file**\n\nIf you have EPG data in XML format from a supplier, you can drop it in the data folder of your /config volume mapping. If it doesn't exist, create it. Then choose the XML file grabber in Configuration --> Channel/EPG --> EPG Grabber Modules.\nIf you use WebGrab+Plus, choose the WebGrab+Plus XML file grabber. The XML file goes in the same path as above.\nThe xml file has to be named guide.xml.\n\nFor advanced setup of tvheadend, go to [Tvheadend][appurl]\n\n**Picons**\n\nWe have added all the picons from [picons](https://github.com/picons/picons) in the folder /picons. To enable the use of these picons, add the path to the Channel icon path in Configuration --> General --> Base.\nYou need to enable minimum advanced view level to see the picons options.\n\n## Additional runtime parameters\n\nIn some cases it might be necessary to start tvheadend with additional parameters, for example to enable debugging or specify webroot for reverse proxy. Be sure to have the right parameters set, as adding the wrong once might lead to the container not starting correctly.\n","changelogs":[{"date":"31.08.22:","desc":"Update sample env vars and how RUN_OPTS are handled."},{"date":"19.08.22:","desc":"Switch to new picons builder."},{"date":"16.04.22:","desc":"Added URL XMLTV grabber."},{"date":"05.01.22:","desc":"Rebase to Alpine 3.15. Disable execinfo to fix builds. Update xmltv."},{"date":"11.05.21:","desc":"Added Intel iHD driver support."},{"date":"02.06.20:","desc":"Update to Alpine 3.12."},{"date":"27.12.19:","desc":"Add requests and perl-json-xs package."},{"date":"27.12.19:","desc":"Update to Alpine 3.11."},{"date":"02.10.19:","desc":"Improve permission fixing on render & dvb devices."},{"date":"18.08.19:","desc":"Add AMD drivers."},{"date":"02.08.19:","desc":"Attempt to automatically fix permissions on /dev/dri and /dev/dvb."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"27.03.19:","desc":"Rebase to Alpine 3.9, fix init logic to only chown once."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.03.19:","desc":"Bump xmltv to 0.6.1."},{"date":"28.02.19:","desc":"add perl-lwp-useragent-determined."},{"date":"17.02.19:","desc":"Bump xmltv to 5.70, ensure version tagging works by cloning tvheadend."},{"date":"14.02.19:","desc":"Add picons path to config."},{"date":"15.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"12.09.18:","desc":"Rebase to alpine 3.8 and use buildstage type build."},{"date":"21.04.18:","desc":"Add JSON::XS Perl package for grab_tv_huro."},{"date":"24.03.18:","desc":"Add dvbcsa package."},{"date":"04.03.18:","desc":"Use sourceforge master rather than mirror for xmltv."},{"date":"22.02.18:","desc":"Add lost libva-intel-driver."},{"date":"21.02.18:","desc":"Fix wrong version of iconv used."},{"date":"18.02.18:","desc":"Add vaapi support, some cleanup and dropping of deprecated options."},{"date":"04.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"11.12.17:","desc":"Rebase to alpine 3.7, linting fixes."},{"date":"02.09.17:","desc":"Add codec dependencies."},{"date":"13.07.17:","desc":"Increase uniformity across all archs."},{"date":"08.07.17:","desc":"Update README with full path for comskip."},{"date":"02.07.17:","desc":"Move to one branch for all 4.2 releases."},{"date":"27.05.17:","desc":"Rebase to alpine 3.6."},{"date":"01.05.17:","desc":"Update to tvheadend 4.2.1 stable."},{"date":"18.04.17:","desc":"Use repo version of gnu-libiconv rather than compiling."},{"date":"09.04.17:","desc":"Chain cpanm installs in one block and use --installdeps."},{"date":"09.02.17:","desc":"Perl changes, add picons file to gitignore and update XMLTV to 0.5.69."},{"date":"07.02.17:","desc":"Add variable to add additional runtime paramters."},{"date":"05.02.17:","desc":"Update to alpine 3.5 and change dvb-apps to only compile needed libs."},{"date":"14.11.16:","desc":"Add picons from picons.xyz to /picons folder and add info to README."},{"date":"22.09.16:","desc":"Fix broken tv_grab_wg, libs for xmltv and update README."},{"date":"18.09.16:","desc":"Update XMLTV to 0.5.68 and update README."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.09.16:","desc":"Initial Release."}]}},"setup":"The setup depends if you run the one of the stable tags or use latest. Running latest is the easiest as it has a setup wizard.\n\n**Stable**\n\nFirst thing to do is to go to Configuration --> DVB Inputs --> TV adapters and add your LNB/switch info. Then create a new network in the Networks tab and set the correct pre-defined muxes and orbital position.\nGo back to the TV adapters tab and add the newly created network under universal LNB. Go back to the Networks tab and mark the network you created earlier and press the Force Scan button. Tvheadend will now scan the muxes for services.\n\nAfter the scan is done, head to the Services tab and find the services you want as channels, mark them, and press map services. They should now appear under Configuration --> Channel/EPG.\n\n**Latest**\n\nThe first thing to do is to run the setup wizard. If it doesn't pop up at first login, you can find it in Configuration --> General --> Base and click Start Wizard. This will guide you to set up the basic parts of tvheadend.\n\n**Configuring XMLTV grabber**\n\nTo configure the XMLTV grabber, first check if your grabber is listed in Configuration --> Channel/EPG --> EPG Grabber Modules. If it's listed, you will have to configure the grabber before enabling.\nFind the path in the path field of your grabber. We will use the last part. It starts with tv_grab_. Add it after /usr/bin/ in the below command. There should be no space between Usr/bin/ and the part you added.\n\n```\ndocker exec -it -u abc tvheadend /usr/bin/for_you_to_fill_out --configure\n```\n\nNow follow the onscreen progress. If you get asked about cache, just accept the default. After you have configured your grabber, you can go back and enable your grabber.\n\nIf you allready have a configuration file, you can add it in the .xmltv folder where you mapped the /config volume. If it's not created, create it.\n\n**Comskip**\nThis container comes with Comskip for commercial flagging of recordings. This you have to add in the recording config of tvheadend.\nGo to Configuration --> Recording. Change the view level to advanced in the top right corner, and add the below in the Post-processor command field.\n\n```\n/usr/bin/comskip --ini=/config/comskip/comskip.ini \"%f\"\n```\n\nNow comskip will run after each recording is finished. You will find comskip.ini in the comskip folder of your /config volume mapping. See the [Comskip](http://www.kaashoek.com/comskip/) homepage for tuning of the ini file.\n\n\n**FFmpeg**\n\nFFmpeg is installed in /usr/bin/ in case you need to use it with pipe.\n\n**EPG XML file**\n\nIf you have EPG data in XML format from a supplier, you can drop it in the data folder of your /config volume mapping. If it doesn't exist, create it. Then choose the XML file grabber in Configuration --> Channel/EPG --> EPG Grabber Modules.\nIf you use WebGrab+Plus, choose the WebGrab+Plus XML file grabber. The XML file goes in the same path as above.\nThe xml file has to be named guide.xml.\n\nFor advanced setup of tvheadend, go to [Tvheadend][appurl]\n\n**Picons**\n\nWe have added all the picons from [picons](https://github.com/picons/picons) in the folder /picons. To enable the use of these picons, add the path to the Channel icon path in Configuration --> General --> Base.\nYou need to enable minimum advanced view level to see the picons options.\n\n## Additional runtime parameters\n\nIn some cases it might be necessary to start tvheadend with additional parameters, for example to enable debugging or specify webroot for reverse proxy. Be sure to have the right parameters set, as adding the wrong once might lead to the container not starting correctly.\n"},{"id":"ubooquity","name":"ubooquity","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, lightweight and easy-to-use home server for your comics and ebooks. Use it to access your files from anywhere, with a tablet, an e-reader, a phone or a computer.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ubooquity-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ubooquity"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ubooquity"}],"containers":[{"name":"ubooquity","image":"linuxserver/ubooquity","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MAXMEM","default":"<maxmem>","description":"To set the maximum memory. ( ex: set '1024' for 1GB )"}],"volumes":[{"container":"/config","description":"Config files and database for ubooquity.","key":"config"},{"container":"/books","description":"Location of books."},{"container":"/comics","description":"Location of comics."},{"container":"/files","description":"Location of raw files."}],"ports":[{"container":"2202","description":"The library port.","protocol":"tcp","web":false},{"container":"2203","description":"The admin port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ubooquity","project_url":"https://vaemendis.net/ubooquity/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ubooquity-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, lightweight and easy-to-use home server for your comics and ebooks. Use it to access your files from anywhere, with a tablet, an e-reader, a phone or a computer.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"MAXMEM","env_value":"<maxmem>","desc":"To set the maximum memory. ( ex: set '1024' for 1GB )"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Config files and database for ubooquity."},{"vol_path":"/books","vol_host_path":"<path to books>","desc":"Location of books."},{"vol_path":"/comics","vol_host_path":"<path to comics>","desc":"Location of comics."},{"vol_path":"/files","vol_host_path":"<path to raw files>","desc":"Location of raw files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"2202","internal_port":"2202","port_desc":"The library port."},{"external_port":"2203","internal_port":"2203","port_desc":"The admin port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"**IMPORTANT**\nUbooquity has now been upgraded to [version 2](http://vaemendis.net/ubooquity/article19/ubooquity-2-1-0) and for existing v1.x users we recommend cleaning your appdata and reinstalling, due to changes in the application itself making the two versions essentially incompatible with each other. Also the admin page and library pages are now on separate ports as detailed below.\n\nAccess the admin page at `http://<your-ip>:2203/ubooquity/admin` and set a password.\n\nThen you can access the webui at `http://<your-ip>:2202/ubooquity/`\n\nThis container will automatically scan your files at startup.\n\n### MAXMEM\n\nThe quantity of memory allocated to Ubooquity depends on the hardware your are running it on. If this quantity is too small, you might sometime saturate it with when performing memory intensive operations. Thats when you get `java.lang.OutOfMemoryError:` Java heap space errors.\n\nYou can explicitly set the amount of memory Ubooquity is allowed to use (be careful to set a value lower than the actual physical memory of your hardware). Value is a number of megabytes ( put just a number, without MB )\n\nIf no value is set it will default to 512MB.\n","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.10.18:","desc":"Upgrade to Ubooquity 2.1.2."},{"date":"23.08.18:","desc":"Rebase to alpine 3.8."},{"date":"09.12.17:","desc":"Rebase to alpine 3.7."},{"date":"07.10.17:","desc":"Upgrade to Ubooquity 2.1.1."},{"date":"16.07.17:","desc":"Upgrade to Ubooquity 2.1.0, see setting up application section for important info for existing v1.x users."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"08.04.17:","desc":"Switch to java from 3.5 repo, fixes login crashes."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"06.12.16:","desc":"Initial Release."}]}},"setup":"**IMPORTANT**\nUbooquity has now been upgraded to [version 2](http://vaemendis.net/ubooquity/article19/ubooquity-2-1-0) and for existing v1.x users we recommend cleaning your appdata and reinstalling, due to changes in the application itself making the two versions essentially incompatible with each other. Also the admin page and library pages are now on separate ports as detailed below.\n\nAccess the admin page at `http://<your-ip>:2203/ubooquity/admin` and set a password.\n\nThen you can access the webui at `http://<your-ip>:2202/ubooquity/`\n\nThis container will automatically scan your files at startup.\n\n### MAXMEM\n\nThe quantity of memory allocated to Ubooquity depends on the hardware your are running it on. If this quantity is too small, you might sometime saturate it with when performing memory intensive operations. Thats when you get `java.lang.OutOfMemoryError:` Java heap space errors.\n\nYou can explicitly set the amount of memory Ubooquity is allowed to use (be careful to set a value lower than the actual physical memory of your hardware). Value is a number of megabytes ( put just a number, without MB )\n\nIf no value is set it will default to 512MB.\n"},{"id":"unifi-controller","name":"unifi-controller","description":"The [{{ project_name|capitalize }}]({{ project_url }}) software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/unifi-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/unifi-controller"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-unifi-controller"}],"containers":[{"name":"unifi-controller","image":"linuxserver/unifi-controller","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use (e.g. Europe/London) - [see list](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)"},{"id":"MEM_LIMIT","default":"1024","description":"Optionally change the Java memory limit (in Megabytes). Set to `default` to reset to default"},{"id":"MEM_STARTUP","default":"1024","description":"Optionally change the Java initial/minimum memory (in Megabytes). Set to `default` to reset to default"}],"volumes":[{"container":"/config","description":"All Unifi data stored here","key":"config"}],"ports":[{"container":"8443","description":"Unifi web admin port","protocol":"tcp","web":false},{"container":"3478/udp","description":"Unifi STUN port","protocol":"tcp","web":false},{"container":"10001/udp","description":"Required for AP discovery","protocol":"tcp","web":false},{"container":"8080","description":"Required for device communication","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"unifi-controller","project_url":"https://www.ubnt.com/enterprise/#unifi","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/unifi-banner.png","project_blurb":"The [{{ project_name|capitalize }}]({{ project_url }}) software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"All Unifi data stored here"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8443","internal_port":"8443","port_desc":"Unifi web admin port"},{"external_port":"3478","internal_port":"3478/udp","port_desc":"Unifi STUN port"},{"external_port":"10001","internal_port":"10001/udp","port_desc":"Required for AP discovery"},{"external_port":"8080","internal_port":"8080","port_desc":"Required for device communication"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use (e.g. Europe/London) - [see list](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MEM_LIMIT","env_value":"1024","desc":"Optionally change the Java memory limit (in Megabytes). Set to `default` to reset to default"},{"env_var":"MEM_STARTUP","env_value":"1024","desc":"Optionally change the Java initial/minimum memory (in Megabytes). Set to `default` to reset to default"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"1900","internal_port":"1900/udp","port_desc":"Required for `Make controller discoverable on L2 network` option"},{"external_port":"8843","internal_port":"8843","port_desc":"Unifi guest portal HTTPS redirect port"},{"external_port":"8880","internal_port":"8880","port_desc":"Unifi guest portal HTTP redirect port"},{"external_port":"6789","internal_port":"6789","port_desc":"For mobile throughput test"},{"external_port":"5514","internal_port":"5514/udp","port_desc":"Remote syslog port"}],"app_setup_block_enabled":true,"app_setup_block":"The webui is at https://ip:8443, setup with the first run wizard.\n\nFor Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption).\n\nIn order to manually adopt a device take these steps:\n\n```\nssh ubnt@$AP-IP\nset-inform http://$address:8080/inform\n```\n\nThe default device password is `ubnt`. `$address` is the IP address of the host you are running this container on and `$AP-IP` is the Access Point IP address.\n\nWhen using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessable) ip address.\n","changelogs":[{"date":"23.01.23:","desc":"Exclude `run` from `/config` volume."},{"date":"30.11.22:","desc":"Bump JRE to 11."},{"date":"01.06.22:","desc":"Deprecate armhf."},{"date":"23.12.21:","desc":"Move min/max memory config from run to system.properties."},{"date":"22.12.21:","desc":"Move deb package install to first init to avoid overlayfs performance issues."},{"date":"13.12.21:","desc":"Rebase 64 bit containers to Focal."},{"date":"11.12.21:","desc":"Add java opts to mitigate CVE-2021-44228."},{"date":"11.06.21:","desc":"Allow for changing Java initial mem via new optional environment variable."},{"date":"12.01.21:","desc":"Deprecate the `LTS` tag as Unifi no longer releases LTS stable builds. Existing users can switch to the `latest` tag. Direct upgrade from 5.6.42 (LTS) to 6.0.42 (latest) tested successfully."},{"date":"17.07.20:","desc":"Rebase 64 bit containers to Bionic and Mongo 3.6."},{"date":"16.06.20:","desc":"Add logrotate."},{"date":"02.06.20:","desc":"Updated port list & descriptions. Moved some ports to optional."},{"date":"14.11.19:","desc":"Changed url for deb package to match new Ubiquity domain."},{"date":"29.07.19:","desc":"Allow for changing Java mem limit via new optional environment variable."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.02.19:","desc":"Initial release of new unifi-controller image with new tags and pipeline logic"}]}},"setup":"The webui is at https://ip:8443, setup with the first run wizard.\n\nFor Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption).\n\nIn order to manually adopt a device take these steps:\n\n```\nssh ubnt@$AP-IP\nset-inform http://$address:8080/inform\n```\n\nThe default device password is `ubnt`. `$address` is the IP address of the host you are running this container on and `$AP-IP` is the Access Point IP address.\n\nWhen using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessable) ip address.\n"},{"id":"webgrabplus","name":"webgrabplus","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-site incremental xmltv epg grabber. It collects tv-program guide data from selected tvguide sites for your favourite channels.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/webgrabplus.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/webgrabplus"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-webgrabplus"}],"containers":[{"name":"webgrabplus","image":"linuxserver/webgrabplus","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Where webgrabplus should store it's config files.","key":"config"},{"container":"/data","description":"Where webgrabplus should store it's data files."}]}],"meta":{"readme-vars":{"project_name":"webgrabplus","project_url":"http://www.webgrabplus.com","project_logo":"http://www.webgrabplus.com/sites/default/themes/WgTheme/images/slideshows/EPG_fading.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-site incremental xmltv epg grabber. It collects tv-program guide data from selected tvguide sites for your favourite channels.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":true,"param_hostname":"webgrabplus","param_hostname_desc":"Set the hostname for the container for the license check.","param_usage_include_mac_address":true,"param_mac_address":"00:00:00:00:00:00","param_mac_address_desc":"Set the mac_address for the container for the license check.","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where webgrabplus should store it's config files."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Where webgrabplus should store it's data files."}],"param_usage_include_ports":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"To configure WebGrab+Plus follow the [documentation](http://www.webgrabplus.com/documentation/configuration/)\n\n**Please note that depending on your host this container may not work with the `no-new-privileges=true` security-opt.**\n\nNote that there are some things in the guide that does not apply to this container. Below you can find the changes.\n\n**The configuration files are found where your config volume is mounted.**\n**Do not change the filename tag in the configuration file!**\n\nThe /data volume mapping is where WebGrab+Plus outputs the xml file. To use the xml file in another program, you have to point it to the host path you mapped the /data volume to.\n\nTo adjust the scheduled cron job for grabbing, edit the wg3-cron file found in the `/config` folder. After you have edited the the wg3-cron file, restart the container to apply the new schedule.\nDo not adjust the command!\n\n**Note that due to something in version 3, we had to change the commands for scheduling the grab. If you have a version where there is a wg-cron file in your /config mount, delete it and use wg3-cron instead.**\n\nBelow is the syntax of the cron file.\n\n```\n  minute (0 - 59)\n   hour (0 - 23)\n    day of month (1 - 31)\n     month (1 - 12)\n      day of week (0 - 6) (Sunday to Saturday;\n                                            7 is also Sunday on some systems)\n     \n     \n * * * * *  /bin/bash /defaults/update.sh\n```\n","changelogs":[{"date":"23.03.22:","desc":"Rebase to Alpine 3.16 and s6v3. Update to dotnet 6."},{"date":"29.04.22:","desc":"Add `hostname` and `mac_address` arguments that are needed for the license check to compose and cli samples."},{"date":"23.03.22:","desc":"Rebase to Alpine 3.15."},{"date":"23.03.22:","desc":"Update to use dotnet instead of mono."},{"date":"06.01.22:","desc":"Rebase to Ubuntu focal. Enable auto builds on version updates (beta and stable)."},{"date":"17.12.21:","desc":"Update to version 3.2.2 beta."},{"date":"05.08.21:","desc":"Update to version 3.2.1 beta."},{"date":"05.06.21:","desc":"Added mono-devel dependency."},{"date":"04.06.21:","desc":"Update to version 3.1.8 beta."},{"date":"22.03.21:","desc":"Update to version 3.1.7 beta."},{"date":"07.03.21:","desc":"Update to version 3.1.6 beta."},{"date":"29.01.21:","desc":"Update external version number to show as 3.1.5."},{"date":"24.01.21:","desc":"Update to version 3.1.5 beta."},{"date":"22.12.20:","desc":"Update to version 3.1.4 beta."},{"date":"12.10.20:","desc":"Fix version number in jenkinsfile."},{"date":"12.10.20:","desc":"Update to version 3.1.1 beta."},{"date":"22.06.20:","desc":"Add mono webrequest library."},{"date":"18.06.20:","desc":"Update to v3.1.0."},{"date":"29.03.20:","desc":"Update to v3.0.0. Changed to use wg3-cron file."},{"date":"28.05.19:","desc":"Update to v2.1.0 and beta v2.1.9, rebase to bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"21.03.19:","desc":"Update to beta 2.1.7."},{"date":"19.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.01.18:","desc":"Initial Release."}]}},"setup":"To configure WebGrab+Plus follow the [documentation](http://www.webgrabplus.com/documentation/configuration/)\n\n**Please note that depending on your host this container may not work with the `no-new-privileges=true` security-opt.**\n\nNote that there are some things in the guide that does not apply to this container. Below you can find the changes.\n\n**The configuration files are found where your config volume is mounted.**\n**Do not change the filename tag in the configuration file!**\n\nThe /data volume mapping is where WebGrab+Plus outputs the xml file. To use the xml file in another program, you have to point it to the host path you mapped the /data volume to.\n\nTo adjust the scheduled cron job for grabbing, edit the wg3-cron file found in the `/config` folder. After you have edited the the wg3-cron file, restart the container to apply the new schedule.\nDo not adjust the command!\n\n**Note that due to something in version 3, we had to change the commands for scheduling the grab. If you have a version where there is a wg-cron file in your /config mount, delete it and use wg3-cron instead.**\n\nBelow is the syntax of the cron file.\n\n```\n  minute (0 - 59)\n   hour (0 - 23)\n    day of month (1 - 31)\n     month (1 - 12)\n      day of week (0 - 6) (Sunday to Saturday;\n                                            7 is also Sunday on some systems)\n     \n     \n * * * * *  /bin/bash /defaults/update.sh\n```\n"},{"id":"webtop","name":"webtop","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Alpine, Ubuntu, Fedora, and Arch based containers containing full desktop environments in officially supported flavors accessible via any modern web browser.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/webtop-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/webtop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-webtop"}],"containers":[{"name":"webtop","image":"linuxserver/webtop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."},{"id":"TITLE","default":"Webtop","description":"String which will be used as page/tab title in the web browser."}],"volumes":[{"container":"/var/run/docker.sock","description":"Docker Socket on the system, if you want to use Docker in the container"},{"container":"/config","description":"abc users home directory","key":"config"}],"ports":[{"container":"3000","description":"Web Desktop GUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"webtop","project_url":"https://github.com/linuxserver/docker-webtop","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/webtop-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Alpine, Ubuntu, Fedora, and Arch based containers containing full desktop environments in officially supported flavors accessible via any modern web browser.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"XFCE Alpine"},{"tag":"ubuntu-xfce","desc":"XFCE Ubuntu"},{"tag":"fedora-xfce","desc":"XFCE Fedora"},{"tag":"arch-xfce","desc":"XFCE Arch"},{"tag":"alpine-kde","desc":"KDE Alpine"},{"tag":"ubuntu-kde","desc":"KDE Ubuntu"},{"tag":"fedora-kde","desc":"KDE Fedora"},{"tag":"arch-kde","desc":"KDE Arch"},{"tag":"alpine-mate","desc":"MATE Alpine"},{"tag":"ubuntu-mate","desc":"MATE Ubuntu"},{"tag":"fedora-mate","desc":"MATE Fedora"},{"tag":"arch-mate","desc":"MATE Arch"},{"tag":"alpine-i3","desc":"i3 Alpine"},{"tag":"ubuntu-i3","desc":"i3 Ubuntu"},{"tag":"fedora-i3","desc":"i3 Fedora"},{"tag":"arch-i3","desc":"i3 Arch"},{"tag":"alpine-openbox","desc":"Openbox Alpine"},{"tag":"ubuntu-openbox","desc":"Openbox Ubuntu"},{"tag":"fedora-openbox","desc":"Openbox Fedora"},{"tag":"arch-openbox","desc":"Openbox Arch"},{"tag":"alpine-icewm","desc":"IceWM Alpine"},{"tag":"ubuntu-icewm","desc":"IceWM Ubuntu"},{"tag":"fedora-icewm","desc":"IceWM Fedora"},{"tag":"arch-icewm","desc":"IceWM Arch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"abc users home directory"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web Desktop GUI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."},{"env_var":"TITLE","env_value":"Webtop","desc":"String which will be used as page/tab title in the web browser."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/run/docker.sock","vol_host_path":"/var/run/docker.sock","desc":"Docker Socket on the system, if you want to use Docker in the container"}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"We set this to 1 gig to prevent modern web browsers from crashing"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for GL support (Linux hosts only)"}],"app_setup_block_enabled":true,"app_setup_block":"The Webtop can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\nYou can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste, an onscreen keyboard, or a baked in file manager. This can also be accessed by clicking the small circle on the left side of the screen.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\n\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it webtop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt. \n","changelogs":[{"date":"21.10.22:","desc":"Rebase xfce to Alpine 3.16, migrate to s6v3."},{"date":"12.03.22:","desc":"Add documentation for mounting in a GPU."},{"date":"05.02.22:","desc":"Rebase KDE Ubuntu to Jammy, add new documentation for updated gclient, stop recommending priv mode."},{"date":"21.09.21:","desc":"Add Fedora and Arch images, show seccomp settings in readme."},{"date":"26.09.21:","desc":"Rebase to Alpine versions to 3.14."},{"date":"20.04.21:","desc":"Initial release."}]}},"setup":"The Webtop can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\nYou can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste, an onscreen keyboard, or a baked in file manager. This can also be accessed by clicking the small circle on the left side of the screen.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\n\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it webtop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt. \n"},{"id":"wikijs","name":"wikijs","description":"[{{ project_name|capitalize }}]({{ project_url }}) A modern, lightweight and powerful wiki app built on NodeJS.","icon":"https://static.requarks.io/logo/wikijs-full.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wikijs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wikijs"}],"containers":[{"name":"wikijs","image":"linuxserver/wikijs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Wiki.js config is stored.","key":"config"},{"container":"/data","description":"Where Wiki.js data is stored."}],"ports":[{"container":"3000","description":"Port for Wiki.js's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"wikijs","project_url":"https://github.com/Requarks/wiki","project_logo":"https://static.requarks.io/logo/wikijs-full.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A modern, lightweight and powerful wiki app built on NodeJS.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to config>","desc":"Where Wiki.js config is stored."},{"vol_path":"/data","vol_host_path":"<path to data>","desc":"Where Wiki.js data is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Port for Wiki.js's web interface."}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":false,"app_setup_block":"","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"28.04.20:","desc":"Added python dependency for some NPM modules as well as git for storage module"},{"date":"14.12.19:","desc":"Initial Release."}]}}},{"id":"wireguard","name":"wireguard","description":"[WireGuard]({{ project_url }}) is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.","icon":"https://www.wireguard.com/img/wireguard.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wireguard"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wireguard"}],"containers":[{"name":"wireguard","image":"linuxserver/wireguard","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SERVERURL","default":"wireguard.domain.com","description":"External IP or domain name for docker host. Used in server mode. If set to `auto`, the container will try to determine and set the external IP automatically"},{"id":"SERVERPORT","default":"51820","description":"External port for docker host. Used in server mode."},{"id":"PEERS","default":"1","description":"Number of peers to create confs for. Required for server mode. Can also be a list of names: `myPC,myPhone,myTablet` (alphanumeric only)"},{"id":"PEERDNS","default":"auto","description":"DNS server set in peer/client configs (can be set as `8.8.8.8`). Used in server mode. Defaults to `auto`, which uses wireguard docker host's DNS via included CoreDNS forward."},{"id":"INTERNAL_SUBNET","default":"10.13.13.0","description":"Internal subnet for the wireguard and server and peers (only change if it clashes). Used in server mode."},{"id":"ALLOWEDIPS","default":"0.0.0.0/0","description":"The IPs/Ranges that the peers will be able to reach using the VPN connection. If not specified the default value is: '0.0.0.0/0, ::0/0' This will cause ALL traffic to route through the VPN, if you want split tunneling, set this to only the IPs you would like to use the tunnel AND the ip of the server's WG ip, such as 10.13.13.1."},{"id":"PERSISTENTKEEPALIVE_PEERS","default":"","description":"Set to `all` or a list of comma separated peers (ie. `1,4,laptop`) for the wireguard server to send keepalive packets to listed peers every 25 seconds. Useful if server is accessed via domain name and has dynamic IP. Used only in server mode."},{"id":"LOG_CONFS","default":"true","description":"Generated QR codes will be displayed in the docker log. Set to `false` to skip log output."}],"volumes":[{"container":"/lib/modules","description":"Maps host's modules folder. Only required if compiling wireguard modules."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"51820/udp","description":"wireguard port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"wireguard","project_url":"https://www.wireguard.com/","project_logo":"https://www.wireguard.com/img/wireguard.svg","project_blurb":"[WireGuard]({{ project_url }}) is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases with support for compiling Wireguard modules"},{"tag":"alpine","desc":"Stable releases based on Alpine *without* support for compiling Wireguard modules"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/lib/modules","vol_host_path":"/lib/modules","desc":"Maps host's modules folder. Only required if compiling wireguard modules."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"51820","internal_port":"51820/udp","port_desc":"wireguard port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"},{"cap_add_var":"SYS_MODULE"}],"custom_params":[{"name":"sysctl","name_compose":"sysctls","value":["net.ipv4.conf.all.src_valid_mark=1"],"desc":"Required for client mode.","array":"true"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SERVERURL","env_value":"wireguard.domain.com","desc":"External IP or domain name for docker host. Used in server mode. If set to `auto`, the container will try to determine and set the external IP automatically"},{"env_var":"SERVERPORT","env_value":"51820","desc":"External port for docker host. Used in server mode."},{"env_var":"PEERS","env_value":"1","desc":"Number of peers to create confs for. Required for server mode. Can also be a list of names: `myPC,myPhone,myTablet` (alphanumeric only)"},{"env_var":"PEERDNS","env_value":"auto","desc":"DNS server set in peer/client configs (can be set as `8.8.8.8`). Used in server mode. Defaults to `auto`, which uses wireguard docker host's DNS via included CoreDNS forward."},{"env_var":"INTERNAL_SUBNET","env_value":"10.13.13.0","desc":"Internal subnet for the wireguard and server and peers (only change if it clashes). Used in server mode."},{"env_var":"ALLOWEDIPS","env_value":"0.0.0.0/0","desc":"The IPs/Ranges that the peers will be able to reach using the VPN connection. If not specified the default value is: '0.0.0.0/0, ::0/0' This will cause ALL traffic to route through the VPN, if you want split tunneling, set this to only the IPs you would like to use the tunnel AND the ip of the server's WG ip, such as 10.13.13.1."},{"env_var":"PERSISTENTKEEPALIVE_PEERS","env_value":"","desc":"Set to `all` or a list of comma separated peers (ie. `1,4,laptop`) for the wireguard server to send keepalive packets to listed peers every 25 seconds. Useful if server is accessed via domain name and has dynamic IP. Used only in server mode."},{"env_var":"LOG_CONFS","env_value":"true","desc":"Generated QR codes will be displayed in the docker log. Set to `false` to skip log output."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"During container start, it will first check if the wireguard module is already installed and loaded. Kernels newer than 5.6 generally have the wireguard module built-in (along with some older custom kernels). However, the module may not be enabled. Make sure it is enabled prior to starting the container.\n\nIf the kernel is not built-in, or installed on host, the container will check if the kernel headers are present (in `/usr/src`) and if not, it will attempt to download the necessary kernel headers from the `ubuntu xenial/bionic`, `debian/raspbian buster` repos; then will attempt to compile and install the kernel module. If the kernel headers are not found in either `usr/src` or in the repos mentioned, container will sleep indefinitely as wireguard cannot be installed.\n\nIf you're on a debian/ubuntu based host with a custom or downstream distro provided kernel (ie. Pop!_OS), the container won't be able to install the kernel headers from the regular ubuntu and debian repos. In those cases, you can try installing the headers on the host via `sudo apt install linux-headers-$(uname -r)` (if distro version) and then add a volume mapping for `/usr/src:/usr/src`, or if custom built, map the location of the existing headers to allow the container to use host installed headers to build the kernel module (tested successful on Pop!_OS, ymmv).\n\nWith regards to arm32/64 devices, Raspberry Pi 2-4 running the [official ubuntu images](https://ubuntu.com/download/raspberry-pi) or Raspbian Buster are supported out of the box. For all other devices and OSes, you can try installing the kernel headers on the host, and mapping `/usr/src:/usr/src` and it may just work (no guarantees).\n\nThis can be run as a server or a client, based on the parameters used.\n\n## Server Mode\n\nIf the environment variable `PEERS` is set to a number or a list of strings separated by comma, the container will run in server mode and the necessary server and peer/client confs will be generated. The peer/client config qr codes will be output in the docker log if `LOG_CONFS` is set to `true`. They will also be saved in text and png format under `/config/peerX` in case `PEERS` is a variable and an integer or `/config/peer_X` in case a list of names was provided instead of an integer.\n\nVariables `SERVERURL`, `SERVERPORT`, `INTERNAL_SUBNET`, `PEERDNS`, `INTERFACE`, `ALLOWEDIPS` and `PERSISTENTKEEPALIVE_PEERS` are optional variables used for server mode. Any changes to these environment variables will trigger regeneration of server and peer confs. Peer/client confs will be recreated with existing private/public keys. Delete the peer folders for the keys to be recreated along with the confs.\n\nTo add more peers/clients later on, you increment the `PEERS` environment variable or add more elements to the list and recreate the container.\n\nTo display the QR codes of active peers again, you can use the following command and list the peer numbers as arguments: `docker exec -it wireguard /app/show-peer 1 4 5` or `docker exec -it wireguard /app/show-peer myPC myPhone myTablet` (Keep in mind that the QR codes are also stored as PNGs in the config folder).\n\nThe templates used for server and peer confs are saved under `/config/templates`. Advanced users can modify these templates and force conf generation by deleting `/config/wg0.conf` and restarting the container.\n\n## Client Mode\n\nDo not set the `PEERS` environment variable. Drop your client conf into the config folder as `/config/wg0.conf` and start the container.\n\nIf you get IPv6 related errors in the log and connection cannot be established, edit the `AllowedIPs` line in your peer/client wg0.conf to include only `0.0.0.0/0` and not `::/0`; and restart the container.\n\n## Road warriors, roaming and returning home\n\nIf you plan to use Wireguard both remotely and locally, say on your mobile phone, you will need to consider routing. Most firewalls will not route ports forwarded on your WAN interface correctly to the LAN out of the box. This means that when you return home, even though you can see the Wireguard server, the return packets will probably get lost.\n\nThis is not a Wireguard specific issue and the two generally accepted solutions are NAT reflection (setting your edge router/firewall up in such a way as it translates internal packets correctly) or split horizon DNS (setting your internal DNS to return the private rather than public IP when connecting locally).\n\nBoth of these approaches have positives and negatives however their setup is out of scope for this document as everyone's network layout and equipment will be different.\n\n## Maintaining local access to attached services\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nWhen routing via Wireguard from another container using the `service` option in docker, you might lose access to the containers webUI locally. To avoid this, exclude the docker subnet from being routed via Wireguard by modifying your `wg0.conf` like so (modifying the subnets as you require):\n\n  ```ini\n  [Interface]\n  PrivateKey = <private key>\n  Address = 9.8.7.6/32\n  DNS = 8.8.8.8\n  PostUp = DROUTE=$(ip route | grep default | awk '{print $3}'); HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route add $HOMENET3 via $DROUTE;ip route add $HOMENET2 via $DROUTE; ip route add $HOMENET via $DROUTE;iptables -I OUTPUT -d $HOMENET -j ACCEPT;iptables -A OUTPUT -d $HOMENET2 -j ACCEPT; iptables -A OUTPUT -d $HOMENET3 -j ACCEPT;  iptables -A OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n  PreDown = HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route del $HOMENET3 via $DROUTE;ip route del $HOMENET2 via $DROUTE; ip route del $HOMENET via $DROUTE; iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT; iptables -D OUTPUT -d $HOMENET -j ACCEPT; iptables -D OUTPUT -d $HOMENET2 -j ACCEPT; iptables -D OUTPUT -d $HOMENET3 -j ACCEPT\n  ```\n\n## Site-to-site VPN\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nSite-to-site VPN in server mode requires customizing the `AllowedIPs` statement for a specific peer in `wg0.conf`. Since `wg0.conf` is autogenerated when server vars are changed, it is not recommended to edit it manually.\n\nIn order to customize the `AllowedIPs` statement for a specific peer in `wg0.conf`, you can set an env var `SERVER_ALLOWEDIPS_PEER_<peer name or number>` to the additional subnets you'd like to add, comma separated and excluding the peer IP (ie. `\"192.168.1.0/24,192.168.2.0/24\"`). Replace `<peer name or number>` with either the name or number of a peer (whichever is used in the `PEERS` var).\n\nFor instance `SERVER_ALLOWEDIPS_PEER_laptop=\"192.168.1.0/24,192.168.2.0/24\"` will result in the wg0.conf entry `AllowedIPs = 10.13.13.2,192.168.1.0/24,192.168.2.0/24` for the peer named `laptop`.\n\nKeep in mind that this var will only be considered when the confs are regenerated. Adding this var for an existing peer won't force a regeneration. You can delete wg0.conf and restart the container to force regeneration if necessary.\n\nDon't forget to set the necessary POSTUP and POSTDOWN rules in your client's peer conf for lan access.\n","changelogs":[{"date":"28.01.23:","desc":"Patch wg-quick to suppress false positive sysctl warning."},{"date":"10.01.23:","desc":"Add new var to add `PersistentKeepalive` to server config for select peers to survive server IP changes when domain name is used."},{"date":"26.10.22:","desc":"Better handle unsupported peer names. Improve logging."},{"date":"12.10.22:","desc":"Add Alpine branch. Optimize wg and coredns services."},{"date":"09.10.22:","desc":"Switch back to iptables-legacy due to issues on some hosts."},{"date":"04.10.22:","desc":"Rebase to Jammy. Upgrade to s6v3."},{"date":"16.05.22:","desc":"Improve NAT handling in server mode when multiple ethernet devices are present."},{"date":"23.04.22:","desc":"Add pre-shared key support. Automatically added to all new peer confs generated, existing ones are left without to ensure no breaking changes."},{"date":"10.04.22:","desc":"Rebase to Ubuntu Focal. Add `LOG_CONFS` env var. Remove deprecated `add-peer` command."},{"date":"28.10.21:","desc":"Add site-to-site vpn support."},{"date":"11.02.21:","desc":"Fix bug related to changing internal subnet and named peer confs not updating."},{"date":"06.10.20:","desc":"Disable CoreDNS in client mode, or if port 53 is already in use in server mode."},{"date":"04.10.20:","desc":"Allow to specify a list of names as PEERS and add ALLOWEDIPS environment variable. Also, add peer name/id to each one of the peer sections in wg0.conf. Important: Existing users need to delete `/config/templates/peer.conf` and restart"},{"date":"27.09.20:","desc":"Cleaning service binding example to have accurate PreDown script."},{"date":"06.08.20:","desc":"Replace resolvconf with openresolv due to dns issues when a client based on this image is connected to a server also based on this image. Add IPv6 info to readme. Display kernel version in logs."},{"date":"29.07.20:","desc":"Update Coredns config to detect dns loops (existing users need to delete `/config/coredns/Corefile` and restart)."},{"date":"27.07.20:","desc":"Update Coredns config to prevent issues with non-user-defined bridge networks (existing users need to delete `/config/coredns/Corefile` and restart)."},{"date":"05.07.20:","desc":"Add Debian updates and security repos for headers."},{"date":"25.06.20:","desc":"Simplify module tests, prevent iptables issues from resulting in false negatives."},{"date":"19.06.20:","desc":"Add support for Ubuntu Focal (20.04) kernels. Compile wireguard tools and kernel module instead of using the ubuntu packages. Make module install optional. Improve verbosity in logs."},{"date":"29.05.20:","desc":"Add support for 64bit raspbian."},{"date":"28.04.20:","desc":"Add Buster/Stretch backports repos for Debian. Tested with OMV 5 and OMV 4 (on kernel 4.19.0-0.bpo.8-amd64)."},{"date":"20.04.20:","desc":"Fix typo in client mode conf existence check."},{"date":"13.04.20:","desc":"Fix bug that forced conf recreation on every start."},{"date":"08.04.20:","desc":"Add arm32/64 builds and enable multi-arch (rpi4 with ubuntu and raspbian buster tested). Add CoreDNS for `PEERDNS=auto` setting. Update the `add-peer`/`show-peer` scripts to utilize the templates and the `INTERNAL_SUBNET` var (previously missed, oops)."},{"date":"05.04.20:","desc":"Add `INTERNAL_SUBNET` variable to prevent subnet clashes. Add templates for server and peer confs."},{"date":"01.04.20:","desc":"Add `show-peer` script and include info on host installed headers."},{"date":"31.03.20:","desc":"Initial Release."}]}},"setup":"During container start, it will first check if the wireguard module is already installed and loaded. Kernels newer than 5.6 generally have the wireguard module built-in (along with some older custom kernels). However, the module may not be enabled. Make sure it is enabled prior to starting the container.\n\nIf the kernel is not built-in, or installed on host, the container will check if the kernel headers are present (in `/usr/src`) and if not, it will attempt to download the necessary kernel headers from the `ubuntu xenial/bionic`, `debian/raspbian buster` repos; then will attempt to compile and install the kernel module. If the kernel headers are not found in either `usr/src` or in the repos mentioned, container will sleep indefinitely as wireguard cannot be installed.\n\nIf you're on a debian/ubuntu based host with a custom or downstream distro provided kernel (ie. Pop!_OS), the container won't be able to install the kernel headers from the regular ubuntu and debian repos. In those cases, you can try installing the headers on the host via `sudo apt install linux-headers-$(uname -r)` (if distro version) and then add a volume mapping for `/usr/src:/usr/src`, or if custom built, map the location of the existing headers to allow the container to use host installed headers to build the kernel module (tested successful on Pop!_OS, ymmv).\n\nWith regards to arm32/64 devices, Raspberry Pi 2-4 running the [official ubuntu images](https://ubuntu.com/download/raspberry-pi) or Raspbian Buster are supported out of the box. For all other devices and OSes, you can try installing the kernel headers on the host, and mapping `/usr/src:/usr/src` and it may just work (no guarantees).\n\nThis can be run as a server or a client, based on the parameters used.\n\n## Server Mode\n\nIf the environment variable `PEERS` is set to a number or a list of strings separated by comma, the container will run in server mode and the necessary server and peer/client confs will be generated. The peer/client config qr codes will be output in the docker log if `LOG_CONFS` is set to `true`. They will also be saved in text and png format under `/config/peerX` in case `PEERS` is a variable and an integer or `/config/peer_X` in case a list of names was provided instead of an integer.\n\nVariables `SERVERURL`, `SERVERPORT`, `INTERNAL_SUBNET`, `PEERDNS`, `INTERFACE`, `ALLOWEDIPS` and `PERSISTENTKEEPALIVE_PEERS` are optional variables used for server mode. Any changes to these environment variables will trigger regeneration of server and peer confs. Peer/client confs will be recreated with existing private/public keys. Delete the peer folders for the keys to be recreated along with the confs.\n\nTo add more peers/clients later on, you increment the `PEERS` environment variable or add more elements to the list and recreate the container.\n\nTo display the QR codes of active peers again, you can use the following command and list the peer numbers as arguments: `docker exec -it wireguard /app/show-peer 1 4 5` or `docker exec -it wireguard /app/show-peer myPC myPhone myTablet` (Keep in mind that the QR codes are also stored as PNGs in the config folder).\n\nThe templates used for server and peer confs are saved under `/config/templates`. Advanced users can modify these templates and force conf generation by deleting `/config/wg0.conf` and restarting the container.\n\n## Client Mode\n\nDo not set the `PEERS` environment variable. Drop your client conf into the config folder as `/config/wg0.conf` and start the container.\n\nIf you get IPv6 related errors in the log and connection cannot be established, edit the `AllowedIPs` line in your peer/client wg0.conf to include only `0.0.0.0/0` and not `::/0`; and restart the container.\n\n## Road warriors, roaming and returning home\n\nIf you plan to use Wireguard both remotely and locally, say on your mobile phone, you will need to consider routing. Most firewalls will not route ports forwarded on your WAN interface correctly to the LAN out of the box. This means that when you return home, even though you can see the Wireguard server, the return packets will probably get lost.\n\nThis is not a Wireguard specific issue and the two generally accepted solutions are NAT reflection (setting your edge router/firewall up in such a way as it translates internal packets correctly) or split horizon DNS (setting your internal DNS to return the private rather than public IP when connecting locally).\n\nBoth of these approaches have positives and negatives however their setup is out of scope for this document as everyone's network layout and equipment will be different.\n\n## Maintaining local access to attached services\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nWhen routing via Wireguard from another container using the `service` option in docker, you might lose access to the containers webUI locally. To avoid this, exclude the docker subnet from being routed via Wireguard by modifying your `wg0.conf` like so (modifying the subnets as you require):\n\n  ```ini\n  [Interface]\n  PrivateKey = <private key>\n  Address = 9.8.7.6/32\n  DNS = 8.8.8.8\n  PostUp = DROUTE=$(ip route | grep default | awk '{print $3}'); HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route add $HOMENET3 via $DROUTE;ip route add $HOMENET2 via $DROUTE; ip route add $HOMENET via $DROUTE;iptables -I OUTPUT -d $HOMENET -j ACCEPT;iptables -A OUTPUT -d $HOMENET2 -j ACCEPT; iptables -A OUTPUT -d $HOMENET3 -j ACCEPT;  iptables -A OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n  PreDown = HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route del $HOMENET3 via $DROUTE;ip route del $HOMENET2 via $DROUTE; ip route del $HOMENET via $DROUTE; iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT; iptables -D OUTPUT -d $HOMENET -j ACCEPT; iptables -D OUTPUT -d $HOMENET2 -j ACCEPT; iptables -D OUTPUT -d $HOMENET3 -j ACCEPT\n  ```\n\n## Site-to-site VPN\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nSite-to-site VPN in server mode requires customizing the `AllowedIPs` statement for a specific peer in `wg0.conf`. Since `wg0.conf` is autogenerated when server vars are changed, it is not recommended to edit it manually.\n\nIn order to customize the `AllowedIPs` statement for a specific peer in `wg0.conf`, you can set an env var `SERVER_ALLOWEDIPS_PEER_<peer name or number>` to the additional subnets you'd like to add, comma separated and excluding the peer IP (ie. `\"192.168.1.0/24,192.168.2.0/24\"`). Replace `<peer name or number>` with either the name or number of a peer (whichever is used in the `PEERS` var).\n\nFor instance `SERVER_ALLOWEDIPS_PEER_laptop=\"192.168.1.0/24,192.168.2.0/24\"` will result in the wg0.conf entry `AllowedIPs = 10.13.13.2,192.168.1.0/24,192.168.2.0/24` for the peer named `laptop`.\n\nKeep in mind that this var will only be considered when the confs are regenerated. Adding this var for an existing peer won't force a regeneration. You can delete wg0.conf and restart the container to force regeneration if necessary.\n\nDon't forget to set the necessary POSTUP and POSTDOWN rules in your client's peer conf for lan access.\n"},{"id":"wireshark","name":"wireshark","description":"[Wireshark]({{ project_url }}) is the worlds foremost and widely-used network protocol analyzer. It lets you see whats happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Wireshark development thrives thanks to the volunteer contributions of networking experts around the globe and is the continuation of a project started by Gerald Combs in 1998. ","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/wireshark-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wireshark"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wireshark"}],"containers":[{"name":"wireshark","image":"linuxserver/wireshark","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and potentially dump files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"wireshark","project_url":"https://www.wireshark.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/wireshark-icon.png","project_blurb":"[Wireshark]({{ project_url }}) is the worlds foremost and widely-used network protocol analyzer. It lets you see whats happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Wireshark development thrives thanks to the volunteer contributions of networking experts around the globe and is the continuation of a project started by Gerald Combs in 1998. ","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_usage_include_ports":false,"param_usage_include_net":true,"param_net":"host","param_net_desc":"Use Host Networking","param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and potentially dump files."}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"WireShark desktop gui, only use this if you are not using host mode and sniffing Docker network traffic."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nIn order to dump from an interface you will need to pass `NET_ADMIN` at a minimum, optionally you can use host networking to capture from your host level device or specify a Docker network you want to capture from.\n\nIf you do not specificy host networking you will need to map port 3000 with `-p 3000:3000`.\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"14.02.22:","desc":"Rebase to Alpine."},{"date":"31.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nIn order to dump from an interface you will need to pass `NET_ADMIN` at a minimum, optionally you can use host networking to capture from your host level device or specify a Docker network you want to capture from.\n\nIf you do not specificy host networking you will need to map port 3000 with `-p 3000:3000`.\n"},{"id":"xbackbone","name":"xbackbone","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple, self-hosted, lightweight PHP file manager that support the instant sharing tool ShareX and *NIX systems. It supports uploading and displaying images, GIF, video, code, formatted text, and file downloading and uploading. Also have a web UI with multi user management, past uploads history and search support.\n","icon":"https://raw.githubusercontent.com/SergiX44/XBackBone/master/docs/img/xbackbone.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/xbackbone"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-xbackbone"}],"containers":[{"name":"xbackbone","image":"linuxserver/xbackbone","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/Oslo","description":"Timezone (i.e., Europe/Oslo)"}],"volumes":[{"container":"/config","description":"config directory volume mapping","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"xbackbone","project_url":"https://github.com/SergiX44/XBackBone","project_logo":"https://raw.githubusercontent.com/SergiX44/XBackBone/master/docs/img/xbackbone.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple, self-hosted, lightweight PHP file manager that support the instant sharing tool ShareX and *NIX systems. It supports uploading and displaying images, GIF, video, code, formatted text, and file downloading and uploading. Also have a web UI with multi user management, past uploads history and search support.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"config directory volume mapping"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/Oslo","desc":"Timezone (i.e., Europe/Oslo)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"app_setup_block_enabled":true,"app_setup_block":"Access the WebUI at \\<your-ip>:80/443. Follow the installation wizard. For more information, check out [XBackBone](https://github.com/SergiX44/XBackBone).\n\nIf you want to change the PHP max upload size you can override the php.ini file by adding options in `/config/php/php-local.ini`\n\nExample:\n\n```ini\n  upload_max_filesize = 25M\n  post_max_size = 25M\n```\n\nFor reverse proxying, remember to change the `base_url` in `/config/www/xbackbone/config.php` to your domain if you initially set up the application with a local url. E.g. `'base_url' => 'https://images.yourdomain.com',`\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"04.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"01.11.22:","desc":"Move application install to /app/www/public, add migration notices for existing users. Container updates should now update the application correctly"},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"02.08.22:","desc":"Added note about updating."},{"date":"06.06.21:","desc":"Initial Release."}]}},"setup":"Access the WebUI at \\<your-ip>:80/443. Follow the installation wizard. For more information, check out [XBackBone](https://github.com/SergiX44/XBackBone).\n\nIf you want to change the PHP max upload size you can override the php.ini file by adding options in `/config/php/php-local.ini`\n\nExample:\n\n```ini\n  upload_max_filesize = 25M\n  post_max_size = 25M\n```\n\nFor reverse proxying, remember to change the `base_url` in `/config/www/xbackbone/config.php` to your domain if you initially set up the application with a local url. E.g. `'base_url' => 'https://images.yourdomain.com',`\n"},{"id":"yq","name":"yq","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/yq.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/yq"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-yq"}],"containers":[{"name":"yq","image":"linuxserver/yq","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"yq","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring:\n\n* regular and timely application updates\n* easy user mappings (PGID, PUID)\n* custom base image with s6 overlay\n* weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n* regular security updates\n\nFind us at:\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [GitHub](https://github.com/linuxserver) - view the source for all of our repositories.\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n# [linuxserver/yq](https://github.com/linuxserver/docker-yq)\n\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-yq)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-yq/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-yq/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/Linuxserver.io/docker-yq/container_registry)\n[![MicroBadger Layers](https://img.shields.io/microbadger/layers/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge)](https://microbadger.com/images/linuxserver/yq \"Get your own version badge on microbadger.com\")\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/yq)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/yq)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-yq%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-yq/job/master/)\n\n[yq](https://github.com/kislyuk/yq): Command-line YAML/XML processor - jq wrapper for YAML and XML documents. This image includes `yq`, `jq`, and `xq`.\n\n## Supported Architectures\n\nOur images support multiple architectures such as `x86-64`, `arm64` and `armhf`. We utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `linuxserver/yq` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Tag |\n| :----: | --- |\n| x86-64 | amd64-latest |\n| arm64 | arm64v8-latest |\n| armhf | arm32v7-latest |\n\n## Usage\n\n### Docker cli\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint yq \\\n  linuxserver/yq \\\n  .foo.bar input.yml\n```\nYou can replace the last line with any yq command and argument, which will be passed to yq inside the image.\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint jq \\\n  linuxserver/yq \\\n  .foo.bar input.json\n```\nYou can replace the last line with any jq command and argument, which will be passed to jq inside the image.\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint xq \\\n  linuxserver/yq \\\n  .foo.bar input.xml\n```\nYou can replace the last line with any xq command and argument, which will be passed to xq inside the image.\n\n### Recommended method\n\nWe provide a very convenient script that allows the yq container to run as if it was installed natively:\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-yq.sh -o /usr/local/bin/yq\nsudo chmod +x /usr/local/bin/yq\n```\nRunning these two commands on your docker host once will let you issue commands such as `yq .foo.bar input.yml` and the yq container will do its job behind the scenes.\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-jq.sh -o /usr/local/bin/jq\nsudo chmod +x /usr/local/bin/jq\n```\nRunning these two commands on your docker host once will let you issue commands such as `jq .foo.bar input.json` and the jq container will do its job behind the scenes.\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-xq.sh -o /usr/local/bin/xq\nsudo chmod +x /usr/local/bin/xq\n```\nRunning these two commands on your docker host once will let you issue commands such as `xq .foo.bar input.xml` and the xq container will do its job behind the scenes.\n\n## Docker Mods\n[![Docker Mods](https://img.shields.io/badge/dynamic/yaml?style=for-the-badge&color=E68523&label=mods&query=%24.mods%5B%27yq%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=yq \"view available mods for this container.\")\n\nWe publish various [Docker Mods](https://github.com/linuxserver/docker-mods) to enable additional functionality within the containers. The list of Mods available for this image (if any) can be accessed via the dynamic badge above.\n\n\n## Support Info\n\n* image version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/yq`\n\n## Updating Info\n\n### Via Docker Cli\n* Update the image: `docker pull linuxserver/yq`\n* You can also remove the old dangling images: `docker image prune`\n\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n```\ngit clone https://github.com/linuxserver/docker-yq.git\ncd docker-yq\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t linuxserver/yq:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n```\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **19.09.22:** - Rebase to 3.17.\n* **19.09.22:** - Rebase to 3.15.\n* **18.05.21:** - Rebase to 3.13. add linuxserver wheel repo.\n* **09.10.20:** - Fix run scripts evaluating `$` in cases where they should not (ex: inside single quotes). Please rerun the [Recommended method](https://github.com/linuxserver/docker-yq#recommended-method) install/setup commands.\n* **07.10.20:** - Initial Release.\n\n{%- endraw %}\n"}}},{"id":"znc","name":"znc","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an IRC network bouncer or BNC. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/znc.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/znc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-znc"}],"containers":[{"name":"znc","image":"linuxserver/znc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where local ZNC data is stored.","key":"config"}],"ports":[{"container":"6501","description":"Port ZNC listens on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"znc","project_url":"http://wiki.znc.in/ZNC","project_logo":"http://wiki.znc.in/resources/assets/wiki.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an IRC network bouncer or BNC. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where local ZNC data is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6501","internal_port":"6501","port_desc":"Port ZNC listens on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"To log in to the application, browse to http://<hostip>:6501.\n\n* Default User: admin\n* Default Password: admin\n`change password ASAP.`\n","changelogs":[{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"02.11.19:","desc":"Add znc-palaver module."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"31.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"30.01.19:","desc":"Add push and clientbuffer modules."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8, use buildstage."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"07.12.17:","desc":"Rebase alpine linux 3.7."},{"date":"25.10.17:","desc":"Remove debug switch from run command."},{"date":"26.05.17:","desc":"Rebase alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase alpine linux 3.5."},{"date":"19.01.17:","desc":"Add playback module."},{"date":"07.01.17:","desc":"Add ca-certificates package, resolve sasl issues."},{"date":"07.12.16:","desc":"Use scanelf to determine runtime dependencies. Fix error with continuation."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"20.08.16:","desc":"Rebase to alpine linux, move to main repository."},{"date":"11.12.15:","desc":"Initial Release."}]}},"setup":"To log in to the application, browse to http://<hostip>:6501.\n\n* Default User: admin\n* Default Password: admin\n`change password ASAP.`\n"}],"_id":"content:all.json","_type":"json","title":"All","_source":"content","_file":"all.json","_extension":"json"},{"_path":"/apps/adguardhome-sync","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"adguardhome-sync","name":"adguardhome-sync","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a tool to synchronize AdGuardHome config to replica instances.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/adguardhomesync-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/adguardhome-sync"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-adguardhome-sync"}],"containers":[{"name":"adguardhome-sync","image":"linuxserver/adguardhome-sync","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"CONFIGFILE","default":"/config/adguardhome-sync.yaml","description":"Set a custom config file."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"8080","description":"Port for AdGuardHome Sync's web API.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"adguardhome-sync","project_url":"https://github.com/bakito/adguardhome-sync/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/adguardhomesync-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a tool to synchronize AdGuardHome config to replica instances.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Port for AdGuardHome Sync's web API."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONFIGFILE","env_value":"/config/adguardhome-sync.yaml","desc":"Set a custom config file."}],"opt_param_usage_include_vols":false,"app_setup_block_enabled":true,"app_setup_block":"Edit the adguardhome-sync.yaml with your AdGuardHome instance details, for more information check out [AdGuardHome Sync](https://github.com/bakito/adguardhome-sync/).\n","changelogs":[{"date":"03.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"18.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"09.08.21:","desc":"Rebase to Alpine 3.14."},{"date":"08.04.21:","desc":"Initial Release."}]}},"setup":"Edit the adguardhome-sync.yaml with your AdGuardHome instance details, for more information check out [AdGuardHome Sync](https://github.com/bakito/adguardhome-sync/).\n","_id":"content:apps:adguardhome-sync.json","_type":"json","title":"Adguardhome Sync","_source":"content","_file":"apps/adguardhome-sync.json","_extension":"json"},{"_path":"/apps/airsonic-advanced","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"airsonic-advanced","name":"airsonic-advanced","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/airsonic-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/airsonic-advanced"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-airsonic-advanced"}],"containers":[{"name":"airsonic-advanced","image":"linuxserver/airsonic-advanced","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CONTEXT_PATH","default":"<URL_BASE>","description":"For setting url-base in reverse proxy setups."},{"id":"JAVA_OPTS","default":"<options>","description":"For passing additional java options."}],"volumes":[{"container":"/media","description":"Location of other media."},{"container":"/config","description":"Configuration file location.","key":"config"},{"container":"/music","description":"Location of music."},{"container":"/playlists","description":"Location for playlists to be saved to."},{"container":"/podcasts","description":"Location of podcasts."}],"ports":[{"container":"4040","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"airsonic-advanced","project_url":"https://github.com/airsonic-advanced/airsonic-advanced","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/airsonic-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Latest releases of Airsonic-Advanced"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/config>","desc":"Configuration file location."},{"vol_path":"/music","vol_host_path":"</path/to/music>","desc":"Location of music."},{"vol_path":"/playlists","vol_host_path":"</path/to/playlists>","desc":"Location for playlists to be saved to."},{"vol_path":"/podcasts","vol_host_path":"</path/to/podcasts>","desc":"Location of podcasts."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4040","internal_port":"4040","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONTEXT_PATH","env_value":"<URL_BASE>","desc":"For setting url-base in reverse proxy setups."},{"env_var":"JAVA_OPTS","env_value":"<options>","desc":"For passing additional java options."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/media","vol_host_path":"</path/to/other media>","desc":"Location of other media."}],"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/snd","device_host_path":"/dev/snd","desc":"Only needed to pass your host sound device to Airsonic's Java jukebox player."}],"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"\nWe don't formally support upgrading from Airsonic to Airsonic Advanced, it may or may not work for you and we'd recommend making backups before attempting this. Following the upgrade you may experience a forced rescan of your library so take this into account if you have a lot of files.\n\nPlease see notes about upgrading from v10 to v11 [here](https://github.com/airsonic-advanced/airsonic-advanced#usage)\n\nAccess WebUI at `<your-ip>:4040`.\n\nDefault user/pass is admin/admin\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`. For some reverse proxies, you may need to pass `JAVA_OPTS=-Dserver.use-forward-headers=true` for airsonic to generate the proper URL schemes.\n\nNote that if you want to use [Airsonic's Java jukebox player](https://airsonic.github.io/docs/jukebox/), then `PGID` will need to match the group of your sound device (e.g. `/dev/snd`).\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"25.07.22:","desc":"Add vorbis-tools."},{"date":"02.01.22:","desc":"Initial Release."}]}},"setup":"\nWe don't formally support upgrading from Airsonic to Airsonic Advanced, it may or may not work for you and we'd recommend making backups before attempting this. Following the upgrade you may experience a forced rescan of your library so take this into account if you have a lot of files.\n\nPlease see notes about upgrading from v10 to v11 [here](https://github.com/airsonic-advanced/airsonic-advanced#usage)\n\nAccess WebUI at `<your-ip>:4040`.\n\nDefault user/pass is admin/admin\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`. For some reverse proxies, you may need to pass `JAVA_OPTS=-Dserver.use-forward-headers=true` for airsonic to generate the proper URL schemes.\n\nNote that if you want to use [Airsonic's Java jukebox player](https://airsonic.github.io/docs/jukebox/), then `PGID` will need to match the group of your sound device (e.g. `/dev/snd`).\n","_id":"content:apps:airsonic-advanced.json","_type":"json","title":"Airsonic Advanced","_source":"content","_file":"apps/airsonic-advanced.json","_extension":"json"},{"_path":"/apps/apprise-api","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"apprise-api","name":"apprise-api","description":"[{{ project_name|capitalize }}]({{ project_url }}) Takes advantage of [Apprise](https://github.com/caronc/apprise) through your network with a user-friendly API.\n\n* Send notifications to more then 65+ services.\n* An incredibly lightweight gateway to Apprise.\n* A production ready micro-service at your disposal.\n\nApprise API was designed to easily fit into existing (and new) eco-systems that are looking for a simple notification solution.\n","icon":"https://raw.githubusercontent.com/caronc/apprise-api/master/apprise_api/static/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/apprise-api"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-apprise-api"}],"containers":[{"name":"apprise-api","image":"linuxserver/apprise-api","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where config is stored.","key":"config"}],"ports":[{"container":"8000","description":"Port for apprise's interface and API.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"apprise-api","project_url":"https://github.com/caronc/apprise-api","project_logo":"https://raw.githubusercontent.com/caronc/apprise-api/master/apprise_api/static/logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) Takes advantage of [Apprise](https://github.com/caronc/apprise) through your network with a user-friendly API.\n\n* Send notifications to more then 65+ services.\n* An incredibly lightweight gateway to Apprise.\n* A production ready micro-service at your disposal.\n\nApprise API was designed to easily fit into existing (and new) eco-systems that are looking for a simple notification solution.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where config is stored."}],"param_device_map":false,"param_devices":[],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Port for apprise's interface and API."}],"opt_param_usage_include_env":false,"opt_param_env_vars":[],"opt_param_usage_include_vols":false,"opt_param_volumes":[],"opt_param_usage_include_ports":false,"opt_param_ports":[],"opt_param_device_map":false,"opt_param_devices":[],"cap_add_param":false,"cap_add_param_vars":[],"opt_cap_add_param":false,"opt_cap_add_param_vars":[],"optional_block_1":false,"optional_block_1_items":"","privileged":false,"app_setup_block_enabled":false,"app_setup_block":[],"changelogs":[{"date":"17.10.22:","desc":"Rebase to alpine 3.16, migrate to S6V3"},{"date":"28.02.21:","desc":"Rebase to alpine 3.15."},{"date":"03.11.21:","desc":"Increase uWSGI buffer size to 32kb."},{"date":"16.05.21:","desc":"Add linuxserver wheel index."},{"date":"26.02.21:","desc":"Initial Release."}]}},"_id":"content:apps:apprise-api.json","_type":"json","title":"Apprise Api","_source":"content","_file":"apps/apprise-api.json","_extension":"json"},{"_path":"/apps/audacity","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"audacity","name":"audacity","description":"[Audacity]({{ project_url }}) is an easy-to-use, multi-track audio editor and recorder. Developed by a group of volunteers as open source.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/audacity-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/audacity"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-audacity"}],"containers":[{"name":"audacity","image":"linuxserver/audacity","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and images","key":"config"}],"ports":[{"container":"3000","description":"Audacity desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"audacity","project_url":"https://www.audacityteam.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/audacity-logo.png","project_blurb":"[Audacity]({{ project_url }}) is an easy-to-use, multi-track audio editor and recorder. Developed by a group of volunteers as open source.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and images"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Audacity desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"13.12.22:","desc":"Rebase to Jammy."},{"date":"14.09.21:","desc":"Use the official appimage, switch to single arch (x86_64). Armhf and aarch64 users can remain on version 3.0.2 but there won't be further updates."},{"date":"07.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:audacity.json","_type":"json","title":"Audacity","_source":"content","_file":"apps/audacity.json","_extension":"json"},{"_path":"/apps/audiobookshelf","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"audiobookshelf","name":"Audio Book Shelf","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/adguardhome-sync.png","links":[{"type":"docker","url":"https://hub.docker.com/r/advplyr/audiobookshelf"},{"type":"docs","url":"https://audiobookshelf.org/docs"}],"containers":[{"name":"audiobookshelf","image":"advplyr/audiobookshelf","env":[{"id":"AUDIOBOOKSHELF_UID","key":"PUID","description":"User ID","default":"99"},{"id":"AUDIOBOOKSHELF_GID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/audiobooks","description":"Path to your Audiobooks","key":"audiobooks"},{"container":"/podcasts","description":"Path to your Podcasts","key":"podcasts"},{"container":"/metadata","description":"Path to your Metadata"},{"container":"/config","description":"Path to your Config","key":"config"}],"ports":[{"key":"webui","container":80,"description":"Web Interface","protocol":"tcp","web":true}]}],"_id":"content:apps:audiobookshelf.json","_type":"json","title":"Audiobookshelf","_source":"content","_file":"apps/audiobookshelf.json","_extension":"json"},{"_path":"/apps/babybuddy","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"babybuddy","name":"babybuddy","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a buddy for babies! Helps caregivers track sleep, feedings, diaper changes, tummy time and more to learn about and predict baby's needs without (as much) guess work.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/babybuddy-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/babybuddy"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-babybuddy"}],"containers":[{"name":"babybuddy","image":"linuxserver/babybuddy","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"CSRF_TRUSTED_ORIGINS","default":"http://127.0.0.1:8000,https://babybuddy.domain.com","description":"Add any address you'd like to access babybuddy at (comma separated, no spaces)"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration and data.","key":"config"}],"ports":[{"container":"8000","description":"the port for the web ui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"babybuddy","project_url":"https://github.com/babybuddy/babybuddy","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/babybuddy-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a buddy for babies! Helps caregivers track sleep, feedings, diaper changes, tummy time and more to learn about and predict baby's needs without (as much) guess work.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"the port for the web ui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"CSRF_TRUSTED_ORIGINS","env_value":"http://127.0.0.1:8000,https://babybuddy.domain.com","desc":"Add any address you'd like to access babybuddy at (comma separated, no spaces)"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8000` (or whichever host port is mapped in docker arguments). The default user/pass are `admin:admin`.\n\nBy default BabyBuddy uses sqlite3. To use an external database like postgresql or mysql/mariadb instead, you can use the environment variables listed in [BabyBuddy docs](https://github.com/babybuddy/babybuddy#configuration).\n","changelogs":[{"date":"16.01.23:","desc":"Rebase to Alpine 3.17."},{"date":"23.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"28.05.22:","desc":"Add missing PUID/PGID vars to readme."},{"date":"03.04.22:","desc":"Rebase to alpine-nginx baseimage. Add `CSRF_TRUSTED_ORIGINS` env var."},{"date":"11.12.21:","desc":"Add py3-mysqlclient for mysql/mariadb."},{"date":"14.11.21:","desc":"Add lxml dependencies (temp fix for amd64 by force compiling lxml)."},{"date":"25.07.21:","desc":"Add libpq for postgresql."},{"date":"08.07.21:","desc":"Fix pip install issue."},{"date":"05.07.21:","desc":"Update Gunicorn parameters to prevent `WORKER_TIMEOUT` issue."},{"date":"22.06.21:","desc":"Initial release."}]}},"setup":"Access the webui at `<your-ip>:8000` (or whichever host port is mapped in docker arguments). The default user/pass are `admin:admin`.\n\nBy default BabyBuddy uses sqlite3. To use an external database like postgresql or mysql/mariadb instead, you can use the environment variables listed in [BabyBuddy docs](https://github.com/babybuddy/babybuddy#configuration).\n","_id":"content:apps:babybuddy.json","_type":"json","title":"Babybuddy","_source":"content","_file":"apps/babybuddy.json","_extension":"json"},{"_path":"/apps/bazarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"bazarr","name":"bazarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/bazarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/bazarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-bazarr"}],"containers":[{"name":"bazarr","image":"linuxserver/bazarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/movies","description":"Location of your movies"},{"container":"/tv","description":"Location of your TV Shows"},{"container":"/config","description":"Bazarr data","key":"config"}],"ports":[{"container":"6767","description":"Allows HTTP access to the internal webserver.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"bazarr","project_url":"https://www.bazarr.media/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/bazarr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from Bazarr"},{"tag":"development","desc":"Pre-releases from Bazarr"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/bazarr/config","desc":"Bazarr data"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6767","internal_port":"6767","port_desc":"Allows HTTP access to the internal webserver."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/movies","vol_host_path":"/path/to/movies","desc":"Location of your movies"},{"vol_path":"/tv","vol_host_path":"/path/to/tv","desc":"Location of your TV Shows"}],"app_setup_block_enabled":true,"app_setup_block":"- Once running the URL will be `http://<host-ip>:6767`.\n- You must complete all the setup parameters in the webui before you can save the config.\n","changelogs":[{"date":"23.01.23:","desc":"Rebase master branch to Alpine 3.17."},{"date":"11.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"15.15.21:","desc":"Temp fix for lxml, compile from scratch to avoid broken official wheel."},{"date":"25.10.21:","desc":"Rebase to alpine 3.14. Fix numpy wheel."},{"date":"22.10.21:","desc":"Added openblas package to prevent numpy error."},{"date":"16.05.21:","desc":"Use wheel index."},{"date":"19.04.21:","desc":"Install from release zip."},{"date":"07.04.21:","desc":"Move app to /app/bazarr/bin, add `package_info`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"23.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.05.20:","desc":"Add donation links for Bazarr to Github sponsors button and container log."},{"date":"08.04.20:","desc":"Removed /movies and /tv volumes from Dockerfiles."},{"date":"28.12.19:","desc":"Upgrade to Python 3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"12.06.19:","desc":"Swap to install deps using maintainers requirements.txt, add ffmpeg for ffprobe."},{"date":"17.04.19:","desc":"Add default UTC timezone if user does not set it."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.09.18:","desc":"Initial release."}]}},"setup":"- Once running the URL will be `http://<host-ip>:6767`.\n- You must complete all the setup parameters in the webui before you can save the config.\n","_id":"content:apps:bazarr.json","_type":"json","title":"Bazarr","_source":"content","_file":"apps/bazarr.json","_extension":"json"},{"_path":"/apps/beets","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"beets","name":"beets","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/beets-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/beets"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-beets"}],"containers":[{"name":"beets","image":"linuxserver/beets","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/music","description":"Music library"},{"container":"/downloads","description":"Non processed music"}],"ports":[{"container":"8337","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"beets","project_url":"http://beets.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/beets-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Beets Releases"},{"tag":"nightly","desc":"Built against head of Beets git, generally considered unstable but a likely choice for power users of the application."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/music","vol_host_path":"</path/to/music/library>","desc":"Music library"},{"vol_path":"/downloads","vol_host_path":"</path/to/ingest>","desc":"Non processed music"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8337","internal_port":"8337","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Edit the config file in /config\n\nTo edit the config from within the container use `beet config -e`\n\nFor a command prompt as user abc `docker exec -it -u abc beets bash`\n\nSee [Beets](http://beets.io/) for more info.\n\nContains [beets-extrafiles](https://github.com/Holzhaus/beets-extrafiles) plugin, [configuration details](https://github.com/Holzhaus/beets-extrafiles#usage)\n","changelogs":[{"date":"15.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.05.19:","desc":"Add flac and mp3val binaries required for badfiles plugin."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.03.19:","desc":"Swap copyartifacts for extrafiles, update endpoints with nightly tag."},{"date":"01.03.19:","desc":"Switch to python3."},{"date":"07.02.19:","desc":"Add fftw-dev build dependency for chromaprint."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.08.18:","desc":"Rebase to alpine 3.8, use alpine repo version of pylast."},{"date":"12.08.18:","desc":"Add requests pip package."},{"date":"04.03.18:","desc":"Upgrade mp3gain to 1.6.1."},{"date":"02.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"27.12.17:","desc":"Add beautifulsoup4 pip package."},{"date":"06.12.17:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"16.01.17:","desc":"Add packages required for replaygain."},{"date":"24.12.16:","desc":"Add [beets-copyartifacts](https://github.com/sbarakat/beets-copyartifacts) plugin."},{"date":"07.12.16:","desc":"Edit cmake options for chromaprint, should now build and install fpcalc, add gstreamer lib"},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"01.10.16:","desc":"Add nano and editor variable to allow editing of the config from the container command line."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"24.09.16:","desc":"Rebase to alpine linux."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.01.16:","desc":"Change ffpmeg repository, other version crashes container"},{"date":"06.11.15:","desc":"Initial Release"},{"date":"29.11.15:","desc":"Take out term setting, causing issues with key entry for some users"}]}},"setup":"Edit the config file in /config\n\nTo edit the config from within the container use `beet config -e`\n\nFor a command prompt as user abc `docker exec -it -u abc beets bash`\n\nSee [Beets](http://beets.io/) for more info.\n\nContains [beets-extrafiles](https://github.com/Holzhaus/beets-extrafiles) plugin, [configuration details](https://github.com/Holzhaus/beets-extrafiles#usage)\n","_id":"content:apps:beets.json","_type":"json","title":"Beets","_source":"content","_file":"apps/beets.json","_extension":"json"},{"_path":"/apps/blender","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"blender","name":"blender","description":"[Blender]({{ project_url }}) is a free and open-source 3D computer graphics software toolset used for creating animated films, visual effects, art, 3D printed models, motion graphics, interactive 3D applications, virtual reality, and computer games. **This image does not support GPU rendering out of the box only accelerated workspace experience**","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/blender-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/blender"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-blender"}],"containers":[{"name":"blender","image":"linuxserver/blender","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Blender desktop gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"blender","project_url":"https://www.blender.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/blender-logo.png","project_blurb":"[Blender]({{ project_url }}) is a free and open-source 3D computer graphics software toolset used for creating animated films, visual effects, art, 3D printed models, motion graphics, interactive 3D applications, virtual reality, and computer games. **This image does not support GPU rendering out of the box only accelerated workspace experience**","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Blender desktop gui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for hardware acceleration (Linux hosts only)"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, this may be required depending on your Docker and storage configuration."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration\n\nThis only applies to your desktop experience, this container is capable of supporting accelerated rendering with /dev/dri mounted in, but the AMD HIP and Nvidia CUDA runtimes are massive which are not installed by default in this container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nArm devices can run this image, but generally should not mount in /dev/dri. The OpenGL ES version is not high enough to run Blender. The program can run on these platforms though, leveraging CPU LLVMPipe rendering.\n\nDue to lack of arm32/64 binaries from the upstream project, our arm32/64 images install the latest version from the ubuntu repo, which is usually behind and thus the version the image is tagged with does not match the version contained.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"13.12.22:","desc":"Rebase to Jammy, migrate to s6v3."},{"date":"06.05.22:","desc":"Use the full semver version in image tags. Arm32/64 version tags are inaccurate due to installing from ubuntu repo, which is usually behind."},{"date":"12.03.22:","desc":"Initial Release."}]}},"setup":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration\n\nThis only applies to your desktop experience, this container is capable of supporting accelerated rendering with /dev/dri mounted in, but the AMD HIP and Nvidia CUDA runtimes are massive which are not installed by default in this container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nArm devices can run this image, but generally should not mount in /dev/dri. The OpenGL ES version is not high enough to run Blender. The program can run on these platforms though, leveraging CPU LLVMPipe rendering.\n\nDue to lack of arm32/64 binaries from the upstream project, our arm32/64 images install the latest version from the ubuntu repo, which is usually behind and thus the version the image is tagged with does not match the version contained.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","_id":"content:apps:blender.json","_type":"json","title":"Blender","_source":"content","_file":"apps/blender.json","_extension":"json"},{"_path":"/apps/boinc","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"boinc","name":"boinc","description":"[BOINC]({{ project_url }}) is a platform for high-throughput computing on a large scale (thousands or millions of computers). It can be used for volunteer computing (using consumer devices) or grid computing (using organizational resources). It supports virtualized, parallel, and GPU-based applications.","icon":"https://raw.githubusercontent.com/BOINC/boinc/master/doc/logo/boinc_logo_black.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/boinc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-boinc"}],"containers":[{"name":"boinc","image":"linuxserver/boinc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PASSWORD","default":"","description":"Optionally set a password for the gui."}],"volumes":[{"container":"/config","description":"Where BOINC should store its database and config.","key":"config"}],"ports":[{"container":"8080","description":"Boinc desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"boinc","project_url":"https://boinc.berkeley.edu/","project_logo":"https://raw.githubusercontent.com/BOINC/boinc/master/doc/logo/boinc_logo_black.jpg","project_blurb":"[BOINC]({{ project_url }}) is a platform for high-throughput computing on a large scale (thousands or millions of computers). It can be used for volunteer computing (using consumer devices) or grid computing (using organizational resources). It supports virtualized, parallel, and GPU-based applications.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where BOINC should store its database and config."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Boinc desktop gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PASSWORD","env_value":"","desc":"Optionally set a password for the gui."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU (vaapi)."}],"opt_cap_add_param":false,"optional_block_1":false,"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"This image sets up the BOINC client and manager and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n\nIt is recommended to switch to `Advanced View` in the top menu, because the `Computing Preferences` don't seem to be displayed in `Simple View`.\n\nSometimes, the pop-up windows may open in a tiny box in the upper left corner of the screen. When that happens, you can find the corner and resize them.\n\n## GPU Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n```--device=/dev/dri:/dev/dri```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the BOINC docker container.\n","changelogs":[{"date":"14.11.22:","desc":"Fix opencl driver."},{"date":"18.09.22:","desc":"Rebase to jammy."},{"date":"24.02.22:","desc":"Rebase to focal."},{"date":"31.01.22:","desc":"Improve device permissions setting verbosity."},{"date":"23.03.21:","desc":"Rebase to rdesktop-web baseimage. Deprecate `GUAC_USER` and `GUAC_PASS` env vars. Existing users can set the new var `PASSWORD` for the user `abc`."},{"date":"01.04.20:","desc":"Install boinc from ppa."},{"date":"17.03.20:","desc":"Add armhf and aarch64 builds and switch to multi-arch image."},{"date":"16.03.20:","desc":"Clean up old pid files."},{"date":"15.03.20:","desc":"Initial release."}]}},"setup":"This image sets up the BOINC client and manager and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n\nIt is recommended to switch to `Advanced View` in the top menu, because the `Computing Preferences` don't seem to be displayed in `Simple View`.\n\nSometimes, the pop-up windows may open in a tiny box in the upper left corner of the screen. When that happens, you can find the corner and resize them.\n\n## GPU Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n```--device=/dev/dri:/dev/dri```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the BOINC docker container.\n","_id":"content:apps:boinc.json","_type":"json","title":"Boinc","_source":"content","_file":"apps/boinc.json","_extension":"json"},{"_path":"/apps/booksonic-air","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"booksonic-air","name":"booksonic-air","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a platform for accessing the audiobooks you own wherever you are. At the moment the platform consists of:\n* Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic.\n* Booksonic App - An DSub based Android app for connection to Booksonic-Air servers.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/booksonic-air.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/booksonic-air"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-booksonic-air"}],"containers":[{"name":"booksonic-air","image":"linuxserver/booksonic-air","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CONTEXT_PATH","default":"url-base","description":"Base url for use with reverse proxies etc."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/audiobooks","description":"Audiobooks."},{"container":"/podcasts","description":"Podcasts."},{"container":"/othermedia","description":"Other media."}],"ports":[{"container":"4040","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"booksonic-air","project_url":"http://booksonic.org","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/booksonic-air.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a platform for accessing the audiobooks you own wherever you are. At the moment the platform consists of:\n* Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic.\n* Booksonic App - An DSub based Android app for connection to Booksonic-Air servers.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable booksonic-air releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"CONTEXT_PATH","env_value":"url-base","desc":"Base url for use with reverse proxies etc."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/audiobooks","vol_host_path":"</path/to/audiobooks>","desc":"Audiobooks."},{"vol_path":"/podcasts","vol_host_path":"</path/to/podcasts>","desc":"Podcasts."},{"vol_path":"/othermedia","vol_host_path":"</path/to/othermedia>","desc":"Other media."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4040","internal_port":"4040","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Whilst this is a more up to date rebase of the original Booksonic server, upgrading in place is not supported and a fresh install has been recommended. Default user/pass is admin/admin","changelogs":[{"date":"18.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"15.09.20:","desc":"Initial Release."}]}},"setup":"Whilst this is a more up to date rebase of the original Booksonic server, upgrading in place is not supported and a fresh install has been recommended. Default user/pass is admin/admin","_id":"content:apps:booksonic-air.json","_type":"json","title":"Booksonic Air","_source":"content","_file":"apps/booksonic-air.json","_extension":"json"},{"_path":"/apps/bookstack","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"bookstack","name":"bookstack","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free and open source Wiki designed for creating beautiful documentation. Featuring a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease.\n\nPowered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore.\n\nFor more information on BookStack visit their website and check it out: https://www.bookstackapp.com\n","icon":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/bookstack-logo500x500.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/bookstack"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-bookstack"}],"containers":[{"name":"bookstack","image":"linuxserver/bookstack","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"APP_URL","default":"","description":"for specifying the IP:port or URL your application will be accessed on (ie. `http://192.168.1.1:6875` or `https://bookstack.mydomain.com`"},{"id":"DB_HOST","default":"<yourdbhost>","description":"for specifying the database host"},{"id":"DB_PORT","default":"<yourdbport>","description":"for specifying the database port if not default 3306"},{"id":"DB_USER","default":"<yourdbuser>","description":"for specifying the database user"},{"id":"DB_PASS","default":"<yourdbpass>","description":"for specifying the database password (non-alphanumeric passwords must be properly escaped.)"},{"id":"DB_DATABASE","default":"bookstackapp","description":"for specifying the database to be used"}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"}],"ports":[{"container":"80","description":"will map the container's port 80 to port 6875 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"bookstack","project_url":"https://github.com/BookStackApp/BookStack","project_logo":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/bookstack-logo500x500.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free and open source Wiki designed for creating beautiful documentation. Featuring a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease.\n\nPowered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore.\n\nFor more information on BookStack visit their website and check it out: https://www.bookstackapp.com\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"APP_URL","env_value":"","desc":"for specifying the IP:port or URL your application will be accessed on (ie. `http://192.168.1.1:6875` or `https://bookstack.mydomain.com`"},{"env_var":"DB_HOST","env_value":"<yourdbhost>","desc":"for specifying the database host"},{"env_var":"DB_PORT","env_value":"<yourdbport>","desc":"for specifying the database port if not default 3306"},{"env_var":"DB_USER","env_value":"<yourdbuser>","desc":"for specifying the database user"},{"env_var":"DB_PASS","env_value":"<yourdbpass>","desc":"for specifying the database password (non-alphanumeric passwords must be properly escaped.)"},{"env_var":"DB_DATABASE","env_value":"bookstackapp","desc":"for specifying the database to be used"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6875","internal_port":"80","port_desc":"will map the container's port 80 to port 6875 on the host"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"custom_compose":"---\nversion: \"2\"\nservices:\n  bookstack:\n    image: lscr.io/linuxserver/bookstack\n    container_name: bookstack\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - APP_URL=\n      - DB_HOST=bookstack_db\n      - DB_PORT=3306\n      - DB_USER=bookstack\n      - DB_PASS=<yourdbpass>\n      - DB_DATABASE=bookstackapp\n    volumes:\n      - /path/to/data:/config\n    ports:\n      - 6875:80\n    restart: unless-stopped\n    depends_on:\n      - bookstack_db\n  bookstack_db:\n    image: lscr.io/linuxserver/mariadb\n    container_name: bookstack_db\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - MYSQL_ROOT_PASSWORD=<yourdbpass>\n      - TZ=Europe/London\n      - MYSQL_DATABASE=bookstackapp\n      - MYSQL_USER=bookstack\n      - MYSQL_PASSWORD=<yourdbpass>\n    volumes:\n      - /path/to/data:/config\n    restart: unless-stopped\n","app_setup_block_enabled":true,"app_setup_block":"\nThe default username is admin@admin.com with the password of **password**, access the container at http://dockerhost:6875.\n\nThis application is dependent on a MySQL database be it one you already have or a new one. If you do not already have one, set up our MariaDB container here https://hub.docker.com/r/linuxserver/mariadb/.\n\n\nIf you intend to use this application behind a subfolder reverse proxy, such as our SWAG container or Traefik you will need to make sure that the `APP_URL` environment variable is set to your external domain, or it will not work\n\nDocumentation for BookStack can be found at https://www.bookstackapp.com/docs/\n\n### Advanced Users (full control over the .env file)\nIf you wish to use the extra functionality of BookStack such as email, Memcache, LDAP and so on you will need to make your own .env file with guidance from the BookStack documentation.\n  \nWhen you create the container, do not set any arguments for any SQL settings. The container will copy an exemplary .env file to /config/www/.env on your host system for you to edit.\n\n#### PDF Rendering\n[wkhtmltopdf](https://wkhtmltopdf.org/) is available to use as an alternative PDF rendering generator as described at https://www.bookstackapp.com/docs/admin/pdf-rendering/.\n\nThe path to wkhtmltopdf in this image to include in your .env file is `/usr/bin/wkhtmltopdf`.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"16.01.23:","desc":"Wrap `.env` values in quotes."},{"date":"05.01.23:","desc":"Fix db password setting (sed escape `&`)."},{"date":"21.12.22:","desc":"Update db info in .env file when env vars are updated."},{"date":"10.10.22:","desc":"Remove password escape logic which caused problems for a small subset of users."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"14.03.22:","desc":"Add symlinks for theme support."},{"date":"11.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"12.01.21:","desc":"Remove unused requirement, as of release 0.31.0."},{"date":"17.12.20:","desc":"Make APP_URL var required (upstream changes)."},{"date":"17.09.20:","desc":"Rebase to alpine 3.12. Fix APP_URL setting. Bump php post max and upload max filesizes to 100MB by default."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"26.07.19:","desc":"Use old version of tidyhtml pending upstream fixes."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"14.06.19:","desc":"Add wkhtmltopdf to image for PDF rendering."},{"date":"20.04.19:","desc":"Rebase to Alpine 3.9, add MySQL init logic."},{"date":"22.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"20.01.19:","desc":"Added php7-curl"},{"date":"04.11.18:","desc":"Added php7-ldap"},{"date":"15.10.18:","desc":"Changed functionality for advanced users"},{"date":"08.10.18:","desc":"Advanced mode, symlink changes, sed fixing, docs updated, added some composer files"},{"date":"23.09.28:","desc":"Updates pre-release"},{"date":"02.07.18:","desc":"Initial Release."}]}},"setup":"\nThe default username is admin@admin.com with the password of **password**, access the container at http://dockerhost:6875.\n\nThis application is dependent on a MySQL database be it one you already have or a new one. If you do not already have one, set up our MariaDB container here https://hub.docker.com/r/linuxserver/mariadb/.\n\n\nIf you intend to use this application behind a subfolder reverse proxy, such as our SWAG container or Traefik you will need to make sure that the `APP_URL` environment variable is set to your external domain, or it will not work\n\nDocumentation for BookStack can be found at https://www.bookstackapp.com/docs/\n\n### Advanced Users (full control over the .env file)\nIf you wish to use the extra functionality of BookStack such as email, Memcache, LDAP and so on you will need to make your own .env file with guidance from the BookStack documentation.\n  \nWhen you create the container, do not set any arguments for any SQL settings. The container will copy an exemplary .env file to /config/www/.env on your host system for you to edit.\n\n#### PDF Rendering\n[wkhtmltopdf](https://wkhtmltopdf.org/) is available to use as an alternative PDF rendering generator as described at https://www.bookstackapp.com/docs/admin/pdf-rendering/.\n\nThe path to wkhtmltopdf in this image to include in your .env file is `/usr/bin/wkhtmltopdf`.\n","_id":"content:apps:bookstack.json","_type":"json","title":"Bookstack","_source":"content","_file":"apps/bookstack.json","_extension":"json"},{"_path":"/apps/budge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"budge","name":"budge","description":"[{{ project_name }}]({{ project_url }}) is an open source 'budgeting with envelopes' personal finance app.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/budge.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/budge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-budge"}],"containers":[{"name":"budge","image":"linuxserver/budge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Persistent config files","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"budge","project_url":"https://github.com/linuxserver/budge","project_logo":"","project_blurb":"[{{ project_name }}]({{ project_url }}) is an open source 'budgeting with envelopes' personal finance app.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/{{ project_name }}/config","desc":"Persistent config files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"app_setup_block_enabled":true,"app_setup_block":"Access the web gui at http://SERVERIP:PORT\n","changelogs":[{"date":"29.11.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"04.15.22:","desc":"Added NPM command to run db migrations."},{"date":"02.05.22:","desc":"Initial Release."}]}},"setup":"Access the web gui at http://SERVERIP:PORT\n","_id":"content:apps:budge.json","_type":"json","title":"Budge","_source":"content","_file":"apps/budge.json","_extension":"json"},{"_path":"/apps/calibre-web","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"calibre-web","name":"calibre-web","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database.   It is also possible to integrate google drive and edit metadata and your calibre library through the app itself.\n\nThis software is a fork of library and licensed under the GPL v3 License.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/calibre-web-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/calibre-web"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-calibre-web"}],"containers":[{"name":"calibre-web","image":"linuxserver/calibre-web","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"DOCKER_MODS","default":"linuxserver/mods:universal-calibre","description":"#optional & **x86-64 only** Adds the ability to perform ebook conversion"},{"id":"OAUTHLIB_RELAX_TOKEN_SCOPE","default":"1","description":"Optionally set this to allow Google OAUTH to work"}],"volumes":[{"container":"/config","description":"Where calibre-web stores the internal database and config.","key":"config"},{"container":"/books","description":"Where your preexisting calibre database is located."}],"ports":[{"container":"8083","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"calibre-web","project_url":"https://github.com/janeczku/calibre-web","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/calibre-web-icon.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database.   It is also possible to integrate google drive and edit metadata and your calibre library through the app itself.\n\nThis software is a fork of library and licensed under the GPL v3 License.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Releases of Calibre-Web"},{"tag":"nightly","desc":"Commits to the master branch of Calibre-Web"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where calibre-web stores the internal database and config."},{"vol_path":"/books","vol_host_path":"/path/to/calibre/library","desc":"Where your preexisting calibre database is located."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8083","internal_port":"8083","port_desc":"WebUI"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_MODS","env_value":"linuxserver/mods:universal-calibre","desc":"#optional & **x86-64 only** Adds the ability to perform ebook conversion"},{"env_var":"OAUTHLIB_RELAX_TOKEN_SCOPE","env_value":"1","desc":"Optionally set this to allow Google OAUTH to work"}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://your-ip:8083`\n\nOn the initial setup screen, enter `/books` as your calibre library location.\n\n**Default admin login:**\n*Username:* admin\n*Password:* admin123\n\nUnrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of `/usr/bin/unrar`\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable ebook conversion utilising Calibre, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as shown in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Calibre E-Book Converter** to `/usr/bin/ebook-convert`\n\nThis image contains the [kepubify](https://pgaskin.net/kepubify/) ebook conversion tool (MIT License) to convert epub to kepub.  In the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Kepubify E-Book Converter** to `/usr/bin/kepubify`\n","changelogs":[{"date":"27.12.22:","desc":"Add ghostscript, libxtst6, libxkbfile-dev."},{"date":"20.12.22:","desc":"Improve init script and prevent harmless error."},{"date":"19.10.22:","desc":"Rebase to jammy. Upgrade to s6v3. Clean up build dependencies."},{"date":"04.11.21:","desc":"Update pip arguments to ignore distro installed packages."},{"date":"24.06.21:","desc":"Add note on optional OAUTHLIB_RELAX_TOKEN_SCOPE for Google OAUTH support."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"10.02.21:","desc":"Add libxrandr2"},{"date":"25.01.21:","desc":"Add nightly tag"},{"date":"19.01.21:","desc":"Add python3-pkg-resources"},{"date":"13.01.21:","desc":"Rebase to Ubuntu Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"12.10.20:","desc":"Add libxi6"},{"date":"12.07.20:","desc":"Add kepubify for arm64v8"},{"date":"05.06.20:","desc":"Add kepubify for x86-64 and arm32v7"},{"date":"06.05.20:","desc":"Add libxslt1.1 and update ImageMagick policy"},{"date":"19.01.20:","desc":"Adding LDAP libs."},{"date":"13.10.19:","desc":"Migrate to Python3."},{"date":"01.08.19:","desc":"Add libxcomposite1."},{"date":"13.06.19:","desc":"Add docker mod to enable optional ebook conversion on x86-64.  Add unrar."},{"date":"02.06.19:","desc":"Rebase to Ubuntu Bionic & add Gdrive support."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"23.02.19:","desc":"Rebase to alpine 3.9, use repo version of imagemagick."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"03.01.19:","desc":"Remove guest user from default app.db."},{"date":"16.08.18:","desc":"Rebase to alpine 3.8."},{"date":"03.07.18:","desc":"New build pushed, all versions below `67` have [vulnerability](https://github.com/janeczku/calibre-web/issues/534)."},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"06.12.17:","desc":"Rebase to alpine 3.7."},{"date":"27.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"24.07.17:","desc":"Curl version for imagemagick."},{"date":"17.07.17:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://your-ip:8083`\n\nOn the initial setup screen, enter `/books` as your calibre library location.\n\n**Default admin login:**\n*Username:* admin\n*Password:* admin123\n\nUnrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of `/usr/bin/unrar`\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable ebook conversion utilising Calibre, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as shown in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Calibre E-Book Converter** to `/usr/bin/ebook-convert`\n\nThis image contains the [kepubify](https://pgaskin.net/kepubify/) ebook conversion tool (MIT License) to convert epub to kepub.  In the Calibre-Web admin page (Basic Configuration:External Binaries) set the **Path to Kepubify E-Book Converter** to `/usr/bin/kepubify`\n","_id":"content:apps:calibre-web.json","_type":"json","title":"Calibre Web","_source":"content","_file":"apps/calibre-web.json","_extension":"json"},{"_path":"/apps/calibre","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"calibre","name":"calibre","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a powerful and easy to use e-book manager. Users say its outstanding and a must-have. Itll allow you to do nearly everything and it takes things a step beyond normal e-book software. Its also completely free and open source and great for both casual users and computer experts.","icon":"https://github.com/kovidgoyal/calibre/raw/master/resources/images/lt.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/calibre"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-calibre"}],"containers":[{"name":"calibre","image":"linuxserver/calibre","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PASSWORD","default":"","description":"Optionally set a password for the gui."},{"id":"CLI_ARGS","default":"","description":"Optionally pass cli start arguments to calibre."}],"volumes":[{"container":"/config","description":"Where calibre should store its database and library.","key":"config"}],"ports":[{"container":"8080","description":"Calibre desktop gui.","protocol":"tcp","web":false},{"container":"8081","description":"Calibre webserver gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"calibre","project_url":"https://calibre-ebook.com/","project_logo":"https://github.com/kovidgoyal/calibre/raw/master/resources/images/lt.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a powerful and easy to use e-book manager. Users say its outstanding and a must-have. Itll allow you to do nearly everything and it takes things a step beyond normal e-book software. Its also completely free and open source and great for both casual users and computer experts.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-<version tag>"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-<version tag>"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where calibre should store its database and library."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Calibre desktop gui."},{"external_port":"8081","internal_port":"8081","port_desc":"Calibre webserver gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PASSWORD","env_value":"","desc":"Optionally set a password for the gui."},{"env_var":"CLI_ARGS","env_value":"","desc":"Optionally pass cli start arguments to calibre."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"This image sets up the calibre desktop app and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nPort 8081 is reserved for Calibre's built-in webserver, which can be enabled within the desktop app settings, and the internal port must be set to `8081` although it will then be available at the host mapped port for external access.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n","changelogs":[{"date":"19.10.22:","desc":"Set the window title to `Calibre`. Remove websocat as it is now handled properly in the baseimage."},{"date":"18.10.22:","desc":"Deprecate Arch branch."},{"date":"07.10.22:","desc":"Start calibre window maximized."},{"date":"16.09.22:","desc":"Rebase to jammy."},{"date":"24.07.22:","desc":"Add arm64 build for master branch."},{"date":"11.07.22:","desc":"Update dependencies for Calibre 6."},{"date":"28.05.22:","desc":"Rebase to focal."},{"date":"31.03.22:","desc":"Fix umask."},{"date":"28.02.22:","desc":"Add speech support to bionic image."},{"date":"05.01.22:","desc":"Add arch branch for arm platforms."},{"date":"20.04.21:","desc":"Fix the HOME folder."},{"date":"19.04.21:","desc":"Add libnss3 back in. Make sure Calibre can access environment variables."},{"date":"18.04.21:","desc":"Start calibre on container start rather than gui connect."},{"date":"15.04.21:","desc":"Rebase to rdesktop-web baseimage. Deprecate `GUAC_USER` and `GUAC_PASS` env vars. Existing users can set the new var `PASSWORD` for the user `abc`."},{"date":"25.09.20:","desc":"Switch to python3, add various new dependencies for calibre 5.0."},{"date":"10.05.19:","desc":"Add new env var `CLI_ARGS` to pass start arguments to calibre."},{"date":"18.03.19:","desc":"Let Calibre access environment variables, add optional umask setting."},{"date":"23.10.19:","desc":"Remove reccomended deps and zenity for character compatibility."},{"date":"18.10.19:","desc":"Add python-xdg."},{"date":"08.10.19:","desc":"Add fonts-wqy-microhei ttf-wqy-zenhei fcitx-rime dependency to resolve issue with Chinese encoding."},{"date":"04.10.19:","desc":"Add libxkbcommon-x11-0 dependency to resolve issue with Calibre 4."},{"date":"08.08.19:","desc":"Add zenity for international character support in dialog boxes."},{"date":"12.07.19:","desc":"Download binary from calibre website instead of github."},{"date":"29.04.19:","desc":"Initial release."}]}},"setup":"This image sets up the calibre desktop app and makes its interface available via Guacamole server in the browser. The interface is available at `http://your-ip:8080`.\n\nBy default, there is no password set for the main gui. Optional environment variable `PASSWORD` will allow setting a password for the user `abc`.\n\nPort 8081 is reserved for Calibre's built-in webserver, which can be enabled within the desktop app settings, and the internal port must be set to `8081` although it will then be available at the host mapped port for external access.\n\nYou can access advanced features of the Guacamole remote desktop using `ctrl`+`alt`+`shift` enabling you to use remote copy/paste and different languages.\n","_id":"content:apps:calibre.json","_type":"json","title":"Calibre","_source":"content","_file":"apps/calibre.json","_extension":"json"},{"_path":"/apps/changedetection.io","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"changedetection.io","name":"changedetection.io","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides free, open-source web page monitoring, notification and change detection.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/changedetection-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/changedetection.io"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-changedetection.io"}],"containers":[{"name":"changedetection.io","image":"linuxserver/changedetection.io","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"","description":"Specify the full URL (including protocol) when running behind a reverse proxy"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"5000","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"changedetection.io","project_url":"https://github.com/dgtlmoon/changedetection.io","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/changedetection-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides free, open-source web page monitoring, notification and change detection.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5000","internal_port":"5000","port_desc":"WebUI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"","desc":"Specify the full URL (including protocol) when running behind a reverse proxy"}],"custom_compose":"---\nversion: \"2.1\"\nservices:\n  changedetection:\n    image: lscr.io/linuxserver/changedetection.io:latest\n    container_name: changedetection\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/London\n      - BASE_URL= #optional\n    volumes:\n      - /path/to/appdata/config:/config\n    ports:\n      - 5000:5000\n    restart: unless-stopped\n","app_setup_block_enabled":true,"app_setup_block":"Webui is accessible at http://SERVERIP:PORT\n\nPlease note that this image does not contain the [Playwright content fetcher](https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher#docker-compose-based) due to a lack of support for muslc-based systems. If you require this feature please use [Selenium](https://github.com/linuxserver/docker-changedetection.io/issues/3#issuecomment-1250251715) or the [official container](https://github.com/dgtlmoon/changedetection.io#docker)\n\nFor more info read [the wiki](https://github.com/dgtlmoon/changedetection.io/wiki).\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"09.10.22:","desc":"Add make as build dep to fix pip jq build on armhf."},{"date":"07.08.22:","desc":"Initial release."}]}},"setup":"Webui is accessible at http://SERVERIP:PORT\n\nPlease note that this image does not contain the [Playwright content fetcher](https://github.com/dgtlmoon/changedetection.io/wiki/Playwright-content-fetcher#docker-compose-based) due to a lack of support for muslc-based systems. If you require this feature please use [Selenium](https://github.com/linuxserver/docker-changedetection.io/issues/3#issuecomment-1250251715) or the [official container](https://github.com/dgtlmoon/changedetection.io#docker)\n\nFor more info read [the wiki](https://github.com/dgtlmoon/changedetection.io/wiki).\n","_id":"content:apps:changedetection.io.json","_type":"json","title":"ChangedetectionIo","_source":"content","_file":"apps/changedetection.io.json","_extension":"json"},{"_path":"/apps/code-server","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"code-server","name":"code-server","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/codeserver.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/code-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-code-server"}],"containers":[{"name":"code-server","image":"linuxserver/code-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"param_usage_include_ports":false,"param_usage_include_vols":false,"param_usage_include_env":false,"param_volumes":[],"param_ports":[],"param_env_vars":[]}},"_id":"content:apps:code-server.json","_type":"json","title":"Code Server","_source":"content","_file":"apps/code-server.json","_extension":"json"},{"_path":"/apps/cops","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"cops","name":"cops","description":"[{{ project_name|capitalize }}]({{ project_url }}) by Sbastien Lucas, stands for Calibre OPDS (and HTML) Php Server.\n\nCOPS links to your Calibre library database and allows downloading and emailing of books directly from a web browser and provides a OPDS feed to connect to your devices.\n\nChanges in your Calibre library are reflected immediately in your COPS pages.\n\nSee : [COPS's home]({{ project_url }}) for more details.\n\nDon't forget to check the [Wiki](https://github.com/seblucas/cops/wiki).\n\n## Why? (taken from the author's site)\n\nIn my opinion Calibre is a marvelous tool but is too big and has too much\ndependencies to be used for its content server.\n\nThat's the main reason why I coded this OPDS server. I needed a simple\ntool to be installed on a small server (Seagate Dockstar in my case).\n\nI initially thought of Calibre2OPDS but as it generate static file no\nsearch was possible.\n\nLater I added an simple HTML catalog that should be usable on my Kobo.\n\nSo COPS's main advantages are :\n * No need for many dependencies.\n * No need for a lot of CPU or RAM.\n * Not much code.\n * Search is available.\n * With Dropbox / owncloud it's very easy to have an up to date OPDS server.\n * It was fun to code.\n\nIf you want to use the OPDS feed don't forget to specify feed.php at the end of your URL.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/cops-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/cops"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-cops"}],"containers":[{"name":"cops","image":"linuxserver/cops","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"COPS Application Data.","key":"config"},{"container":"/books","description":"Calibre metadata.db location."}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"cops","project_url":"http://blog.slucas.fr/en/oss/calibre-opds-php-server","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/cops-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) by Sbastien Lucas, stands for Calibre OPDS (and HTML) Php Server.\n\nCOPS links to your Calibre library database and allows downloading and emailing of books directly from a web browser and provides a OPDS feed to connect to your devices.\n\nChanges in your Calibre library are reflected immediately in your COPS pages.\n\nSee : [COPS's home]({{ project_url }}) for more details.\n\nDon't forget to check the [Wiki](https://github.com/seblucas/cops/wiki).\n\n## Why? (taken from the author's site)\n\nIn my opinion Calibre is a marvelous tool but is too big and has too much\ndependencies to be used for its content server.\n\nThat's the main reason why I coded this OPDS server. I needed a simple\ntool to be installed on a small server (Seagate Dockstar in my case).\n\nI initially thought of Calibre2OPDS but as it generate static file no\nsearch was possible.\n\nLater I added an simple HTML catalog that should be usable on my Kobo.\n\nSo COPS's main advantages are :\n * No need for many dependencies.\n * No need for a lot of CPU or RAM.\n * Not much code.\n * Search is available.\n * With Dropbox / owncloud it's very easy to have an up to date OPDS server.\n * It was fun to code.\n\nIf you want to use the OPDS feed don't forget to specify feed.php at the end of your URL.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"COPS Application Data."},{"vol_path":"/books","vol_host_path":"<path to data>","desc":"Calibre metadata.db location."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<docker host ip>:80`. For connecting via OPDS on a mobile device use `http://<docker host ip>:80/feed.php`. It is strongly suggested that you reverse proxy this prior to exposing to the internet. For more information, such as requiring credentials, check the COPS Wiki (linked above).\n\nThe linuxserver version gives you access to `config_local.php` in `/config` to customise your install to suit your needs, it also includes the dependencies required to directly view epub books in your browser.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.11.20:","desc":"Pin composer version to 1.10.17."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"27.02.19:","desc":"Upgrade packages during install to prevent mismatch with baseimage."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Add multiarch and pipeline logic."},{"date":"21.08.18:","desc":"Rebase to alpine 3.8."},{"date":"02.07.18:","desc":"Add php7-ctype dependency."},{"date":"08.01.18:","desc":"Rebase to alpine 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.04.17:","desc":"Add composer packages, reduce layers."},{"date":"02.04.17:","desc":"Updated to version 1.1.0."},{"date":"05.02.17:","desc":"Updated to Alpine 3.5 & PHP7."},{"date":"24.10.16:","desc":"Updated to implement user based config."},{"date":"24.10.16:","desc":"Updated to version 1.0.1."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"28.09.16:","desc":"Add php5-zlib."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"29.08.16:","desc":"Add php5-opcache."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"12.08.16:","desc":"Initial Release."}]}},"setup":"Access the webui at `http://<docker host ip>:80`. For connecting via OPDS on a mobile device use `http://<docker host ip>:80/feed.php`. It is strongly suggested that you reverse proxy this prior to exposing to the internet. For more information, such as requiring credentials, check the COPS Wiki (linked above).\n\nThe linuxserver version gives you access to `config_local.php` in `/config` to customise your install to suit your needs, it also includes the dependencies required to directly view epub books in your browser.\n","_id":"content:apps:cops.json","_type":"json","title":"Cops","_source":"content","_file":"apps/cops.json","_extension":"json"},{"_path":"/apps/daapd","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"daapd","name":"daapd","description":"[{{ project_name|capitalize }}]({{ project_url }}) (iTunes) media server with support for AirPlay devices, Apple Remote (and compatibles), Chromecast, MPD and internet radio.","icon":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/daapd-git.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/daapd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-daapd"}],"containers":[{"name":"daapd","image":"linuxserver/daapd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where daapd server stores its config and dbase files.","key":"config"},{"container":"/music","description":"Map to your music folder."}]}],"meta":{"readme-vars":{"project_name":"daapd","project_url":"https://owntone.github.io/owntone-server/","project_logo":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/daapd-git.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (iTunes) media server with support for AirPlay devices, Apple Remote (and compatibles), Chromecast, MPD and internet radio.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where daapd server stores its config and dbase files."},{"vol_path":"/music","vol_host_path":"<path to music>","desc":"Map to your music folder."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Map your music folder, open up itunes on the same LAN to see your music there.\n\nThe web interface is available at `http://<your ip>:3689`\n\nFor further setup options of remotes etc, check out the daapd website, [Owntone]({{ project_url }}).\n\n## Enable spotify connect server\n\nEnable the spotify connect server by creating a pipe named 'spotify' in the root of your mounted music folder (not possible on most network mounts):\n\n```sh\nmkfifo <music_folder>/spotify\n```\n\nThe spotify connect server should show up as the 'forked-daapd' device in your Spotify application.\n\nIt is recommended to set the `pipe_autostart` option to `true` in your forked-daapd config.\n","changelogs":[{"date":"31.05.22:","desc":"Make sure the user has access to the audio device."},{"date":"31.05.22:","desc":"Add new deps, flex and bison."},{"date":"12.02.22:","desc":"Rebase to Alpine 3.15."},{"date":"14.09.21:","desc":"Enabled librespot. Disabled spotify on ARMv7"},{"date":"10.07.21:","desc":"Change of paths to work with the new package name, OwnTone."},{"date":"02.04.21:","desc":"Update upstream repo, again."},{"date":"30.03.21:","desc":"Update upstream repo."},{"date":"06.10.20:","desc":"Enabled Spotify on Alpine 3.12 for X86_64 and ARMv7."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"16.01.20:","desc":"Rebase to alpine linux 3.11 and build antlr3c from source."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"20.08.18:","desc":"Rebase to alpine linux 3.8."},{"date":"09.06.18:","desc":"Use buildstage and update dependencies."},{"date":"05.03.18:","desc":"Use updated configure ac and disable avcodecsend to hopefully mitigate crashes with V26."},{"date":"25.02.18:","desc":"Query version before pull and build latest release."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"07.12.17:","desc":"Rebase to alpine linux 3.7."},{"date":"03.12.17:","desc":"Bump to 25.0, cpu core counting routine for faster builds, linting fixes."},{"date":"26.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"10.01.17:","desc":"Bump to 24.2."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"17.09.16:","desc":"Rebase to alpine linux, remove redundant spotify support, move to main repository."},{"date":"28.02.16:","desc":"Add chromecast support, bump dependency versions."},{"date":"04.01.16:","desc":"Disable ipv6 by default because in v23.4 it doesn't work in unraid with it set."},{"date":"17.12.15:","desc":"Add in spotify support."},{"date":"25.11.15:","desc":"Initial Release."}]}},"setup":"Map your music folder, open up itunes on the same LAN to see your music there.\n\nThe web interface is available at `http://<your ip>:3689`\n\nFor further setup options of remotes etc, check out the daapd website, [Owntone]({{ project_url }}).\n\n## Enable spotify connect server\n\nEnable the spotify connect server by creating a pipe named 'spotify' in the root of your mounted music folder (not possible on most network mounts):\n\n```sh\nmkfifo <music_folder>/spotify\n```\n\nThe spotify connect server should show up as the 'forked-daapd' device in your Spotify application.\n\nIt is recommended to set the `pipe_autostart` option to `true` in your forked-daapd config.\n","_id":"content:apps:daapd.json","_type":"json","title":"Daapd","_source":"content","_file":"apps/daapd.json","_extension":"json"},{"_path":"/apps/darktable","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"darktable","name":"darktable","description":"[darktable]({{ project_url }}) is an open source photography workflow application and raw developer. A virtual lighttable and darkroom for photographers. It manages your digital negatives in a database, lets you view them through a zoomable lighttable and enables you to develop raw images and enhance them.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/darktable-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/darktable"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-darktable"}],"containers":[{"name":"darktable","image":"linuxserver/darktable","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and images","key":"config"}],"ports":[{"container":"3000","description":"Darktable desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"darktable","project_url":"https://www.darktable.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/darktable-logo.png","project_blurb":"[darktable]({{ project_url }}) is an open source photography workflow application and raw developer. A virtual lighttable and darkroom for photographers. It manages your digital negatives in a database, lets you view them through a zoomable lighttable and enables you to develop raw images and enhance them.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and images"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Darktable desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"31.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"01.10.21:","desc":"Rebase to Alpine 3.14."},{"date":"07.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:darktable.json","_type":"json","title":"Darktable","_source":"content","_file":"apps/darktable.json","_extension":"json"},{"_path":"/apps/davos","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"davos","name":"davos","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an FTP automation tool that periodically scans given host locations for new files. It can be configured for various purposes, including listening for specific files to appear in the host location, ready for it to download and then move, if required. It also supports completion notifications as well as downstream API calls, to further the workflow.\n","icon":"https://raw.githubusercontent.com/linuxserver/davos/master/docs/list.PNG","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/davos"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-davos"}],"containers":[{"name":"davos","image":"linuxserver/davos","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/config","description":"davos's config location. This is where it stores its database file and logs.","key":"config"},{"container":"/download","description":"davos's file download location"}],"ports":[{"container":"8080","description":"This is the default port that davos runs under","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"davos","project_url":"https://github.com/linuxserver/davos","project_logo":"https://raw.githubusercontent.com/linuxserver/davos/master/docs/list.PNG","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an FTP automation tool that periodically scans given host locations for new files. It can be configured for various purposes, including listening for specific files to appear in the host location, ready for it to download and then move, if required. It also supports completion notifications as well as downstream API calls, to further the workflow.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"davos's config location. This is where it stores its database file and logs."},{"vol_path":"/download","vol_host_path":"<path to downloads folder>","desc":"davos's file download location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"This is the default port that davos runs under"}],"app_setup_block_enabled":true,"app_setup_block":"The application does not require any set up other than starting the docker container. Further documentation can be found on the [davos GitHub repository page](https://github.com/linuxserver/davos).\n","changelogs":[{"date":"15.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.03.19:","desc":"Updating runtime deps due to change in OpenJRE."},{"date":"08.03.19:","desc":"Updating build environment to pass proper build flags and use gradle wrapper."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.11.16:","desc":"Initial Release."}]}},"setup":"The application does not require any set up other than starting the docker container. Further documentation can be found on the [davos GitHub repository page](https://github.com/linuxserver/davos).\n","_id":"content:apps:davos.json","_type":"json","title":"Davos","_source":"content","_file":"apps/davos.json","_extension":"json"},{"_path":"/apps/ddclient","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ddclient","name":"ddclient","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Perl client used to update dynamic DNS entries for accounts on Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ddclient-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ddclient"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ddclient"}],"containers":[{"name":"ddclient","image":"linuxserver/ddclient","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where ddclient should store its config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"ddclient","project_url":"https://github.com/ddclient/ddclient","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ddclient-logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Perl client used to update dynamic DNS entries for accounts on Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways.","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where ddclient should store its config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Edit the `ddclient.conf` file found in your `/config` volume (also see official [ddclient documentation](https://ddclient.net)). This config file has many providers to choose from and you basically just have to uncomment your provider and add username/password where requested. If you modify ddclient.conf, ddclient will automaticcaly restart and read the config.\n\n### Get dynamic IP from Fritz.Box\nIf ddclient shall fetch the dynamic (public) IP-address from a fritz.box (AVM) add the following line to `/config/ddclient.conf`:\n````\nuse=cmd, cmd=/etc/ddclient/get-ip-from-fritzbox\n````\n","changelogs":[{"date":"20.10.22:","desc":"Update build instructions for 3.10.0. Update default `ddclient.conf`."},{"date":"15.01.22:","desc":"Rebase to Alpine 3.15"},{"date":"15.05.21:","desc":"Distribute script 'sample-get-ip-from-fritzbox' from ddclient repo"},{"date":"08.03.21:","desc":"Added bind-tools to provide nsupdate"},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"08.02.20:","desc":"Ingest from Github."},{"date":"06.02.19:","desc":"Fix permissions."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.03.19:","desc":"Add perl-io-socket-inet6 for ipv6 support."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"22.08.18:","desc":"Rebase to alpine 3.8."},{"date":"10.08.18:","desc":"Update to ddclient v3.9.0. For Cloudflare users, please ensure you remove the line `server=www.cloudflare.com` from your `ddclient.conf`."},{"date":"07.12.17:","desc":"Rebase to alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"10.02.17:","desc":"Rebase to alpine 3.5."},{"date":"26.11.16:","desc":"Update README to new standard and add icon and other small details."},{"date":"29.08.16:","desc":"Initial release."}]}},"setup":"Edit the `ddclient.conf` file found in your `/config` volume (also see official [ddclient documentation](https://ddclient.net)). This config file has many providers to choose from and you basically just have to uncomment your provider and add username/password where requested. If you modify ddclient.conf, ddclient will automaticcaly restart and read the config.\n\n### Get dynamic IP from Fritz.Box\nIf ddclient shall fetch the dynamic (public) IP-address from a fritz.box (AVM) add the following line to `/config/ddclient.conf`:\n````\nuse=cmd, cmd=/etc/ddclient/get-ip-from-fritzbox\n````\n","_id":"content:apps:ddclient.json","_type":"json","title":"Ddclient","_source":"content","_file":"apps/ddclient.json","_extension":"json"},{"_path":"/apps/deluge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"deluge","name":"deluge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a lightweight, Free Software, cross-platform BitTorrent client.\n\n* Full Encryption\n* WebUI\n* Plugin System\n* Much more...\n","icon":"https://avatars2.githubusercontent.com/u/6733935?v=3&s=200","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/deluge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-deluge"}],"containers":[{"name":"deluge","image":"linuxserver/deluge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use"},{"id":"DELUGE_LOGLEVEL","default":"error","description":"set the loglevel output when running Deluge, default is info for deluged and warning for delgued-web"}],"volumes":[{"container":"/config","description":"deluge configs","key":"config"},{"container":"/downloads","description":"torrent download directory"}],"ports":[{"container":"8112","description":"Port for webui","protocol":"tcp","web":false},{"container":"6881","description":"Inbound torrent traffic (See App Setup)","protocol":"tcp","web":false},{"container":"6881/udp","description":"Inbound torrent traffic (See App Setup)","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"deluge","project_url":"http://deluge-torrent.org/","project_logo":"https://avatars2.githubusercontent.com/u/6733935?v=3&s=200","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a lightweight, Free Software, cross-platform BitTorrent client.\n\n* Full Encryption\n* WebUI\n* Plugin System\n* Much more...\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/deluge/config","desc":"deluge configs"},{"vol_path":"/downloads","vol_host_path":"/path/to/your/downloads","desc":"torrent download directory"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8112","internal_port":"8112","port_desc":"Port for webui"},{"external_port":"6881","internal_port":"6881","port_desc":"Inbound torrent traffic (See App Setup)"},{"external_port":"6881","internal_port":"6881/udp","port_desc":"Inbound torrent traffic (See App Setup)"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DELUGE_LOGLEVEL","env_value":"error","desc":"set the loglevel output when running Deluge, default is info for deluged and warning for delgued-web"}],"app_setup_block_enabled":true,"app_setup_block":"The admin interface is available at `http://SERVER-IP:8112` with a default user/password of admin/deluge.\n\nTo change the password (recommended) log in to the web interface and go to Preferences->Interface->Password.\n\nChange the inbound port to 6881 (or whichever port you've mapped for the container) under Preferences->Network, otherwise random ports will be used.\n","changelogs":[{"date":"29.11.22:","desc":"Restore geoip using py3-geoip as an interim measure."},{"date":"24.11.22:","desc":"Remove GeoIP packages as geoip will not build under Py 3.11 and Deluge still doesn't support geoip2."},{"date":"22.11.22:","desc":"Update GeoIP URL for new IPFS domain."},{"date":"29.08.22:","desc":"Rebase to Alpine Edge again to follow latest releases."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"16.06.22:","desc":"Rebase to Alpine 3.16 from edge."},{"date":"22.02.22:","desc":"Rebase to Alpine, config on first startup, add GeoIP."},{"date":"15.01.22:","desc":"Rebase to Focal."},{"date":"07.06.21:","desc":"Remove host networking from readme examples"},{"date":"23.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"09.05.19:","desc":"Add python3 requests and future modules."},{"date":"24.08.19:","desc":"Add ability to set LogLevel for Deluge."},{"date":"09.06.19:","desc":"Update to 2.x using deluge ppa."},{"date":"02.05.19:","desc":"Install full version of 7zip."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"15.11.18:","desc":"Add deluge-console."},{"date":"11.11.18:","desc":"Rebase to Ubuntu Bionic, add pipeline multiarch logic."},{"date":"09.04.18:","desc":"update to libressl2.7-libssl."},{"date":"29.03.18:","desc":"Rebase to alpine edge."},{"date":"07.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.11.17:","desc":"Change libressl2.6-libssl repo."},{"date":"01.07.17:","desc":"Add curl package."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"29.04.17:","desc":"Add variable for user defined umask."},{"date":"28.04.17:","desc":"update to libressl2.5-libssl."},{"date":"28.12.16:","desc":"Rebase to alpine 3.5 baseimage."},{"date":"17.11.16:","desc":"Rebase to edge baseimage."},{"date":"13.10.16:","desc":"Switch to libressl as openssl deprecated from alpine linux and deluge dependency no longer installs"},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"30.08.16:","desc":"Use pip packages for some critical dependencies."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"15.08.16:","desc":"Rebase to alpine linux."},{"date":"09.11.15:","desc":"Add unrar and unzip"},{"date":"15.10.15:","desc":"Initial Release."}]}},"setup":"The admin interface is available at `http://SERVER-IP:8112` with a default user/password of admin/deluge.\n\nTo change the password (recommended) log in to the web interface and go to Preferences->Interface->Password.\n\nChange the inbound port to 6881 (or whichever port you've mapped for the container) under Preferences->Network, otherwise random ports will be used.\n","_id":"content:apps:deluge.json","_type":"json","title":"Deluge","_source":"content","_file":"apps/deluge.json","_extension":"json"},{"_path":"/apps/digikam","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"digikam","name":"digikam","description":"[digiKam]({{ project_url }}): Professional Photo Management with the Power of Open Source","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/digikam.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/digikam"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-digikam"}],"containers":[{"name":"digikam","image":"linuxserver/digikam","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York."},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores database.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"digikam","project_url":"https://www.digikam.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/digikam.png","project_blurb":"[digiKam]({{ project_url }}): Professional Photo Management with the Power of Open Source","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_usage_include_ports":false,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores database."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"digiKam desktop gui"}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n#### Mysql Internal\n\nWhen using mysql internal mode for the database you will need to click on \"Find\" Button for all the required binaries (mysql_install_db,mysqladmin,mysqld). Then select the binary file and press Open.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"20.01.23:","desc":"Added breeze-icons package for icon support."},{"date":"21.11.22:","desc":"Trigger upon baseimage updates (arch being a rolling distro has too many dependency breaks otherwise). Release version will be the baseimage build date going forward."},{"date":"20.10.22:","desc":"Migrate to s6v3."},{"date":"07.03.22:","desc":"Add Exiftool and firefox for image exports."},{"date":"20.02.22:","desc":"Add MariaDB, expand documentation."},{"date":"15.02.22:","desc":"Rebase to Arch."},{"date":"27.12.21:","desc":"Rebase to focal to resolve dependency issues."},{"date":"27.03.21:","desc":"Download link fixed."},{"date":"20.05.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n#### Mysql Internal\n\nWhen using mysql internal mode for the database you will need to click on \"Find\" Button for all the required binaries (mysql_install_db,mysqladmin,mysqld). Then select the binary file and press Open.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","_id":"content:apps:digikam.json","_type":"json","title":"Digikam","_source":"content","_file":"apps/digikam.json","_extension":"json"},{"_path":"/apps/dillinger","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"dillinger","name":"dillinger","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a cloud-enabled, mobile-ready, offline-storage, AngularJS powered HTML5 Markdown editor.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dillinger.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/dillinger"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-dillinger"}],"containers":[{"name":"dillinger","image":"linuxserver/dillinger","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Dillinger plugin config files","key":"config"}],"ports":[{"container":"8080","description":"The port for the Dillinger web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"dillinger","project_url":"https://github.com/joemccann/dillinger","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dillinger.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a cloud-enabled, mobile-ready, offline-storage, AngularJS powered HTML5 Markdown editor.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to configs>","desc":"Dillinger plugin config files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"The port for the Dillinger web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://your-ip:8080 , keep in mind that storage for this application is in your browser session not server side. Only plugin configurations will ever be stored server side. \n","changelogs":[{"date":"19.04.22:","desc":"Rebase to Alpine."},{"date":"31.05.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://your-ip:8080 , keep in mind that storage for this application is in your browser session not server side. Only plugin configurations will ever be stored server side. \n","_id":"content:apps:dillinger.json","_type":"json","title":"Dillinger","_source":"content","_file":"apps/dillinger.json","_extension":"json"},{"_path":"/apps/diskover","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"diskover","name":"diskover","description":"[{{ project_name }}]({{ project_url }}) is an open source file system indexer that uses Elasticsearch to index and manage data across heterogeneous storage systems.","icon":"https://raw.githubusercontent.com/diskoverdata/diskover-community/master/diskover-web/public/images/diskover.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/diskover"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-diskover"}],"containers":[{"name":"diskover","image":"linuxserver/diskover","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"ES_HOST","default":"elasticsearch","description":"ElasticSearch host (optional)"},{"id":"ES_PORT","default":"9200","description":"ElasticSearch port (optional)"},{"id":"ES_USER","default":"elastic","description":"ElasticSearch username (optional)"},{"id":"ES_PASS","default":"changeme","description":"ElasticSearch password (optional)"}],"volumes":[{"container":"/config","description":"Persistent config files","key":"config"},{"container":"/data","description":"Default mount point to crawl"}],"ports":[{"container":"80","description":"diskover Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"diskover","project_url":"https://github.com/diskoverdata/diskover-community","project_logo":"https://raw.githubusercontent.com/diskoverdata/diskover-community/master/diskover-web/public/images/diskover.png","project_blurb":"[{{ project_name }}]({{ project_url }}) is an open source file system indexer that uses Elasticsearch to index and manage data across heterogeneous storage systems.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/{{ project_name }}/config","desc":"Persistent config files"},{"vol_path":"/data","vol_host_path":"/path/to/{{ project_name }}/data","desc":"Default mount point to crawl"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"diskover Web UI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"ES_HOST","env_value":"elasticsearch","desc":"ElasticSearch host (optional)"},{"env_var":"ES_PORT","env_value":"9200","desc":"ElasticSearch port (optional)"},{"env_var":"ES_USER","env_value":"elastic","desc":"ElasticSearch username (optional)"},{"env_var":"ES_PASS","env_value":"changeme","desc":"ElasticSearch password (optional)"}],"custom_compose":"version: '2'\nservices:\n  diskover:\n    image: lscr.io/linuxserver/diskover\n    container_name: diskover\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=America/New_York\n      - ES_HOST=elasticsearch\n      - ES_PORT=9200\n    volumes:\n      - /path/to/diskover/config:/config\n      - /path/to/diskover/data:/data\n    ports:\n      - 80:80\n    mem_limit: 4096m\n    restart: unless-stopped\n    depends_on:\n      - elasticsearch\n  elasticsearch:\n    container_name: elasticsearch\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=true\n      - bootstrap.memory_lock=true\n      - \"ES_JAVA_OPTS=-Xms1g -Xmx1g\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    volumes:\n      - /path/to/esdata:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n    depends_on:\n      - elasticsearch-helper\n    restart: unless-stopped\n  elasticsearch-helper:\n    image: alpine\n    command: sh -c \"sysctl -w vm.max_map_count=262144\"\n    privileged: true\n","app_setup_block_enabled":true,"app_setup_block":"This application is dependent on an ElasticSearch instance. Please see the example compose file for additional information.\n\nThe default username is diskover with the password of **darkdata**, access the container at `http://<host-ip>/`. The UI may be unusable until a valid index has been created.\n\nThe default diskover-web Constants.php file located at `/config/diskover-web.conf.d/Constants.php` will need to be edited to allow diskover-web to communicate with the ElasticSearch container. The following entries will need to be edited:\n* `const ES_HOST = elasticsearch`\n* `const ES_PORT = 9200`\n\nThe application doesn't start an index by default. A crontab is created inside of the `/config` directory and can be set up to run automated indexes of `/data`. Changes to this crontab file require a restart to apply. You can also manually run an index by executing `/app/diskover/diskover.py` either in interactive or detached mode:\n\n* `docker exec -u abc -d diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the background\n* `docker exec -u abc -it diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the foreground\n","changelogs":[{"date":"25.02.22:","desc":"Add php7-sqlite3 to support rc4 release."},{"date":"03.11.21:","desc":"Added more support for potential config files."},{"date":"31.10.21:","desc":"Added xpack.security variable to ElasticSearch; added instructions to edit Constants.php in diskover; corrected command needed to manually generate an index in diskover"},{"date":"11.10.21:","desc":"Updated to diskover-community v2."},{"date":"19.11.20:","desc":"Fix pip packages."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.11.18:","desc":"Initial Release."}]}},"setup":"This application is dependent on an ElasticSearch instance. Please see the example compose file for additional information.\n\nThe default username is diskover with the password of **darkdata**, access the container at `http://<host-ip>/`. The UI may be unusable until a valid index has been created.\n\nThe default diskover-web Constants.php file located at `/config/diskover-web.conf.d/Constants.php` will need to be edited to allow diskover-web to communicate with the ElasticSearch container. The following entries will need to be edited:\n* `const ES_HOST = elasticsearch`\n* `const ES_PORT = 9200`\n\nThe application doesn't start an index by default. A crontab is created inside of the `/config` directory and can be set up to run automated indexes of `/data`. Changes to this crontab file require a restart to apply. You can also manually run an index by executing `/app/diskover/diskover.py` either in interactive or detached mode:\n\n* `docker exec -u abc -d diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the background\n* `docker exec -u abc -it diskover python3 /app/diskover/diskover.py -i diskover-my_index_name /data` Will run an index in the foreground\n","_id":"content:apps:diskover.json","_type":"json","title":"Diskover","_source":"content","_file":"apps/diskover.json","_extension":"json"},{"_path":"/apps/docker-compose","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"docker-compose","name":"docker-compose","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/dockercompose.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/docker-compose"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-docker-compose"}],"containers":[{"name":"docker-compose","image":"linuxserver/docker-compose","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"docker-compose","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring:\n\n* regular and timely application updates\n* easy user mappings (PGID, PUID)\n* custom base image with s6 overlay\n* weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n* regular security updates\n\nFind us at:\n\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [GitHub](https://github.com/linuxserver) - view the source for all of our repositories.\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n# [linuxserver/docker-compose](https://github.com/linuxserver/docker-docker-compose)\n\n[![Scarf.io pulls](https://scarf.sh/installs-badge/linuxserver-ci/linuxserver%2Fdocker-compose?color=94398d&label-color=555555&logo-color=ffffff&style=for-the-badge&package-type=docker)](https://scarf.sh/gateway/linuxserver-ci/docker/linuxserver%2Fdocker-compose)\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-docker-compose)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github&include_prereleases)](https://github.com/linuxserver/docker-docker-compose/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-docker-compose/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/linuxserver.io/docker-docker-compose/container_registry)\n[![Quay.io](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Quay.io)](https://quay.io/repository/linuxserver.io/docker-compose)\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/docker-compose)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/docker-compose.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/docker-compose)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-docker-compose%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-docker-compose/job/master/)\n\n[docker-compose](https://github.com/docker/compose) is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application's services. Then, using a single command, you create and start all the services from your configuration.\n\n[![docker-compose](https://github.com/docker/compose/raw/master/logo.png)](https://github.com/docker/compose)\n\n## Supported Architectures\n\nWe utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `lscr.io/linuxserver/docker-compose:latest` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Available | Tag |\n| :----: | :----: | ---- |\n| x86-64 |  | amd64-\\<version tag\\> |\n| arm64 |  | arm64v8-\\<version tag\\> |\n| armhf|  | arm32v7-\\<version tag\\> |\n\n## Version Tags\n\nThis image provides various versions that are available via tags. Please read the descriptions carefully and exercise caution when using unstable or development tags.\n\n| Tag | Available | Description |\n| :----: | :----: |--- |\n| latest |  | docker-compose v1 releases |\n| alpine |  | docker-compose v1 releases with our alpine baseimage |\n| v2 |  | docker compose v2 releases |\n\n## Usage\n\n### Docker cli\n\n```\ndocker run --rm \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  lscr.io/linuxserver/docker-compose:latest \\\n  up\n```\nYou can replace the last line with any docker-compose command and argument, which will be passed to docker-compose inside the image.\n\n### Recommended method\n\nWe provide a very convenient script that allows the docker-compose container to run as if it was installed natively:\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n```\n\nRunning these two commands on your docker host once will let you issue commands such as `docker-compose up -d` and the docker-compose container will do its job behind the scenes.\n\n## Docker Mods\n\n[![Docker Mods](https://img.shields.io/badge/dynamic/yaml?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=docker-compose&query=%24.mods%5B%27docker-compose%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=docker-compose \"view available mods for this container.\") [![Docker Universal Mods](https://img.shields.io/badge/dynamic/yaml?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=universal&query=%24.mods%5B%27universal%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=universal \"view available universal mods.\")\n\nWe publish various [Docker Mods](https://github.com/linuxserver/docker-mods) to enable additional functionality within the containers. The list of Mods available for this image (if any) as well as universal mods that can be applied to any one of our images can be accessed via the dynamic badges above.\n\n## Support Info\n\n* Shell access whilst the container is running: `docker exec -it docker-compose /bin/bash`\n* To monitor the logs of the container in realtime: `docker logs -f docker-compose`\n* container version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' docker-compose`\n* image version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' lscr.io/linuxserver/docker-compose:latest`\n\n## Updating Info\n\nMost of our images are static, versioned, and require an image update and container recreation to update the app inside. With some exceptions (ie. nextcloud, plex), we do not recommend or support updating apps inside the container. Please consult the [Application Setup](#application-setup) section above to see if it is recommended for the image.\n\nBelow are the instructions for updating containers:\n\n### Via Docker Run\n\n* Update the image: `docker pull lscr.io/linuxserver/docker-compose:latest`\n* You can also remove the old dangling images: `docker image prune`\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n\n```bash\ngit clone https://github.com/linuxserver/docker-docker-compose.git\ncd docker-docker-compose\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t lscr.io/linuxserver/docker-compose:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **15.03.22:** - Add v2 branch. Change master to only fetch v1 releases. Change alpine to only fetch v1 releases. Rebase master to focal. Rebase alpine to 3.15.\n* **17.12.20:** - Update run.sh with formatting changes.\n* **04.10.20:** - Update run.sh with changes from upstream.\n* **31.08.20:** - Update tox and virtualenv.\n* **31.07.20:** - Add support for global env var `DOCKER_COMPOSE_IMAGE_TAG` in the `run.sh` script.\n* **06.07.20:** - Publish docker-compose and docker-cli binaries in Github releases.\n* **01.07.20:** - Release alpine based images at `alpine` tag.\n* **04.06.20:** - Bump docker-cli to 19.03.8, auto-detect python3 version.\n* **19.05.20:** - Initial Release.\n\n{%- endraw %}\n"}},"_id":"content:apps:docker-compose.json","_type":"json","title":"Docker Compose","_source":"content","_file":"apps/docker-compose.json","_extension":"json"},{"_path":"/apps/dokuwiki","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"dokuwiki","name":"dokuwiki","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple to use and highly versatile Open Source wiki software that doesn't require a database. It is loved by users for its clean and readable syntax. The ease of maintenance, backup and integration makes it an administrator's favorite. Built in access controls and authentication connectors make DokuWiki especially useful in the enterprise context and the large number of plugins contributed by its vibrant community allow for a broad range of use cases beyond a traditional wiki.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dokuwiki-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/dokuwiki"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-dokuwiki"}],"containers":[{"name":"dokuwiki","image":"linuxserver/dokuwiki","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"APP_URL","default":"/dokuwiki","description":"Specify an APP_URL to append to your root location, helpful for subfolder reverse proxy setups.  Does not take effect until after first restart following setup."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"80","description":"Application HTTP Port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"dokuwiki","project_url":"https://www.dokuwiki.org/dokuwiki/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/dokuwiki-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple to use and highly versatile Open Source wiki software that doesn't require a database. It is loved by users for its clean and readable syntax. The ease of maintenance, backup and integration makes it an administrator's favorite. Built in access controls and authentication connectors make DokuWiki especially useful in the enterprise context and the large number of plugins contributed by its vibrant community allow for a broad range of use cases beyond a traditional wiki.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application HTTP Port"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"APP_URL","env_value":"/dokuwiki","desc":"Specify an APP_URL to append to your root location, helpful for subfolder reverse proxy setups.  Does not take effect until after first restart following setup."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"443","internal_port":"443","port_desc":"#optional Application HTTPS Port"}],"app_setup_block_enabled":true,"app_setup_block":"Upon first install go to `http://$IP:$PORT/install.php` once you have completed the setup, restart the container, login as admin and set \"Use nice URLs\" in the `admin/Configuration Settings` panel to `.htaccess` and tick `Use slash as namespace separator in URLs` to enable [nice URLs](https://www.dokuwiki.org/rewrite) you will find the webui at `http://$IP:$PORT/`, for more info see [{{ project_name|capitalize }}]({{ project_url }})\n","changelogs":[{"date":"28.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"11.13.22:","desc":"Move lib/images/smileys/local and lib/images/interwiki outside of the container for user defined smiley and interwiki icon support."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"20.07.21:","desc":"Add php7-dom, fixes minor issues in sprintdoc template."},{"date":"15.04.21:","desc":"Add `vendor` folder to deny list."},{"date":"21.02.21:","desc":"Store search index outside of container, set absolute (default) path for `savedir`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"28.09.20:","desc":"Add php7-pdo_sqlite and php7-sqlite3."},{"date":"23.09.20:","desc":"Fix php-local.ini bug introduced in the prior PR."},{"date":"14.09.20:","desc":"Rebase to alpine 3.12. Add php7-ctype, php7-curl, php7-pdo_mysql, php7-pdo_pgsql, php7-pecl-imagick and php7-iconv. Bump upload max filesize and post max size to 100MB. Remove deprecated APP_URL env var. Fix breaking addons."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"01.12.19:","desc":"Add php7-ldap package to support LDAP authentication."},{"date":"28.05.19:","desc":"Initial Release."}]}},"setup":"Upon first install go to `http://$IP:$PORT/install.php` once you have completed the setup, restart the container, login as admin and set \"Use nice URLs\" in the `admin/Configuration Settings` panel to `.htaccess` and tick `Use slash as namespace separator in URLs` to enable [nice URLs](https://www.dokuwiki.org/rewrite) you will find the webui at `http://$IP:$PORT/`, for more info see [{{ project_name|capitalize }}]({{ project_url }})\n","_id":"content:apps:dokuwiki.json","_type":"json","title":"Dokuwiki","_source":"content","_file":"apps/dokuwiki.json","_extension":"json"},{"_path":"/apps/domoticz","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"domoticz","name":"domoticz","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Home Automation System that lets you monitor and configure various devices like: Lights, Switches, various sensors/meters like Temperature, Rain, Wind, UV, Electra, Gas, Water and much more. Notifications/Alerts can be sent to any mobile device.","icon":"https://github.com/domoticz/domoticz/raw/master/www/images/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/domoticz"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-domoticz"}],"containers":[{"name":"domoticz","image":"linuxserver/domoticz","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"WEBROOT","default":"domoticz","description":"Sets webroot to domoticz for usage with subfolder reverse proxy. Not needed unless reverse proxying."},{"id":"DBASE","default":"<path to database>","description":"Sets path to database. Do not set unless you know what this does."}],"volumes":[{"container":"/config","description":"Where Domoticz stores config files and data.","key":"config"}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"6144","description":"Domoticz communication port.","protocol":"tcp","web":false},{"container":"1443","description":"Domoticz communication port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"domoticz","project_url":"https://www.domoticz.com","project_logo":"https://github.com/domoticz/domoticz/raw/master/www/images/logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Home Automation System that lets you monitor and configure various devices like: Lights, Switches, various sensors/meters like Temperature, Rain, Wind, UV, Electra, Gas, Water and much more. Notifications/Alerts can be sent to any mobile device.","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Current latest stable."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where Domoticz stores config files and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"6144","internal_port":"6144","port_desc":"Domoticz communication port."},{"external_port":"1443","internal_port":"1443","port_desc":"Domoticz communication port."}],"param_device_map":true,"param_devices":[{"device_path":"path to device","device_host_path":"path to device","desc":"For passing through USB devices."}],"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"WEBROOT","env_value":"domoticz","desc":"Sets webroot to domoticz for usage with subfolder reverse proxy. Not needed unless reverse proxying."},{"env_var":"DBASE","env_value":"<path to database>","desc":"Sets path to database. Do not set unless you know what this does."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Passing Through USB Devices\n\nTo get full use of Domoticz, you probably have a USB device you want to pass through. To figure out which device to pass through, you have to connect the device and look in dmesg for the device node created. Issue the command 'dmesg | tail' after you connected your device and you should see something like below.\n\n```\nusb 1-1.2: new full-speed USB device number 7 using ehci-pci\nftdi_sio 1-1.2:1.0: FTDI USB Serial Device converter detected\nusb 1-1.2: Detected FT232RL\nusb 1-1.2: FTDI USB Serial Device converter now attached to ttyUSB0\n```\nAs you can see above, the device node created is ttyUSB0. It does not say where, but it's almost always in /dev/. The correct tag for passing through this USB device is '--device /dev/ttyUSB0:/dev/ttyUSB0'\n"],"app_setup_block_enabled":true,"app_setup_block":"To configure Domoticz, go to the IP of your docker host on the port you configured (default 8080), and add your hardware in Setup > Hardware.\nThe user manual is available at [www.domoticz.com]({{ project_url }})\n","changelogs":[{"date":"15.10.22:","desc":"Remove deprecated legacy stable branches."},{"date":"05.02.22:","desc":"Set default webroot to /. Add env. variable for setting custom databas path."},{"date":"26.12.20:","desc":"Rebase to Ubuntu Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"24.11.19:","desc":"Change to using domoticz builtin Lua and MQTT."},{"date":"03.11.19:","desc":"Set capabilities for domoticz binary and move cmake from edge repo."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10. Add iputils for ping. Fix typo in readme. Fix permissions for custom icons."},{"date":"12.05.19:","desc":"Add boost dependencies and turn off static boost build. Bump to Alpine 3.9."},{"date":"30.03.19:","desc":"Add env variable to set webroot."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"19.02.19:","desc":"Fix branch for version logic."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"02.07.18:","desc":"Add openssh package."},{"date":"01.07.18:","desc":"Fix backup/restore in webgui."},{"date":"03.04.18:","desc":"Add dependencies for BroadlinkRM2 plugin."},{"date":"20.01.18:","desc":"Move telldus core to repo to prevent build fail when source site goes down."},{"date":"18.01.18:","desc":"Remove logging to syslog in the run command to prevent double logging."},{"date":"04.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"26.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"26.02.17:","desc":"Add curl and replace openssl with libressl."},{"date":"11.02.17:","desc":"Update README."},{"date":"03.01.17:","desc":"Initial Release."}]}},"setup":"To configure Domoticz, go to the IP of your docker host on the port you configured (default 8080), and add your hardware in Setup > Hardware.\nThe user manual is available at [www.domoticz.com]({{ project_url }})\n","_id":"content:apps:domoticz.json","_type":"json","title":"Domoticz","_source":"content","_file":"apps/domoticz.json","_extension":"json"},{"_path":"/apps/doplarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"doplarr","name":"doplarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an *arr request bot for Discord.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doplarr-logo_title.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/doplarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-doplarr"}],"containers":[{"name":"doplarr","image":"linuxserver/doplarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"DISCORD__TOKEN","default":"","description":"Specify your discord bot token."},{"id":"OVERSEERR__API","default":"","description":"Specify your Overseerr API key. Leave blank if using Radarr/Sonarr."},{"id":"OVERSEERR__URL","default":"http://localhost:5055","description":"Specify your Overseerr URL. Leave blank if using Radarr/Sonarr."},{"id":"RADARR__API","default":"","description":"Specify your Radarr API key. Leave blank if using Overseerr."},{"id":"RADARR__URL","default":"http://localhost:7878","description":"Specify your Radarr URL. Leave blank if using Overseerr."},{"id":"SONARR__API","default":"","description":"Specify your Sonarr API key. Leave blank if using Overseerr."},{"id":"SONARR__URL","default":"http://localhost:8989","description":"Specify your Sonarr URL. Leave blank if using Overseerr."},{"id":"DISCORD__MAX_RESULTS","default":"25","description":"Sets the maximum size of the search results selection"},{"id":"DISCORD__REQUESTED_MSG_STYLE","default":":plain","description":"Sets the style of the request alert message. One of `:plain` `:embed` `:none`"},{"id":"SONARR__QUALITY_PROFILE","default":"","description":"The name of the quality profile to use by default for Sonarr"},{"id":"RADARR__QUALITY_PROFILE","default":"","description":"The name of the quality profile to use by default for Radarr"},{"id":"SONARR__ROOTFOLDER","default":"","description":"The root folder to use by default for Sonarr"},{"id":"RADARR__ROOTFOLDER","default":"","description":"The root folder to use by default for Radarr"},{"id":"SONARR__LANGUAGE_PROFILE","default":"","description":"The name of the language profile to use by default for Sonarr"},{"id":"OVERSEERR__DEFAULT_ID","default":"","description":"The Overseerr user id to use by default if there is no associated discord account for the requester"},{"id":"PARTIAL_SEASONS","default":"true","description":"Sets whether users can request partial seasons."},{"id":"LOG_LEVEL","default":":info","description":"The log level for the logging backend. This can be changed for debugging purposes. One of trace `:debug` `:info` `:warn` `:error` `:fatal` `:report`"},{"id":"JAVA_OPTS","default":"","description":"For passing additional java options."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"doplarr","project_url":"https://github.com/kiranshila/Doplarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doplarr-logo_title.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an *arr request bot for Discord.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"DISCORD__TOKEN","env_value":"","desc":"Specify your discord bot token."},{"env_var":"OVERSEERR__API","env_value":"","desc":"Specify your Overseerr API key. Leave blank if using Radarr/Sonarr."},{"env_var":"OVERSEERR__URL","env_value":"http://localhost:5055","desc":"Specify your Overseerr URL. Leave blank if using Radarr/Sonarr."},{"env_var":"RADARR__API","env_value":"","desc":"Specify your Radarr API key. Leave blank if using Overseerr."},{"env_var":"RADARR__URL","env_value":"http://localhost:7878","desc":"Specify your Radarr URL. Leave blank if using Overseerr."},{"env_var":"SONARR__API","env_value":"","desc":"Specify your Sonarr API key. Leave blank if using Overseerr."},{"env_var":"SONARR__URL","env_value":"http://localhost:8989","desc":"Specify your Sonarr URL. Leave blank if using Overseerr."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DISCORD__MAX_RESULTS","env_value":"25","desc":"Sets the maximum size of the search results selection"},{"env_var":"DISCORD__REQUESTED_MSG_STYLE","env_value":":plain","desc":"Sets the style of the request alert message. One of `:plain` `:embed` `:none`"},{"env_var":"SONARR__QUALITY_PROFILE","env_value":"","desc":"The name of the quality profile to use by default for Sonarr"},{"env_var":"RADARR__QUALITY_PROFILE","env_value":"","desc":"The name of the quality profile to use by default for Radarr"},{"env_var":"SONARR__ROOTFOLDER","env_value":"","desc":"The root folder to use by default for Sonarr"},{"env_var":"RADARR__ROOTFOLDER","env_value":"","desc":"The root folder to use by default for Radarr"},{"env_var":"SONARR__LANGUAGE_PROFILE","env_value":"","desc":"The name of the language profile to use by default for Sonarr"},{"env_var":"OVERSEERR__DEFAULT_ID","env_value":"","desc":"The Overseerr user id to use by default if there is no associated discord account for the requester"},{"env_var":"PARTIAL_SEASONS","env_value":"true","desc":"Sets whether users can request partial seasons."},{"env_var":"LOG_LEVEL","env_value":":info","desc":"The log level for the logging backend. This can be changed for debugging purposes. One of trace `:debug` `:info` `:warn` `:error` `:fatal` `:report`"},{"env_var":"JAVA_OPTS","env_value":"","desc":"For passing additional java options."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Start by following the [Discord](https://github.com/kiranshila/Doplarr#discord) setup instructions from Doplarr's readme.\n\nNOTE: The `DISCORD__TOKEN` environment variable is required to run the container!\n\n- If you are using Overseerr, fill in the Overseerr API and URL variables, and leave the Radarr/Sonarr variables blank.\n- If you are using Radarr/Sonarr (and not using Overseerr), fill in the Radarr/Sonarr API and URL variables, and leave the Overseerr variables blank.\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`.\n\nReview and adjust any [Optional Settings](https://github.com/kiranshila/Doplarr#optional-settings) from Doplarr's readme.\n","changelogs":[{"date":"18.12.22:","desc":"Rebase to alpine 3.17, upgrade to openjdk17."},{"date":"01.05.22:","desc":"Remove `DISCORD__ROLE_ID` environment variable, see [Permissions Configuration](https://github.com/kiranshila/Doplarr/blob/main/docs/configuration.md#permissions)."},{"date":"30.01.22:","desc":"Variable adjustments."},{"date":"30.01.22:","desc":"Initial Release."}]}},"setup":"Start by following the [Discord](https://github.com/kiranshila/Doplarr#discord) setup instructions from Doplarr's readme.\n\nNOTE: The `DISCORD__TOKEN` environment variable is required to run the container!\n\n- If you are using Overseerr, fill in the Overseerr API and URL variables, and leave the Radarr/Sonarr variables blank.\n- If you are using Radarr/Sonarr (and not using Overseerr), fill in the Radarr/Sonarr API and URL variables, and leave the Overseerr variables blank.\n\nExtra java options can be passed with the JAVA_OPTS environment variable, eg `-e JAVA_OPTS=\"-Xmx256m -Xms256m\"`.\n\nReview and adjust any [Optional Settings](https://github.com/kiranshila/Doplarr#optional-settings) from Doplarr's readme.\n","_id":"content:apps:doplarr.json","_type":"json","title":"Doplarr","_source":"content","_file":"apps/doplarr.json","_extension":"json"},{"_path":"/apps/doublecommander","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"doublecommander","name":"doublecommander","description":"[Double Commander]({{ project_url }}) is a free cross platform open source file manager with two panels side by side. It is inspired by Total Commander and features some new ideas.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doublecommander-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/doublecommander"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-doublecommander"}],"containers":[{"name":"doublecommander","image":"linuxserver/doublecommander","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"},{"container":"/data","description":"Host data directories, mount as many as needed."}],"ports":[{"container":"3000","description":"Double Commander desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"doublecommander","project_url":"https://doublecmd.sourceforge.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/doublecommander-icon.png","project_blurb":"[Double Commander]({{ project_url }}) is a free cross platform open source file manager with two panels side by side. It is inspired by Total Commander and features some new ideas.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Host data directories, mount as many as needed."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Double Commander desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.09.22:","desc":"Migrate to s6v3."},{"date":"15.02.21:","desc":"Rebase to Ubuntu Jammy."},{"date":"14.12.21:","desc":"Rebase to Ubuntu focal."},{"date":"25.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:doublecommander.json","_type":"json","title":"Doublecommander","_source":"content","_file":"apps/doublecommander.json","_extension":"json"},{"_path":"/apps/duckdns","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"duckdns","name":"duckdns","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/duckdns.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/duckdns"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-duckdns"}],"containers":[{"name":"duckdns","image":"linuxserver/duckdns","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBDOMAINS","default":"subdomain1,subdomain2","description":"multiple subdomains allowed, comma separated, no spaces"},{"id":"TOKEN","default":"token","description":"DuckDNS token"},{"id":"LOG_FILE","default":"false","description":"Set to `true` to log to file (also need to map /config)."}]}],"meta":{"readme-vars":{"project_name":"duckdns","project_url":"https://duckdns.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/duckdns.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":"","common_param_env_vars_enabled":"optional","param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"","param_net_desc":"","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"SUBDOMAINS","env_value":"subdomain1,subdomain2","desc":"multiple subdomains allowed, comma separated, no spaces"},{"env_var":"TOKEN","env_value":"token","desc":"DuckDNS token"}],"param_usage_include_vols":false,"param_volumes":"","param_usage_include_ports":false,"param_ports":"","param_device_map":false,"param_devices":"","cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"LOG_FILE","env_value":"false","desc":"Set to `true` to log to file (also need to map /config)."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Used in conjunction with logging to file."}],"opt_param_usage_include_ports":false,"opt_param_ports":"","opt_param_device_map":false,"opt_param_devices":"","opt_cap_add_param":false,"opt_cap_add_param_vars":"","optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"- Go to the [duckdns website]({{project_url}}), register your subdomain(s) and retrieve your token\n- Create a container with your subdomain(s) and token\n- It will update your IP with the DuckDNS service every 5 minutes (with a random jitter)\n","changelogs":[{"date":"23.09.22:","desc":"Rebase to alpine 3.16 and s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"17.05.22:","desc":"Don't allow insecure connections and add timeout."},{"date":"17.05.22:","desc":"Add random jitter to update time."},{"date":"23.02.22:","desc":"Append to log file instead of overwriting every time."},{"date":"03.05.21:","desc":"Re-adjust cron timings to prevent peak times, update code formatting."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.04.20:","desc":"Add donation links for DuckDNS."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"24.09.19:","desc":"Fix perms on github and remove chmod that can stall the container."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"08.02.19:","desc":"Update readme with optional parameters."},{"date":"10.12.18:","desc":"Fix docker compose example."},{"date":"15.10.18:","desc":"Multi-arch image."},{"date":"22.08.18:","desc":"Rebase to alpine 3.8."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"17.11.16:","desc":"Initial release."}]}},"setup":"- Go to the [duckdns website]({{project_url}}), register your subdomain(s) and retrieve your token\n- Create a container with your subdomain(s) and token\n- It will update your IP with the DuckDNS service every 5 minutes (with a random jitter)\n","_id":"content:apps:duckdns.json","_type":"json","title":"Duckdns","_source":"content","_file":"apps/duckdns.json","_extension":"json"},{"_path":"/apps/duplicati","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"duplicati","name":"duplicati","description":"[{{ project_name|capitalize }}]({{ project_url }}) works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/duplicati-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/duplicati"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-duplicati"}],"containers":[{"name":"duplicati","image":"linuxserver/duplicati","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"CLI_ARGS","default":"","description":"Optionally specify any [CLI variables](https://duplicati.readthedocs.io/en/latest/07-other-command-line-utilities/) you want to launch the app with"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/backups","description":"Path to store local backups."},{"container":"/source","description":"Path to source for files to backup."}],"ports":[{"container":"8200","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"duplicati","project_url":"https://www.duplicati.com/","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/duplicati-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Beta releases of Duplicati"},{"tag":"development","desc":"Canary releases of Duplicati"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains all relevant configuration files."},{"vol_path":"/backups","vol_host_path":"</path/to/backups>","desc":"Path to store local backups."},{"vol_path":"/source","vol_host_path":"</path/to/source>","desc":"Path to source for files to backup."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8200","internal_port":"8200","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CLI_ARGS","env_value":"","desc":"Optionally specify any [CLI variables](https://duplicati.readthedocs.io/en/latest/07-other-command-line-utilities/) you want to launch the app with"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The webui is at `<your ip>:8200` , create backup jobs etc via the webui, for local backups select `/backups` as the destination. For more information see [Duplicati]({{project_url}}).\n","changelogs":[{"date":"03.08.22:","desc":"Deprecate armhf."},{"date":"25.04.22:","desc":"Rebase to mono:focal."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"16.07.19:","desc":"Allow for additional command line arguments in an environment variable."},{"date":"28.06.19:","desc":"Rebase to bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"28.02.19:","desc":"Allow access from all hostnames, clarify info on image tags."},{"date":"13.01.19:","desc":"Use jq instead of awk in dockerfiles."},{"date":"11.01.19:","desc":"Multi-arch image."},{"date":"09.12.17:","desc":"Fix continuation lines."},{"date":"31.08.17:","desc":"Build only beta or release versions (thanks deasmi)."},{"date":"24.04.17:","desc":"Initial release."}]}},"setup":"The webui is at `<your ip>:8200` , create backup jobs etc via the webui, for local backups select `/backups` as the destination. For more information see [Duplicati]({{project_url}}).\n","_id":"content:apps:duplicati.json","_type":"json","title":"Duplicati","_source":"content","_file":"apps/duplicati.json","_extension":"json"},{"_path":"/apps/emby","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"emby","name":"emby","description":"[{{ project_name|capitalize }}]({{ project_url }}) organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emby-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/emby"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-emby"}],"containers":[{"name":"emby","image":"linuxserver/emby","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/opt/vc/lib","description":"Path for Raspberry Pi OpenMAX libs *optional*."},{"container":"/config","description":"Emby data storage location. *This can grow very large, 50gb+ is likely for a large collection.*","key":"config"},{"container":"/data/tvshows","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"container":"/data/movies","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"ports":[{"container":"8096","description":"Http webUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"emby","project_url":"https://emby.media/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emby-logo.png","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server.","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable emby releases"},{"tag":"beta","desc":"Beta emby releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/library","desc":"Emby data storage location. *This can grow very large, 50gb+ is likely for a large collection.*"},{"vol_path":"/data/tvshows","vol_host_path":"/path/to/tvshows","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"vol_path":"/data/movies","vol_host_path":"/path/to/movies","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8096","internal_port":"8096","port_desc":"Http webUI."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/opt/vc/lib","vol_host_path":"/opt/vc/lib","desc":"Path for Raspberry Pi OpenMAX libs *optional*."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel or AMD GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/vchiq","device_host_path":"/dev/vchiq","desc":"Only needed if you want to use your Raspberry Pi OpenMax video encoding (Bellagio)."},{"device_path":"/dev/video10","device_host_path":"/dev/video10","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video11","device_host_path":"/dev/video11","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video12","device_host_path":"/dev/video12","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8920","internal_port":"8920","port_desc":"Https webUI (you need to setup your own certificate)."}],"unraid_template_sync":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://<your-ip>:8096`\n\nEmby has very complete and verbose documentation located [here](https://github.com/MediaBrowser/Wiki/wiki) .\n\nHardware acceleration users for Intel Quicksync and AMD VAAPI will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n```--device=/dev/dri:/dev/dri```\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the emby docker.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi OpenMAX will need to mount their /dev/vchiq video device inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n```\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their /dev/video1X devices inside of the container by passing the following options when running or creating the container:\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","changelogs":[{"date":"26.09.22:","desc":"Update chown behavior."},{"date":"18.09.22:","desc":"Migrate to s6v3, rebase to Ubuntu Jammy."},{"date":"19.05.21:","desc":"Structural changes upstream."},{"date":"17.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information. Remove no longer used mapping for /transcode."},{"date":"21.12.20:","desc":"Rebase to Focal, see [here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal) for troubleshooting armhf."},{"date":"03.11.20:","desc":"Fix issue with missing samba folder."},{"date":"13.11.20:","desc":"Fix issue with samba and ffmpeg."},{"date":"03.07.20:","desc":"Add support for amd vaapi hw transcode."},{"date":"29.02.20:","desc":"Add v4l2 support on Raspberry Pi."},{"date":"26.02.20:","desc":"Add openmax support on Raspberry Pi."},{"date":"15.02.20:","desc":"Allow restarting emby from the gui (also allows for auto restarts after addon updates)."},{"date":"02.10.19:","desc":"Improve permission fixing for render and dvb devices."},{"date":"13.08.19:","desc":"Add umask environment variable."},{"date":"24.06.19:","desc":"Fix typos in readme."},{"date":"30.05.19:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://<your-ip>:8096`\n\nEmby has very complete and verbose documentation located [here](https://github.com/MediaBrowser/Wiki/wiki) .\n\nHardware acceleration users for Intel Quicksync and AMD VAAPI will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n```--device=/dev/dri:/dev/dri```\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the emby docker.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi OpenMAX will need to mount their /dev/vchiq video device inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n```\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their /dev/video1X devices inside of the container by passing the following options when running or creating the container:\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","_id":"content:apps:emby.json","_type":"json","title":"Emby","_source":"content","_file":"apps/emby.json","_extension":"json"},{"_path":"/apps/embystat","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"embystat","name":"embystat","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a personal web server that can calculate all kinds of statistics from your (local) Emby server. Just install this on your server and let him calculate all kinds of fun stuff.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/embystat-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/embystat"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-embystat"}],"containers":[{"name":"embystat","image":"linuxserver/embystat","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"/embystat","description":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"6555","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"embystat","project_url":"https://github.com/mregni/EmbyStat","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/embystat-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a personal web server that can calculate all kinds of statistics from your (local) Emby server. Just install this on your server and let him calculate all kinds of fun stuff.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"EmbyStat releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6555","internal_port":"6555","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"/embystat","desc":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:6555`. Follow the setup wizard on initial install.  Then configure the required services.\n","changelogs":[{"date":"11.06.22:","desc":"Rebase to focal, update disable updates flag."},{"date":"08.04.20:","desc":"Structural changes for beta18."},{"date":"04.12.19:","desc":"Disable in app updates."},{"date":"12.11.19:","desc":"Multi-arch builds."},{"date":"10.09.19:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:6555`. Follow the setup wizard on initial install.  Then configure the required services.\n","_id":"content:apps:embystat.json","_type":"json","title":"Embystat","_source":"content","_file":"apps/embystat.json","_extension":"json"},{"_path":"/apps/emulatorjs","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"emulatorjs","name":"emulatorjs","description":"[{{ project_name|capitalize }}]({{ project_url }}) - In browser web based emulation portable to nearly any device for many retro consoles. A mix of emulators is used between Libretro and EmulatorJS.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emulatorjs-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/emulatorjs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-emulatorjs"}],"containers":[{"name":"emulatorjs","image":"linuxserver/emulatorjs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder for reverse proxies IE '/FOLDER/'"}],"volumes":[{"container":"/config","description":"Path to store user profiles","key":"config"},{"container":"/data","description":"Path to store roms/artwork"}],"ports":[{"container":"3000","description":"Rom/artwork management interface, used to generate/manage config files and download artwork","protocol":"tcp","web":false},{"container":"80","description":"Emulation frontend containing static web files used to browse and launch games","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"emulatorjs","project_url":"https://github.com/linuxserver/emulatorjs","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/emulatorjs-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - In browser web based emulation portable to nearly any device for many retro consoles. A mix of emulators is used between Libretro and EmulatorJS.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Path to store user profiles"},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Path to store roms/artwork"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Rom/artwork management interface, used to generate/manage config files and download artwork"},{"external_port":"80","internal_port":"80","port_desc":"Emulation frontend containing static web files used to browse and launch games"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"4001","internal_port":"4001","port_desc":"IPFS peering port, if you want to participate in the P2P network to distribute frontend artwork please forward this to the Internet"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder for reverse proxies IE '/FOLDER/'"}],"app_setup_block_enabled":true,"app_setup_block":"The Backend can be accessed at:\n\n* http://yourhost:3000/\n\nThe first thing you will need to do is click to download the default art/configs from this interface, this will setup a skeleton directory in your `/data` mount. From there add roms to the respective `roms` directories and follow the on screen instructions to add them to your web frontend running on port 80.\n\nThe frontend application has been initially optimized around being used with a standard gamepad (more specifically for modern Xbox consoles that have chromium based Edge browsers). The navigation revolves around the up/down/left/right keys to browse the menus and launch games.\nMobile browsers will function, just keep in mind compatibility will be reduced especially for CD based games.\n\n**It is important to note that some of the current emulators used for this frontend are obfuscated code, efforts are being made to [reverse engineer it](https://github.com/ethanaobrien/emulatorjs/) but you should know it can potentially reach out to third party services if you manually enable features like netplay (this should never happen in a stock setup). The point of this message is that on top of the de-obfuscation effort there is also effort to stop using binary blobs and shift to built from source libretro emscripten blobs, for now this web based emulation stack is the best for useability and compatibility. We are in the process to transitioning to libretro cores for emulators, currently 27/30 emulators have been replaced.**\n\n**For Xbox users please click the select button a couple times after launching a game to ensure the B button does not trigger a \"back\" action in the browser. (official name \"view button\" it is the two small squares) Exiting the controller mode and back to browser controls can be triggered by holding the start button for 3 seconds. (official name \"menu button\" the three lines) You will be unable to use features like save states and modify controller layouts on the emulatorjs based emulators currently as I have not determined a methodology of re-entering controller mode once you exit it. All normal game saves will function given you exit the game play screen cleanly using the B button for back this includes multi disc games for psx. Your game saves are stored in browser storage by hostname so if you make any changes to your local hosted setup (port or IP) the saves will not follow with it. For libretro based emulators you can use the button combination start+select+L+R to access the libretro menu and change settings/save or load/etc.**\n\n**We know about most of the oddities like crackling sound for some emulators, rendering issues, and games unreliably auto launching to fullscreen. In general full CD games on the Xbox web browser do not seem to work due to their size if you have a chd/pbp less than 450 megs it will run. Edge on Xbox has some kind of undocumented ram limitation of about a gigabyte. Until all emulators are transitioned to libretro cores the oddities of using self hosted EmulatorJS will not be something that can or should be solved using hacky workarounds interacting with obfuscated code. Just keep in mind these are full blown machine emulators running in Javascript in a browser, do not expect bare metal performance.**\n\nMounting in existing rom directories can be achieved by pointing to the default folder structure, IE lets say you would like to mount your NES library:\n\n`-v /path/to/nes/roms:/data/nes/roms`\n\nThe folder names are:\n* 3do\n* arcade\n* atari2600\n* atari7800\n* colecovision\n* doom\n* gb\n* gba\n* gbc\n* jaguar\n* lynx\n* msx\n* n64\n* nds\n* nes\n* ngp\n* odyssey2\n* pce\n* psx\n* sega32x\n* segaCD\n* segaGG\n* segaMD\n* segaMS\n* segaSaturn\n* segaSG\n* snes\n* vb\n* vectrex\n* ws\n","changelogs":[{"date":"24.11.22:","desc":"Update IPFS links for chdman."},{"date":"04.04.22:","desc":"Ingest pre-built chdman bins during build time."},{"date":"23.02.22:","desc":"Update ingestion point for emulatorjs bins."},{"date":"25.01.22:","desc":"Allow users to mount in existing rom directories."},{"date":"14.01.22:","desc":"Add profile paths and rebase to Alpine 3.15."},{"date":"04.01.22:","desc":"Add headers needed for Threaded emulators."},{"date":"29.11.21:","desc":"Add wasm mime type to NGINX."},{"date":"26.11.21:","desc":"Configure IPFS in a lower power mode, use homebuilt blobs for emu cores."},{"date":"19.11.21:","desc":"Pin retroarch version."},{"date":"14.11.21:","desc":"Update default cores to ingest."},{"date":"23.10.21:","desc":"Initial release."}]}},"setup":"The Backend can be accessed at:\n\n* http://yourhost:3000/\n\nThe first thing you will need to do is click to download the default art/configs from this interface, this will setup a skeleton directory in your `/data` mount. From there add roms to the respective `roms` directories and follow the on screen instructions to add them to your web frontend running on port 80.\n\nThe frontend application has been initially optimized around being used with a standard gamepad (more specifically for modern Xbox consoles that have chromium based Edge browsers). The navigation revolves around the up/down/left/right keys to browse the menus and launch games.\nMobile browsers will function, just keep in mind compatibility will be reduced especially for CD based games.\n\n**It is important to note that some of the current emulators used for this frontend are obfuscated code, efforts are being made to [reverse engineer it](https://github.com/ethanaobrien/emulatorjs/) but you should know it can potentially reach out to third party services if you manually enable features like netplay (this should never happen in a stock setup). The point of this message is that on top of the de-obfuscation effort there is also effort to stop using binary blobs and shift to built from source libretro emscripten blobs, for now this web based emulation stack is the best for useability and compatibility. We are in the process to transitioning to libretro cores for emulators, currently 27/30 emulators have been replaced.**\n\n**For Xbox users please click the select button a couple times after launching a game to ensure the B button does not trigger a \"back\" action in the browser. (official name \"view button\" it is the two small squares) Exiting the controller mode and back to browser controls can be triggered by holding the start button for 3 seconds. (official name \"menu button\" the three lines) You will be unable to use features like save states and modify controller layouts on the emulatorjs based emulators currently as I have not determined a methodology of re-entering controller mode once you exit it. All normal game saves will function given you exit the game play screen cleanly using the B button for back this includes multi disc games for psx. Your game saves are stored in browser storage by hostname so if you make any changes to your local hosted setup (port or IP) the saves will not follow with it. For libretro based emulators you can use the button combination start+select+L+R to access the libretro menu and change settings/save or load/etc.**\n\n**We know about most of the oddities like crackling sound for some emulators, rendering issues, and games unreliably auto launching to fullscreen. In general full CD games on the Xbox web browser do not seem to work due to their size if you have a chd/pbp less than 450 megs it will run. Edge on Xbox has some kind of undocumented ram limitation of about a gigabyte. Until all emulators are transitioned to libretro cores the oddities of using self hosted EmulatorJS will not be something that can or should be solved using hacky workarounds interacting with obfuscated code. Just keep in mind these are full blown machine emulators running in Javascript in a browser, do not expect bare metal performance.**\n\nMounting in existing rom directories can be achieved by pointing to the default folder structure, IE lets say you would like to mount your NES library:\n\n`-v /path/to/nes/roms:/data/nes/roms`\n\nThe folder names are:\n* 3do\n* arcade\n* atari2600\n* atari7800\n* colecovision\n* doom\n* gb\n* gba\n* gbc\n* jaguar\n* lynx\n* msx\n* n64\n* nds\n* nes\n* ngp\n* odyssey2\n* pce\n* psx\n* sega32x\n* segaCD\n* segaGG\n* segaMD\n* segaMS\n* segaSaturn\n* segaSG\n* snes\n* vb\n* vectrex\n* ws\n","_id":"content:apps:emulatorjs.json","_type":"json","title":"Emulatorjs","_source":"content","_file":"apps/emulatorjs.json","_extension":"json"},{"_path":"/apps/endlessh","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"endlessh","name":"endlessh","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an SSH tarpit that very slowly sends an endless, random SSH banner. It keeps SSH clients locked up for hours or even days at a time. The purpose is to put your real SSH server on another port and then let the script kiddies get stuck in this tarpit instead of bothering a real server.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/openssh-server-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/endlessh"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-endlessh"}],"containers":[{"name":"endlessh","image":"linuxserver/endlessh","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"MSDELAY","default":"10000","description":"The endless banner is sent one line at a time. This is the delay in milliseconds between individual lines."},{"id":"MAXLINES","default":"32","description":"The length of each line is randomized. This controls the maximum length of each line. Shorter lines may keep clients on for longer if they give up after a certain number of bytes."},{"id":"MAXCLIENTS","default":"4096","description":"Maximum number of connections to accept at a time. Connections beyond this are not immediately rejected, but will wait in the queue."},{"id":"LOGFILE","default":"false","description":"By default, the app logs to container log. If this is set to `true`, the log will be output to file under `/config/logs/endlessh` (`/config` needs to be mapped)."},{"id":"BINDFAMILY","default":"","description":"By default, the app binds to IPv4 and IPv6 addresses. Set it to `4` or `6` to bind to IPv4 only or IPv6 only, respectively. Leave blank to bind to both."}],"ports":[{"container":"2222","description":"ssh port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"endlessh","project_url":"https://github.com/skeeto/endlessh","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/openssh-server-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an SSH tarpit that very slowly sends an endless, random SSH banner. It keeps SSH clients locked up for hours or even days at a time. The purpose is to put your real SSH server on another port and then let the script kiddies get stuck in this tarpit instead of bothering a real server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"22","internal_port":"2222","port_desc":"ssh port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MSDELAY","env_value":"10000","desc":"The endless banner is sent one line at a time. This is the delay in milliseconds between individual lines."},{"env_var":"MAXLINES","env_value":"32","desc":"The length of each line is randomized. This controls the maximum length of each line. Shorter lines may keep clients on for longer if they give up after a certain number of bytes."},{"env_var":"MAXCLIENTS","env_value":"4096","desc":"Maximum number of connections to accept at a time. Connections beyond this are not immediately rejected, but will wait in the queue."},{"env_var":"LOGFILE","env_value":"false","desc":"By default, the app logs to container log. If this is set to `true`, the log will be output to file under `/config/logs/endlessh` (`/config` needs to be mapped)."},{"env_var":"BINDFAMILY","env_value":"","desc":"By default, the app binds to IPv4 and IPv6 addresses. Set it to `4` or `6` to bind to IPv4 only or IPv6 only, respectively. Leave blank to bind to both."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Required if `LOGFILE` is set to `true`."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The app listens on the port mapped for ssh connections. To log to file, set the environment variable `LOGFILE` to `true` and map a volume for `/config`. The logs will be under `/config/logs/endlessh`.\n","changelogs":[{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"20.07.22:","desc":"Rebase to Alpine 3.16."},{"date":"16.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"07.10.21:","desc":"Fix typo on MAXLINES var."},{"date":"08.06.21:","desc":"Add BINDFAMILY option."},{"date":"16.04.21:","desc":"Initial Release."}]}},"setup":"The app listens on the port mapped for ssh connections. To log to file, set the environment variable `LOGFILE` to `true` and map a volume for `/config`. The logs will be under `/config/logs/endlessh`.\n","_id":"content:apps:endlessh.json","_type":"json","title":"Endlessh","_source":"content","_file":"apps/endlessh.json","_extension":"json"},{"_path":"/apps/fail2ban","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"fail2ban","name":"fail2ban","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a daemon to ban hosts that cause multiple authentication errors.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/fail2ban-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/fail2ban"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-fail2ban"}],"containers":[{"name":"fail2ban","image":"linuxserver/fail2ban","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/remotelogs/airsonic:ro","description":"Optional path to airsonic log folder. Mounted as Read Only."},{"container":"/remotelogs/apache2:ro","description":"Optional path to apache2 log folder. Mounted as Read Only."},{"container":"/remotelogs/authelia:ro","description":"Optional path to authelia log folder. Mounted as Read Only."},{"container":"/remotelogs/emby:ro","description":"Optional path to emby log folder. Mounted as Read Only."},{"container":"/remotelogs/filebrowser:ro","description":"Optional path to filebrowser log folder. Mounted as Read Only."},{"container":"/remotelogs/homeassistant:ro","description":"Optional path to homeassistant log folder. Mounted as Read Only."},{"container":"/remotelogs/lighttpd:ro","description":"Optional path to lighttpd log folder. Mounted as Read Only."},{"container":"/remotelogs/nextcloud:ro","description":"Optional path to nextcloud log folder. Mounted as Read Only."},{"container":"/remotelogs/nginx:ro","description":"Optional path to nginx log folder. Mounted as Read Only."},{"container":"/remotelogs/nzbget:ro","description":"Optional path to nzbget log folder. Mounted as Read Only."},{"container":"/remotelogs/overseerr:ro","description":"Optional path to overseerr log folder. Mounted as Read Only."},{"container":"/remotelogs/prowlarr:ro","description":"Optional path to prowlarr log folder. Mounted as Read Only."},{"container":"/remotelogs/radarr:ro","description":"Optional path to radarr log folder. Mounted as Read Only."},{"container":"/remotelogs/sabnzbd:ro","description":"Optional path to sabnzbd log folder. Mounted as Read Only."},{"container":"/remotelogs/sonarr:ro","description":"Optional path to sonarr log folder. Mounted as Read Only."},{"container":"/remotelogs/unificontroller:ro","description":"Optional path to unificontroller log folder. Mounted as Read Only."},{"container":"/remotelogs/vaultwarden:ro","description":"Optional path to vaultwarden log folder. Mounted as Read Only."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/var/log:ro","description":"Host logs. Mounted as Read Only."}]}],"meta":{"readme-vars":{"project_name":"fail2ban","project_url":"http://www.fail2ban.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/fail2ban-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a daemon to ban hosts that cause multiple authentication errors.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."},{"vol_path":"/var/log:ro","vol_host_path":"/var/log","desc":"Host logs. Mounted as Read Only."}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"},{"cap_add_var":"NET_RAW"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/remotelogs/airsonic:ro","vol_host_path":"/path/to/airsonic/log","desc":"Optional path to airsonic log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/apache2:ro","vol_host_path":"/path/to/apache2/log","desc":"Optional path to apache2 log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/authelia:ro","vol_host_path":"/path/to/authelia/log","desc":"Optional path to authelia log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/emby:ro","vol_host_path":"/path/to/emby/log","desc":"Optional path to emby log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/filebrowser:ro","vol_host_path":"/path/to/filebrowser/log","desc":"Optional path to filebrowser log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/homeassistant:ro","vol_host_path":"/path/to/homeassistant/log","desc":"Optional path to homeassistant log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/lighttpd:ro","vol_host_path":"/path/to/lighttpd/log","desc":"Optional path to lighttpd log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nextcloud:ro","vol_host_path":"/path/to/nextcloud/log","desc":"Optional path to nextcloud log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nginx:ro","vol_host_path":"/path/to/nginx/log","desc":"Optional path to nginx log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/nzbget:ro","vol_host_path":"/path/to/nzbget/log","desc":"Optional path to nzbget log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/overseerr:ro","vol_host_path":"/path/to/overseerr/log","desc":"Optional path to overseerr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/prowlarr:ro","vol_host_path":"/path/to/prowlarr/log","desc":"Optional path to prowlarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/radarr:ro","vol_host_path":"/path/to/radarr/log","desc":"Optional path to radarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/sabnzbd:ro","vol_host_path":"/path/to/sabnzbd/log","desc":"Optional path to sabnzbd log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/sonarr:ro","vol_host_path":"/path/to/sonarr/log","desc":"Optional path to sonarr log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/unificontroller:ro","vol_host_path":"/path/to/unificontroller/log","desc":"Optional path to unificontroller log folder. Mounted as Read Only."},{"vol_path":"/remotelogs/vaultwarden:ro","vol_host_path":"/path/to/vaultwarden/log","desc":"Optional path to vaultwarden log folder. Mounted as Read Only."}],"app_setup_block_enabled":true,"app_setup_block":"This container is designed to allow fail2ban to function at the host level, as well as at the docker container level.\nIf you are running applications on the host, you will need to set the `chain` to `INPUT` in the jail for that application.\n\n### [Configuration Files](https://github.com/linuxserver/fail2ban-confs)\n\nOn first run, the container will create a number of folders and files in `/config`. The default configurations for fail2ban are all disabled by default.\n\nPlease refer to the [Configuration README](https://github.com/linuxserver/fail2ban-confs/blob/master/README.md), which can be viewed in our repository, or in your config folder at `/config/fail2ban/README.md`.\n\n### Remote Logs\n\nAll jails require the ability to read the application log files.\nWe recommend mounting each application's log folder as a volume to the container (illustrated by the optional volumes in our documentation).\nMounting individual log files can cause issues and is not recommended.\n\nThe `/remotelogs` path is designed to act as a parent for all log files you would like fail2ban to be able to use.\nEach log file should be mounted in a subfolder underneath `/remotelogs`, ex:\n- `/remotelogs/nginx/` would mount a folder containing the nginx logs to the container\n","changelogs":[{"date":"15.12.22:","desc":"Rebase to Alpine 3.17, Add ssmtp and whois packages. Symlink config to allow live reloading."},{"date":"25.08.22:","desc":"Update README to clarify remote log information."},{"date":"09.08.22:","desc":"Initial Release."}]}},"setup":"This container is designed to allow fail2ban to function at the host level, as well as at the docker container level.\nIf you are running applications on the host, you will need to set the `chain` to `INPUT` in the jail for that application.\n\n### [Configuration Files](https://github.com/linuxserver/fail2ban-confs)\n\nOn first run, the container will create a number of folders and files in `/config`. The default configurations for fail2ban are all disabled by default.\n\nPlease refer to the [Configuration README](https://github.com/linuxserver/fail2ban-confs/blob/master/README.md), which can be viewed in our repository, or in your config folder at `/config/fail2ban/README.md`.\n\n### Remote Logs\n\nAll jails require the ability to read the application log files.\nWe recommend mounting each application's log folder as a volume to the container (illustrated by the optional volumes in our documentation).\nMounting individual log files can cause issues and is not recommended.\n\nThe `/remotelogs` path is designed to act as a parent for all log files you would like fail2ban to be able to use.\nEach log file should be mounted in a subfolder underneath `/remotelogs`, ex:\n- `/remotelogs/nginx/` would mount a folder containing the nginx logs to the container\n","_id":"content:apps:fail2ban.json","_type":"json","title":"Fail2ban","_source":"content","_file":"apps/fail2ban.json","_extension":"json"},{"_path":"/apps/feed2toot","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"feed2toot","name":"feed2toot","description":"[{{ project_name|capitalize }}]({{ project_url }}) automatically parses rss feeds, identifies new posts and posts them on the Mastodon social network.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/feed2toot-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/feed2toot"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-feed2toot"}],"containers":[{"name":"feed2toot","image":"linuxserver/feed2toot","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"FEED_LIMIT","default":"5","description":"Limit number of RSS entries published at each execution."}],"volumes":[{"container":"/config","description":"Local path for feed2toot config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"feed2toot","project_url":"https://gitlab.com/chaica/feed2toot","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/feed2toot-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) automatically parses rss feeds, identifies new posts and posts them on the Mastodon social network.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local path for feed2toot config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"FEED_LIMIT","env_value":"5","desc":"Limit number of RSS entries published at each execution."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Run `docker run --rm -it -w /config -v /path/to/data:/config -e PUID=1000 -e PGID=1000 lscr.io/linuxserver/feed2toot /usr/bin/register_feed2toot_app` to generate credential files (be sure to set the correct volume path and PUID/PGID values).\n\nEdit the feed2toot.ini in /config to configure your instance name and RSS feeds.\n\nSee the [feed2toot docs](https://feed2toot.readthedocs.io/en/latest/) for more information.\n","changelogs":[{"date":"22.12.22:","desc":"Rebase to alpine 3.17."},{"date":"14.11.22:","desc":"Initial Release."}]}},"setup":"Run `docker run --rm -it -w /config -v /path/to/data:/config -e PUID=1000 -e PGID=1000 lscr.io/linuxserver/feed2toot /usr/bin/register_feed2toot_app` to generate credential files (be sure to set the correct volume path and PUID/PGID values).\n\nEdit the feed2toot.ini in /config to configure your instance name and RSS feeds.\n\nSee the [feed2toot docs](https://feed2toot.readthedocs.io/en/latest/) for more information.\n","_id":"content:apps:feed2toot.json","_type":"json","title":"Feed2toot","_source":"content","_file":"apps/feed2toot.json","_extension":"json"},{"_path":"/apps/ffmpeg","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ffmpeg","name":"ffmpeg","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/ffmpeg.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ffmpeg"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ffmpeg"}],"containers":[{"name":"ffmpeg","image":"linuxserver/ffmpeg","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"ffmpeg","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring :-\n\n * regular and timely application updates\n * easy user mappings (PGID, PUID)\n * custom base image with s6 overlay\n * weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n * regular security updates\n\nFind us at:\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [Podcast](https://anchor.fm/linuxserverio) - on hiatus. Coming back soon (late 2018).\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n[![Scarf.io pulls](https://scarf.sh/installs-badge/linuxserver-ci/linuxserver%2Fffmpeg?color=94398d&label-color=555555&logo-color=ffffff&style=for-the-badge&package-type=docker)](https://scarf.sh/gateway/linuxserver-ci/docker/linuxserver%2Fffmpeg)\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-ffmpeg)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-ffmpeg/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-ffmpeg/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/linuxserver.io/docker-ffmpeg/container_registry)\n[![Quay.io](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Quay.io)](https://quay.io/repository/linuxserver.io/ffmpeg)\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/ffmpeg)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/ffmpeg.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/ffmpeg)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-ffmpeg%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-ffmpeg/job/master/)\n\n[FFmpeg](https://ffmpeg.org) - A complete, cross-platform solution to record, convert and stream audio and video.\n\n\n[![ffmpeg](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ffmpeg.png)](https://ffmpeg.org)\n\n## Supported Architectures\n\nWe utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `lscr.io/linuxserver/ffmpeg:latest` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Available | Tag |\n| :----: | :----: | ---- |\n| x86-64 |  | amd64-\\<version tag\\> |\n| arm64 |  | arm64v8-\\<version tag\\> |\n| armhf|  | arm32v7-\\<version tag\\> |\n\n## Usage\n\nUnlike most of our container library this image is meant to be run ephemerally from the command line parsing user input for a custom FFmpeg command. You will need to understand some Docker basics to use this image and be familiar with how to construct an FFmpeg command. In the commands below we will be bind mounting our current working directory from the CLI to /config, the assumption is that input.mkv is in your current working directory.\n\nIf an input file is detected we will run FFmpeg as that user/group so the output file will match it's permissions.\nThe image supports Hardware acceleration on x86 pay close attention to the variables for the examples below.\n\n### Basic Transcode\n\n```\ndocker run --rm -it \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -i /config/input.mkv \\\n  -c:v libx264 \\\n  -b:v 4M \\\n  -vf scale=1280:720 \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n### Hardware accelerated (VAAPI)\n\n```\ndocker run --rm -it \\\n  --device=/dev/dri:/dev/dri \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -vaapi_device /dev/dri/renderD128 \\\n  -i /config/input.mkv \\\n  -c:v h264_vaapi \\\n  -b:v 4M \\\n  -vf 'format=nv12|vaapi,hwupload,scale_vaapi=w=1280:h=720' \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n### Nvidia Hardware accelerated\n\n```\ndocker run --rm -it \\\n  --runtime=nvidia \\\n  -v $(pwd):/config \\\n  linuxserver/ffmpeg \\\n  -hwaccel nvdec \\\n  -i /config/input.mkv \\\n  -c:v h264_nvenc \\\n  -b:v 4M \\\n  -vf scale=1280:720 \\\n  -c:a copy \\\n  /config/output.mkv\n```\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n```\ngit clone https://github.com/linuxserver/docker-ffmpeg.git\ncd docker-ffmpeg\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t linuxserver/ffmpeg:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n```\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **14.12.22:** - Rebase to Jammy, bump to 5.1.2.\n* **19.06.22:** - Rebase to Focal.\n* **26.08.21:** - Add support for libOpenCL.\n* **01.07.21:** - Bump to 4.4.\n* **17.06.20:** - Bump to 4.3.\n* **16.06.20:** - Add support for libvmaf.\n* **01.08.19:** - Initial release.\n{%- endraw %}\n"}},"_id":"content:apps:ffmpeg.json","_type":"json","title":"Ffmpeg","_source":"content","_file":"apps/ffmpeg.json","_extension":"json"},{"_path":"/apps/filezilla","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"filezilla","name":"filezilla","description":"[FIleZilla]({{ project_url }}) Client is a fast and reliable cross-platform FTP, FTPS and SFTP client with lots of useful features and an intuitive graphical user interface.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/filezilla-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/filezilla"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-filezilla"}],"containers":[{"name":"filezilla","image":"linuxserver/filezilla","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"FileZilla desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"filezilla","project_url":"https://filezilla-project.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/filezilla-logo.png","project_blurb":"[FIleZilla]({{ project_url }}) Client is a fast and reliable cross-platform FTP, FTPS and SFTP client with lots of useful features and an intuitive graphical user interface.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"FileZilla desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"18.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:filezilla.json","_type":"json","title":"Filezilla","_source":"content","_file":"apps/filezilla.json","_extension":"json"},{"_path":"/apps/firefox","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"firefox","name":"firefox","description":"[Firefox]({{ project_url }}) Browser, also known as Mozilla Firefox or simply Firefox, is a free and open-source web browser developed by the Mozilla Foundation and its subsidiary, the Mozilla Corporation. Firefox uses the Gecko layout engine to render web pages, which implements current and anticipated web standards.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/firefox-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/firefox"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-firefox"}],"containers":[{"name":"firefox","image":"linuxserver/firefox","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Firefox desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"firefox","project_url":"https://www.mozilla.org/en-US/firefox/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/firefox-logo.png","project_blurb":"[Firefox]({{ project_url }}) Browser, also known as Mozilla Firefox or simply Firefox, is a free and open-source web browser developed by the Mozilla Foundation and its subsidiary, the Mozilla Corporation. Firefox uses the Gecko layout engine to render web pages, which implements current and anticipated web standards.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Firefox desktop gui."}],"custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"This is needed for any modern website to function like youtube."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15, stop using ESR."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"19.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:firefox.json","_type":"json","title":"Firefox","_source":"content","_file":"apps/firefox.json","_extension":"json"},{"_path":"/apps/fleet","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"fleet","name":"fleet","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides an online web interface which displays a set of maintained images from one or more owned repositories.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/fleet.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/fleet"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-fleet"}],"containers":[{"name":"fleet","image":"linuxserver/fleet","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"fleet_admin_authentication_type","default":"DATABASE","description":"A switch to define how Fleet manages user logins. If set to DATABASE, see the related optional params. Can be set to either DATABASE or PROPERTIES."},{"id":"fleet_database_url","default":"jdbc:mariadb://<url>:3306/fleet","description":"The full JDBC connection string to the Fleet database"},{"id":"fleet_database_username","default":"fleet_user","description":"The username with the relevant GRANT permissions for the database"},{"id":"fleet_database_password","default":"dbuserpassword","description":"The database user's password."},{"id":"fleet_admin_secret","default":"randomstring","description":"A string used as part of the password key derivation process."}],"volumes":[{"container":"/config","description":"The primary config file and rolling log files.","key":"config"}],"ports":[{"container":"8080","description":"Http port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"fleet","project_url":"https://github.com/linuxserver/fleet","project_logo":"","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides an online web interface which displays a set of maintained images from one or more owned repositories.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"fleet_admin_authentication_type","env_value":"DATABASE","desc":"A switch to define how Fleet manages user logins. If set to DATABASE, see the related optional params. Can be set to either DATABASE or PROPERTIES."},{"env_var":"fleet_database_url","env_value":"jdbc:mariadb://<url>:3306/fleet","desc":"The full JDBC connection string to the Fleet database"},{"env_var":"fleet_database_username","env_value":"fleet_user","desc":"The username with the relevant GRANT permissions for the database"},{"env_var":"fleet_database_password","env_value":"dbuserpassword","desc":"The database user's password."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"The primary config file and rolling log files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Http port"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"fleet_admin_secret","env_value":"randomstring","desc":"A string used as part of the password key derivation process."}],"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Navigate to `http://your_ip_here:8080` to display the home page. If `DATABASE` is selected as the preferred authentication process, ensure that you set up an\ninitial user via `http://your_ip_here:8080/setup`. Once done, that page will no longer be available. A restart is preferable as it will remove the page altogether.\nOnce complete, you can log into the app via `http://your_ip_here:8080/login` to manage your repositories.\n","changelogs":[{"date":"02.05.22:","desc":"Rebase to Alpine 3.15."},{"date":"13.12.21:","desc":"Add mitigations for CVE-2021-44228"},{"date":"26.04.20:","desc":"Updated to keep in line with v2.0.0 branch of Fleet"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"02.07.19:","desc":"Rebasing to alpine 3.10."},{"date":"02.07.19:","desc":"Stop container if fleet fails."},{"date":"19.05.19:","desc":"Use new base images for arm versions."},{"date":"01.04.19:","desc":"Initial Release"}]}},"setup":"Navigate to `http://your_ip_here:8080` to display the home page. If `DATABASE` is selected as the preferred authentication process, ensure that you set up an\ninitial user via `http://your_ip_here:8080/setup`. Once done, that page will no longer be available. A restart is preferable as it will remove the page altogether.\nOnce complete, you can log into the app via `http://your_ip_here:8080/login` to manage your repositories.\n","_id":"content:apps:fleet.json","_type":"json","title":"Fleet","_source":"content","_file":"apps/fleet.json","_extension":"json"},{"_path":"/apps/foldingathome","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"foldingathome","name":"foldingathome","description":"[Folding@home]({{ project_url }}) is a distributed computing project for simulating protein dynamics, including the process of protein folding and the movements of proteins implicated in a variety of diseases. It brings together citizen scientists who volunteer to run simulations of protein dynamics on their personal computers. Insights from this data are helping scientists to better understand biology, and providing new opportunities for developing therapeutics.","icon":"https://foldingathome.org/wp-content/uploads/2016/09/folding-at-home-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/foldingathome"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-foldingathome"}],"containers":[{"name":"foldingathome","image":"linuxserver/foldingathome","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Folding@home should store its database and config.","key":"config"}],"ports":[{"container":"7396","description":"Folding@home web gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"foldingathome","project_url":"https://foldingathome.org/","project_logo":"https://foldingathome.org/wp-content/uploads/2016/09/folding-at-home-logo.png","project_blurb":"[Folding@home]({{ project_url }}) is a distributed computing project for simulating protein dynamics, including the process of protein folding and the movements of proteins implicated in a variety of diseases. It brings together citizen scientists who volunteer to run simulations of protein dynamics on their personal computers. Insights from this data are helping scientists to better understand biology, and providing new opportunities for developing therapeutics.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where Folding@home should store its database and config."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"7396","internal_port":"7396","port_desc":"Folding@home web gui."}],"param_device_map":false,"cap_add_param":false,"cap_add_param_vars":"","opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"36330","internal_port":"36330","port_desc":"Optional port for connecting remotely via FAHControl app (no password)."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU (vaapi)."}],"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"This image sets up the Folding@home client. The interface is available at `http://your-ip:7396`.\n\nThe built-in webserver provides very basic control (ie. GPUs are only active when set to `Medium` or higher). For more fine grained control of individual devices, you can use the FAHControl app on a different device and connect remotely via port `36330` (no password).\n\nThere are a couple of minor issues with the webgui:\n- If you get an \"ERR_EMPTY_RESPONSE\" error when trying to access via IP, it's most likely due to a clash of cookies/cache. Try opening in an incgnito window.\n- If you're getting a constant refresh of the window but no display of info, try a force refresh via `shft-F5` or `ctrl-F5`.\n\n## GPU Hardware Acceleration\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the foldingathome docker container.\n","changelogs":[{"date":"14.12.22:","desc":"Rebase to Ubuntu Jammy, migrate to s6v3."},{"date":"15.01.22:","desc":"Rebase to Ubuntu Focal. Add arm64v8 builds (cpu only). Increase verbosity about gpu driver permission settings."},{"date":"09.01.21:","desc":"Add nvidia.icd."},{"date":"14.04.20:","desc":"Add Folding@home donation links."},{"date":"20.03.20:","desc":"Initial release."}]}},"setup":"This image sets up the Folding@home client. The interface is available at `http://your-ip:7396`.\n\nThe built-in webserver provides very basic control (ie. GPUs are only active when set to `Medium` or higher). For more fine grained control of individual devices, you can use the FAHControl app on a different device and connect remotely via port `36330` (no password).\n\nThere are a couple of minor issues with the webgui:\n- If you get an \"ERR_EMPTY_RESPONSE\" error when trying to access via IP, it's most likely due to a clash of cookies/cache. Try opening in an incgnito window.\n- If you're getting a constant refresh of the window but no display of info, try a force refresh via `shft-F5` or `ctrl-F5`.\n\n## GPU Hardware Acceleration\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the foldingathome docker container.\n","_id":"content:apps:foldingathome.json","_type":"json","title":"Foldingathome","_source":"content","_file":"apps/foldingathome.json","_extension":"json"},{"_path":"/apps/freshrss","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"freshrss","name":"freshrss","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, self-hostable aggregator for rss feeds.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/freshrss-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/freshrss"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-freshrss"}],"containers":[{"name":"freshrss","image":"linuxserver/freshrss","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Local storage for freshrss site files.","key":"config"}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"freshrss","project_url":"https://freshrss.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/freshrss-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, self-hostable aggregator for rss feeds.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local storage for freshrss site files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui set up wizard at `http://serverIP:port`\n\nFor external databases, create a user and database in your mysql/mariadb server (not root) and then follow the setup wizard in the webui. Use the IP address for \"host\" of your database server.  \n\nAdditional extensions can be dropped into `/config/www/freshrss/extensions` and will be active after container restart.\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"21.10.22:","desc":"Fix cron init to properly migrate existing installations to new app location."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"31.03.20:","desc":"Internalize app and enable updates for existing users, allow user customized crontab."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Add multi arch and pipeline logic."},{"date":"05.09.18:","desc":"Rebase to alpine linux 3.8."},{"date":"17.03.18:","desc":"Update nginx config to resolve api not working."},{"date":"08.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"23.02.17:","desc":"Rebase to alpine linux 3.5 and nginx."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"08.10.16:","desc":"Add Sqlite support for standalone operation."},{"date":"27.09.16:","desc":"Fix for cron job."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"23.11.15:","desc":"Update dependencies to latest requirements."},{"date":"21.08.15:","desc":"Initial Release."}]}},"setup":"Access the webui set up wizard at `http://serverIP:port`\n\nFor external databases, create a user and database in your mysql/mariadb server (not root) and then follow the setup wizard in the webui. Use the IP address for \"host\" of your database server.  \n\nAdditional extensions can be dropped into `/config/www/freshrss/extensions` and will be active after container restart.\n","_id":"content:apps:freshrss.json","_type":"json","title":"Freshrss","_source":"content","_file":"apps/freshrss.json","_extension":"json"},{"_path":"/apps/grav","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"grav","name":"grav","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Fast, Simple, and Flexible, file-based Web-platform.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/grav-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/grav"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-grav"}],"containers":[{"name":"grav","image":"linuxserver/grav","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"grav","project_url":"https://github.com/getgrav/grav/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/grav-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Fast, Simple, and Flexible, file-based Web-platform.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"For more information check out the [Grav documentation](https://learn.getgrav.org/). Our image includes the [grav-admin](https://github.com/getgrav/grav-plugin-admin) plugin.\n\nTo use the CLI tools you need to pass the working directory as part of your exec command (or use an interactive shell), e.g. `docker exec -it -w /app/www/public grav bin/gpm`\n","changelogs":[{"date":"11.12.22:","desc":"Rebase to Alpine 3.17, PHP 8.1."},{"date":"05.09.22:","desc":"All php to read envs passed to container."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"03.09.21:","desc":"Added support for Redis caching."},{"date":"01.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"09.04.21:","desc":"Initial Release."}]}},"setup":"For more information check out the [Grav documentation](https://learn.getgrav.org/). Our image includes the [grav-admin](https://github.com/getgrav/grav-plugin-admin) plugin.\n\nTo use the CLI tools you need to pass the working directory as part of your exec command (or use an interactive shell), e.g. `docker exec -it -w /app/www/public grav bin/gpm`\n","_id":"content:apps:grav.json","_type":"json","title":"Grav","_source":"content","_file":"apps/grav.json","_extension":"json"},{"_path":"/apps/grocy","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"grocy","name":"grocy","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an ERP system for your kitchen! Cut down on food waste, and manage your chores with this brilliant utility.\n\nKeep track of your purchases, how much food you are wasting, what chores need doing and what batteries need charging with this proudly Open Source tool\n\nFor more information on grocy visit their website and check it out: https://grocy.info\n","icon":"https://grocy.info/img/grocy_logo.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/grocy"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-grocy"}],"containers":[{"name":"grocy","image":"linuxserver/grocy","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"for specifying your timezone"}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"}],"ports":[{"container":"80","description":"will map the container's port 80 to port 9283 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"grocy","project_url":"https://github.com/grocy/grocy","project_logo":"https://grocy.info/img/grocy_logo.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an ERP system for your kitchen! Cut down on food waste, and manage your chores with this brilliant utility.\n\nKeep track of your purchases, how much food you are wasting, what chores need doing and what batteries need charging with this proudly Open Source tool\n\nFor more information on grocy visit their website and check it out: https://grocy.info\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"for specifying your timezone"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9283","internal_port":"80","port_desc":"will map the container's port 80 to port 9283 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Grocy is simple to get running. Configure the container with instructions below, start it, and you can then access it\nby visiting http://your.ip:9283 - once the page loads, you can log in with the default username and password of admin / admin\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.08.21:","desc":"Rebase to Alpine 3.14 and PHP 8."},{"date":"25.07.21:","desc":"Add 'int','json' and 'zlib' PHP extensions."},{"date":"10.05.21:","desc":"Reduce image size."},{"date":"08.04.21:","desc":"Update docs to reflect jenkins builder changes."},{"date":"17.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.01.21:","desc":"Add 'ldap' PHP extension."},{"date":"22.12.20:","desc":"Add 'ctype' PHP extension."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"22.09.19:","desc":"Add 'gd' PHP extension."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"27.12.18:","desc":"Initial Release."}]}},"setup":"Grocy is simple to get running. Configure the container with instructions below, start it, and you can then access it\nby visiting http://your.ip:9283 - once the page loads, you can log in with the default username and password of admin / admin\n","_id":"content:apps:grocy.json","_type":"json","title":"Grocy","_source":"content","_file":"apps/grocy.json","_extension":"json"},{"_path":"/apps/guacd","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"guacd","name":"guacd","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. This container is only the backend server component needed to use The official or 3rd party HTML5 frontends.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/guacd.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/guacd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-guacd"}],"containers":[{"name":"guacd","image":"linuxserver/guacd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"ports":[{"container":"4822","description":"Port Guacamole server listens on","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"guacd","project_url":"https://guacamole.apache.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/guacd.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Apache Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. This container is only the backend server component needed to use The official or 3rd party HTML5 frontends.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","common_param_env_vars_enabled":false,"param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"4822","internal_port":"4822","port_desc":"Port Guacamole server listens on"}],"param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"This is a backend only service, to leverage Guacd server you need to use either the official Java frontend [guacamole-client](https://github.com/apache/guacamole-client) or an open source alternative like [guacamole-lite](https://github.com/vadimpronin/guacamole-lite). \n","changelogs":[{"date":"11.03.22:","desc":"Bump to 1.4.0."},{"date":"15.05.21:","desc":"Add terminus font for SSH support."},{"date":"08.05.21:","desc":"Bump to 1.3.0, rebase to Alpine."},{"date":"27.07.20:","desc":"Bump to 1.2.0."},{"date":"17.04.20:","desc":"Bump back 1.1.0, rebase to focal"},{"date":"08.02.20:","desc":"Bump to 1.1.0."},{"date":"25.05.19:","desc":"Initial Release."}]}},"setup":"This is a backend only service, to leverage Guacd server you need to use either the official Java frontend [guacamole-client](https://github.com/apache/guacamole-client) or an open source alternative like [guacamole-lite](https://github.com/vadimpronin/guacamole-lite). \n","_id":"content:apps:guacd.json","_type":"json","title":"Guacd","_source":"content","_file":"apps/guacd.json","_extension":"json"},{"_path":"/apps/habridge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"habridge","name":"habridge","description":"[{{ project_name|capitalize }}]({{ project_url }}) emulates Philips Hue API to other home automation gateways such as an Amazon Echo/Dot Gen 1 (gen 2 has issues discovering ha-bridge) or other systems that support Philips Hue. The Bridge handles basic commands such as \"On\", \"Off\" and \"brightness\" commands of the hue protocol. This bridge can control most devices that have a distinct API.\n\nIn the cases of systems that require authorization and/or have APIs that cannot be handled in the current method, a module may need to be built. The Harmony Hub is such a module and so is the Nest module. The Bridge has helpers to build devices for the gateway for the Logitech Harmony Hub, Vera, Vera Lite or Vera Edge, Nest, Somfy Tahoma, Home Assistant, Domoticz, MQTT, HAL, Fibaro, HomeWizard, LIFX, OpenHAB, FHEM, Broadlink and the ability to proxy all of your real Hue bridges behind this bridge.\n\nThis bridge was built to help put the Internet of Things together.\n\nFor more information about how to use this software have a look at their Wiki [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","icon":"https://raw.githubusercontent.com/bwssytems/ha-bridge/master/src/main/resources/public/img/favicon.ico","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/habridge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-habridge"}],"containers":[{"name":"habridge","image":"linuxserver/habridge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"SEC_KEY","default":"<Your Key To Encrypt Security Data>","description":"Key used to secure communication."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where HABridge stores config files and data.","key":"config"}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"50000","description":"HABridge communication port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"habridge","project_url":"http://bwssystems.com/#/habridge","project_logo":"https://raw.githubusercontent.com/bwssytems/ha-bridge/master/src/main/resources/public/img/favicon.ico","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) emulates Philips Hue API to other home automation gateways such as an Amazon Echo/Dot Gen 1 (gen 2 has issues discovering ha-bridge) or other systems that support Philips Hue. The Bridge handles basic commands such as \"On\", \"Off\" and \"brightness\" commands of the hue protocol. This bridge can control most devices that have a distinct API.\n\nIn the cases of systems that require authorization and/or have APIs that cannot be handled in the current method, a module may need to be built. The Harmony Hub is such a module and so is the Nest module. The Bridge has helpers to build devices for the gateway for the Logitech Harmony Hub, Vera, Vera Lite or Vera Edge, Nest, Somfy Tahoma, Home Assistant, Domoticz, MQTT, HAL, Fibaro, HomeWizard, LIFX, OpenHAB, FHEM, Broadlink and the ability to proxy all of your real Hue bridges behind this bridge.\n\nThis bridge was built to help put the Internet of Things together.\n\nFor more information about how to use this software have a look at their Wiki [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"SEC_KEY","env_value":"<Your Key To Encrypt Security Data>","desc":"Key used to secure communication."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where HABridge stores config files and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"50000","internal_port":"50000","port_desc":"HABridge communication port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"To set up the ha-bridge simply go to http://localhost:8080. Once you are in the webui you can add devices and configure ha-bridge to your liking.\n\nFor information on how to configure ha-bridge, go to their wiki at [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","changelogs":[{"date":"11.12.22:","desc":"Rebasing to alpine 3.17."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"28.08.18:","desc":"Rebase to alpine 3.8."},{"date":"12.04.18:","desc":"Add workaround to bind to port 80 if needed."},{"date":"08.04.18:","desc":"Initial Release."}]}},"setup":"To set up the ha-bridge simply go to http://localhost:8080. Once you are in the webui you can add devices and configure ha-bridge to your liking.\n\nFor information on how to configure ha-bridge, go to their wiki at [https://github.com/bwssytems/ha-bridge/wiki](https://github.com/bwssytems/ha-bridge/wiki)\n","_id":"content:apps:habridge.json","_type":"json","title":"Habridge","_source":"content","_file":"apps/habridge.json","_extension":"json"},{"_path":"/apps/headphones","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"headphones","name":"headphones","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated music downloader for NZB and Torrent, written in Python. It supports SABnzbd, NZBget, Transmission, Torrent and Blackhole.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/headphones-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/headphones"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-headphones"}],"containers":[{"name":"headphones","image":"linuxserver/headphones","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"VERSION","default":"latest","description":"Supported values are LATEST, PLEXPASS or a specific version number."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/downloads","description":"ISOs."},{"container":"/music","description":"Your music directory."}],"ports":[{"container":"8181","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"headphones","project_url":"https://github.com/rembo10/headphones","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/headphones-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated music downloader for NZB and Torrent, written in Python. It supports SABnzbd, NZBget, Transmission, Torrent and Blackhole.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."},{"vol_path":"/downloads","vol_host_path":"</path/to/downloads>","desc":"ISOs."},{"vol_path":"/music","vol_host_path":"</path/to/music>","desc":"Your music directory."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8181","internal_port":"8181","port_desc":"Application WebUI"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":false,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"VERSION","env_value":"latest","desc":"Supported values are LATEST, PLEXPASS or a specific version number."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."}],"opt_param_usage_include_ports":false,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":["```","include optional stuff","```"],"app_setup_block_enabled":false,"app_setup_block":"","changelogs":[{"date":"02.02.22:","desc":"Rebasing to alpine 3.15. Updating to Python 3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"09.05.19:","desc":"Add default UTC timezone if user does not set it."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.08.18:","desc":"Rebase to alpine 3.8."},{"date":"03.04.18:","desc":"Remove forced port and update README."},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Add flac package to handle FLAC based .cue."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.05.17:","desc":"Reduce layer, replace broken source for shntool."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"23.12.16:","desc":"Fix capitalisation in README."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README, compile shntool."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"18.07.15:","desc":"Inital Release"}]}},"_id":"content:apps:headphones.json","_type":"json","title":"Headphones","_source":"content","_file":"apps/headphones.json","_extension":"json"},{"_path":"/apps/healthchecks","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"healthchecks","name":"healthchecks","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.\n","icon":"https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/welcome.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/healthchecks"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-healthchecks"}],"containers":[{"name":"healthchecks","image":"linuxserver/healthchecks","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"SITE_ROOT","default":"","description":"The site's top-level URL and the port it listens to if differrent than 80 or 443 (e.g., https://healthchecks.example.com:8000)"},{"id":"SITE_NAME","default":"","description":"The site's name (e.g., \"Example Corp HealthChecks\")"},{"id":"DEFAULT_FROM_EMAIL","default":"","description":"From email for alerts"},{"id":"EMAIL_HOST","default":"","description":"SMTP host"},{"id":"EMAIL_PORT","default":"","description":"SMTP port"},{"id":"EMAIL_HOST_USER","default":"","description":"SMTP user"},{"id":"EMAIL_HOST_PASSWORD","default":"","description":"SMTP password"},{"id":"EMAIL_USE_TLS","default":"","description":"Use TLS for SMTP (`True` or `False`)"},{"id":"SUPERUSER_EMAIL","default":"","description":"Superuser email"},{"id":"SUPERUSER_PASSWORD","default":"","description":"Superuser password"},{"id":"REGENERATE_SETTINGS","default":"","description":"Defaults to False. Set to True to always override the `local_settings.py` file with values from environment variables. Do not set to True if you have made manual modifications to this file."},{"id":"ALLOWED_HOSTS","default":"","description":"Array of valid hostnames for the server `[\"test.com\",\"test2.com\"]` (default: `[\"*\"]`)"},{"id":"APPRISE_ENABLED","default":"","description":"Defaults to False. A boolean that turns on/off the Apprise integration (https://github.com/caronc/apprise)"},{"id":"DEBUG","default":"","description":"Defaults to True. Debug mode relaxes CSRF protections and increases logging verbosity but should be disabled for production instances as it will impact performance and security."},{"id":"INTEGRATIONS_ALLOW_PRIVATE_IPS","default":"","description":"Defaults to False. Set to True to allow integrations to connect to private IP addresses."},{"id":"PING_EMAIL_DOMAIN","default":"","description":"The domain to use for generating ping email addresses."},{"id":"SECRET_KEY","default":"","description":"A secret key used for cryptographic signing. Will generate a secure value if one is not supplied"},{"id":"SITE_LOGO_URL","default":"","description":"Full URL to custom site logo"}],"volumes":[{"container":"/config","description":"Database and healthchecks config directory","key":"config"}],"ports":[{"container":"8000","description":"Healthchecks Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"healthchecks","project_url":"https://github.com/healthchecks/healthchecks","project_logo":"https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/welcome.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and healthchecks config directory"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"SITE_ROOT","env_value":"","desc":"The site's top-level URL and the port it listens to if differrent than 80 or 443 (e.g., https://healthchecks.example.com:8000)"},{"env_var":"SITE_NAME","env_value":"","desc":"The site's name (e.g., \"Example Corp HealthChecks\")"},{"env_var":"DEFAULT_FROM_EMAIL","env_value":"","desc":"From email for alerts"},{"env_var":"EMAIL_HOST","env_value":"","desc":"SMTP host"},{"env_var":"EMAIL_PORT","env_value":"","desc":"SMTP port"},{"env_var":"EMAIL_HOST_USER","env_value":"","desc":"SMTP user"},{"env_var":"EMAIL_HOST_PASSWORD","env_value":"","desc":"SMTP password"},{"env_var":"EMAIL_USE_TLS","env_value":"","desc":"Use TLS for SMTP (`True` or `False`)"},{"env_var":"SUPERUSER_EMAIL","env_value":"","desc":"Superuser email"},{"env_var":"SUPERUSER_PASSWORD","env_value":"","desc":"Superuser password"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"REGENERATE_SETTINGS","env_value":"","desc":"Defaults to False. Set to True to always override the `local_settings.py` file with values from environment variables. Do not set to True if you have made manual modifications to this file."},{"env_var":"ALLOWED_HOSTS","env_value":"","desc":"Array of valid hostnames for the server `[\"test.com\",\"test2.com\"]` (default: `[\"*\"]`)"},{"env_var":"APPRISE_ENABLED","env_value":"","desc":"Defaults to False. A boolean that turns on/off the Apprise integration (https://github.com/caronc/apprise)"},{"env_var":"DEBUG","env_value":"","desc":"Defaults to True. Debug mode relaxes CSRF protections and increases logging verbosity but should be disabled for production instances as it will impact performance and security."},{"env_var":"INTEGRATIONS_ALLOW_PRIVATE_IPS","env_value":"","desc":"Defaults to False. Set to True to allow integrations to connect to private IP addresses."},{"env_var":"PING_EMAIL_DOMAIN","env_value":"","desc":"The domain to use for generating ping email addresses."},{"env_var":"SECRET_KEY","env_value":"","desc":"A secret key used for cryptographic signing. Will generate a secure value if one is not supplied"},{"env_var":"SITE_LOGO_URL","env_value":"","desc":"Full URL to custom site logo"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Healthchecks Web UI"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"2525","internal_port":"2525","port_desc":"Port for inbound SMTP pings"}],"app_setup_block_enabled":true,"app_setup_block":"Access the WebUI at <your-ip>:8000. For more information, check out [Healthchecks](https://github.com/healthchecks/healthchecks).\n","changelogs":[{"date":"22.12.22:","desc":"Rebase to Alpine 3.17. Add extra deps for pycurl. Add INTEGRATIONS_ALLOW_PRIVATE_IPS."},{"date":"18.10.22:","desc":"Add curl-dev to fix broken pip builds."},{"date":"11.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"27.09.22:","desc":"Fix sending of Email Reports"},{"date":"08.01.22:","desc":"Fix CSRF setting for Django 4.0 (introduced in v1.25.0)"},{"date":"11.11.21:","desc":"Add Apprise to Docker as in v1.24.0"},{"date":"10.09.21:","desc":"Fix creation of superuser"},{"date":"07.08.21:","desc":"Update custom logo handling to support changes in v1.22.0"},{"date":"11.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"18.05.21:","desc":"Add linuxserver wheel index."},{"date":"11.01.21:","desc":"Add libffi-dev to allow building of python cryptography lib."},{"date":"19.07.20:","desc":"Rebasing to alpine 3.12, fixed 'ALLOWED_HOSTS' bug, now defaults to wildcard"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"31.10.19:","desc":"Add postgres client and fix config for CSRF."},{"date":"23.10.19:","desc":"Allow to create superuser"},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.04.19:","desc":"Rebase to Alpine 3.9."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.02.19:","desc":"Adding mysql libs needed for using a database."},{"date":"11.10.18:","desc":"adding pipeline logic and multi arching release"},{"date":"15.11.17:","desc":"`git pull` is now in Dockerfile so each tagged container contains the same code version"},{"date":"17.10.17:","desc":"Fixed `local_settings.py` output"},{"date":"27.09.17:","desc":"Initial Release."}]}},"setup":"Access the WebUI at <your-ip>:8000. For more information, check out [Healthchecks](https://github.com/healthchecks/healthchecks).\n","_id":"content:apps:healthchecks.json","_type":"json","title":"Healthchecks","_source":"content","_file":"apps/healthchecks.json","_extension":"json"},{"_path":"/apps/hedgedoc","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"hedgedoc","name":"hedgedoc","description":"[HedgeDoc]({{ project_url }}) gives you access to all your files wherever you are.\n\nHedgeDoc is a real-time, multi-platform collaborative markdown note editor.  This means that you can write notes with other people on your desktop, tablet or even on the phone.  You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hedgedoc-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/hedgedoc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-hedgedoc"}],"containers":[{"name":"hedgedoc","image":"linuxserver/hedgedoc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"DB_HOST","default":"<hostname or ip>","description":"Host address of mysql database"},{"id":"DB_PORT","default":"3306","description":"Port to access mysql database default is 3306"},{"id":"DB_USER","default":"hedgedoc","description":"Database user"},{"id":"DB_PASS","default":"<secret password>","description":"Database password"},{"id":"DB_NAME","default":"hedgedoc","description":"Database name"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CMD_DOMAIN","default":"localhost","description":"The address the gui will be accessed at (ie. `192.168.1.1` or `hedgedoc.domain.com`)."},{"id":"CMD_URL_ADDPORT","default":"false","description":"Set to `true` if using a port other than `80` or `443`."},{"id":"CMD_PROTOCOL_USESSL","default":"false","description":"Set to `true` if accessing over https via reverse proxy."},{"id":"CMD_PORT","default":"3000","description":"If you wish to access hedgedoc at a port different than 80, 443 or 3000, you need to set this to that port (ie. `CMD_PORT=5000`) and change the port mapping accordingly (5000:5000)."},{"id":"CMD_ALLOW_ORIGIN","default":"['localhost']","description":"Comma-separated list of allowed hostnames"}],"volumes":[{"container":"/config","description":"HedgeDoc config and configurable files","key":"config"}],"ports":[{"container":"3000","description":"Web gui port (internal port also needs to be changed if accessing at port other than 80, 443 and 3000).","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"hedgedoc","project_url":"https://hedgedoc.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hedgedoc-banner.png","project_blurb":"[HedgeDoc]({{ project_url }}) gives you access to all your files wherever you are.\n\nHedgeDoc is a real-time, multi-platform collaborative markdown note editor.  This means that you can write notes with other people on your desktop, tablet or even on the phone.  You can sign-in via multiple auth providers like Facebook, Twitter, GitHub and many more on the homepage.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"DB_HOST","env_value":"<hostname or ip>","desc":"Host address of mysql database"},{"env_var":"DB_PORT","env_value":"3306","desc":"Port to access mysql database default is 3306"},{"env_var":"DB_USER","env_value":"hedgedoc","desc":"Database user"},{"env_var":"DB_PASS","env_value":"<secret password>","desc":"Database password"},{"env_var":"DB_NAME","env_value":"hedgedoc","desc":"Database name"},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"CMD_DOMAIN","env_value":"localhost","desc":"The address the gui will be accessed at (ie. `192.168.1.1` or `hedgedoc.domain.com`)."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CMD_URL_ADDPORT","env_value":"false","desc":"Set to `true` if using a port other than `80` or `443`."},{"env_var":"CMD_PROTOCOL_USESSL","env_value":"false","desc":"Set to `true` if accessing over https via reverse proxy."},{"env_var":"CMD_PORT","env_value":"3000","desc":"If you wish to access hedgedoc at a port different than 80, 443 or 3000, you need to set this to that port (ie. `CMD_PORT=5000`) and change the port mapping accordingly (5000:5000)."},{"env_var":"CMD_ALLOW_ORIGIN","env_value":"['localhost']","desc":"Comma-separated list of allowed hostnames"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"HedgeDoc config and configurable files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web gui port (internal port also needs to be changed if accessing at port other than 80, 443 and 3000)."}],"app_setup_block_enabled":true,"app_setup_block":"HedgeDoc web interface can be accessed `http://${IP}:3000/`, if you want to use a custom domain or anything besides port 3000 you will need to leverage their env settings for callbacks: (specifically for CMD_DOMAIN, CMD_PORT and CMD_URL_ADDPORT)\n\n[Full list of HedgeDoc options](https://docs.hedgedoc.org/configuration/)\n\nFor convience we provide a working example using Mysql as a backend in this document, if you do not wish to use our custom environment values or a Mysql database backend feel free to leverage any of the settings laid out in the link above.\n\nTo run behind a reverse proxy we have a [preconfigured config](https://github.com/linuxserver/reverse-proxy-confs/blob/master/hedgedoc.subdomain.conf.sample) using docker networking included in our [SWAG](https://github.com/linuxserver/docker-swag) image and you can read how to use this in the [Reverse Proxy Confs repository](https://github.com/linuxserver/reverse-proxy-confs/#how-to-use-these-reverse-proxy-configs)\n","changelogs":[{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"10.04.22:","desc":"Use python3 to build node sqlite3."},{"date":"10.02.22:","desc":"Rebase to Alpine 3.15."},{"date":"09.02.22:","desc":"Add optional var `CMD_PORT` that is needed for accessing at port other than 80, 443 and 3000."},{"date":"09.12.21:","desc":"Add optional var `CMD_PROTOCOL_USESSL` that is needed for reverse proxy."},{"date":"07.12.21:","desc":"Rebase to ubuntu focal. Update to node 16. Make sure uploads are persistent."},{"date":"15.10.21:","desc":"Add required env var `CMD_DOMAIN`."},{"date":"05.05.21:","desc":"Remove symlinking some folders from config to /opt/hedgedoc/public."},{"date":"03.05.21:","desc":"Remove deprecated sequalizerc step."},{"date":"22.12.20:","desc":"Initial release"}]}},"setup":"HedgeDoc web interface can be accessed `http://${IP}:3000/`, if you want to use a custom domain or anything besides port 3000 you will need to leverage their env settings for callbacks: (specifically for CMD_DOMAIN, CMD_PORT and CMD_URL_ADDPORT)\n\n[Full list of HedgeDoc options](https://docs.hedgedoc.org/configuration/)\n\nFor convience we provide a working example using Mysql as a backend in this document, if you do not wish to use our custom environment values or a Mysql database backend feel free to leverage any of the settings laid out in the link above.\n\nTo run behind a reverse proxy we have a [preconfigured config](https://github.com/linuxserver/reverse-proxy-confs/blob/master/hedgedoc.subdomain.conf.sample) using docker networking included in our [SWAG](https://github.com/linuxserver/docker-swag) image and you can read how to use this in the [Reverse Proxy Confs repository](https://github.com/linuxserver/reverse-proxy-confs/#how-to-use-these-reverse-proxy-configs)\n","_id":"content:apps:hedgedoc.json","_type":"json","title":"Hedgedoc","_source":"content","_file":"apps/hedgedoc.json","_extension":"json"},{"_path":"/apps/heimdall","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"heimdall","name":"heimdall","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to organise all those links to your most used web sites and web applications in a simple way.\n\nSimplicity is the key to Heimdall.\n\nWhy not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/heimdall-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/heimdall"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-heimdall"}],"containers":[{"name":"heimdall","image":"linuxserver/heimdall","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"heimdall","project_url":"https://heimdall.site","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/heimdall-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to organise all those links to your most used web sites and web applications in a simple way.\n\nSimplicity is the key to Heimdall.\n\nWhy not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Heimdall releases."},{"tag":"development","desc":"Latest commit from the github 2.x branch."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the web gui at http://SERVERIP:PORT\n\n\n### Adding password protection\n\nThis image now supports password protection through htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it heimdall htpasswd -c /config/nginx/.htpasswd <username>`. Replace <username> with a username of your choice and you will be asked to enter a password. Uncomment the `basic auth` lines in `/config/nginx/site-confs/default.conf` and restart the container.\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"14.11.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"04.11.22:","desc":"Build commits to upstream branch 2.x for the `development` tag."},{"date":"13.03.21:","desc":"Make searchproviders.yaml user configurable."},{"date":"10.02.21:","desc":"Revert to alpine 3.12 as php 7.4 broke laravel."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"17.08.20:","desc":"Add php7-curl."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"17.01.20:","desc":"Use nginx from baseimage."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"16.07.19:","desc":"Save laravel.log to /config/log/heimdall."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"01.04.19:","desc":"Fix permission detect logic."},{"date":"26.03.19:","desc":"Install Heimdall during container start to prevent delayed start due to overlayfs bug with recursive chown."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"15.03.19:","desc":"Clarify docker image tags in readme."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.18:","desc":"Generate random app key in .env for new installs."},{"date":"20.11.18:","desc":"Upgrade baseimage packages during build."},{"date":"04.11.18:","desc":"Add php7-zip."},{"date":"31.10.18:","desc":"Add queue service."},{"date":"17.10.18:","desc":"Symlink avatars folder."},{"date":"16.10.18:","desc":"Updated fastcgi_params for user login support."},{"date":"07.10.18:","desc":"Symlink `.env` rather than copy. It now resides under `/config/www`"},{"date":"30.09.18:","desc":"Multi-arch image. Move `.env` to `/config`."},{"date":"05.09.18:","desc":"Rebase to alpine linux 3.8."},{"date":"06.03.18:","desc":"Use password protection if htpasswd is set. Existing users can delete their default site config at /config/nginx/site-confs/default.conf and restart the container, a new default site config with htpasswd support will be created in its place"},{"date":"12.02.18:","desc":"Initial Release."}]}},"setup":"Access the web gui at http://SERVERIP:PORT\n\n\n### Adding password protection\n\nThis image now supports password protection through htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it heimdall htpasswd -c /config/nginx/.htpasswd <username>`. Replace <username> with a username of your choice and you will be asked to enter a password. Uncomment the `basic auth` lines in `/config/nginx/site-confs/default.conf` and restart the container.\n","_id":"content:apps:heimdall.json","_type":"json","title":"Heimdall","_source":"content","_file":"apps/heimdall.json","_extension":"json"},{"_path":"/apps/homeassistant","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"homeassistant","name":"homeassistant","description":"[Home Assistant Core]({{ project_url }}) - Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server. \n","icon":"https://github.com/home-assistant/home-assistant.io/raw/next/source/images/favicon-192x192-full.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/homeassistant"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-homeassistant"}],"containers":[{"name":"homeassistant","image":"linuxserver/homeassistant","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify your TimeZone e.g. Europe/London."}],"volumes":[{"container":"/config","description":"Home Assistant config storage path.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"homeassistant","project_url":"https://www.home-assistant.io/","project_logo":"https://github.com/home-assistant/home-assistant.io/raw/next/source/images/favicon-192x192-full.png","project_blurb":"[Home Assistant Core]({{ project_url }}) - Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server. \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"optional_block_1":true,"optional_block_1_items":["#### Host vs. Bridge\n\nHome Assistant can [discover][hb0] and automatically configure\n[zeroconf][hb1]/[mDNS][hb2] and [UPnP][hb3] devices on your network. In\norder for this to work you must create the container with `--net=host`.\n\n[hb0]: https://www.home-assistant.io/integrations/discovery/#mdns-and-upnp\n[hb1]: https://en.wikipedia.org/wiki/Zero-configuration_networking\n[hb2]: https://en.wikipedia.org/wiki/Multicast_DNS\n[hb3]: https://en.wikipedia.org/wiki/Universal_Plug_and_Play\n"],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Home Assistant config storage path."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify your TimeZone e.g. Europe/London."}],"param_usage_include_ports":false,"param_usage_include_net":true,"param_net":"host","param_net_desc":"Shares host networking with container. Required for some devices to be discovered by Home Assistant.","opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8123","internal_port":"8123","port_desc":"Application WebUI, only use this if you are not using host mode."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/path/to/device","device_host_path":"/path/to/device","desc":"For passing through USB, serial or gpio devices."}],"app_setup_block_enabled":true,"app_setup_block":"This image is based on Home Assistant Core.\n\nThe Webui can be found at `http://your-ip:8123`. Follow the wizard to set up Home Assistant.\n","unraid_template_sync":false,"changelogs":[{"date":"16.11.22:","desc":"Fix the dep conflict for google calendar."},{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"29.07.22:","desc":"Improve usb device permission fix."},{"date":"07.07.22:","desc":"Rebase to alpine 3.16, switch to cp310 wheels."},{"date":"07.05.22:","desc":"Build matplotlib with the same Numpy version as HA req."},{"date":"31.03.22:","desc":"Install pycups."},{"date":"07.03.22:","desc":"Install PySwitchbot."},{"date":"02.03.22:","desc":"Update pip and use legacy resolver, clean up temp python files, reduce image size."},{"date":"04.02.22:","desc":"Always compile grpcio on arm32v7 due to pypi pushing a glibc only wheel."},{"date":"12.12.21:","desc":"Use the new `build.yaml` to determine HA base version."},{"date":"25.09.21:","desc":"Use the new lsio homeassistant wheel repo, instead of the HA wheels."},{"date":"13.09.21:","desc":"Build psycopg locally as the HA provided wheel does not seem to work properly."},{"date":"13.09.21:","desc":"Fix setcap in service. Build CISO8601 locally as the HA provided wheel does not seem to work properly."},{"date":"12.09.21:","desc":"Rebase to alpine 3.14. Build on native armhf."},{"date":"09.08.21:","desc":"Fixed broken build caused by missing dependency."},{"date":"01.07.21:","desc":"Remove HACS dependencies as it caused a crash in Home-assistant."},{"date":"25.02.21:","desc":"Add python dependencies from homeassistant base image."},{"date":"07.02.21:","desc":"Fix building from the wrong requirement file. Add ssh client & external DB libs."},{"date":"06.02.21:","desc":"Add iputils so ping works as non root user."},{"date":"30.01.21:","desc":"Initial Release."}]}},"setup":"This image is based on Home Assistant Core.\n\nThe Webui can be found at `http://your-ip:8123`. Follow the wizard to set up Home Assistant.\n","_id":"content:apps:homeassistant.json","_type":"json","title":"Homeassistant","_source":"content","_file":"apps/homeassistant.json","_extension":"json"},{"_path":"/apps/homer","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"homer","name":"Homer","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/homer.png","links":[{"type":"docker","url":"https://hub.docker.com/r/b4bz/homer"},{"type":"github","url":"https://github.com/bastienwirtz/homer"}],"containers":[{"name":"budge","image":"b4bz/homer","env":[{"id":"INIT_ASSETS","description":"Generate default assets","default":"1"}],"volumes":[{"container":"/www/assets","description":"Assets folder","key":"config"}],"ports":[{"key":"webui","container":8080,"description":"WebUI port","protocol":"tcp","web":true}]}],"_id":"content:apps:homer.json","_type":"json","title":"Homer","_source":"content","_file":"apps/homer.json","_extension":"json"},{"_path":"/apps/htpcmanager","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"htpcmanager","name":"htpcmanager","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a front end for many htpc related applications.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/htpcmanager-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/htpcmanager"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-htpcmanager"}],"containers":[{"name":"htpcmanager","image":"linuxserver/htpcmanager","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"8085","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"htpcmanager","project_url":"https://github.com/HTPC-Manager/HTPC-Manager","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/htpcmanager-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a front end for many htpc related applications.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8085","internal_port":"8085","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"The webui is found at port 8085. Smartmontools and psutil have not been included, you can safely ignore the warning error in the log.","changelogs":[{"date":"24.08.22:","desc":"Rebase to alpine 3.15, use linuxserver.io wheel repo."},{"date":"08.04.21:","desc":"Fix build."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.10.20:","desc":"Rebase to alpine 3.12, python3, change upstream project"},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"20.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"26.09.16:","desc":"Add back cherrypy after removal from baseimage."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"14.01.15:","desc":"Remove hardcoded loglevel from the run command, set in webui"},{"date":"19.09.15:","desc":"Initial Release."}]}},"setup":"The webui is found at port 8085. Smartmontools and psutil have not been included, you can safely ignore the warning error in the log.","_id":"content:apps:htpcmanager.json","_type":"json","title":"Htpcmanager","_source":"content","_file":"apps/htpcmanager.json","_extension":"json"},{"_path":"/apps/ipfs","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ipfs","name":"ipfs","description":"[{{ project_name|capitalize }}]({{ project_url }}) - A peer-to-peer hypermedia protocol designed to make the web faster, safer, and more open.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Ipfs-logo-1024-ice-text.png/480px-Ipfs-logo-1024-ice-text.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ipfs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ipfs"}],"containers":[{"name":"ipfs","image":"linuxserver/ipfs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"IPFS storage and config files/logs","key":"config"}],"ports":[{"container":"80","description":"The port for the IPFS web UI","protocol":"tcp","web":false},{"container":"4001","description":"Peering port, this is the only port you should expose to the internet","protocol":"tcp","web":false},{"container":"5001","description":"API port, the clientside webUI needs to be able to talk to this from whatever machine your web browser is on","protocol":"tcp","web":false},{"container":"8080","description":"Gateway Port, actually serves IPFS content","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ipfs","project_url":"https://ipfs.io/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Ipfs-logo-1024-ice-text.png/480px-Ipfs-logo-1024-ice-text.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - A peer-to-peer hypermedia protocol designed to make the web faster, safer, and more open.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_deprecation_status":true,"project_deprecation_message":"Please use the official IPFS container here:\nhttps://hub.docker.com/r/ipfs/go-ipfs\nWhen this project started the web interface was not integrated well\nwith the default IPFS server. Now it is great and well maintained, hosting\nit on a static webserver does not make much sense anymore.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"IPFS storage and config files/logs"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"The port for the IPFS web UI"},{"external_port":"4001","internal_port":"4001","port_desc":"Peering port, this is the only port you should expose to the internet"},{"external_port":"5001","internal_port":"5001","port_desc":"API port, the clientside webUI needs to be able to talk to this from whatever machine your web browser is on"},{"external_port":"8080","internal_port":"8080","port_desc":"Gateway Port, actually serves IPFS content"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"443","internal_port":"443","port_desc":"HTTPS port for web UI"}],"app_setup_block_enabled":true,"app_setup_block":"In order to push files beyond your local gateway you have to make sure port 4001 is forwarded to the internet. This is required for IPFS peers to reach in and grab your files so public gateways can serve them.\n\nAccess the webui at http://localhost , if not using localhost scroll to the bottom of the page and set the API Address setting to IE http://192.168.1.10:5001 , from there you can upload and manage files you push to IPFS. Your gateway to access IPFS files is http://localhost:8080/ipfs/YOUR-FILE-HASH-HERE . You can also simply use public IPFS gateways like: \n* Cloudflare - https://cloudflare-ipfs.com/ipfs/YOUR-FILE-HASH-HERE\n* IPFS.io - https://ipfs.io/ipfs/YOUR-FILE-HASH-HERE\n* Eternum.io - https://ipfs.eternum.io/ipfs/YOUR-FILE-HASH-HERE\n\nCloudflare is a solid option as they actually edge cache the files on their CDN so even if your node pinning the item goes down for periods of time their cache will last up to a month. \n\nFor more on using IPFS please read the docs [here](https://docs.ipfs.io/)\n \n","changelogs":[{"date":"02.02.22:","desc":"Deprecate."},{"date":"19.09.21:","desc":"Build webui from source. Update code formatting. Rebase to Alpine 3.14."},{"date":"01.04.21:","desc":"Add migration bins to image to support upgrades."},{"date":"24.02.20:","desc":"Rebase to Alpine 3.13."},{"date":"09.07.19:","desc":"Initial version."}]}},"setup":"In order to push files beyond your local gateway you have to make sure port 4001 is forwarded to the internet. This is required for IPFS peers to reach in and grab your files so public gateways can serve them.\n\nAccess the webui at http://localhost , if not using localhost scroll to the bottom of the page and set the API Address setting to IE http://192.168.1.10:5001 , from there you can upload and manage files you push to IPFS. Your gateway to access IPFS files is http://localhost:8080/ipfs/YOUR-FILE-HASH-HERE . You can also simply use public IPFS gateways like: \n* Cloudflare - https://cloudflare-ipfs.com/ipfs/YOUR-FILE-HASH-HERE\n* IPFS.io - https://ipfs.io/ipfs/YOUR-FILE-HASH-HERE\n* Eternum.io - https://ipfs.eternum.io/ipfs/YOUR-FILE-HASH-HERE\n\nCloudflare is a solid option as they actually edge cache the files on their CDN so even if your node pinning the item goes down for periods of time their cache will last up to a month. \n\nFor more on using IPFS please read the docs [here](https://docs.ipfs.io/)\n \n","_id":"content:apps:ipfs.json","_type":"json","title":"Ipfs","_source":"content","_file":"apps/ipfs.json","_extension":"json"},{"_path":"/apps/jackett","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"jackett","name":"jackett","description":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: it translates queries from apps (Sonarr, SickRage, CouchPotato, Mylar, etc) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/jackett-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jackett"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jackett"}],"containers":[{"name":"jackett","image":"linuxserver/jackett","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"AUTO_UPDATE","default":"true","description":"Allow Jackett to update inside of the container (currently recommended by Jackett and enabled by default)"},{"id":"RUN_OPTS","default":"<run options here>","description":"Optionally specify additional arguments to be passed."}],"volumes":[{"container":"/config","description":"Where Jackett should store its config file.","key":"config"},{"container":"/downloads","description":"Path to torrent blackhole."}],"ports":[{"container":"9117","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"jackett","project_url":"https://github.com/Jackett/Jackett","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/jackett-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: it translates queries from apps (Sonarr, SickRage, CouchPotato, Mylar, etc) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Jackett Releases"},{"tag":"development","desc":"Latest Jackett Releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where Jackett should store its config file."},{"vol_path":"/downloads","vol_host_path":"<path to blackhole>","desc":"Path to torrent blackhole."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9117","internal_port":"9117","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"AUTO_UPDATE","env_value":"true","desc":"Allow Jackett to update inside of the container (currently recommended by Jackett and enabled by default)"},{"env_var":"RUN_OPTS","env_value":"<run options here>","desc":"Optionally specify additional arguments to be passed."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"The web interface is at `<your-ip>:9117` , configure various trackers and connections to other apps there.\nMore info at [{{ project_name|capitalize }}]({{ project_url }}).\n\nDisable autoupdates in the webui to prevent jackett crashing, the image is refreshed when new versions are released.\n","changelogs":[{"date":"10.05.22:","desc":"Rebase to Ubuntu Focal."},{"date":"24.05.20:","desc":"Allow user to optionally enable auto updates."},{"date":"31.12.19:","desc":"Remove agressive startup chowning."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.03.19:","desc":"Switch to net-core builds of jackett, not dependant on mono and smaller images."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"11.06.18:","desc":"Ensure root ownership of Jackett files."},{"date":"13.12.17:","desc":"Fix continuation lines."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, ubuntu xenial based."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"29.10.16:","desc":"Call python2 from edge main to satisfy new mono dependency."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"22.09.16:","desc":"Remove autoupdate, tidy up Dockerfile."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"06.08.16:","desc":"Rebase to alpine linux for smaller image."},{"date":"25.01.16:","desc":"Initial Release."}]}},"setup":"The web interface is at `<your-ip>:9117` , configure various trackers and connections to other apps there.\nMore info at [{{ project_name|capitalize }}]({{ project_url }}).\n\nDisable autoupdates in the webui to prevent jackett crashing, the image is refreshed when new versions are released.\n","_id":"content:apps:jackett.json","_type":"json","title":"Jackett","_source":"content","_file":"apps/jackett.json","_extension":"json"},{"_path":"/apps/jellyfin","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"jellyfin","name":"jellyfin","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it.","icon":"https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jellyfin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jellyfin"}],"containers":[{"name":"jellyfin","image":"linuxserver/jellyfin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use (e.g. Europe/London)."},{"id":"JELLYFIN_PublishedServerUrl","default":"192.168.0.5","description":"Set the autodiscovery response domain or IP address."}],"volumes":[{"container":"/opt/vc/lib","description":"Path for Raspberry Pi OpenMAX libs *optional*."},{"container":"/config","description":"Jellyfin data storage location. *This can grow very large, 50gb+ is likely for a large collection.*","key":"config"},{"container":"/data/tvshows","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"container":"/data/movies","description":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"ports":[{"container":"8096","description":"Http webUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"jellyfin","project_url":"https://jellyfin.github.io/","project_logo":"https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it.","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Jellyfin releases"},{"tag":"nightly","desc":"Nightly Jellyfin releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/library","desc":"Jellyfin data storage location. *This can grow very large, 50gb+ is likely for a large collection.*"},{"vol_path":"/data/tvshows","vol_host_path":"/path/to/tvseries","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."},{"vol_path":"/data/movies","vol_host_path":"/path/to/movies","desc":"Media goes here. Add as many as needed e.g. `/data/movies`, `/data/tv`, etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8096","internal_port":"8096","port_desc":"Http webUI."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use (e.g. Europe/London)."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"JELLYFIN_PublishedServerUrl","env_value":"192.168.0.5","desc":"Set the autodiscovery response domain or IP address."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/opt/vc/lib","vol_host_path":"/opt/vc/lib","desc":"Path for Raspberry Pi OpenMAX libs *optional*."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your Intel GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/vcsm","device_host_path":"/dev/vcsm","desc":"Only needed if you want to use your Raspberry Pi MMAL video decoding (Enabled as OpenMax H264 decode in gui settings)."},{"device_path":"/dev/vchiq","device_host_path":"/dev/vchiq","desc":"Only needed if you want to use your Raspberry Pi OpenMax video encoding."},{"device_path":"/dev/video10","device_host_path":"/dev/video10","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video11","device_host_path":"/dev/video11","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."},{"device_path":"/dev/video12","device_host_path":"/dev/video12","desc":"Only needed if you want to use your Raspberry Pi V4L2 video encoding."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8920","internal_port":"8920","port_desc":"Optional - Https webUI (you need to set up your own certificate)."},{"external_port":"7359","internal_port":"7359/udp","port_desc":"Optional - Allows clients to discover Jellyfin on the local network."},{"external_port":"1900","internal_port":"1900/udp","port_desc":"Optional - Service discovery used by DNLA and clients."}],"optional_parameters":"The [official documentation for ports](https://jellyfin.org/docs/general/networking/index.html) has additional ports that can provide auto discovery.\n\nService Discovery (`1900/udp`) - Since client auto-discover would break if this option were configurable, you cannot change this in the settings at this time. DLNA also uses this port and is required to be in the local subnet.\n\nClient Discovery (`7359/udp`) - Allows clients to discover Jellyfin on the local network. A broadcast message to this port with \"Who is Jellyfin Server?\" will get a JSON response that includes the server address, ID, and name.\n\n```\n  -p 7359:7359/udp \\\n  -p 1900:1900/udp \\\n```\n\nThe [official documentation for environmentals](https://jellyfin.org/docs/general/administration/configuration.html) has additional environmentals that can provide additional configurability such as migrating to the native Jellyfin image.\n","app_setup_block_enabled":true,"app_setup_block":"Webui can be found at `http://<your-ip>:8096`\n\nMore information can be found on the official documentation [here](https://jellyfin.org/docs/general/quick-start.html).\n\n## Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n`--device=/dev/dri:/dev/dri`\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nTo enable the OpenCL based DV, HDR10 and HLG tone-mapping, please refer to the OpenCL-Intel mod from here:\n\nhttps://mods.linuxserver.io/?mod=jellyfin\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the jellyfin docker container.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi MMAL/OpenMAX will need to mount their `/dev/vcsm` and `/dev/vchiq` video devices inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n\n```\n--device=/dev/vcsm:/dev/vcsm\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their `/dev/video1X` devices inside of the container by passing the following options when running or creating the container:\n\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","unraid_template_sync":false,"changelogs":[{"date":"07.12.22:","desc":"Rebase master to Jammy, migrate to s6v3."},{"date":"11.06.22:","desc":"Switch to upstream repo's ffmpeg5 build."},{"date":"05.01.22:","desc":"Specify Intel iHD driver versions to avoid mismatched libva errors."},{"date":"25.12.21:","desc":"Fix video device group perms error message."},{"date":"10.12.21:","desc":"Rework readme, disable template sync."},{"date":"22.09.21:","desc":"Pull only the server, web and ffmpeg packages instead of the wrapper."},{"date":"23.06.21:","desc":"Add log message if device permissions are incorrect. Pin jellyfin dependency versions to prevent upstream apt repo issues. Deprecate the `bionic` tag."},{"date":"21.05.21:","desc":"Add nvidia.icd file to fix missing tonemapping using Nvidia HW."},{"date":"20.01.21:","desc":"Add Jellyfin Binary Environmentals"},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.11.20:","desc":"Rebase to Focal, branch off Bionic."},{"date":"22.07.20:","desc":"Ingest releases from Jellyfin repo."},{"date":"28.04.20:","desc":"Replace MMAL/OMX dependency device `/dev/vc-mem` with `/dev/vcsm` as the former was not sufficient for raspbian."},{"date":"11.04.20:","desc":"Enable hw decode (mmal) on Raspberry Pi, update readme instructions, add donation info, create missing default transcodes folder."},{"date":"11.03.20:","desc":"Add Pi V4L2 support, remove optional transcode mapping (location is selected in the gui, defaults to path under `/config`)."},{"date":"30.01.20:","desc":"Add nightly tag."},{"date":"09.01.20:","desc":"Add Pi OpenMax support."},{"date":"02.10.19:","desc":"Improve permission fixing for render & dvb devices."},{"date":"31.07.19:","desc":"Add AMD drivers for vaapi support on x86."},{"date":"13.06.19:","desc":"Add Intel drivers for vaapi support on x86."},{"date":"07.06.19:","desc":"Initial release."}]}},"setup":"Webui can be found at `http://<your-ip>:8096`\n\nMore information can be found on the official documentation [here](https://jellyfin.org/docs/general/quick-start.html).\n\n## Hardware Acceleration\n\n### Intel\n\nHardware acceleration users for Intel Quicksync will need to mount their /dev/dri video device inside of the container by passing the following command when running or creating the container:\n\n`--device=/dev/dri:/dev/dri`\n\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\nTo enable the OpenCL based DV, HDR10 and HLG tone-mapping, please refer to the OpenCL-Intel mod from here:\n\nhttps://mods.linuxserver.io/?mod=jellyfin\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\n\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the jellyfin docker container.\n\n### OpenMAX (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi MMAL/OpenMAX will need to mount their `/dev/vcsm` and `/dev/vchiq` video devices inside of the container and their system OpenMax libs by passing the following options when running or creating the container:\n\n```\n--device=/dev/vcsm:/dev/vcsm\n--device=/dev/vchiq:/dev/vchiq\n-v /opt/vc/lib:/opt/vc/lib\n```\n\n### V4L2 (Raspberry Pi)\n\nHardware acceleration users for Raspberry Pi V4L2 will need to mount their `/dev/video1X` devices inside of the container by passing the following options when running or creating the container:\n\n```\n--device=/dev/video10:/dev/video10\n--device=/dev/video11:/dev/video11\n--device=/dev/video12:/dev/video12\n```\n","_id":"content:apps:jellyfin.json","_type":"json","title":"Jellyfin","_source":"content","_file":"apps/jellyfin.json","_extension":"json"},{"_path":"/apps/jenkins-builder","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"jenkins-builder","name":"jenkins-builder","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/jenkinsbuilder.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/jenkins-builder"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-jenkins-builder"}],"containers":[{"name":"jenkins-builder","image":"linuxserver/jenkins-builder","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"jenkins-builder","full_custom_readme":"{% raw -%}\n# linuxserver/jenkins-builder\n\nExpects to run as part of the LSIO CI process. Not for public consumption.\n\n## Running against remote project\n\n```bash\ndocker run --rm \\\n  -e CONTAINER_NAME=${CONTAINER_NAME} \\\n  -v ${TEMPDIR}:/ansible/jenkins \\\n  lscr.io/linuxserver/jenkins-builder:latest\n```\n\n## Running against local project\n\nIf you need to test functionality just navigate to the folder with the jenkins-vars.yml and run:\n\n```bash\ndocker pull lscr.io/linuxserver/jenkins-builder:latest && \\\ndocker run --rm \\\n  -v $(pwd):/tmp \\\n  -e LOCAL=true \\\n  -e PUID=$(id -u) -e PGID=$(id -g) \\\n  lscr.io/linuxserver/jenkins-builder:latest && \\\nrm -rf .jenkins-external\n```\n\nNewly generated files (including `README.md`, `Jenkinsfile`, issue templates, etc.) will overwrite the existing files in your current working directory.\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n\n```bash\ngit clone https://github.com/linuxserver/docker-jenkins-builder.git\ncd docker-jenkins-builder\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t lscr.io/linuxserver/jenkins-builder:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\nThe following line is only in this repo for loop testing:\n\n- { date: \"01.01.50:\", desc: \"I am the release message for this internal repo.\" }\n{%- endraw %}\n"}},"_id":"content:apps:jenkins-builder.json","_type":"json","title":"Jenkins Builder","_source":"content","_file":"apps/jenkins-builder.json","_extension":"json"},{"_path":"/apps/kasm","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"kasm","name":"kasm","description":"[{{ project_name|capitalize }}]({{ project_url }}) Workspaces is a docker container streaming platform for delivering browser-based access to desktops, applications, and web services. Kasm uses devops-enabled Containerized Desktop Infrastructure (CDI) to create on-demand, disposable, docker containers that are accessible via web browser. Example use-cases include Remote Browser Isolation (RBI), Data Loss Prevention (DLP), Desktop as a Service (DaaS), Secure Remote Access Services (RAS), and Open Source Intelligence (OSINT) collections.\n\nThe rendering of the graphical-based containers is powered by the open-source project [KasmVNC](https://www.kasmweb.com/kasmvnc.html?utm_campaign=LinuxServer&utm_source=kasmvnc).\n","icon":"https://kasm-ci.s3.amazonaws.com/kasm_wide.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/kasm"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-kasm"}],"containers":[{"name":"kasm","image":"linuxserver/kasm","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"KASM_PORT","default":"443","description":"Specify the port you bind to the outside for Kasm Workspaces."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"DOCKER_HUB_USERNAME","default":"USER","description":"Optionally specify a DockerHub Username to pull private images."},{"id":"DOCKER_HUB_PASSWORD","default":"PASS","description":"Optionally specify a DockerHub password to pull private images."}],"volumes":[{"container":"/profiles","description":"Optionally specify a path for persistent profile storage."},{"container":"/dev/input","description":"Optional for gamepad support."},{"container":"/run/udev/data","description":"Optional for gamepad support."},{"container":"/opt","description":"Docker and installation storage."}],"ports":[{"container":"3000","description":"Kasm Installation wizard. (https)","protocol":"tcp","web":false},{"container":"443","description":"Kasm Workspaces interface. (https)","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"kasm","project_url":"https://www.kasmweb.com/?utm_campaign=LinuxServer&utm_source=listing","project_logo":"https://kasm-ci.s3.amazonaws.com/kasm_wide.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) Workspaces is a docker container streaming platform for delivering browser-based access to desktops, applications, and web services. Kasm uses devops-enabled Containerized Desktop Infrastructure (CDI) to create on-demand, disposable, docker containers that are accessible via web browser. Example use-cases include Remote Browser Isolation (RBI), Data Loss Prevention (DLP), Desktop as a Service (DaaS), Secure Remote Access Services (RAS), and Open Source Intelligence (OSINT) collections.\n\nThe rendering of the graphical-based containers is powered by the open-source project [KasmVNC](https://www.kasmweb.com/kasmvnc.html?utm_campaign=LinuxServer&utm_source=kasmvnc).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Kasm releases"},{"tag":"develop","desc":"Tip of develop"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"KASM_PORT","env_value":"443","desc":"Specify the port you bind to the outside for Kasm Workspaces."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/opt","vol_host_path":"/path/to/data","desc":"Docker and installation storage."}],"param_device_map":false,"param_devices":[],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Kasm Installation wizard. (https)"},{"external_port":"443","internal_port":"443","port_desc":"Kasm Workspaces interface. (https)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_HUB_USERNAME","env_value":"USER","desc":"Optionally specify a DockerHub Username to pull private images."},{"env_var":"DOCKER_HUB_PASSWORD","env_value":"PASS","desc":"Optionally specify a DockerHub password to pull private images."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/profiles","vol_host_path":"/path/to/profiles","desc":"Optionally specify a path for persistent profile storage."},{"vol_path":"/dev/input","vol_host_path":"/dev/input","desc":"Optional for gamepad support."},{"vol_path":"/run/udev/data","vol_host_path":"/run/udev/data","desc":"Optional for gamepad support."}],"opt_param_usage_include_ports":false,"opt_param_ports":[],"opt_param_device_map":false,"opt_param_devices":[],"cap_add_param":false,"cap_add_param_vars":[],"opt_cap_add_param":false,"opt_cap_add_param_vars":[],"optional_block_1":false,"optional_block_1_items":"","privileged":true,"app_setup_block_enabled":true,"app_setup_block":"This container uses [Docker in Docker](https://www.docker.com/blog/docker-can-now-run-within-docker/) and requires being run in `privileged` mode. This container also requires an initial setup that runs on port 3000.\n\n**Unlike other containers the web interface port (default 443) needs to be set for the env variable `KASM_PORT` and both the inside and outside port IE for 4443 `KASM_PORT=4443` `-p 4443:4443`**\n\n**Unraid users due to the DinD storage layer `/opt/` should be mounted directly to a disk IE `/mnt/disk1/appdata/path` or optimally with a cache disk at `/mnt/cache/appdata/path`**\n\nAccess the installation wizard at https://`your ip`:3000 and follow the instructions there. Once setup is complete access https://`your ip`:443 and login with the credentials you entered during setup. The default users are:\n\n* admin@kasm.local\n* user@kasm.local\n\nCurrently Synology systems are not supported due to them blocking CPU scheduling in their Kernel.\n\n### GPU Support\n\nDuring installation an option will be presented to force all Workspace containers to mount in and use a specific GPU. If using an NVIDIA GPU you will need to pass `-e NVIDIA_VISIBLE_DEVICES=all` or `--gpus all` and have the [NVIDIA Container Runtime](https://github.com/NVIDIA/nvidia-container-runtime) installed on the host. Also if using NVIDIA, Kasm Workspaces has [native NVIDIA support](https://www.kasmweb.com/docs/latest/how_to/gpu.html) so you can optionally opt to simply use that instead of he manual override during installation. \n\n### Gamepad support\n\nIn order to properly create virtual Gamepads you will need to mount from your host `/dev/input` and `/run/udev/data`. Please see [HERE](https://www.kasmweb.com/docs/develop/guide/gamepad_passthrough.html) for instructions on enabling gamepad support.\n\n### Persistant profiles\n\nIn order to use persistant profiles in Workspaces you will need to mount in a folder to use from your host to `/profiles`. From there when configuring a workspace you can set the `Persistant Profile Path` to IE `/profiles/ubuntu-focal/{username}/`, more infomation can be found [HERE](https://www.kasmweb.com/docs/latest/how_to/persistent_profiles.html).\n","changelogs":[{"date":"05.11.22:","desc":"Rebase to Jammy, add support for GPUs, add support for Gamepads."},{"date":"23.09.22:","desc":"Migrate to s6v3."},{"date":"02.07.22:","desc":"Initial Release."}]}},"setup":"This container uses [Docker in Docker](https://www.docker.com/blog/docker-can-now-run-within-docker/) and requires being run in `privileged` mode. This container also requires an initial setup that runs on port 3000.\n\n**Unlike other containers the web interface port (default 443) needs to be set for the env variable `KASM_PORT` and both the inside and outside port IE for 4443 `KASM_PORT=4443` `-p 4443:4443`**\n\n**Unraid users due to the DinD storage layer `/opt/` should be mounted directly to a disk IE `/mnt/disk1/appdata/path` or optimally with a cache disk at `/mnt/cache/appdata/path`**\n\nAccess the installation wizard at https://`your ip`:3000 and follow the instructions there. Once setup is complete access https://`your ip`:443 and login with the credentials you entered during setup. The default users are:\n\n* admin@kasm.local\n* user@kasm.local\n\nCurrently Synology systems are not supported due to them blocking CPU scheduling in their Kernel.\n\n### GPU Support\n\nDuring installation an option will be presented to force all Workspace containers to mount in and use a specific GPU. If using an NVIDIA GPU you will need to pass `-e NVIDIA_VISIBLE_DEVICES=all` or `--gpus all` and have the [NVIDIA Container Runtime](https://github.com/NVIDIA/nvidia-container-runtime) installed on the host. Also if using NVIDIA, Kasm Workspaces has [native NVIDIA support](https://www.kasmweb.com/docs/latest/how_to/gpu.html) so you can optionally opt to simply use that instead of he manual override during installation. \n\n### Gamepad support\n\nIn order to properly create virtual Gamepads you will need to mount from your host `/dev/input` and `/run/udev/data`. Please see [HERE](https://www.kasmweb.com/docs/develop/guide/gamepad_passthrough.html) for instructions on enabling gamepad support.\n\n### Persistant profiles\n\nIn order to use persistant profiles in Workspaces you will need to mount in a folder to use from your host to `/profiles`. From there when configuring a workspace you can set the `Persistant Profile Path` to IE `/profiles/ubuntu-focal/{username}/`, more infomation can be found [HERE](https://www.kasmweb.com/docs/latest/how_to/persistent_profiles.html).\n","_id":"content:apps:kasm.json","_type":"json","title":"Kasm","_source":"content","_file":"apps/kasm.json","_extension":"json"},{"_path":"/apps/kdenlive","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"kdenlive","name":"kdenlive","description":"[Kdenlive]({{ project_url }}) is a powerful free and open source cross-platform video editing program made by the KDE community. Feature rich and production ready.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/kdenlive-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/kdenlive"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-kdenlive"}],"containers":[{"name":"kdenlive","image":"linuxserver/kdenlive","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Kdenlive desktop gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"kdenlive","project_url":"https://kdenlive.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/kdenlive-logo.png","project_blurb":"[Kdenlive]({{ project_url }}) is a powerful free and open source cross-platform video editing program made by the KDE community. Feature rich and production ready.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Kdenlive desktop gui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"This might be needed to prevent crashing"}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for hardware acceleration (Linux hosts only)"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, this may be required depending on your Docker and storage configuration."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration (x86_64 only)\n\nIn order to perform hardware transcoding you will need to mount a video device into the container. Some of the default hardware rendering/transcode profiles will point to devices in /dev/dri for `vaapi_device`. Make sure the profile you are using points to the correct device in the container. IE if you have intel integrated graphics along with an Nvdia or AMD video card you might have renderD128, renderD129, etc. To check which device is which use vainfo from inside the container: (right click the desktop and open xterm)\n\n```\nvainfo --display drm --device /dev/dri/renderD128\n```\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","changelogs":[{"date":"16.09.22:","desc":"Migrate to s6v3."},{"date":"09.03.22:","desc":"Update seccomp explanation."},{"date":"07.03.22:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\n## Hardware Acceleration (x86_64 only)\n\nIn order to perform hardware transcoding you will need to mount a video device into the container. Some of the default hardware rendering/transcode profiles will point to devices in /dev/dri for `vaapi_device`. Make sure the profile you are using points to the correct device in the container. IE if you have intel integrated graphics along with an Nvdia or AMD video card you might have renderD128, renderD129, etc. To check which device is which use vainfo from inside the container: (right click the desktop and open xterm)\n\n```\nvainfo --display drm --device /dev/dri/renderD128\n```\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n","_id":"content:apps:kdenlive.json","_type":"json","title":"Kdenlive","_source":"content","_file":"apps/kdenlive.json","_extension":"json"},{"_path":"/apps/lazylibrarian","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"lazylibrarian","name":"lazylibrarian","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a program to follow authors and grab metadata for all your digital reading needs. It uses a combination of Goodreads Librarything and optionally GoogleBooks as sources for author info and book info.  This container is based on the DobyTang fork.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lazylibrarian-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lazylibrarian"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lazylibrarian"}],"containers":[{"name":"lazylibrarian","image":"linuxserver/lazylibrarian","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"},{"id":"DOCKER_MODS","default":"linuxserver/calibre-web:calibre|linuxserver/mods:lazylibrarian-ffmpeg","description":"Allows additional functionality to be added, e.g. the Calibredb import program (optional, more info below)"}],"volumes":[{"container":"/books","description":"Books location"},{"container":"/config","description":"LazyLibrarian config","key":"config"},{"container":"/downloads","description":"Download location"}],"ports":[{"container":"5299","description":"The port for the LazyLibrarian webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lazylibrarian","project_url":"https://lazylibrarian.gitlab.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lazylibrarian-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a program to follow authors and grab metadata for all your digital reading needs. It uses a combination of Goodreads Librarything and optionally GoogleBooks as sources for author info and book info.  This container is based on the DobyTang fork.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"LazyLibrarian config"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads/","desc":"Download location"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/books","vol_host_path":"/path/to/data/","desc":"Books location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5299","internal_port":"5299","port_desc":"The port for the LazyLibrarian webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"DOCKER_MODS","env_value":"linuxserver/calibre-web:calibre|linuxserver/mods:lazylibrarian-ffmpeg","desc":"Allows additional functionality to be added, e.g. the Calibredb import program (optional, more info below)"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<your-ip>:5299/home`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n\n### Calibredb import\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable the Calibredb import program:, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as detailed in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the LazyLibrarian config page (Processing:Calibredb import program:) set the path to converter tool to `/usr/bin/calibredb`\n\n### ffmpeg\n\nBy adding `linuxserver/mods:lazylibrarian-ffmpeg` to your `DOCKER_MODS` environment variable you can install ffmpeg into your container on startup.\nThis allows you to use the audiobook conversion features of LazyLibrarian.\nYou can enable it in the Web UI under Settings > Processing > External Programs by setting the ffmpeg path to `ffmpeg`.\n\n### Media folders\n\nWe have set `/books` as ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional path if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"07.12.22:","desc":"Rebase to Ubuntu Jammy, migrate to s6v3. Use pyproject.toml for deps. Build unrar from source."},{"date":"27.09.22:","desc":"Switch to `Levenshtein`, add cmake as build dep on armhf."},{"date":"07.05.22:","desc":"Rebase to Ubuntu Focal."},{"date":"22.05.21:","desc":"Make the paths clearer to the user, remove optional volume."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.10.19:","desc":"Changed gitlab download link."},{"date":"23.10.19:","desc":"Add python module Pillow."},{"date":"31.07.19:","desc":"Add pyopenssl, remove git dependency during build time."},{"date":"09.07.19:","desc":"Rebase to Ubuntu Bionic, enables Calibre docker mod."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"05.03.19:","desc":"Added apprise python package."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"10.12.18:","desc":"Moved to Pipeline Building"},{"date":"16.08.18:","desc":"Rebase to alpine 3.8"},{"date":"05.01.18:","desc":"Deprecate cpu_core routine lack of scaling"},{"date":"12.12.17:","desc":"Rebase to alpine 3.7"},{"date":"21.07.17:","desc":"Internal git pull instead of at runtime"},{"date":"25.05.17:","desc":"Rebase to alpine 3.6"},{"date":"07.02.17:","desc":"Rebase to alpine 3.5"},{"date":"30.01.17:","desc":"Compile libunrar.so to allow reading of .cbr format files"},{"date":"12.01.17:","desc":"Add ghostscript package, allows magazine covers to be created etc"},{"date":"14.10.16:","desc":"Add version layer information"},{"date":"03.10.16:","desc":"Fix non-persistent settings and make log folder"},{"date":"28.09.16:","desc":"Inital Release"}]}},"setup":"Access the webui at `http://<your-ip>:5299/home`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n\n### Calibredb import\n\n**64bit only** We have implemented the optional ability to pull in the dependencies to enable the Calibredb import program:, this means if you don't require this feature the container isn't uneccessarily bloated but should you require it, it is easily available.\nThis optional layer will be rebuilt automatically on our CI pipeline upon new Calibre releases so you can stay up to date.\nTo use this option add the optional environmental variable as detailed in the docker-mods section to pull an addition docker layer to enable ebook conversion and then in the LazyLibrarian config page (Processing:Calibredb import program:) set the path to converter tool to `/usr/bin/calibredb`\n\n### ffmpeg\n\nBy adding `linuxserver/mods:lazylibrarian-ffmpeg` to your `DOCKER_MODS` environment variable you can install ffmpeg into your container on startup.\nThis allows you to use the audiobook conversion features of LazyLibrarian.\nYou can enable it in the Web UI under Settings > Processing > External Programs by setting the ffmpeg path to `ffmpeg`.\n\n### Media folders\n\nWe have set `/books` as ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional path if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","_id":"content:apps:lazylibrarian.json","_type":"json","title":"Lazylibrarian","_source":"content","_file":"apps/lazylibrarian.json","_extension":"json"},{"_path":"/apps/ldap-auth","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ldap-auth","name":"ldap-auth","description":"[{{ project_name|capitalize }}]({{ project_url }}) software is for authenticating users who request protected resources from servers proxied by nginx. It includes a daemon (ldap-auth) that communicates with an authentication server, and a webserver daemon that generates an authentication cookie based on the users credentials. The daemons are written in Python for use with a Lightweight Directory Access Protocol (LDAP) authentication server (OpenLDAP or Microsoft Windows Active Directory 2003 and 2012).","icon":"https://jumpcloud.com/wp-content/uploads/2016/12/LDAP_Logo-1420591101.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ldap-auth"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ldap-auth"}],"containers":[{"name":"ldap-auth","image":"linuxserver/ldap-auth","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"FERNETKEY","default":"","description":"Optionally define a custom fernet key, has to be base64-encoded 32-byte (only needed if container is frequently recreated, or if using multi-node setups, invalidating previous authentications)"},{"id":"CERTFILE","default":"","description":"Point this to a certificate file to enable HTTP over SSL (HTTPS) for the ldap auth daemon"},{"id":"KEYFILE","default":"","description":"Point this to the private key file, matching the certificate file referred to in CERTFILE"}],"ports":[{"container":"8888","description":"the port for ldap auth daemon","protocol":"tcp","web":false},{"container":"9000","description":"the port for ldap login page","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ldap-auth","project_url":"https://github.com/nginxinc/nginx-ldap-auth","project_logo":"https://jumpcloud.com/wp-content/uploads/2016/12/LDAP_Logo-1420591101.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) software is for authenticating users who request protected resources from servers proxied by nginx. It includes a daemon (ldap-auth) that communicates with an authentication server, and a webserver daemon that generates an authentication cookie based on the users credentials. The daemons are written in Python for use with a Lightweight Directory Access Protocol (LDAP) authentication server (OpenLDAP or Microsoft Windows Active Directory 2003 and 2012).","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":"","param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"the port for ldap auth daemon"},{"external_port":"9000","internal_port":"9000","port_desc":"the port for ldap login page"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"FERNETKEY","env_value":"","desc":"Optionally define a custom fernet key, has to be base64-encoded 32-byte (only needed if container is frequently recreated, or if using multi-node setups, invalidating previous authentications)"},{"env_var":"CERTFILE","env_value":"","desc":"Point this to a certificate file to enable HTTP over SSL (HTTPS) for the ldap auth daemon"},{"env_var":"KEYFILE","env_value":"","desc":"Point this to the private key file, matching the certificate file referred to in CERTFILE"}],"app_setup_block_enabled":true,"app_setup_block":"- This container itself does not have any settings and it relies on the pertinent information passed through in http headers of incoming requests. Make sure that your webserver is set up with the right config.\n- Here's a sample config: [nginx-ldap-auth.conf](https://github.com/nginxinc/nginx-ldap-auth/blob/master/nginx-ldap-auth.conf).\n- Unlike the upstream project, this image encodes the cookie information with fernet, using a randomly generated key during container creation (or optionally user defined).\n- Also unlike the upstream project, this image serves the login page at `/ldaplogin` (as well as `/login`) to prevent clashes with reverse proxied apps that may also use `/login` for their internal auth.\n","changelogs":[{"date":"19.09.22:","desc":"Rebase to alpine 3.17."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"14.05.21:","desc":"Add linuxserver wheel index."},{"date":"12.02.21:","desc":"Clean up cargo/rust cache."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"08.09.20:","desc":"Set form action correctly."},{"date":"30.07.20:","desc":"Fix bug related to unset optional `CERTFILE` and `KEYFILE` vars."},{"date":"27.07.20:","desc":"Add support for HTTP over SSL (HTTPS)."},{"date":"21.07.20:","desc":"Add support for optional user defined fernet key."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12, serve login page at `/ldaplogin` as well as `/login`, to prevent clashes with reverese proxied apps."},{"date":"17.05.20:","desc":"Add support for self-signed CA certs."},{"date":"20.02.20:","desc":"Switch to python3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"01.07.19:","desc":"Fall back to base64 encoding when basic http auth is used."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.09.18:","desc":"Update pip"},{"date":"14.09.18:","desc":"Add TZ parameter, remove unnecessary PUID/PGID params"},{"date":"11.08.18:","desc":"Initial release."}]}},"setup":"- This container itself does not have any settings and it relies on the pertinent information passed through in http headers of incoming requests. Make sure that your webserver is set up with the right config.\n- Here's a sample config: [nginx-ldap-auth.conf](https://github.com/nginxinc/nginx-ldap-auth/blob/master/nginx-ldap-auth.conf).\n- Unlike the upstream project, this image encodes the cookie information with fernet, using a randomly generated key during container creation (or optionally user defined).\n- Also unlike the upstream project, this image serves the login page at `/ldaplogin` (as well as `/login`) to prevent clashes with reverse proxied apps that may also use `/login` for their internal auth.\n","_id":"content:apps:ldap-auth.json","_type":"json","title":"Ldap Auth","_source":"content","_file":"apps/ldap-auth.json","_extension":"json"},{"_path":"/apps/libreoffice","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"libreoffice","name":"libreoffice","description":"[LibreOffice]({{ project_url }}) is a free and powerful office suite, and a successor to OpenOffice.org (commonly known as OpenOffice). Its clean interface and feature-rich tools help you unleash your creativity and enhance your productivity.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/libreoffice-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/libreoffice"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-libreoffice"}],"containers":[{"name":"libreoffice","image":"linuxserver/libreoffice","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and documents","key":"config"}],"ports":[{"container":"3000","description":"LibreOffice desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"libreoffice","project_url":"https://www.libreoffice.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/libreoffice-logo.png","project_blurb":"[LibreOffice]({{ project_url }}) is a free and powerful office suite, and a successor to OpenOffice.org (commonly known as OpenOffice). Its clean interface and feature-rich tools help you unleash your creativity and enhance your productivity.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and documents"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"LibreOffice desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"05.04.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:libreoffice.json","_type":"json","title":"Libreoffice","_source":"content","_file":"apps/libreoffice.json","_extension":"json"},{"_path":"/apps/librespeed","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"librespeed","name":"librespeed","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.\n\nNo Flash, No Java, No Websocket, No Bullshit.\n","icon":"https://raw.githubusercontent.com/librespeed/speedtest/master/.logo/logo3.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/librespeed"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-librespeed"}],"containers":[{"name":"librespeed","image":"linuxserver/librespeed","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PASSWORD","default":"PASSWORD","description":"Set the password for the results database."},{"id":"CUSTOM_RESULTS","default":"false","description":"(optional) set to `true` to enable custom results page in `/config/www/results/index.php`."},{"id":"DB_TYPE","default":"sqlite","description":"Defaults to `sqlite`, can also be set to `mysql` or `postgresql`."},{"id":"DB_NAME","default":"DB_NAME","description":"Database name. Required for mysql and pgsql."},{"id":"DB_HOSTNAME","default":"DB_HOSTNAME","description":"Database address. Required for mysql and pgsql."},{"id":"DB_USERNAME","default":"DB_USERNAME","description":"Database username. Required for mysql and pgsql."},{"id":"DB_PASSWORD","default":"DB_PASSWORD","description":"Database password. Required for mysql and pgsql."},{"id":"DB_PORT","default":"DB_PORT","description":"Database port. Required for mysql."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"librespeed","project_url":"https://github.com/librespeed/speedtest","project_logo":"https://raw.githubusercontent.com/librespeed/speedtest/master/.logo/logo3.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.\n\nNo Flash, No Java, No Websocket, No Bullshit.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"PASSWORD","env_value":"PASSWORD","desc":"Set the password for the results database."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CUSTOM_RESULTS","env_value":"false","desc":"(optional) set to `true` to enable custom results page in `/config/www/results/index.php`."},{"env_var":"DB_TYPE","env_value":"sqlite","desc":"Defaults to `sqlite`, can also be set to `mysql` or `postgresql`."},{"env_var":"DB_NAME","env_value":"DB_NAME","desc":"Database name. Required for mysql and pgsql."},{"env_var":"DB_HOSTNAME","env_value":"DB_HOSTNAME","desc":"Database address. Required for mysql and pgsql."},{"env_var":"DB_USERNAME","env_value":"DB_USERNAME","desc":"Database username. Required for mysql and pgsql."},{"env_var":"DB_PASSWORD","env_value":"DB_PASSWORD","desc":"Database password. Required for mysql and pgsql."},{"env_var":"DB_PORT","env_value":"DB_PORT","desc":"Database port. Required for mysql."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the speedtest webui at `http://SERVERIP`. The results database can be accessed at `http://SERVERIP/results/stats.php` with the password set.  \nThe default template used is based on `example-singleServer-full.html`. However, all templates are provided for reference at `/config/www/`. Feel free to customize `/config/www/index.html` as you like. Delete the file and restart to go back to the image default.  \n\nYou can optionally place customized `speedtest.js` and `speedtest_worker.js` files under `/config/www` and they will supersede the defaults after a container start. Keep in mind that once you do so, they will no longer be updated. You can delete them and recreate the container to go back to the image defaults.  \n\nIf you are setting up a mysql or postgresql database, you first need to import the tables into your database as described at the following link  \nhttps://github.com/librespeed/speedtest/blob/master/doc.md#creating-the-database\n\nTo enable a custom results page set the environment variable `CUSTOM_RESULTS=true` and start (or restart) the container at least once for `/config/www/results/index.php` to be created and modify this file to your liking.\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"01.03.21:","desc":"Fix up database settings. Make sure `index.html` is recreated."},{"date":"28.02.21:","desc":"Added php7-ctype."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"29.04.20:","desc":"Add donation links for LibreSpeed to Github sponsor button and container log."},{"date":"09.01.20:","desc":"Initial Release."}]}},"setup":"Access the speedtest webui at `http://SERVERIP`. The results database can be accessed at `http://SERVERIP/results/stats.php` with the password set.  \nThe default template used is based on `example-singleServer-full.html`. However, all templates are provided for reference at `/config/www/`. Feel free to customize `/config/www/index.html` as you like. Delete the file and restart to go back to the image default.  \n\nYou can optionally place customized `speedtest.js` and `speedtest_worker.js` files under `/config/www` and they will supersede the defaults after a container start. Keep in mind that once you do so, they will no longer be updated. You can delete them and recreate the container to go back to the image defaults.  \n\nIf you are setting up a mysql or postgresql database, you first need to import the tables into your database as described at the following link  \nhttps://github.com/librespeed/speedtest/blob/master/doc.md#creating-the-database\n\nTo enable a custom results page set the environment variable `CUSTOM_RESULTS=true` and start (or restart) the container at least once for `/config/www/results/index.php` to be created and modify this file to your liking.\n","_id":"content:apps:librespeed.json","_type":"json","title":"Librespeed","_source":"content","_file":"apps/librespeed.json","_extension":"json"},{"_path":"/apps/lidarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"lidarr","name":"lidarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","icon":"https://github.com/lidarr/Lidarr/raw/develop/Logo/400.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lidarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lidarr"}],"containers":[{"name":"lidarr","image":"linuxserver/lidarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/music","description":"Music files (See note in Application setup)."},{"container":"/downloads","description":"Path to your download folder for music (See note in Application setup)."},{"container":"/config","description":"Configuration files for Lidarr.","key":"config"}],"ports":[{"container":"8686","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lidarr","project_url":"https://github.com/lidarr/Lidarr","project_logo":"https://github.com/lidarr/Lidarr/raw/develop/Logo/400.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Lidarr releases."},{"tag":"develop","desc":"Develop Lidarr Releases."},{"tag":"nightly","desc":"Nightly Lidarr Releases."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"opt_param_usage_include_env":false,"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files for Lidarr."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/music","vol_host_path":"/path/to/music","desc":"Music files (See note in Application setup)."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Path to your download folder for music (See note in Application setup)."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8686","internal_port":"8686","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8686`, for more information check out [Lidarr]({{ project_url }}).\n\nSpecial Note: Following our current folder structure will result in an inability to hardlink from your downloads to your Music folder because they are on seperate volumes. To support hardlinking, simply ensure that the Music and downloads data are on a single volume. For example, if you have /mnt/storage/Music and /mnt/storage/downloads/completed/Music, you would want something like /mnt/storage:/media for your volume. Then you can hardlink from /media/downloads/completed to /media/Music.\n\nAnother item to keep in mind, is that within lidarr itself, you should then map your download client folder to your lidarr folder: Settings -> Download Client -> advanced -> remote path mappings. I input the host of my download client (matches the download client defined) remote path is /downloads/Music (relative to the internal container path) and local path is /media/downloads/completed/Music, assuming you have folders to seperate your downloaded data types.\n\n### Media folders\n\nWe have set `/music` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"17.01.23:","desc":"Rebase master branch to Alpine 3.17, migrate to s6v3."},{"date":"06.06.22:","desc":"Rebase master branch to Alpine 3.15."},{"date":"06.05.22:","desc":"Rebase master branch to Focal."},{"date":"06.05.22:","desc":"Rebase develop branch to Alpine."},{"date":"04.02.22:","desc":"Rebase nightly branch to Alpine, deprecate nightly-alpine branch."},{"date":"30.12.21:","desc":"Add nightly-alpine branch."},{"date":"01.08.21:","desc":"Add libchromaprint-tools."},{"date":"11.07.21:","desc":"Make the paths clearer to the user."},{"date":"18.04.21:","desc":"Switch `latest` tag to net core."},{"date":"25.01.21:","desc":"Publish `develop` tag."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"18.04.20:","desc":"Removed /downloads and /music volumes from Dockerfiles."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"08.03.19:","desc":"Rebase to Bionic, use proposed endpoint for libchromaprint."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"22.04.18:","desc":"Switch to beta builds."},{"date":"17.03.18:","desc":"Add ENV XDG_CONFIG_HOME=\"/config/xdg\" to Dockerfile for signalr fix."},{"date":"27.02.18:","desc":"Use json to query for new version."},{"date":"23.02.18:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:8686`, for more information check out [Lidarr]({{ project_url }}).\n\nSpecial Note: Following our current folder structure will result in an inability to hardlink from your downloads to your Music folder because they are on seperate volumes. To support hardlinking, simply ensure that the Music and downloads data are on a single volume. For example, if you have /mnt/storage/Music and /mnt/storage/downloads/completed/Music, you would want something like /mnt/storage:/media for your volume. Then you can hardlink from /media/downloads/completed to /media/Music.\n\nAnother item to keep in mind, is that within lidarr itself, you should then map your download client folder to your lidarr folder: Settings -> Download Client -> advanced -> remote path mappings. I input the host of my download client (matches the download client defined) remote path is /downloads/Music (relative to the internal container path) and local path is /media/downloads/completed/Music, assuming you have folders to seperate your downloaded data types.\n\n### Media folders\n\nWe have set `/music` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","_id":"content:apps:lidarr.json","_type":"json","title":"Lidarr","_source":"content","_file":"apps/lidarr.json","_extension":"json"},{"_path":"/apps/limnoria","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"limnoria","name":"limnoria","description":"[{{ project_name|capitalize }}]({{ project_url }}) A robust, full-featured, and user/programmer-friendly Python IRC bot, with many existing plugins. Successor of the well-known Supybot.","icon":"https://raw.githubusercontent.com/linuxserver/docker-limnoria/master/logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/limnoria"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-limnoria"}],"containers":[{"name":"limnoria","image":"linuxserver/limnoria","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Limnoria config is stored.","key":"config"}],"ports":[{"container":"8080","description":"Port for Limnoria's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"limnoria","project_url":"https://github.com/ProgVal/limnoria","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-limnoria/master/logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A robust, full-featured, and user/programmer-friendly Python IRC bot, with many existing plugins. Successor of the well-known Supybot.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"path/to/config","desc":"Where Limnoria config is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Port for Limnoria's web interface."}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"### New Configuration\n\nIf you do not have an existing config you will need to start the container and then run the following wizard command:\n\n`docker exec -it -w /config -u abc limnoria limnoria-wizard`\n\n### Existing Configuration\n\nIf you have an existing config, adjust the directory settings in your conf file as follows:\n\n```conf\nsupybot.directories.backup: /config/backup\nsupybot.directories.conf: /config/conf\nsupybot.directories.data: /config/data\nsupybot.directories.data.tmp: /config/data/tmp\nsupybot.directories.data.web: /config/web\nsupybot.directories.log: /config/logs\nsupybot.directories.plugins: /config/plugins\n```\n\nNOTE: These are not grouped together in the file. You will need to search your conf file for the variables.\n\nThen place your conf file and any of your existing directories in /config and start up the container.\n\n### Plugin Requirements\n\nThe container will pip install any requirements.txt it finds in the /config/plugins folder on startup.\n\nIf you install a plugin using the PluginDownloader that includes a requirements.txt you can \nexecute a shell into the container and then use `pip install /config/plugins/ThePlugin/requirements.txt`\nor restart the container and the requirements will be installed. \n","changelogs":[{"date":"22.12.22:","desc":"Rebase to alpine 3.17."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"25.05.21:","desc":"Install plugin requirements on container init."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"13.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"13.01.20:","desc":"Initial Release."}]}},"setup":"### New Configuration\n\nIf you do not have an existing config you will need to start the container and then run the following wizard command:\n\n`docker exec -it -w /config -u abc limnoria limnoria-wizard`\n\n### Existing Configuration\n\nIf you have an existing config, adjust the directory settings in your conf file as follows:\n\n```conf\nsupybot.directories.backup: /config/backup\nsupybot.directories.conf: /config/conf\nsupybot.directories.data: /config/data\nsupybot.directories.data.tmp: /config/data/tmp\nsupybot.directories.data.web: /config/web\nsupybot.directories.log: /config/logs\nsupybot.directories.plugins: /config/plugins\n```\n\nNOTE: These are not grouped together in the file. You will need to search your conf file for the variables.\n\nThen place your conf file and any of your existing directories in /config and start up the container.\n\n### Plugin Requirements\n\nThe container will pip install any requirements.txt it finds in the /config/plugins folder on startup.\n\nIf you install a plugin using the PluginDownloader that includes a requirements.txt you can \nexecute a shell into the container and then use `pip install /config/plugins/ThePlugin/requirements.txt`\nor restart the container and the requirements will be installed. \n","_id":"content:apps:limnoria.json","_type":"json","title":"Limnoria","_source":"content","_file":"apps/limnoria.json","_extension":"json"},{"_path":"/apps/lychee","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"lychee","name":"lychee","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free photo-management tool, which runs on your server or web-space. Installing is a matter of seconds. Upload, manage and share photos like from a native application. Lychee comes with everything you need and all your photos are stored securely.\"\n\n### UPGRADE WARNING\n\nPlease note that the v4 upgrade process resets ALL password-protected albums. Any albums that were made public with a password will need to be re-secured.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lychee-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/lychee"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-lychee"}],"containers":[{"name":"lychee","image":"linuxserver/lychee","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"DB_HOST","default":"mariadb","description":"for specifying the database host"},{"id":"DB_PORT","default":"3306","description":"for specifying the database port"},{"id":"DB_USERNAME","default":"lychee","description":"for specifying the database user"},{"id":"DB_PASSWORD","default":"dbpassword","description":"for specifying the database password"},{"id":"DB_DATABASE","default":"lychee","description":"for specifying the database to be used"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/pictures","description":"Where lychee will store uploaded data."}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"lychee","project_url":"https://lycheeorg.github.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/lychee-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free photo-management tool, which runs on your server or web-space. Installing is a matter of seconds. Upload, manage and share photos like from a native application. Lychee comes with everything you need and all your photos are stored securely.\"\n\n### UPGRADE WARNING\n\nPlease note that the v4 upgrade process resets ALL password-protected albums. Any albums that were made public with a password will need to be re-secured.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Contains all relevant configuration files."},{"vol_path":"/pictures","vol_host_path":"/path/to/pictures","desc":"Where lychee will store uploaded data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"DB_HOST","env_value":"mariadb","desc":"for specifying the database host"},{"env_var":"DB_PORT","env_value":"3306","desc":"for specifying the database port"},{"env_var":"DB_USERNAME","env_value":"lychee","desc":"for specifying the database user"},{"env_var":"DB_PASSWORD","env_value":"dbpassword","desc":"for specifying the database password"},{"env_var":"DB_DATABASE","env_value":"lychee","desc":"for specifying the database to be used"}],"optional_block_1":false,"optional_block_1_items":"","custom_compose":"version: \"3\"\nservices:\n  mariadb:\n    image: lscr.io/linuxserver/mariadb:latest\n    container_name: lychee_mariadb\n    restart: always\n    volumes:\n      - /path/to/mariadb/data:/config\n    environment:\n      - MYSQL_ROOT_PASSWORD=rootpassword\n      - MYSQL_DATABASE=lychee\n      - MYSQL_USER=lychee\n      - MYSQL_PASSWORD=dbpassword\n      - PGID=1000\n      - PUID=1000\n      - TZ=Europe/London\n  lychee:\n    image: lscr.io/linuxserver/lychee:latest\n    container_name: lychee\n    restart: always\n    depends_on:\n      - mariadb\n    volumes:\n      - /path/to/config:/config\n      - /path/to/pictures:/pictures\n    environment:\n      - DB_HOST=mariadb\n      - DB_USERNAME=lychee\n      - DB_PASSWORD=dbpassword\n      - DB_DATABASE=lychee\n      - DB_PORT=3306\n      - PGID=1000\n      - PUID=1000\n      - TZ=Europe/London\n    ports:\n      - 80:80\n","app_setup_block_enabled":true,"app_setup_block":"**This image will not work with a prefilled `/pictures` mount, lychee wants total control over this folder**\n\nSetup mysql/mariadb and account via the webui, accessible at http://SERVERIP:PORT\nMore info at [lychee]({{ project_url }}).\n","changelogs":[{"date":"11.01.23:","desc":"Rebasing to alpine 3.17 with php8.1. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base)). Switch to git clone as builds fail with the release artifact."},{"date":"13.05.21:","desc":"Make readme clearer."},{"date":"18.04.21:","desc":"Add php-intl for v4.3."},{"date":"31.01.21:","desc":"Add jpegoptim."},{"date":"15.01.21:","desc":"Rebase to alpine 3.13, add php7-ctype."},{"date":"10.07.20:","desc":"Upgrade to Lychee v4 and rebased to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"23.10.19:","desc":"Increase fastcgi timeouts (existing users need to manually update)."},{"date":"19.09.19:","desc":"Update project website url."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"05.05.19:","desc":"Rebase to alpine 3.9, use new armv7 image format."},{"date":"21.01.18:","desc":"Added ffmpeg for video thumbnail creation, switched to installing zip release instead of source tarball, created small thumbnails folder, switched to dynamic readme."},{"date":"14.01.19:","desc":"Adding pipeline logic and multi arch.."},{"date":"04.09.18:","desc":"Rebase to alpine 3.8, switch to LycheeOrg repository."},{"date":"08.01.18:","desc":"Rebase to alpine 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"03.05.17:","desc":"Use repo pinning to better solve dependencies, use repo version of php7-imagick."},{"date":"12.02.17:","desc":"Initial Release."}]}},"setup":"**This image will not work with a prefilled `/pictures` mount, lychee wants total control over this folder**\n\nSetup mysql/mariadb and account via the webui, accessible at http://SERVERIP:PORT\nMore info at [lychee]({{ project_url }}).\n","_id":"content:apps:lychee.json","_type":"json","title":"Lychee","_source":"content","_file":"apps/lychee.json","_extension":"json"},{"_path":"/apps/mariadb","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mariadb","name":"mariadb","description":"[{{ project_name|capitalize }}]({{ project_url }}) is one of the most popular database servers. Made by the original developers of MySQL.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mariadb-git.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mariadb"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mariadb"}],"containers":[{"name":"mariadb","image":"linuxserver/mariadb","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"MYSQL_ROOT_PASSWORD","default":"ROOT_ACCESS_PASSWORD","description":"Set this to root password for installation (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MYSQL_DATABASE","default":"USER_DB_NAME","description":"Specify the name of a database to be created on image startup."},{"id":"MYSQL_USER","default":"MYSQL_USER","description":"This user will have superuser access to the database specified by MYSQL_DATABASE (do not use root here)."},{"id":"MYSQL_PASSWORD","default":"DATABASE_PASSWORD","description":"Set this to the password you want to use for you MYSQL_USER (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"id":"REMOTE_SQL","default":"http://URL1/your.sql,https://URL2/your.sql","description":"Set this to ingest sql files from an http/https endpoint (comma seperated array)."}],"volumes":[{"container":"/config","description":"Contains the db itself and all assorted settings.","key":"config"}],"ports":[{"container":"3306","description":"Mariadb listens on this port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mariadb","project_url":"https://mariadb.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mariadb-git.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is one of the most popular database servers. Made by the original developers of MySQL.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Latest mariadb release with an Alpine base."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"MYSQL_ROOT_PASSWORD","env_value":"ROOT_ACCESS_PASSWORD","desc":"Set this to root password for installation (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"path_to_data","desc":"Contains the db itself and all assorted settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3306","internal_port":"3306","port_desc":"Mariadb listens on this port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MYSQL_DATABASE","env_value":"USER_DB_NAME","desc":"Specify the name of a database to be created on image startup."},{"env_var":"MYSQL_USER","env_value":"MYSQL_USER","desc":"This user will have superuser access to the database specified by MYSQL_DATABASE (do not use root here)."},{"env_var":"MYSQL_PASSWORD","env_value":"DATABASE_PASSWORD","desc":"Set this to the password you want to use for you MYSQL_USER (minimum 4 characters & non-alphanumeric passwords must be properly escaped)."},{"env_var":"REMOTE_SQL","env_value":"http://URL1/your.sql,https://URL2/your.sql","desc":"Set this to ingest sql files from an http/https endpoint (comma seperated array)."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"If you didn't set a password during installation, (see logs for warning) use\n`mariadb-admin -u root -p<PASSWORD>`\nto set one at the docker prompt...\n\nNOTE changing the MYSQL_ROOT_PASSWORD variable after the container has set up the initial databases has no effect, use the mysqladmin tool to change your mariadb password.\n\nNOTE if you want to use (MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD) **all three** of these variables need to be set you cannot pick and choose.\n\nUnraid users, it is advisable to edit the template/webui after setup and remove reference to this variable.\n\nFind custom.cnf in /config for config changes (restart container for them to take effect)\n, the databases in /config/databases and the log in /config/log/myqsl\n\n### Loading passwords and users from files\n\nThe `MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD REMOTE_SQL` env values can be set in a file:\n\n```\n/config/env\n```\n\nUsing the following format:\n\n```\nMYSQL_ROOT_PASSWORD=\"ROOT_ACCESS_PASSWORD\"\nMYSQL_DATABASE=\"USER_DB_NAME\"\nMYSQL_USER=\"MYSQL_USER\"\nMYSQL_PASSWORD=\"DATABASE_PASSWORD\"\nREMOTE_SQL=\"http://URL1/your.sql,https://URL2/your.sql\"\n```\n\nThese settings can be mixed and matched with Docker ENV settings as you require, but the settings in the file will always take precedence.\n\n### Bootstrapping a new instance\n\nWe support a one time run of custom sql files on init. In order to use this place `*.sql` files in:\n\n```\n/config/initdb.d/\n```\nThis will have the same effect as setting the `REMOTE_SQL` environment variable. The sql will only be run on the containers first boot and setup.\n\n### Upgrading\n\nWhen this container initializes, if `MYSQL_ROOT_PASSWORD` is set an upgrade check will run. If an upgrade is required the log will indicate the need to run:\n\n```\nmariadb-upgrade -u root -p<PASSWORD>\n```\n","changelogs":[{"date":"09.12.22:","desc":"Add upgrade check warning."},{"date":"11.10.22:","desc":"Rebase master to Alpine 3.16, migrate to s6v3, remove password escape logic which caused problems for a small subset of users."},{"date":"06.07.21:","desc":"Rebase master to alpine."},{"date":"03.07.21:","desc":"Rebase to 3.14."},{"date":"08.02.21:","desc":"Fix new installs."},{"date":"08.02.21:","desc":"Rebase to alpine. Add mariadb-backup."},{"date":"08.02.21:","desc":"Release alpine tag. The alpine release will replace the latest tag in the near future."},{"date":"27.10.19:","desc":"Bump to 10.4, ability use custom sql on initial init ,defining root passwords via file."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"07.03.19:","desc":"Add ability to setup a database and default user on first spinup."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"10.09.18:","desc":"Rebase to ubuntu bionic and use 10.3 mariadb repository."},{"date":"09.12.17:","desc":"Fix continuation lines."},{"date":"12.09.17:","desc":"Gracefully shut down mariadb."},{"date":"27.10.16:","desc":"Implement linting suggestions on database init script."},{"date":"11.10.16:","desc":"Rebase to ubuntu xenial, add version labelling."},{"date":"09.03.16:","desc":"Update to mariadb 10.1. Change to use custom.cnf over my.cnf in /config. Restructured init files to change config options on startup, rather than in the dockerfile."},{"date":"26.01.16:","desc":"Change user of mysqld_safe script to abc, better unclean shutdown handling on restart."},{"date":"23.12.15:","desc":"Remove autoupdating, between some version updates the container breaks."},{"date":"12.08.15:","desc":"Initial Release."}]}},"setup":"If you didn't set a password during installation, (see logs for warning) use\n`mariadb-admin -u root -p<PASSWORD>`\nto set one at the docker prompt...\n\nNOTE changing the MYSQL_ROOT_PASSWORD variable after the container has set up the initial databases has no effect, use the mysqladmin tool to change your mariadb password.\n\nNOTE if you want to use (MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD) **all three** of these variables need to be set you cannot pick and choose.\n\nUnraid users, it is advisable to edit the template/webui after setup and remove reference to this variable.\n\nFind custom.cnf in /config for config changes (restart container for them to take effect)\n, the databases in /config/databases and the log in /config/log/myqsl\n\n### Loading passwords and users from files\n\nThe `MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER MYSQL_PASSWORD REMOTE_SQL` env values can be set in a file:\n\n```\n/config/env\n```\n\nUsing the following format:\n\n```\nMYSQL_ROOT_PASSWORD=\"ROOT_ACCESS_PASSWORD\"\nMYSQL_DATABASE=\"USER_DB_NAME\"\nMYSQL_USER=\"MYSQL_USER\"\nMYSQL_PASSWORD=\"DATABASE_PASSWORD\"\nREMOTE_SQL=\"http://URL1/your.sql,https://URL2/your.sql\"\n```\n\nThese settings can be mixed and matched with Docker ENV settings as you require, but the settings in the file will always take precedence.\n\n### Bootstrapping a new instance\n\nWe support a one time run of custom sql files on init. In order to use this place `*.sql` files in:\n\n```\n/config/initdb.d/\n```\nThis will have the same effect as setting the `REMOTE_SQL` environment variable. The sql will only be run on the containers first boot and setup.\n\n### Upgrading\n\nWhen this container initializes, if `MYSQL_ROOT_PASSWORD` is set an upgrade check will run. If an upgrade is required the log will indicate the need to run:\n\n```\nmariadb-upgrade -u root -p<PASSWORD>\n```\n","_id":"content:apps:mariadb.json","_type":"json","title":"Mariadb","_source":"content","_file":"apps/mariadb.json","_extension":"json"},{"_path":"/apps/mastodon","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mastodon","name":"mastodon","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, open-source social network server based on ActivityPub where users can follow friends and discover new ones..\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mastodon-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mastodon"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mastodon"}],"containers":[{"name":"mastodon","image":"linuxserver/mastodon","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"LOCAL_DOMAIN","default":"example.com","description":"This is the unique identifier of your server in the network. It cannot be safely changed later."},{"id":"REDIS_HOST","default":"redis","description":"Redis server hostname"},{"id":"REDIS_PORT","default":"6379","description":"Redis port"},{"id":"DB_HOST","default":"db","description":"Postgres database hostname"},{"id":"DB_USER","default":"mastodon","description":"Postgres username"},{"id":"DB_NAME","default":"mastodon","description":"Postgres db name"},{"id":"DB_PASS","default":"mastodon","description":"Postgres password"},{"id":"DB_PORT","default":"5432","description":"Portgres port"},{"id":"ES_ENABLED","default":"false","description":"Enable or disable Elasticsearch (requires a separate ES instance)"},{"id":"SECRET_KEY_BASE","default":"","description":"Browser session secret. Changing it will break all active browser sessions."},{"id":"OTP_SECRET","default":"","description":"MFA secret. Changing it will break two-factor authentication."},{"id":"VAPID_PRIVATE_KEY","default":"","description":"Push notification private key. Changing it will break push notifications."},{"id":"VAPID_PUBLIC_KEY","default":"","description":"Push notification public key. Changing it will break push notifications."},{"id":"SMTP_SERVER","default":"mail.example.com","description":"SMTP server for email notifications"},{"id":"SMTP_PORT","default":"25","description":"SMTP server port"},{"id":"SMTP_LOGIN","default":"","description":"SMTP username"},{"id":"SMTP_PASSWORD","default":"","description":"SMTP password"},{"id":"SMTP_FROM_ADDRESS","default":"notifications@example.com","description":"From address for emails send from Mastodon"},{"id":"S3_ENABLED","default":"false","description":"Enable or disable S3 storage of uploaded files"},{"id":"WEB_DOMAIN","default":"mastodon.example.com","description":"This can be set if you want your server identifier to be different to the subdomain hosting Mastodon. See [https://docs.joinmastodon.org/admin/config/#basic](https://docs.joinmastodon.org/admin/config/#basic)"},{"id":"ES_HOST","default":"es","description":"Elasticsearch server hostname"},{"id":"ES_PORT","default":"9200","description":"Elasticsearch port"},{"id":"ES_USER","default":"elastic","description":"Elasticsearch username"},{"id":"ES_PASS","default":"elastic","description":"Elasticsearch password"},{"id":"S3_BUCKET","default":"","description":"S3 bucket hostname"},{"id":"AWS_ACCESS_KEY_ID","default":"","description":"S3 bucket access key ID"},{"id":"AWS_SECRET_ACCESS_KEY","default":"","description":"S3 bucket secret access key"},{"id":"S3_ALIAS_HOST","default":"","description":"Alternate hostname for object fetching if you are front the S3 connections."},{"id":"SIDEKIQ_ONLY","default":"false","description":"Only run the sidekiq service in this container instance. For large scale instances that need better queue handling."},{"id":"SIDEKIQ_QUEUE","default":"","description":"The name of the sidekiq queue to run in this container. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-queues)."},{"id":"SIDEKIQ_DEFAULT","default":"false","description":"Set to `true` on the main container if you're running additional sidekiq instances. It will run the `default` queue."},{"id":"SIDEKIQ_THREADS","default":"5","description":"The number of threads for sidekiq to use. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."},{"id":"DB_POOL","default":"5","description":"The size of the DB connection pool, must be *at least* the same as `SIDEKIQ_THREADS`. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false},{"container":"443","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mastodon","project_url":"https://github.com/mastodon/mastodon/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mastodon-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, open-source social network server based on ActivityPub where users can follow friends and discover new ones..\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"develop","desc":"Pre-releases *only*."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"},{"env_var":"LOCAL_DOMAIN","env_value":"example.com","desc":"This is the unique identifier of your server in the network. It cannot be safely changed later."},{"env_var":"REDIS_HOST","env_value":"redis","desc":"Redis server hostname"},{"env_var":"REDIS_PORT","env_value":"6379","desc":"Redis port"},{"env_var":"DB_HOST","env_value":"db","desc":"Postgres database hostname"},{"env_var":"DB_USER","env_value":"mastodon","desc":"Postgres username"},{"env_var":"DB_NAME","env_value":"mastodon","desc":"Postgres db name"},{"env_var":"DB_PASS","env_value":"mastodon","desc":"Postgres password"},{"env_var":"DB_PORT","env_value":"5432","desc":"Portgres port"},{"env_var":"ES_ENABLED","env_value":"false","desc":"Enable or disable Elasticsearch (requires a separate ES instance)"},{"env_var":"SECRET_KEY_BASE","env_value":"","desc":"Browser session secret. Changing it will break all active browser sessions."},{"env_var":"OTP_SECRET","env_value":"","desc":"MFA secret. Changing it will break two-factor authentication."},{"env_var":"VAPID_PRIVATE_KEY","env_value":"","desc":"Push notification private key. Changing it will break push notifications."},{"env_var":"VAPID_PUBLIC_KEY","env_value":"","desc":"Push notification public key. Changing it will break push notifications."},{"env_var":"SMTP_SERVER","env_value":"mail.example.com","desc":"SMTP server for email notifications"},{"env_var":"SMTP_PORT","env_value":"25","desc":"SMTP server port"},{"env_var":"SMTP_LOGIN","env_value":"","desc":"SMTP username"},{"env_var":"SMTP_PASSWORD","env_value":"","desc":"SMTP password"},{"env_var":"SMTP_FROM_ADDRESS","env_value":"notifications@example.com","desc":"From address for emails send from Mastodon"},{"env_var":"S3_ENABLED","env_value":"false","desc":"Enable or disable S3 storage of uploaded files"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"WEB_DOMAIN","env_value":"mastodon.example.com","desc":"This can be set if you want your server identifier to be different to the subdomain hosting Mastodon. See [https://docs.joinmastodon.org/admin/config/#basic](https://docs.joinmastodon.org/admin/config/#basic)"},{"env_var":"ES_HOST","env_value":"es","desc":"Elasticsearch server hostname"},{"env_var":"ES_PORT","env_value":"9200","desc":"Elasticsearch port"},{"env_var":"ES_USER","env_value":"elastic","desc":"Elasticsearch username"},{"env_var":"ES_PASS","env_value":"elastic","desc":"Elasticsearch password"},{"env_var":"S3_BUCKET","env_value":"","desc":"S3 bucket hostname"},{"env_var":"AWS_ACCESS_KEY_ID","env_value":"","desc":"S3 bucket access key ID"},{"env_var":"AWS_SECRET_ACCESS_KEY","env_value":"","desc":"S3 bucket secret access key"},{"env_var":"S3_ALIAS_HOST","env_value":"","desc":"Alternate hostname for object fetching if you are front the S3 connections."},{"env_var":"SIDEKIQ_ONLY","env_value":"false","desc":"Only run the sidekiq service in this container instance. For large scale instances that need better queue handling."},{"env_var":"SIDEKIQ_QUEUE","env_value":"","desc":"The name of the sidekiq queue to run in this container. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-queues)."},{"env_var":"SIDEKIQ_DEFAULT","env_value":"false","desc":"Set to `true` on the main container if you're running additional sidekiq instances. It will run the `default` queue."},{"env_var":"SIDEKIQ_THREADS","env_value":"5","desc":"The number of threads for sidekiq to use. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."},{"env_var":"DB_POOL","env_value":"5","desc":"The size of the DB connection pool, must be *at least* the same as `SIDEKIQ_THREADS`. See [notes](https://docs.joinmastodon.org/admin/scaling/#sidekiq-threads)."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"},{"external_port":"443","internal_port":"443","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"We provide aliases for the common commands that execute in the correct context so that environment variables from secrets are available to them:\n\n* To generate keys for `SECRET_KEY_BASE` & `OTP_SECRET` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-secret` once for each.\n\n* To generate keys for `VAPID_PRIVATE_KEY` & `VAPID_PUBLIC_KEY` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-vapid`\n\nBoth of the secret generation aliases above can be run without any other setup having been carried out.\n\n* To use `tootctl` you can run something like `docker exec -it lscr.io/linuxserver/mastodon /tootctl <command>`\n\nUsing `tootctl` requires you to complete the initial Mastodon configuration first.\n\nThis container *requires* separate postgres and redis instances to run.\n\nWe support all of the official [environment variables](https://docs.joinmastodon.org/admin/config) for configuration. In place of adding them all to your run/compose you can use an env file such as [this example](https://github.com/mastodon/mastodon/blob/main/.env.production.sample) from the upstream project.\n\nFor more information check out the [mastodon documentation](https://docs.joinmastodon.org/).\n\n### Running separate sidekiq instances\n\nIt is currently only supported to run a single queue per container instance *or* all queues in a single container instance.\n\nAll containers must share the same `/config`` mount and be on a common docker network.\n\n### Strict reverse proxies\n\nThis image automatically redirects to https with a self-signed certificate. If you are using a reverse proxy which validates certificates, you need to [disable this check for the container](https://docs.linuxserver.io/faq#strict-proxy).\n","changelogs":[{"date":"09.01.23:","desc":"Updated nginx conf to fix bring inline with Mastodon configuration (fixes Elk integration)."},{"date":"19.12.22:","desc":"Support separate sidekiq queue instances."},{"date":"05.11.22:","desc":"Initial Release."}]}},"setup":"We provide aliases for the common commands that execute in the correct context so that environment variables from secrets are available to them:\n\n* To generate keys for `SECRET_KEY_BASE` & `OTP_SECRET` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-secret` once for each.\n\n* To generate keys for `VAPID_PRIVATE_KEY` & `VAPID_PUBLIC_KEY` run `docker run --rm -it --entrypoint /bin/bash lscr.io/linuxserver/mastodon generate-vapid`\n\nBoth of the secret generation aliases above can be run without any other setup having been carried out.\n\n* To use `tootctl` you can run something like `docker exec -it lscr.io/linuxserver/mastodon /tootctl <command>`\n\nUsing `tootctl` requires you to complete the initial Mastodon configuration first.\n\nThis container *requires* separate postgres and redis instances to run.\n\nWe support all of the official [environment variables](https://docs.joinmastodon.org/admin/config) for configuration. In place of adding them all to your run/compose you can use an env file such as [this example](https://github.com/mastodon/mastodon/blob/main/.env.production.sample) from the upstream project.\n\nFor more information check out the [mastodon documentation](https://docs.joinmastodon.org/).\n\n### Running separate sidekiq instances\n\nIt is currently only supported to run a single queue per container instance *or* all queues in a single container instance.\n\nAll containers must share the same `/config`` mount and be on a common docker network.\n\n### Strict reverse proxies\n\nThis image automatically redirects to https with a self-signed certificate. If you are using a reverse proxy which validates certificates, you need to [disable this check for the container](https://docs.linuxserver.io/faq#strict-proxy).\n","_id":"content:apps:mastodon.json","_type":"json","title":"Mastodon","_source":"content","_file":"apps/mastodon.json","_extension":"json"},{"_path":"/apps/medusa","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"medusa","name":"medusa","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/medusa-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/medusa"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-medusa"}],"containers":[{"name":"medusa","image":"linuxserver/medusa","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"Medusa config","key":"config"},{"container":"/downloads","description":"Download location"},{"container":"/tv","description":"TV Shows location"}],"ports":[{"container":"8081","description":"The port for the Medusa webui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"medusa","project_url":"https://pymedusa.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/medusa-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Medusa config"},{"vol_path":"/downloads","vol_host_path":"<path to downloads>","desc":"Download location"},{"vol_path":"/tv","vol_host_path":"<path to tv shows>","desc":"TV Shows location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"The port for the Medusa webui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Web interface is at `<your ip>:8081`. \n\nSet paths for downloads, tv-shows to match docker mappings via the webui, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n","changelogs":[{"date":"12.09.22:","desc":"Install ffmpeg for postprocessing."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"28.02.22:","desc":"Install python3 requirements for app."},{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"22.09.19:","desc":"Switch to python3."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.01.19:","desc":"Adding multi arch and pipeline logic"},{"date":"16.08.18:","desc":"Rebase to alpine 3.8"},{"date":"08.12.17:","desc":"Rebase to alpine 3.7"},{"date":"29.11.17:","desc":"Add py-gdbm for subtitles support"},{"date":"26.10.17:","desc":"Mediainfo moved from testing to community repo"},{"date":"10.10.17:","desc":"Use repo version of mediainfo to shorten build time"},{"date":"05.08.17:","desc":"Internal git pull instead of at runtime"},{"date":"25.05.17:","desc":"Rebase to alpine 3.6"},{"date":"07.02.17:","desc":"Rebase to alpine 3.5"},{"date":"02.01.17:","desc":"Initial Release"}]}},"setup":"Web interface is at `<your ip>:8081`. \n\nSet paths for downloads, tv-shows to match docker mappings via the webui, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n","_id":"content:apps:medusa.json","_type":"json","title":"Medusa","_source":"content","_file":"apps/medusa.json","_extension":"json"},{"_path":"/apps/minetest","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"minetest","name":"minetest","description":"[{{ project_name|capitalize }}]({{ project_url }}) (server) is a near-infinite-world block sandbox game and a game engine, inspired by InfiniMiner, Minecraft, and the like.","icon":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/minetest-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/minetest"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-minetest"}],"containers":[{"name":"minetest","image":"linuxserver/minetest","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"CLI_ARGS","default":"\"--gameid minetest --port 30000\"","description":"Optionally specify any [CLI variables](https://wiki.minetest.net/Command_line) you want to launch the app with"}],"volumes":[{"container":"/config/.minetest","description":"Where minetest stores config files and maps etc."}],"ports":[{"container":"30000/udp","description":"Port Minetest listens on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"minetest","project_url":"http://www.minetest.net/","project_logo":"https://raw.githubusercontent.com/linuxserver/beta-templates/master/lsiodev/img/minetest-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (server) is a near-infinite-world block sandbox game and a game engine, inspired by InfiniMiner, Minecraft, and the like.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config/.minetest","vol_host_path":"/path/to/data","desc":"Where minetest stores config files and maps etc."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"30000","internal_port":"30000/udp","port_desc":"Port Minetest listens on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CLI_ARGS","env_value":"\"--gameid minetest --port 30000\"","desc":"Optionally specify any [CLI variables](https://wiki.minetest.net/Command_line) you want to launch the app with"}],"app_setup_block_enabled":true,"app_setup_block":"You can find the world maps, mods folder and config files in /config/.minetest.\n\nIf you want to override the advertised port, ensure you add --port in your CLI_ARGS AND ensure the internal port reflects the change, ie;\nif you set your advertised port to 40000 with --port 40000 then your ports declaration should be 40000:40000/udp\n\n\nClient and server must be the same version, please browse the tags here to pull the appropriate version for your server:\n\nhttps://hub.docker.com/r/linuxserver/{{ project_name }}/tags\n","changelogs":[{"date":"06.08.22:","desc":"Update irrlicht deps."},{"date":"02.05.22:","desc":"Allow specifying the advertised port."},{"date":"17.03.22:","desc":"Install forked irrlicht, add zstd."},{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"12.07.19:","desc":"Bugfix to support multiple CLI variables."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"03.06.19:","desc":"Adding custom cli vars to options."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"04.03.19:","desc":"Rebase to alpine 3.9 to compile 5.0.0 minetest with new build args."},{"date":"14.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"08.08.18:","desc":"Rebase to alpine 3.8, build from latest release tag instead of master."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"08.12.17:","desc":"Rebase to alpine 3.7."},{"date":"30.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"14.02.17:","desc":"Rebase to alpine 3.5."},{"date":"25.11.16:","desc":"Rebase to alpine linux, move to main repo."},{"date":"27.02.16:","desc":"Bump to latest version."},{"date":"19.02.16:","desc":"Change port to UDP, thanks to slashopt for pointing this out."},{"date":"15.02.16:","desc":"Make minetest app a service."},{"date":"01.02.16:","desc":"Add lua-socket dependency."},{"date":"06.11.15:","desc":"Initial Release."}]}},"setup":"You can find the world maps, mods folder and config files in /config/.minetest.\n\nIf you want to override the advertised port, ensure you add --port in your CLI_ARGS AND ensure the internal port reflects the change, ie;\nif you set your advertised port to 40000 with --port 40000 then your ports declaration should be 40000:40000/udp\n\n\nClient and server must be the same version, please browse the tags here to pull the appropriate version for your server:\n\nhttps://hub.docker.com/r/linuxserver/{{ project_name }}/tags\n","_id":"content:apps:minetest.json","_type":"json","title":"Minetest","_source":"content","_file":"apps/minetest.json","_extension":"json"},{"_path":"/apps/minisatip","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"minisatip","name":"minisatip","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-threaded satip server version 1.2 that runs under Linux and it was tested with DVB-S, DVB-S2, DVB-T, DVB-T2, DVB-C, DVB-C2, ATSC and ISDB-T cards.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/minisatip-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/minisatip"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-minisatip"}],"containers":[{"name":"minisatip","image":"linuxserver/minisatip","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"","description":"Specify specific run params for minisatip"},{"id":"VERSION","default":"latest","description":"Supported values are LATEST, PLEXPASS or a specific version number."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"Configuration files and minisatip data","key":"config"}],"ports":[{"container":"8875","description":"Status Page WebUI","protocol":"tcp","web":false},{"container":"554","description":"RTSP Port","protocol":"tcp","web":false},{"container":"1900/udp","description":"App Discovery","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"minisatip","project_url":"https://github.com/catalinii/minisatip","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/minisatip-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-threaded satip server version 1.2 that runs under Linux and it was tested with DVB-S, DVB-S2, DVB-T, DVB-T2, DVB-C, DVB-C2, ATSC and ISDB-T cards.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"RUN_OPTS","env_value":"","desc":"Specify specific run params for minisatip"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files and minisatip data"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8875","internal_port":"8875","port_desc":"Status Page WebUI"},{"external_port":"554","internal_port":"554","port_desc":"RTSP Port"},{"external_port":"1900","internal_port":"1900/udp","port_desc":"App Discovery"}],"param_device_map":true,"param_devices":[{"device_path":"/dev/dvb","device_host_path":"/dev/dvb","desc":"For passing through Tv-cards"}],"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_env_vars":[{"env_var":"VERSION","env_value":"latest","desc":"Supported values are LATEST, PLEXPASS or a specific version number."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"opt_param_usage_include_ports":false,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Additional runtime parameters\n\nIn some cases it might be necessary to start minisatip with additional parameters, for example to configure a unicable LNB. Add the parameters you need and restart the container. Be sure to have the right parameters set as adding the wrong once might lead to the container not starting correctly.\nFor a list of minisatip parameters visit [{{ project_name|capitalize }}]({{ project_url }}) page.\n"],"app_setup_block_enabled":true,"app_setup_block":"Best used in conjunction with [tvheadend](https://github.com/linuxserver/docker-tvheadend)\n\nThere is no setup per se, other than adding your cards for passthrough.\n\nYou can then use your cards as DVB inputs in apps such as tvheadend.\n","changelogs":[{"date":"12.11.22:","desc":"Rebasing to alpine 3.137, upgrading to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"20.02.19:","desc":"Fix run options."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"28.08.18:","desc":"Rebase to Alpine 3.8."},{"date":"13.12.17:","desc":"Rebase to Alpine 3.7."},{"date":"28.05.17:","desc":"Rebase to Alpine 3.6."},{"date":"08.02.17:","desc":"Rebase to Alpine 3.5 and only compile libs in dvb-apps."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"18.09.16:","desc":"Add support for Common Interface."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"15.08.16:","desc":"Initial Release."}]}},"setup":"Best used in conjunction with [tvheadend](https://github.com/linuxserver/docker-tvheadend)\n\nThere is no setup per se, other than adding your cards for passthrough.\n\nYou can then use your cards as DVB inputs in apps such as tvheadend.\n","_id":"content:apps:minisatip.json","_type":"json","title":"Minisatip","_source":"content","_file":"apps/minisatip.json","_extension":"json"},{"_path":"/apps/mods","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mods","name":"mods","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/mods.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mods"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mods"}],"containers":[{"name":"mods","image":"linuxserver/mods","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"404":"Not Found"}},"_id":"content:apps:mods.json","_type":"json","title":"Mods","_source":"content","_file":"apps/mods.json","_extension":"json"},{"_path":"/apps/mstream","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mstream","name":"mstream","description":"[{{ project_name }}]({{ project_url }}) is a personal music streaming server. You can use mStream to stream your music from your home computer to any device, anywhere.  There are mobile apps available for both Android and iPhone.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mstream-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mstream"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mstream"}],"containers":[{"name":"mstream","image":"linuxserver/mstream","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"mStream config","key":"config"},{"container":"/music","description":"Music location"}],"ports":[{"container":"3000","description":"The port for the mStream webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mstream","project_url":"https://mstream.io/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mstream-icon.png","project_blurb":"[{{ project_name }}]({{ project_url }}) is a personal music streaming server. You can use mStream to stream your music from your home computer to any device, anywhere.  There are mobile apps available for both Android and iPhone.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"mStream config"},{"vol_path":"/music","vol_host_path":"/path/to/music","desc":"Music location"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"The port for the mStream webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `http://<your-ip>:3000`\n\nSettings are adjusted through the web ui or via editing of `config.json`. For more information check out [{{ project_name|capitalize }}](https://github.com/IrosTheBeggar/mStream/blob/master/docs/json_config.md#json-config).\n\n## IMPORTANT NOTICE:\nmStream v5 no longer accepts cli arguments for setting the user and password and requires the use of `config.json`. Therefore, the environment variables `USER`, `PASSWORD` and `USE_JSON` are deprecated.\n\nv4's `config.json` is not compatible with v5. Existing `config.json` will be renamed to `config.json.v4-bak` for your reference and a new default `config.json` will be created upon upgrade from v4 to v5.\n","changelogs":[{"date":"05.04.22:","desc":"Move `sync` folder to `/config`."},{"date":"02.04.22:","desc":"Rebase to alpine 3.15. Fix ffmpeg download."},{"date":"17.05.21:","desc":"Deprecating the env vars `USER`, `PASSWORD` and `USE_JSON` as mStream v5 requires the use of `config.json`."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"18.05.19:","desc":"Inital Release"}]}},"setup":"Access the webui at `http://<your-ip>:3000`\n\nSettings are adjusted through the web ui or via editing of `config.json`. For more information check out [{{ project_name|capitalize }}](https://github.com/IrosTheBeggar/mStream/blob/master/docs/json_config.md#json-config).\n\n## IMPORTANT NOTICE:\nmStream v5 no longer accepts cli arguments for setting the user and password and requires the use of `config.json`. Therefore, the environment variables `USER`, `PASSWORD` and `USE_JSON` are deprecated.\n\nv4's `config.json` is not compatible with v5. Existing `config.json` will be renamed to `config.json.v4-bak` for your reference and a new default `config.json` will be created upon upgrade from v4 to v5.\n","_id":"content:apps:mstream.json","_type":"json","title":"Mstream","_source":"content","_file":"apps/mstream.json","_extension":"json"},{"_path":"/apps/mylar3","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mylar3","name":"mylar3","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated Comic Book downloader (cbr/cbz) for use with NZB and torrents written in python. It supports SABnzbd, NZBGET, and many torrent clients in addition to DDL.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mylar-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mylar3"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mylar3"}],"containers":[{"name":"mylar3","image":"linuxserver/mylar3","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/config","description":"Where mylar should store config files.","key":"config"},{"container":"/comics","description":"Map to your comics folder."},{"container":"/downloads","description":"Map to your downloads folder."}],"ports":[{"container":"8090","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mylar3","project_url":"https://github.com/mylar3/mylar3","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mylar-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an automated Comic Book downloader (cbr/cbz) for use with NZB and torrents written in python. It supports SABnzbd, NZBGET, and many torrent clients in addition to DDL.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Mylar3 releases"},{"tag":"nightly","desc":"Commits to Mylar3 `python3-dev` branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where mylar should store config files."},{"vol_path":"/comics","vol_host_path":"/path/to/comics","desc":"Map to your comics folder."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Map to your downloads folder."}],"param_usage_include_env":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"8090","internal_port":"8090","port_desc":"WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"The web ui for settings etc, is on `http://SERVERIP:8090`\nFor more detailed setup options, refer to [{{ project_name|capitalize }}]({{ project_url }}).\n","changelogs":[{"date":"12.10.22:","desc":"Rebase to alpine 3.16 and upgrade to s6v3."},{"date":"01.02.22:","desc":"Rebase to alpine 3.15."},{"date":"02.11.21:","desc":"Rebase to alpine 3.14. Remove `pathlib.py`."},{"date":"25.05.21:","desc":"Add `libwebp` support."},{"date":"17.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"03.01.21:","desc":"Output mylar log to docker log."},{"date":"21.12.20:","desc":"Release `nightly` tag based on commits to upstream `python3-dev` branch."},{"date":"28.09.20:","desc":"Initial release."}]}},"setup":"The web ui for settings etc, is on `http://SERVERIP:8090`\nFor more detailed setup options, refer to [{{ project_name|capitalize }}]({{ project_url }}).\n","_id":"content:apps:mylar3.json","_type":"json","title":"Mylar3","_source":"content","_file":"apps/mylar3.json","_extension":"json"},{"_path":"/apps/mysql-workbench","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"mysql-workbench","name":"mysql-workbench","description":"[MySQL Workbench]({{ project_url }}) is a unified visual tool for database architects, developers, and DBAs. MySQL Workbench provides data modeling, SQL development, and comprehensive administration tools for server configuration, user administration, backup, and much more.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mysql-workbench-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/mysql-workbench"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-mysql-workbench"}],"containers":[{"name":"mysql-workbench","image":"linuxserver/mysql-workbench","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"}],"ports":[{"container":"3000","description":"Mysql Workbench desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"mysql-workbench","project_url":"https://www.mysql.com/products/workbench/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/mysql-workbench-icon.png","project_blurb":"[MySQL Workbench]({{ project_url }}) is a unified visual tool for database architects, developers, and DBAs. MySQL Workbench provides data modeling, SQL development, and comprehensive administration tools for server configuration, user administration, backup, and much more.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Mysql Workbench desktop gui."}],"custom_params":[{"name":"cap-add","name_compose":"cap_add","value":["IPC_LOCK"],"desc":"Required for keyring functionality","array":"true"}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"15.09.22:","desc":"Migrate to s6v3."},{"date":"26.07.22:","desc":"Rebase on jammy."},{"date":"20.04.21:","desc":"Rebase on focal."},{"date":"18.01.21:","desc":"Update libpython dependency."},{"date":"26.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:mysql-workbench.json","_type":"json","title":"Mysql Workbench","_source":"content","_file":"apps/mysql-workbench.json","_extension":"json"},{"_path":"/apps/nano-wallet","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nano-wallet","name":"nano-wallet","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n\nThis container is a simple nginx wrapper for the light wallet located [here](https://github.com/linuxserver/nano-wallet). You will need to pass a valid RPC host when accessing this container.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nano-wallet"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nano-wallet"}],"containers":[{"name":"nano-wallet","image":"linuxserver/nano-wallet","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"ports":[{"container":"80","description":"Webserver port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nano-wallet","project_url":"https://nano.org/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n\nThis container is a simple nginx wrapper for the light wallet located [here](https://github.com/linuxserver/nano-wallet). You will need to pass a valid RPC host when accessing this container.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Webserver port"}],"param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"\nThis container requires a Nano RPC endpoint to communicate with whether a public network or your own, see [here](https://hub.docker.com/r/linuxserver/nano) for more information.\n\nSimply access the container at the URL:\n\nhttp://localhost/#/THE_IP_OR_HOSTNAME_OF_RPC_ENDPOINT\n","changelogs":[{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"23.05.20:","desc":"Initial Release."}]}},"setup":"\nThis container requires a Nano RPC endpoint to communicate with whether a public network or your own, see [here](https://hub.docker.com/r/linuxserver/nano) for more information.\n\nSimply access the container at the URL:\n\nhttp://localhost/#/THE_IP_OR_HOSTNAME_OF_RPC_ENDPOINT\n","_id":"content:apps:nano-wallet.json","_type":"json","title":"Nano Wallet","_source":"content","_file":"apps/nano-wallet.json","_extension":"json"},{"_path":"/apps/nano","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nano","name":"nano","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n","icon":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nano"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nano"}],"containers":[{"name":"nano","image":"linuxserver/nano","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PEER_HOST","default":"localhost","description":"Default peer host (can be overidden with an array by command line options)"},{"id":"LIVE_GENESIS_PUB","default":"GENESIS_PUBLIC","description":"Genesis block public key"},{"id":"LIVE_GENESIS_ACCOUNT","default":"nano_xxxxxx","description":"Genesis block account"},{"id":"LIVE_GENESIS_WORK","default":"WORK_FOR_BLOCK","description":"Genesis block proof of work"},{"id":"LIVE_GENESIS_SIG","default":"BLOCK_SIGNATURE","description":"Genesis block signature"},{"id":"CLI_OPTIONS","default":"--config node.enable_voting=true","description":"Node run command cli args"},{"id":"LMDB_BOOTSTRAP_URL","default":"http://example.com/Nano_64_version_20.7z","description":"HTTP/HTTPS endpoint to download a 7z file with the data.ldb to bootstrap to this node"}],"volumes":[{"container":"/config","description":"Main storage for config and blockchain","key":"config"}],"ports":[{"container":"8075","description":"Nano communication port","protocol":"tcp","web":false},{"container":"3000","description":"RPC interface filtered through a proxy","protocol":"tcp","web":false},{"container":"3001","description":"Https RPC interface filtered through a proxy","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nano","project_url":"https://nano.org/","project_logo":"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Nano_logo.png/640px-Nano_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Nano releases"},{"tag":"beta","desc":"Beta Nano releases"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Main storage for config and blockchain"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8075","internal_port":"8075","port_desc":"Nano communication port"},{"external_port":"7076","internal_port":"3000","port_desc":"RPC interface filtered through a proxy"},{"external_port":"7077","internal_port":"3001","port_desc":"Https RPC interface filtered through a proxy"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PEER_HOST","env_value":"localhost","desc":"Default peer host (can be overidden with an array by command line options)"},{"env_var":"LIVE_GENESIS_PUB","env_value":"GENESIS_PUBLIC","desc":"Genesis block public key"},{"env_var":"LIVE_GENESIS_ACCOUNT","env_value":"nano_xxxxxx","desc":"Genesis block account"},{"env_var":"LIVE_GENESIS_WORK","env_value":"WORK_FOR_BLOCK","desc":"Genesis block proof of work"},{"env_var":"LIVE_GENESIS_SIG","env_value":"BLOCK_SIGNATURE","desc":"Genesis block signature"},{"env_var":"CLI_OPTIONS","env_value":"--config node.enable_voting=true","desc":"Node run command cli args"},{"env_var":"LMDB_BOOTSTRAP_URL","env_value":"http://example.com/Nano_64_version_20.7z","desc":"HTTP/HTTPS endpoint to download a 7z file with the data.ldb to bootstrap to this node"}],"app_setup_block_enabled":true,"app_setup_block":"### Your Genesis account\nBy default this container will launch with a genesis block based on the private key `0000000000000000000000000000000000000000000000000000000000000000`, this should obviously only ever be used for testing purposes. Before you run your node you should use a script baked into this image to determine your private key and required environment variables: \n\n```\ndocker run --rm --entrypoint /genesis.sh linuxserver/nano\nGenerating Genesis block\n!!!!!!! ACCOUNT INFO SAVE THIS INFORMATION IT WILL NOT BE SHOWN AGAIN !!!!!!!!\nPrivate Key: CD4CD6B1E5523D4B5AEDD2B1E5A447C6C6797E729A531A95F9AD7937FC7CD9EA\nPublic Key:  2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D\nAccount:     nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nContainer Environment Values:\n -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n```\n\nThese environment variables will be used for all of the peers in your payment network, but if you are running what you would consider a public or live network never share your private key even if you have drained the funds from that account it can be potentionally used to create valid forks.\n**Even Better**, you should never even trust our Docker image for generating a private key and open block. Do it on an airgapped machine and keep it on a paper wallet.\n\n### RPC Proxy settings\nBy default this container will enable RPC control and publish a custom service that acts as an RPC firewall giving you the ability to whitelist specific RPC calls and overide/add default values.\n\nThe default proxy config is stored in `/config/rpc-proxy.json`: \n\n```\n{\n  \"port\":3000,\n  \"httpsport\":3001,\n  \"rpchost\":\"127.0.0.1\",\n  \"rpcport\":7076,\n  \"certfile\":\"/config/ssl/cert.crt\",\n  \"keyfile\":\"/config/ssl/cert.key\",\n  \"whitelist\":[\n    \"account_info\",\n    \"account_history\",\n    \"block_count\",\n    \"block_info\",\n    \"pending\",\n    \"process\"\n  ],\n  \"overrides\":{\n    \"account-history\":{\n      \"count\":\"64\"\n    },\n    \"pending\":{\n      \"count\":\"8\"\n    }\n  }\n}\n```\n\nThis should be a minimal amount of RPC access needed to run a local light wallet against this endpoint. If you plan on having your network users only run clientside light wallets (local blake2b block generation and block `process` call publishing) you should publically publish this port for access for both port 7076 and 7077. For functional light wallets on Https endpoints we will generate a self signed cert/key combo but you should add the ones associated with your domain. This will allow yours and other https hosted light wallets to hit your RPC endpoint clientside from the users web browser.\n\nOutside of potential https tunneling and actual object parsing (will remove duplicate keys) this is not a conventional API, it simply acts as a firewall and will send and return data just like a local RPC server would. The goal is to be compatible with any existing Nano software if the developers decide to add the ability to connect to alternative network endpoints. \n\n**Our Proxy has not been audited by any security team and is provided as is, though we make the best effort to keep it simple and secure**\n\n### Node configuration via environment\nBefore you get started please review the configuration docs [here](https://docs.nano.org/running-a-node/configuration/)\n\nWe will pass the `CLI_OPTIONS` to the node, here is a run command example:\n\n```\n-e CLI_OPTIONS='--config node.preconfigured_peers=[\"peering.yourhost.com\",\"peering.yourhost2.com\"] \\\n                --config node.enable_voting=true'\n```\n\nThere are many options to know here to run an actual live node especially peering and voting, again please review the docs if you plan to run something outside of a local setup.\n\n### Quickstart Guide\n\nHere we are going to cover the bare minimum commands needed to spinup a local payment network and wallet. \n\nFirst spinup your containers:\n```\ndocker run -d \\\n--name node \\\n-e CLI_OPTIONS='--config node.enable_voting=true' \\\n-p 7076:3000 \\\n--restart unless-stopped \\\nlinuxserver/nano\n```\n```\ndocker run -d \\\n--name=wallet \\\n-p 80:80 \\\n--restart unless-stopped \\\nlinuxserver/nano-wallet\n```\nThen unlock the Genesis funds on the local node to allow it to confirm transactions: \n```\ndocker exec -it node bash\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_create\" }' localhost:7076\n{\n    \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\"\n}\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_add\", \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\", \"key\": \"0000000000000000000000000000000000000000000000000000000000000000\" }' localhost:7076\n{\n    \"account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\"\n}\n```\n\nHere we are using the default private key of `0000000000000000000000000000000000000000000000000000000000000000` for the image.\nNavigate to http://localhost/#/localhost and enter this key. You should be greeted by the genesis account wallet with 340.28 Million Nano.\n\nFrom here you can generate new wallets from the home screen and send/receive funds on your local network. Now you will be running an insecure centralized network with a single voting representative and a zero security private key using the commands above. To spinup a standard private or even public network you should read up on Nano's documentation [HERE](https://docs.nano.org/) and continue reading the network design section below.\n\n### Network design\nThere are 4 main concepts to grasp from a network standpoint as far as types of endpoints. Before we get started here is a basic network diagram:\n\n![image](https://raw.githubusercontent.com/linuxserver/image-docs/master/img/nano-network.png)\n\n#### Principle nodes and voting representatives\nPrinciple nodes are network representatives with the ability to vote due to having a certain threshold of funds unlocked on that node or pointed to that unlocked address. These nodes should be as airgapped as possible while still being an active 24/7 peer of the network. From a tecnical perspective this is a node with an account private key that either has the funds it needs itself or enough users have pointed their accounts to it as a representative. In a live and secure configuration to protect the funds of this account you would use an inactive private key account with the funds in it and locally sign a change of representative block to point to the always online representative.\n\nThese nodes should never process external RPC calls even on a local network, the same rules go for any node with a local unlocked wallet.\n\nKeep in mind the key to the security of the network is that 51% of the funds are pointed to trusted representatives that will generally not argue about chain forks. \n\nIn most deployments the best bet is to heavily centralize your voting nodes, this is unless you are intentionally trying to build a distributed ledger and security model like the main Nano live net. Achieving that will be a long and difficult task.\n\n#### Network peers\n\nTo a normal user simply transacting on the network using off the shelf tools like a web wallet and web based block explorers is generally all that is required. They get a number in a ledger somewhere and are able to locally sign and publish blocks using their private key using your published RPC endpoints.\n\nFor advanced users and just to generally make the network more robust, network operators should promote people running their own nodes. Using this image a network peer simply needs to run a docker run command with your pre-configured variables. IE given the generation example from above in the `Your Genesis account` section:\n\n```\ndocker create \\\n  --name=nano \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.mydomain.com \\\n  -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n  -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n  -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n\nWhen the container spins up it will reach out to the node to bootstrap it's local ledger from peering.mydomain.com . This node once fully synced will be able to run local RPC commands to plug into a wallet and default Nano node wallet commands for automated pocketing of transactions etc. It will also get a list of other peers on the network from it's initial network peering and start participating in your distributed cryptocurrency network.\n\n#### Public RPC endpoints\nThe key to users going to a webpage and managing the funds on your network is the ability to get blockchain information and publish new blocks to theirs. As mentioned earlier we bundle a basic firewall with a core set of RPC functions whitelisted that should be safe to expose publically. \n\nFrom a network design perspective these nodes should be purely what you would consider client peers and never have any wallets registered or private keys stored on them. Also for redundancy optmimally these peers should be run in a cluster behind a load balancer. For standard nodes you are building out a large P2P network, but in the case of the RPC endpoint and specifically the URL the end user is going to pass when accessing their wallet it is up to you to make that resilient.\n\n#### Clientside javascript wallet\nCurrently we publish a pure javascript clientside wallet located here:  \n\nhttps://github.com/linuxserver/nano-wallet\n\nIt is designed to be run 100% clientside in any web browser and use public RPC endpoints to hook into any network and conduct transactions by locally signing then publishing the result.\nThis can be hosted locally with any simple webserver and pointed to a locally run peer, but for full functionality we reccomend providing a public Https URL with these files along with plugging in legitamite SSL certificates into your RPC endpoints running on 7077.\n\n# Running a node on the LinuxServer network\n\nWe maintain our own network which users can get funds to transact on from our [Discord](https://discord.gg/YWrKVTn) server. If you would like to run a node on our network here is our Docker run command:\n```\ndocker create \\\n  --name=lsio-node \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.linuxserver.io \\\n  -e LIVE_GENESIS_PUB=79F2E157B5667F1C8B6CCB6DF691DAC032B85DEC39E231D29976DCED05F5B1BE \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1yhkw7ducsmz5k7pskufytaxoi3kq3gyrgh489bbkxpwxn4zdefyn4rmrrkk \\\n  -e LIVE_GENESIS_WORK=c51204c6b69384cb \\\n  -e LIVE_GENESIS_SIG=90DDE7B4DC038811180FF5DDE8594F1774542A7AADE3DB71A57AA38A5AED42672E1E8D7ACFAC315BDB0EB5DCB542C610B9C49B2560AE575073855259AF065509 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n","changelogs":[{"date":"02.06.20:","desc":"Rebase to Alpine 3.12."},{"date":"28.05.20:","desc":"Add beta tag."},{"date":"17.05.20:","desc":"Initial Release."}]}},"setup":"### Your Genesis account\nBy default this container will launch with a genesis block based on the private key `0000000000000000000000000000000000000000000000000000000000000000`, this should obviously only ever be used for testing purposes. Before you run your node you should use a script baked into this image to determine your private key and required environment variables: \n\n```\ndocker run --rm --entrypoint /genesis.sh linuxserver/nano\nGenerating Genesis block\n!!!!!!! ACCOUNT INFO SAVE THIS INFORMATION IT WILL NOT BE SHOWN AGAIN !!!!!!!!\nPrivate Key: CD4CD6B1E5523D4B5AEDD2B1E5A447C6C6797E729A531A95F9AD7937FC7CD9EA\nPublic Key:  2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D\nAccount:     nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nContainer Environment Values:\n -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n```\n\nThese environment variables will be used for all of the peers in your payment network, but if you are running what you would consider a public or live network never share your private key even if you have drained the funds from that account it can be potentionally used to create valid forks.\n**Even Better**, you should never even trust our Docker image for generating a private key and open block. Do it on an airgapped machine and keep it on a paper wallet.\n\n### RPC Proxy settings\nBy default this container will enable RPC control and publish a custom service that acts as an RPC firewall giving you the ability to whitelist specific RPC calls and overide/add default values.\n\nThe default proxy config is stored in `/config/rpc-proxy.json`: \n\n```\n{\n  \"port\":3000,\n  \"httpsport\":3001,\n  \"rpchost\":\"127.0.0.1\",\n  \"rpcport\":7076,\n  \"certfile\":\"/config/ssl/cert.crt\",\n  \"keyfile\":\"/config/ssl/cert.key\",\n  \"whitelist\":[\n    \"account_info\",\n    \"account_history\",\n    \"block_count\",\n    \"block_info\",\n    \"pending\",\n    \"process\"\n  ],\n  \"overrides\":{\n    \"account-history\":{\n      \"count\":\"64\"\n    },\n    \"pending\":{\n      \"count\":\"8\"\n    }\n  }\n}\n```\n\nThis should be a minimal amount of RPC access needed to run a local light wallet against this endpoint. If you plan on having your network users only run clientside light wallets (local blake2b block generation and block `process` call publishing) you should publically publish this port for access for both port 7076 and 7077. For functional light wallets on Https endpoints we will generate a self signed cert/key combo but you should add the ones associated with your domain. This will allow yours and other https hosted light wallets to hit your RPC endpoint clientside from the users web browser.\n\nOutside of potential https tunneling and actual object parsing (will remove duplicate keys) this is not a conventional API, it simply acts as a firewall and will send and return data just like a local RPC server would. The goal is to be compatible with any existing Nano software if the developers decide to add the ability to connect to alternative network endpoints. \n\n**Our Proxy has not been audited by any security team and is provided as is, though we make the best effort to keep it simple and secure**\n\n### Node configuration via environment\nBefore you get started please review the configuration docs [here](https://docs.nano.org/running-a-node/configuration/)\n\nWe will pass the `CLI_OPTIONS` to the node, here is a run command example:\n\n```\n-e CLI_OPTIONS='--config node.preconfigured_peers=[\"peering.yourhost.com\",\"peering.yourhost2.com\"] \\\n                --config node.enable_voting=true'\n```\n\nThere are many options to know here to run an actual live node especially peering and voting, again please review the docs if you plan to run something outside of a local setup.\n\n### Quickstart Guide\n\nHere we are going to cover the bare minimum commands needed to spinup a local payment network and wallet. \n\nFirst spinup your containers:\n```\ndocker run -d \\\n--name node \\\n-e CLI_OPTIONS='--config node.enable_voting=true' \\\n-p 7076:3000 \\\n--restart unless-stopped \\\nlinuxserver/nano\n```\n```\ndocker run -d \\\n--name=wallet \\\n-p 80:80 \\\n--restart unless-stopped \\\nlinuxserver/nano-wallet\n```\nThen unlock the Genesis funds on the local node to allow it to confirm transactions: \n```\ndocker exec -it node bash\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_create\" }' localhost:7076\n{\n    \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\"\n}\nroot@f1df092971f0:/# curl -d '{ \"action\": \"wallet_add\", \"wallet\": \"A3D63F1B28AC68BCD9E0FF74278C7984A36841C803EF1A81DF92BCD6E3BB18F9\", \"key\": \"0000000000000000000000000000000000000000000000000000000000000000\" }' localhost:7076\n{\n    \"account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\"\n}\n```\n\nHere we are using the default private key of `0000000000000000000000000000000000000000000000000000000000000000` for the image.\nNavigate to http://localhost/#/localhost and enter this key. You should be greeted by the genesis account wallet with 340.28 Million Nano.\n\nFrom here you can generate new wallets from the home screen and send/receive funds on your local network. Now you will be running an insecure centralized network with a single voting representative and a zero security private key using the commands above. To spinup a standard private or even public network you should read up on Nano's documentation [HERE](https://docs.nano.org/) and continue reading the network design section below.\n\n### Network design\nThere are 4 main concepts to grasp from a network standpoint as far as types of endpoints. Before we get started here is a basic network diagram:\n\n![image](https://raw.githubusercontent.com/linuxserver/image-docs/master/img/nano-network.png)\n\n#### Principle nodes and voting representatives\nPrinciple nodes are network representatives with the ability to vote due to having a certain threshold of funds unlocked on that node or pointed to that unlocked address. These nodes should be as airgapped as possible while still being an active 24/7 peer of the network. From a tecnical perspective this is a node with an account private key that either has the funds it needs itself or enough users have pointed their accounts to it as a representative. In a live and secure configuration to protect the funds of this account you would use an inactive private key account with the funds in it and locally sign a change of representative block to point to the always online representative.\n\nThese nodes should never process external RPC calls even on a local network, the same rules go for any node with a local unlocked wallet.\n\nKeep in mind the key to the security of the network is that 51% of the funds are pointed to trusted representatives that will generally not argue about chain forks. \n\nIn most deployments the best bet is to heavily centralize your voting nodes, this is unless you are intentionally trying to build a distributed ledger and security model like the main Nano live net. Achieving that will be a long and difficult task.\n\n#### Network peers\n\nTo a normal user simply transacting on the network using off the shelf tools like a web wallet and web based block explorers is generally all that is required. They get a number in a ledger somewhere and are able to locally sign and publish blocks using their private key using your published RPC endpoints.\n\nFor advanced users and just to generally make the network more robust, network operators should promote people running their own nodes. Using this image a network peer simply needs to run a docker run command with your pre-configured variables. IE given the generation example from above in the `Your Genesis account` section:\n\n```\ndocker create \\\n  --name=nano \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.mydomain.com \\\n  -e LIVE_GENESIS_PUB=2D057DF2EB09E918D3F95B5FCA69A5FD3EA406EF7D1810106324CD7A99FAA32D \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1da7hqsgp4hb55bzkptzsbntdzbyni5gyzar41a88b8fhcezoasfjkgmyk5y \\\n  -e LIVE_GENESIS_WORK=7fd88e48684600b7 \\\n  -e LIVE_GENESIS_SIG=D1DF3A64BB43C131944401632215569A40AAE858ACF6CB59D5C77070E69DBF6435D93807877628A8B142DBF1AC4C562CD2F4CEBEB7D15486BDB7494A6146E007 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n\nWhen the container spins up it will reach out to the node to bootstrap it's local ledger from peering.mydomain.com . This node once fully synced will be able to run local RPC commands to plug into a wallet and default Nano node wallet commands for automated pocketing of transactions etc. It will also get a list of other peers on the network from it's initial network peering and start participating in your distributed cryptocurrency network.\n\n#### Public RPC endpoints\nThe key to users going to a webpage and managing the funds on your network is the ability to get blockchain information and publish new blocks to theirs. As mentioned earlier we bundle a basic firewall with a core set of RPC functions whitelisted that should be safe to expose publically. \n\nFrom a network design perspective these nodes should be purely what you would consider client peers and never have any wallets registered or private keys stored on them. Also for redundancy optmimally these peers should be run in a cluster behind a load balancer. For standard nodes you are building out a large P2P network, but in the case of the RPC endpoint and specifically the URL the end user is going to pass when accessing their wallet it is up to you to make that resilient.\n\n#### Clientside javascript wallet\nCurrently we publish a pure javascript clientside wallet located here:  \n\nhttps://github.com/linuxserver/nano-wallet\n\nIt is designed to be run 100% clientside in any web browser and use public RPC endpoints to hook into any network and conduct transactions by locally signing then publishing the result.\nThis can be hosted locally with any simple webserver and pointed to a locally run peer, but for full functionality we reccomend providing a public Https URL with these files along with plugging in legitamite SSL certificates into your RPC endpoints running on 7077.\n\n# Running a node on the LinuxServer network\n\nWe maintain our own network which users can get funds to transact on from our [Discord](https://discord.gg/YWrKVTn) server. If you would like to run a node on our network here is our Docker run command:\n```\ndocker create \\\n  --name=lsio-node \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e PEER_HOST=peering.linuxserver.io \\\n  -e LIVE_GENESIS_PUB=79F2E157B5667F1C8B6CCB6DF691DAC032B85DEC39E231D29976DCED05F5B1BE \\\n  -e LIVE_GENESIS_ACCOUNT=nano_1yhkw7ducsmz5k7pskufytaxoi3kq3gyrgh489bbkxpwxn4zdefyn4rmrrkk \\\n  -e LIVE_GENESIS_WORK=c51204c6b69384cb \\\n  -e LIVE_GENESIS_SIG=90DDE7B4DC038811180FF5DDE8594F1774542A7AADE3DB71A57AA38A5AED42672E1E8D7ACFAC315BDB0EB5DCB542C610B9C49B2560AE575073855259AF065509 \\\n  -p 8075:8075 \\\n  -p 7076:3000 \\\n  -p 7077:3001 \\\n  -v /path/to/data:/config \\\n  --restart unless-stopped \\\n  linuxserver/nano\n```\n","_id":"content:apps:nano.json","_type":"json","title":"Nano","_source":"content","_file":"apps/nano.json","_extension":"json"},{"_path":"/apps/netbootxyz","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"netbootxyz","name":"netbootxyz","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to PXE boot various operating system installers or utilities from one place within the BIOS without the need of having to go retrieve the media to run the tool. iPXE is used to provide a user friendly menu from within the BIOS that lets you easily choose the operating system you want along with any specific types of versions or bootable flags.","icon":"https://netboot.xyz/images/netboot.xyz.gif","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/netbootxyz"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-netbootxyz"}],"containers":[{"name":"netbootxyz","image":"linuxserver/netbootxyz","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}],"volumes":[{"container":"/assets","description":"Storage for NETBOOT.XYZ bootable assets (live CDs and other files)"},{"container":"/config","description":"Storage for boot menu files and web application config","key":"config"}],"ports":[{"container":"3000","description":"Web configuration interface.","protocol":"tcp","web":false},{"container":"69/udp","description":"TFTP Port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"netbootxyz","project_url":"https://netboot.xyz","project_logo":"https://netboot.xyz/images/netboot.xyz.gif","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a way to PXE boot various operating system installers or utilities from one place within the BIOS without the need of having to go retrieve the media to run the tool. iPXE is used to provide a user friendly menu from within the BIOS that lets you easily choose the operating system you want along with any specific types of versions or bootable flags.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Web application for full self hosting"},{"tag":"tftp","desc":"TFTP server only with NETBOOT.XYZ boot files"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Storage for boot menu files and web application config"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web configuration interface."},{"external_port":"69","internal_port":"69/udp","port_desc":"TFTP Port."}],"param_usage_include_env":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MENU_VERSION","env_value":"1.9.9","desc":"Specify a specific version of boot files you want to use from NETBOOT.XYZ (unset pulls latest)"},{"env_var":"PORT_RANGE","env_value":"30000:30010","desc":"Specify the port range tftp will use for data transfers [(see Wikipedia)](https://en.wikipedia.org/wiki/Trivial_File_Transfer_Protocol#Details)"},{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a sobfolder if running this behind a reverse proxy (IE /proxy/)"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"8080","internal_port":"80","port_desc":"NGINX server for hosting assets."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/assets","vol_host_path":"/path/to/assets","desc":"Storage for NETBOOT.XYZ bootable assets (live CDs and other files)"}],"app_setup_block_enabled":true,"app_setup_block":"To use this image you need an existing DHCP server where you can set this TFTP server as your DHCP boot destination. This image does not contain a DHCP server nor do we aim to support one in the future. This is simply a TFTP server hosting the latest IPXE kernel builds from [netboot.xyz]({{ project_url }}). If you are interested in their project and lack the ability to setup a DHCP server to boot this payload they also have USB stick images you can use available on their [downloads page]({{ project_url }}/downloads/).\n\n### Router Setup Examples\n\n#### PFSense\nServices -> DHCP Server\n\nSet both the option for \"TFTP Server\" and the options under the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP used for TFTP Server\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### OPNsense\nServices -> DHCP Server\n\nUnder the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP of docker host\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### Unifi Security Gateway (with the controller)\nNetworks -> LAN (or the network you want to boot from) -> ADVANCED DHCP OPTIONS\n* tick Enable network boot\n* Server-  YOURSERVERIP\n* Filename- `netboot.xyz.kpxe`\n\n#### EdgeOS/VyOS\nConnect via SSH\n```\nconfigure\nset service dhcp-server use-dnsmasq enable\nset service dns forwarding options \"dhcp-match=set:bios,60,PXEClient:Arch:00000\"\nset service dns forwarding options \"dhcp-boot=tag:bios,netboot.xyz.kpxe,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32,60,PXEClient:Arch:00002\"\nset service dns forwarding options \"dhcp-boot=tag:efi32,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32-1,60,PXEClient:Arch:00006\"\nset service dns forwarding options \"dhcp-boot=tag:efi32-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64,60,PXEClient:Arch:00007\"\nset service dns forwarding options \"dhcp-boot=tag:efi64,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-1,60,PXEClient:Arch:00008\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-2,60,PXEClient:Arch:00009\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-2,netboot.xyz.efi,,SERVERIP\"\ncommit; save\n```\n\n#### DD-WRT\nAdministration -> Services -> Additional DNSMasq Options\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### Tomato\nAdvanced -> DHCP/DNS -> Dnsmasq Custom configuration\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### OpenWRT\n```\nuci set dhcp.@dnsmasq[0].dhcp_match=set:bios,60,PXEClient:Arch:00000\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32,60,PXEClient:Arch:00002\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32-1,60,PXEClient:Arch:00006\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64,60,PXEClient:Arch:00007\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-1,60,PXEClient:Arch:00008\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-2,60,PXEClient:Arch:00009\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\nuci commit\n/etc/init.d/dnsmasq restart\n```\n#### Microsoft Server DHCP\n\n* Run the DHCP program\n* Under Scope/Scope Options\n* check option 066 and enter the FQDN or IP of your TFTP boot server\n* check option 067 and enter one of the following bootfile names:\n   * Default BIOS file name- netboot.xyz.kpxe\n   * UEFI 32 bit file name- netboot.xyz.efi\n   * UEFI 64 bit file name- netboot.xyz.efi\n\nAnything else from a router standpoint is a crapshoot for supporting Dnsmasq options or proprietary PXE boot options, check Google for support (try your exact router model number with 'pxe boot') or look into setting up your own DHCP server in Linux.\n\nThis image also contains `netboot.xyz.efi` which can be used to boot using UEFI network boot. The UEFI boot and menu will have limited functionality if you choose to use it. \n","changelogs":[{"date":"12.10.22:","desc":"Rebasing to Alpine 3.16, migrate to s6v3."},{"date":"29.04.21:","desc":"Rebasing to alpine 3.13, add SUBFOLDER env variable."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"13.12.19:","desc":"Swapping latest tag over to webapp stack for management."},{"date":"10.12.19:","desc":"Adding tftp branch to provide tftp only option to latest users."},{"date":"22.10.19:","desc":"Initial release."}]}},"setup":"To use this image you need an existing DHCP server where you can set this TFTP server as your DHCP boot destination. This image does not contain a DHCP server nor do we aim to support one in the future. This is simply a TFTP server hosting the latest IPXE kernel builds from [netboot.xyz]({{ project_url }}). If you are interested in their project and lack the ability to setup a DHCP server to boot this payload they also have USB stick images you can use available on their [downloads page]({{ project_url }}/downloads/).\n\n### Router Setup Examples\n\n#### PFSense\nServices -> DHCP Server\n\nSet both the option for \"TFTP Server\" and the options under the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP used for TFTP Server\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### OPNsense\nServices -> DHCP Server\n\nUnder the Advanced \"Network Booting\" section. \n* check enable\n* Next server- IP of docker host\n* Default BIOS file name- `netboot.xyz.kpxe`\n* UEFI 32 bit file name- `netboot.xyz.efi`\n* UEFI 64 bit file name- `netboot.xyz.efi`\n\n#### Unifi Security Gateway (with the controller)\nNetworks -> LAN (or the network you want to boot from) -> ADVANCED DHCP OPTIONS\n* tick Enable network boot\n* Server-  YOURSERVERIP\n* Filename- `netboot.xyz.kpxe`\n\n#### EdgeOS/VyOS\nConnect via SSH\n```\nconfigure\nset service dhcp-server use-dnsmasq enable\nset service dns forwarding options \"dhcp-match=set:bios,60,PXEClient:Arch:00000\"\nset service dns forwarding options \"dhcp-boot=tag:bios,netboot.xyz.kpxe,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32,60,PXEClient:Arch:00002\"\nset service dns forwarding options \"dhcp-boot=tag:efi32,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi32-1,60,PXEClient:Arch:00006\"\nset service dns forwarding options \"dhcp-boot=tag:efi32-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64,60,PXEClient:Arch:00007\"\nset service dns forwarding options \"dhcp-boot=tag:efi64,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-1,60,PXEClient:Arch:00008\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-1,netboot.xyz.efi,,SERVERIP\"\nset service dns forwarding options \"dhcp-match=set:efi64-2,60,PXEClient:Arch:00009\"\nset service dns forwarding options \"dhcp-boot=tag:efi64-2,netboot.xyz.efi,,SERVERIP\"\ncommit; save\n```\n\n#### DD-WRT\nAdministration -> Services -> Additional DNSMasq Options\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### Tomato\nAdvanced -> DHCP/DNS -> Dnsmasq Custom configuration\nSet the following lines: \n```\ndhcp-match=set:bios,60,PXEClient:Arch:00000\ndhcp-boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\ndhcp-match=set:efi32,60,PXEClient:Arch:00002\ndhcp-boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi32-1,60,PXEClient:Arch:00006\ndhcp-boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64,60,PXEClient:Arch:00007\ndhcp-boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-1,60,PXEClient:Arch:00008\ndhcp-boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\ndhcp-match=set:efi64-2,60,PXEClient:Arch:00009\ndhcp-boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\n```\n\n#### OpenWRT\n```\nuci set dhcp.@dnsmasq[0].dhcp_match=set:bios,60,PXEClient:Arch:00000\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:bios,netboot.xyz.kpxe,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32,60,PXEClient:Arch:00002\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi32-1,60,PXEClient:Arch:00006\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi32-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64,60,PXEClient:Arch:00007\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-1,60,PXEClient:Arch:00008\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-1,netboot.xyz.efi,,YOURSERVERIP\nuci set dhcp.@dnsmasq[0].dhcp_match=set:efi64-2,60,PXEClient:Arch:00009\nuci set dhcp.@dnsmasq[0].dhcp_boot=tag:efi64-2,netboot.xyz.efi,,YOURSERVERIP\nuci commit\n/etc/init.d/dnsmasq restart\n```\n#### Microsoft Server DHCP\n\n* Run the DHCP program\n* Under Scope/Scope Options\n* check option 066 and enter the FQDN or IP of your TFTP boot server\n* check option 067 and enter one of the following bootfile names:\n   * Default BIOS file name- netboot.xyz.kpxe\n   * UEFI 32 bit file name- netboot.xyz.efi\n   * UEFI 64 bit file name- netboot.xyz.efi\n\nAnything else from a router standpoint is a crapshoot for supporting Dnsmasq options or proprietary PXE boot options, check Google for support (try your exact router model number with 'pxe boot') or look into setting up your own DHCP server in Linux.\n\nThis image also contains `netboot.xyz.efi` which can be used to boot using UEFI network boot. The UEFI boot and menu will have limited functionality if you choose to use it. \n","_id":"content:apps:netbootxyz.json","_type":"json","title":"Netbootxyz","_source":"content","_file":"apps/netbootxyz.json","_extension":"json"},{"_path":"/apps/netbox","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"netbox","name":"netbox","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an IP address management (IPAM) and data center infrastructure management (DCIM) tool. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It is intended to function as a domain-specific source of truth for network operations.\n","icon":"https://raw.githubusercontent.com/netbox-community/netbox/develop/docs/netbox_logo.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/netbox"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-netbox"}],"containers":[{"name":"netbox","image":"linuxserver/netbox","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"<TZ>","description":"Timezone (i.e., America/New_York)"},{"id":"SUPERUSER_EMAIL","default":"<SUPERUSER_EMAIL>","description":"Email address for `admin` account"},{"id":"SUPERUSER_PASSWORD","default":"<SUPERUSER_PASSWORD>","description":"Password for `admin` account"},{"id":"ALLOWED_HOST","default":"<ALLOWED_HOST>","description":"The hostname you will use to access the app (i.e., netbox.example.com)"},{"id":"DB_NAME","default":"<DB_NAME>","description":"Database name (default: netbox)"},{"id":"DB_USER","default":"<DB_USER>","description":"Database user"},{"id":"DB_PASSWORD","default":"<DB_PASSWORD>","description":"Database password"},{"id":"DB_HOST","default":"<DB_HOST>","description":"Database host (default: postgres)"},{"id":"DB_PORT","default":"<DB_PORT>","description":"Database port (defaul: 5432)"},{"id":"REDIS_HOST","default":"<REDIS_HOST>","description":"Redis host (default: redis)"},{"id":"REDIS_PORT","default":"<REDIS_PORT>","description":"Redis port number (default: 6379)"},{"id":"REDIS_PASSWORD","default":"<REDIS_PASSWORD>","description":"Redis password (default: none)"},{"id":"REDIS_DB_TASK","default":"<REDIS_DB_TASK>","description":"Redis database ID for tasks (default: 0)"},{"id":"REDIS_DB_CACHE","default":"<REDIS_DB_CACHE>","description":"Redis database ID for caching (default: 1)"},{"id":"BASE_PATH","default":"<BASE_PATH>","description":"The path you will use to access the app (i.e., /netbox, optional, default: none)"},{"id":"REMOTE_AUTH_ENABLED","default":"<REMOTE_AUTH_ENABLED>","description":"Enable remote authentication (optional, default: False)"},{"id":"REMOTE_AUTH_BACKEND","default":"<REMOTE_AUTH_BACKEND>","description":"Python path to the custom Django authentication backend to use for external user authentication (optional, default: netbox.authentication.RemoteUserBackend)"},{"id":"REMOTE_AUTH_HEADER","default":"<REMOTE_AUTH_HEADER>","description":"Name of the HTTP header which informs NetBox of the currently authenticated user. (optional, default: HTTP_REMOTE_USER)"},{"id":"REMOTE_AUTH_AUTO_CREATE_USER","default":"<REMOTE_AUTH_AUTO_CREATE_USER>","description":"If true, NetBox will automatically create local accounts for users authenticated via a remote service (optional, default: False)"},{"id":"REMOTE_AUTH_DEFAULT_GROUPS","default":"<REMOTE_AUTH_DEFAULT_GROUPS>","description":"The list of groups to assign a new user account when created using remote authentication (optional, default: [])"},{"id":"REMOTE_AUTH_DEFAULT_PERMISSIONS","default":"<REMOTE_AUTH_DEFAULT_PERMISSIONS>","description":"A mapping of permissions to assign a new user account when created using remote authentication (optional, default: {})"}],"volumes":[{"container":"/config","description":"config directory volume mapping","key":"config"}],"ports":[{"container":"8000","description":"will map the container's port 8000 to port 8000 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"netbox","project_url":"https://github.com/netbox-community/netbox","project_logo":"https://raw.githubusercontent.com/netbox-community/netbox/develop/docs/netbox_logo.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an IP address management (IPAM) and data center infrastructure management (DCIM) tool. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It is intended to function as a domain-specific source of truth for network operations.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data on host>","desc":"config directory volume mapping"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"<TZ>","desc":"Timezone (i.e., America/New_York)"},{"env_var":"SUPERUSER_EMAIL","env_value":"<SUPERUSER_EMAIL>","desc":"Email address for `admin` account"},{"env_var":"SUPERUSER_PASSWORD","env_value":"<SUPERUSER_PASSWORD>","desc":"Password for `admin` account"},{"env_var":"ALLOWED_HOST","env_value":"<ALLOWED_HOST>","desc":"The hostname you will use to access the app (i.e., netbox.example.com)"},{"env_var":"DB_NAME","env_value":"<DB_NAME>","desc":"Database name (default: netbox)"},{"env_var":"DB_USER","env_value":"<DB_USER>","desc":"Database user"},{"env_var":"DB_PASSWORD","env_value":"<DB_PASSWORD>","desc":"Database password"},{"env_var":"DB_HOST","env_value":"<DB_HOST>","desc":"Database host (default: postgres)"},{"env_var":"DB_PORT","env_value":"<DB_PORT>","desc":"Database port (defaul: 5432)"},{"env_var":"REDIS_HOST","env_value":"<REDIS_HOST>","desc":"Redis host (default: redis)"},{"env_var":"REDIS_PORT","env_value":"<REDIS_PORT>","desc":"Redis port number (default: 6379)"},{"env_var":"REDIS_PASSWORD","env_value":"<REDIS_PASSWORD>","desc":"Redis password (default: none)"},{"env_var":"REDIS_DB_TASK","env_value":"<REDIS_DB_TASK>","desc":"Redis database ID for tasks (default: 0)"},{"env_var":"REDIS_DB_CACHE","env_value":"<REDIS_DB_CACHE>","desc":"Redis database ID for caching (default: 1)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_PATH","env_value":"<BASE_PATH>","desc":"The path you will use to access the app (i.e., /netbox, optional, default: none)"},{"env_var":"REMOTE_AUTH_ENABLED","env_value":"<REMOTE_AUTH_ENABLED>","desc":"Enable remote authentication (optional, default: False)"},{"env_var":"REMOTE_AUTH_BACKEND","env_value":"<REMOTE_AUTH_BACKEND>","desc":"Python path to the custom Django authentication backend to use for external user authentication (optional, default: netbox.authentication.RemoteUserBackend)"},{"env_var":"REMOTE_AUTH_HEADER","env_value":"<REMOTE_AUTH_HEADER>","desc":"Name of the HTTP header which informs NetBox of the currently authenticated user. (optional, default: HTTP_REMOTE_USER)"},{"env_var":"REMOTE_AUTH_AUTO_CREATE_USER","env_value":"<REMOTE_AUTH_AUTO_CREATE_USER>","desc":"If true, NetBox will automatically create local accounts for users authenticated via a remote service (optional, default: False)"},{"env_var":"REMOTE_AUTH_DEFAULT_GROUPS","env_value":"<REMOTE_AUTH_DEFAULT_GROUPS>","desc":"The list of groups to assign a new user account when created using remote authentication (optional, default: [])"},{"env_var":"REMOTE_AUTH_DEFAULT_PERMISSIONS","env_value":"<REMOTE_AUTH_DEFAULT_PERMISSIONS>","desc":"A mapping of permissions to assign a new user account when created using remote authentication (optional, default: {})"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"will map the container's port 8000 to port 8000 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Netbox requires a postgres database and a redis instance.\n\nAccess the WebUI at <your-ip>:8000. For more information, check out [NetBox](https://github.com/netbox-community/netbox).\n","changelogs":[{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"01.08.22:","desc":"Remove py3-pillow, add tiff to fix deps."},{"date":"26.07.22:","desc":"Add py3-pillow package back on arm to fix build issue."},{"date":"10.12.21:","desc":"Remove py3-pillow package to fix dependency issue with 3.2.0."},{"date":"10.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.04.21:","desc":"Added Redis database environment variables."},{"date":"03.02.21:","desc":"Added remote authentication environment variables."},{"date":"02.01.21:","desc":"Added BASE_PATH environment variable."},{"date":"23.08.20:","desc":"Initial Release."}]}},"setup":"Netbox requires a postgres database and a redis instance.\n\nAccess the WebUI at <your-ip>:8000. For more information, check out [NetBox](https://github.com/netbox-community/netbox).\n","_id":"content:apps:netbox.json","_type":"json","title":"Netbox","_source":"content","_file":"apps/netbox.json","_extension":"json"},{"_path":"/apps/nextcloud","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nextcloud","name":"nextcloud","description":"[{{ project_name|capitalize }}]({{ project_url }}) gives you access to all your files wherever you are.\n\nWhere are your photos and documents? With Nextcloud you pick a server of your choice, at home, in a data center or at a provider. And that is where your files will be. Nextcloud runs on that server, protecting your data and giving you access from your desktop or mobile devices. Through Nextcloud you also access, sync and share your existing data on that FTP drive at the office, a Dropbox or a NAS you have at home.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nextcloud-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nextcloud"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nextcloud"}],"containers":[{"name":"nextcloud","image":"linuxserver/nextcloud","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Nextcloud configs.","key":"config"},{"container":"/data","description":"Your personal data."}],"ports":[{"container":"443","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nextcloud","project_url":"https://nextcloud.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nextcloud-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) gives you access to all your files wherever you are.\n\nWhere are your photos and documents? With Nextcloud you pick a server of your choice, at home, in a data center or at a provider. And that is where your files will be. Nextcloud runs on that server, protecting your data and giving you access from your desktop or mobile devices. Through Nextcloud you also access, sync and share your existing data on that FTP drive at the office, a Dropbox or a NAS you have at home.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Nextcloud releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Nextcloud configs."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Your personal data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"443","internal_port":"443","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `https://<your-ip>:443`, for more information check out [Nextcloud]({{ project_url }}).\n\nDocker image update and recreation of container alone won't update nextcloud version. \n\nIn order to update nextcloud version, you have two options, firstly make sure you are using the latest docker image,then either \n\n1.  Perform the in app gui update. \n2.  Use the CLI version by running `docker exec -it nextcloud updater.phar`\n (Both of these are described [here](https://docs.nextcloud.com/server/latest/admin_manual/maintenance/update.html))\n\nNote:  Both `occ` and `updater.phar` can be run without prepending with `sudo -u abc php` or `sudo -u www-data php`\n\nIf you are not customizing our default nginx configuration you will need to remove the file:\n```\n/config/nginx/site-confs/default.conf\n```\nThen restart the container to replace it with the latest one. \n\n### Collaborative Editing\n\nNextcloud's built-in collaborative editing packages (Collabora/CODE and OnlyOffice) only work on x86_64 systems with glibc, and therefore they are not compatible with our images. You should create separate containers for them and set them up in Nextcloud with their respective connector addons.\n\nIf (auto) installed, those built-in packages may cause instability and should be removed.\n","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"30.09.22:","desc":"Disabled `output_buffering` as per [nextcloud docs](https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/big_file_upload_configuration.html"},{"date":"21.05.22:","desc":"Update version check endpoint."},{"date":"28.04.22:","desc":"Increase OPCache interned strings buffered setting to 16."},{"date":"14.04.22:","desc":"Nginx default site config updated for v23 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container). Fix LDAP connection."},{"date":"11.09.21:","desc":"Rebasing to alpine 3.14"},{"date":"21.03.21:","desc":"Publish `php8` tag for testing."},{"date":"25.02.21:","desc":"Nginx default site config updated for v21 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"21.01.21:","desc":"Fix php iconv (was breaking the mail addon). If installed, attempt to remove broken CODE Server app during startup."},{"date":"20.01.21:","desc":"Increase php fcgi timeout to prevent 504 Gateway timeout errors (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"16.01.21:","desc":"Rebasing to alpine 3.13. Users with issues on 32-bit arm, [see this article](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal-and-alpine-3-13)."},{"date":"12.08.20:","desc":"Various updates to default site config, including added support for webfinger (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"03.06.20:","desc":"Rebasing to alpine 3.12"},{"date":"03.06.20:","desc":"Add php7-bcmath and php7-fileinfo"},{"date":"31.05.20:","desc":"Add aliases for occ and updater.phar"},{"date":"31.03.20:","desc":"Allow crontab to be user customized, fix logrotate."},{"date":"17.01.20:","desc":"Updated php.ini defaults and site config, including an optional HSTS directive (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"18.11.19:","desc":"Nginx default site config updated for v17 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"28.10.19:","desc":"Change cronjob to run every 5 minutes."},{"date":"24.10.19:","desc":"Nginx default site config updated due to CVE-2019-11043 (existing users should delete `/config/nginx/site-confs/default.conf` and restart the container)."},{"date":"14.07.19:","desc":"Download nextcloud during build time."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"27.02.19:","desc":"Updating base nginx config to sync up with v15 requirements."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"25.01.19:","desc":"Add php7-phar for occ upgrades."},{"date":"05.09.18:","desc":"Rebase to alpine 3.8."},{"date":"11.06.18:","desc":"Use latest rather than specific version for initial install."},{"date":"26.04.18:","desc":"Bump default install to 13.0.1."},{"date":"06.02.18:","desc":"Bump default install to 13.0.0."},{"date":"26.01.18:","desc":"Rebase to alpine 3.7, bump default install to 12.0.5."},{"date":"12.12.17:","desc":"Bump default install to 12.0.4, fix continuation lines."},{"date":"15.10.17:","desc":"Sed php.ini for opcache requirements in newer nextcloud versions."},{"date":"20.09.17:","desc":"Bump default install to 12.0.3."},{"date":"19.08.17:","desc":"Bump default install to 12.0.2."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"22.05.17:","desc":"Update to nextcloud 12.0, adding required dependecies and note about commenting out SAMEORIGIN; line."},{"date":"03.05.17:","desc":"Use community repo of memcache."},{"date":"07.03.17:","desc":"Release into main repository and upgrade to php7 and Alpine 3.5."}]}},"setup":"Access the webui at `https://<your-ip>:443`, for more information check out [Nextcloud]({{ project_url }}).\n\nDocker image update and recreation of container alone won't update nextcloud version. \n\nIn order to update nextcloud version, you have two options, firstly make sure you are using the latest docker image,then either \n\n1.  Perform the in app gui update. \n2.  Use the CLI version by running `docker exec -it nextcloud updater.phar`\n (Both of these are described [here](https://docs.nextcloud.com/server/latest/admin_manual/maintenance/update.html))\n\nNote:  Both `occ` and `updater.phar` can be run without prepending with `sudo -u abc php` or `sudo -u www-data php`\n\nIf you are not customizing our default nginx configuration you will need to remove the file:\n```\n/config/nginx/site-confs/default.conf\n```\nThen restart the container to replace it with the latest one. \n\n### Collaborative Editing\n\nNextcloud's built-in collaborative editing packages (Collabora/CODE and OnlyOffice) only work on x86_64 systems with glibc, and therefore they are not compatible with our images. You should create separate containers for them and set them up in Nextcloud with their respective connector addons.\n\nIf (auto) installed, those built-in packages may cause instability and should be removed.\n","_id":"content:apps:nextcloud.json","_type":"json","title":"Nextcloud","_source":"content","_file":"apps/nextcloud.json","_extension":"json"},{"_path":"/apps/nginx","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nginx","name":"nginx","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple webserver with php support. The config files reside in `/config` for easy user customization.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nginx-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nginx"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nginx"}],"containers":[{"name":"nginx","image":"linuxserver/nginx","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains your www content and all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"http","protocol":"tcp","web":false},{"container":"443","description":"https","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nginx","project_url":"https://nginx.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nginx-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple webserver with php support. The config files reside in `/config` for easy user customization.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains your www content and all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http"},{"external_port":"443","internal_port":"443","port_desc":"https"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Add your web files to `/config/www` for hosting.  \nModify the nginx, php and site config files under `/config` as needed  \n*Protip: This container is best combined with a sql server, e.g. [mariadb](https://hub.docker.com/r/linuxserver/mariadb/)*\n","changelogs":[{"date":"16.01.23:","desc":"Remove nchan module because it keeps causing crashes."},{"date":"22.12.22:","desc":"Rebase to Alpine 3.17 with PHP 8.1, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"22.05.22:","desc":"Install nginx version from 3.14."},{"date":"01.07.21:","desc":"Rebasing to alpine 3.14."},{"date":"24.06.21:","desc":"Update default nginx conf folder."},{"date":"12.04.21:","desc":"Add php7-gmp and php7-pecl-mailparse."},{"date":"13.02.21:","desc":"Remove php7-pecl-imagick (it now installs the full imagemagick with too much crud). Users can install it via [this docker mod](https://github.com/linuxserver/docker-mods/tree/swag-imagemagick)."},{"date":"09.02.21:","desc":"Rebasing to alpine 3.13. Add nginx mods brotli and dav-ext. Remove nginx mods lua and lua-upstream (due to regression over the last couple of years)."},{"date":"08.09.20:","desc":"Add php7-xsl."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.04.20:","desc":"Fix unwanted shutdown of the container."},{"date":"11.03.20:","desc":"Add php7-sodium."},{"date":"18.02.20:","desc":"Add geoip2, suppress lua warning."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"18.12.19:","desc":"Add php7-imap and php7-pecl-apcu."},{"date":"13.11.19:","desc":"Add php7-pdo_odbc."},{"date":"24.10.19:","desc":"Add php7-pecl-imagick."},{"date":"06.08.19:","desc":"Add php7-bcmath, ph7-pear, php7-xmlrpc and php7-ftp."},{"date":"02.08.19:","desc":"Add php7-ldap."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"08.05.19:","desc":"Remove default.conf when nginx is upgraded in downstream image."},{"date":"30.04.19:","desc":"Add php-redis."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"02.03.19:","desc":"Add php intl and posix modules."},{"date":"28.02.19:","desc":"Add php7-opcache, remove memcached service due to issues on aarch64 (let us know if you need to enable it)."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"18.11.18:","desc":"Attempt to upgrade packages during build."},{"date":"28.09.18:","desc":"Multi-arch image."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8, inherit nginx.conf from nginx baseimage."},{"date":"11.05.18:","desc":"Add php pgsql support."},{"date":"19.04.18:","desc":"Bind memcached to localhost only, add php7-sqlite3."},{"date":"05.01.18:","desc":"Rebase to alpine 3.7."},{"date":"08.11.17:","desc":"Add php7 soap module."},{"date":"31.10.17:","desc":"Add php7 exif and xmlreader modules."},{"date":"30.09.17:","desc":"Copy additional root files into image."},{"date":"24.09.17:","desc":"Add memcached service."},{"date":"31.08.17:","desc":"Add php7-phar."},{"date":"14.07.17:","desc":"Enable modules dynamically in nginx.conf."},{"date":"22.06.17:","desc":"Add various nginx modules and enable all modules in the default nginx.conf."},{"date":"05.06.17:","desc":"Add php7-bz2."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"18.04.17:","desc":"Add php7-sockets."},{"date":"27.02.17:","desc":"Rebase to alpine 3.5, update to nginx 1.10.2 and php7."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"10.09.16:","desc":"Add badges to README."},{"date":"05.12.15:","desc":"Intial Release."}]}},"setup":"Add your web files to `/config/www` for hosting.  \nModify the nginx, php and site config files under `/config` as needed  \n*Protip: This container is best combined with a sql server, e.g. [mariadb](https://hub.docker.com/r/linuxserver/mariadb/)*\n","_id":"content:apps:nginx.json","_type":"json","title":"Nginx","_source":"content","_file":"apps/nginx.json","_extension":"json"},{"_path":"/apps/ngircd","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ngircd","name":"ngircd","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, portable and lightweight Internet Relay Chat server for small or private networks, developed under the GNU General Public License (GPL). It is easy to configure, can cope with dynamic IP addresses, and supports IPv6, SSL-protected connections as well as PAM for authentication. It is written from scratch and not based on the original IRCd.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ngircd-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ngircd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ngircd"}],"containers":[{"name":"ngircd","image":"linuxserver/ngircd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use e.g. Europe/London"}],"volumes":[{"container":"/config","description":"Where `ngircd.conf` is stored","key":"config"}],"ports":[{"container":"6667","description":"ngircd port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ngircd","project_url":"https://ngircd.barton.de/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ngircd-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, portable and lightweight Internet Relay Chat server for small or private networks, developed under the GNU General Public License (GPL). It is easy to configure, can cope with dynamic IP addresses, and supports IPv6, SSL-protected connections as well as PAM for authentication. It is written from scratch and not based on the original IRCd.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/ngircd/config","desc":"Where `ngircd.conf` is stored"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6667","internal_port":"6667","port_desc":"ngircd port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use e.g. Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"- To setup ngircd you will need to edit `/config/ngircd.conf` which is created the first time the container is run, edit the file and restart the container to implement any config changes.  \n- For information see the ngircd site [here.](https://github.com/ngircd/ngircd/blob/master/doc/sample-ngircd.conf.tmpl)\n","changelogs":[{"date":"11.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"04.07.19:","desc":"Initial release."}]}},"setup":"- To setup ngircd you will need to edit `/config/ngircd.conf` which is created the first time the container is run, edit the file and restart the container to implement any config changes.  \n- For information see the ngircd site [here.](https://github.com/ngircd/ngircd/blob/master/doc/sample-ngircd.conf.tmpl)\n","_id":"content:apps:ngircd.json","_type":"json","title":"Ngircd","_source":"content","_file":"apps/ngircd.json","_extension":"json"},{"_path":"/apps/nntp2nntp","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nntp2nntp","name":"nntp2nntp","description":"[{{ project_name|capitalize }}]({{ project_url }}) proxy allow you to use your NNTP Account from multiple systems, each with own user name and password. It fully supports SSL and you can also limit the access to proxy with SSL certificates. nntp2nntp proxy is very simple and pretty fast.\n## Warning\n\nWhilst we know of no nntp2nntp security issues the [upstream code](https://github.com/linuxserver/nntp2nntp) for this project has received no changes since 06.08.15 and is likely abandoned permanently.  For this reason we strongly recommend you do not make this application public facing and if you must do so other layers of security and SSL should be considered an absolute bare minimum requirement.  We see this proxy being used primarily on a LAN so that all the users NNTP applications can share a common set of internal credentials allowing for central managment of the upstream account e.g change provider, server, thread limits for all applications with one global config change.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nntp2nntp.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nntp2nntp"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nntp2nntp"}],"containers":[{"name":"nntp2nntp","image":"linuxserver/nntp2nntp","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"PUID","default":"<yourUID>","description":"specify your UID"},{"id":"PGID","default":"<yourGID>","description":"specify your GID"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"}],"ports":[{"container":"1563","description":"will map the container's port 1563 to port 1563 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nntp2nntp","project_url":"https://github.com/linuxserver/nntp2nntp","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nntp2nntp.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) proxy allow you to use your NNTP Account from multiple systems, each with own user name and password. It fully supports SSL and you can also limit the access to proxy with SSL certificates. nntp2nntp proxy is very simple and pretty fast.\n## Warning\n\nWhilst we know of no nntp2nntp security issues the [upstream code](https://github.com/linuxserver/nntp2nntp) for this project has received no changes since 06.08.15 and is likely abandoned permanently.  For this reason we strongly recommend you do not make this application public facing and if you must do so other layers of security and SSL should be considered an absolute bare minimum requirement.  We see this proxy being used primarily on a LAN so that all the users NNTP applications can share a common set of internal credentials allowing for central managment of the upstream account e.g change provider, server, thread limits for all applications with one global config change.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v6-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"this will store config on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"PUID","env_value":"<yourUID>","desc":"specify your UID"},{"env_var":"PGID","env_value":"<yourGID>","desc":"specify your GID"},{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"1563","internal_port":"1563","port_desc":"will map the container's port 1563 to port 1563 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Edit sample config file `config/nntp2nntp.conf` with upstream provider details and rename the local users.\n\nNew user passwords can be created by running the password hash generator\n```\ndocker exec -it nntp2nntp /usr/bin/nntp2nntp.py pass\n```\nentering the desired password and copying the resulting string to the relevant user line in `/config/nntp2nntp.conf`\n\nExample with a user called `Dave` and with a password of `password`\n```\nDave    = 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8\n```\n","changelogs":[{"date":"10.10.22:","desc":"Rebase to Alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.04.19:","desc":"Multiarch builds and build from Github fork."},{"date":"15.05.18:","desc":"Initial Release."}]}},"setup":"Edit sample config file `config/nntp2nntp.conf` with upstream provider details and rename the local users.\n\nNew user passwords can be created by running the password hash generator\n```\ndocker exec -it nntp2nntp /usr/bin/nntp2nntp.py pass\n```\nentering the desired password and copying the resulting string to the relevant user line in `/config/nntp2nntp.conf`\n\nExample with a user called `Dave` and with a password of `password`\n```\nDave    = 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8\n```\n","_id":"content:apps:nntp2nntp.json","_type":"json","title":"Nntp2nntp","_source":"content","_file":"apps/nntp2nntp.json","_extension":"json"},{"_path":"/apps/nzbget","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nzbget","name":"nzbget","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a usenet downloader, written in C++ and designed with performance in mind to achieve maximum download speed by using very little system resources.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nzbget-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nzbget"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nzbget"}],"containers":[{"name":"nzbget","image":"linuxserver/nzbget","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"NZBGET_USER","default":"nzbget","description":"Specify the user for web authentication."},{"id":"NZBGET_PASS","default":"tegbzn6789","description":"Specify the password for web authentication."}],"volumes":[{"container":"/downloads","description":"Location of downloads on disk."},{"container":"/config","description":"NZBGet App data.","key":"config"}],"ports":[{"container":"6789","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nzbget","project_url":"http://nzbget.net/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/nzbget-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a usenet downloader, written in C++ and designed with performance in mind to achieve maximum download speed by using very little system resources.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_deprecation_status":true,"project_deprecation_message":"nzbget has been deprecated by its developers. Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable nzbget releases"},{"tag":"testing","desc":"nzbget pre-releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"NZBGet App data."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Location of downloads on disk."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6789","internal_port":"6789","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"NZBGET_USER","env_value":"nzbget","desc":"Specify the user for web authentication."},{"env_var":"NZBGET_PASS","env_value":"tegbzn6789","desc":"Specify the password for web authentication."}],"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui can be found at  `<your-ip>:6789` and the default login details (change ASAP) are\n\n`login:nzbget, password:tegbzn6789`\n\nTo allow scheduling, from the webui set the time correction value in settings/logging.\n\nTo change umask settings.\n\n![](http://i.imgur.com/A4VMbwE.png)\n\nscroll to bottom, set umask like this (example shown for unraid)\n\n![](http://i.imgur.com/mIqDEJJ.png)\n\nYou can add an additional mount point for intermediate unpacking folder with:-\n\n`-v </path/to/intermedia_unpacking_folder>:/intermediate`\n\nfor example, and changing the setting for InterDir in the PATHS tab of settings to `/intermediate`\n\n### Media folders\n\nWe have set `/downloads` as a ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"31.12.22:","desc":"Deprecate image.  Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd"},{"date":"27.11.22:","desc":"Advanced notice: This image will be deprecated on 2022-12-31. Please consider switching to SABnzbd https://github.com/linuxserver/docker-sabnzbd"},{"date":"13.11.22:","desc":"Rebase master to 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"22.02.22:","desc":"Rebase to alpine 3.15, add six and python 7zip tools, allow env variables for credentials."},{"date":"04.07.21:","desc":"Rebase to alpine 3.14."},{"date":"28.05.21:","desc":"Add linuxserver wheel index."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"26.10.20:","desc":"Fix python dependencies."},{"date":"24.08.20:","desc":"Fix ignored umask environment variable."},{"date":"08.06.20:","desc":"Symlink python3 bin to python."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12. Removing python2."},{"date":"13.05.20:","desc":"Add rarfile python package (for DeepUnrar)."},{"date":"01.01.20:","desc":"Add python3 alongside python2 during transition."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"13.06.19:","desc":"Add apprise, chardet & pynzbget packages."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"25.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"20.01.19:","desc":"Add pipeline logic and multi arch, build from source."},{"date":"21.08.18:","desc":"Rebase to alpine 3.8."},{"date":"20.02.18:","desc":"Add note about supplemental mount point for intermediate unpacking."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"02.09.17:","desc":"Place app in subfolder rather than /app."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"20.04.17:","desc":"Add testing branch."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README, perms fix on /app to allow updates."},{"date":"19.08.16:","desc":"Rebase to alpine linux."},{"date":"18.08.15:","desc":"Now useing latest version of unrar beta and implements the universal installer method."}]}},"setup":"Webui can be found at  `<your-ip>:6789` and the default login details (change ASAP) are\n\n`login:nzbget, password:tegbzn6789`\n\nTo allow scheduling, from the webui set the time correction value in settings/logging.\n\nTo change umask settings.\n\n![](http://i.imgur.com/A4VMbwE.png)\n\nscroll to bottom, set umask like this (example shown for unraid)\n\n![](http://i.imgur.com/mIqDEJJ.png)\n\nYou can add an additional mount point for intermediate unpacking folder with:-\n\n`-v </path/to/intermedia_unpacking_folder>:/intermediate`\n\nfor example, and changing the setting for InterDir in the PATHS tab of settings to `/intermediate`\n\n### Media folders\n\nWe have set `/downloads` as a ***optional path***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","_id":"content:apps:nzbget.json","_type":"json","title":"Nzbget","_source":"content","_file":"apps/nzbget.json","_extension":"json"},{"_path":"/apps/nzbhydra2","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"nzbhydra2","name":"nzbhydra2","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a meta search application for NZB indexers, the \"spiritual successor\" to NZBmegasearcH, and an evolution of the original application [NZBHydra](https://github.com/theotherp/nzbhydra).\n\nIt provides easy access to a number of raw and newznab based indexers. The application NZBHydra 2 is replacing NZBHydra 1 and supports migrating from V1. Be wary that there may be some compatibility issues for those migrating from V1 to V2, so ensure you back up your old configuration before moving over to the new version. **NOTE:** The last version that supports migration is `linuxserver/nzbhydra2:v2.10.2-ls49`\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hydra-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/nzbhydra2"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-nzbhydra2"}],"containers":[{"name":"nzbhydra2","image":"linuxserver/nzbhydra2","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where nzbhydra2 should store config files.","key":"config"},{"container":"/downloads","description":"NZB download folder."}],"ports":[{"container":"5076","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"nzbhydra2","project_url":"https://github.com/theotherp/nzbhydra2","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/hydra-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a meta search application for NZB indexers, the \"spiritual successor\" to NZBmegasearcH, and an evolution of the original application [NZBHydra](https://github.com/theotherp/nzbhydra).\n\nIt provides easy access to a number of raw and newznab based indexers. The application NZBHydra 2 is replacing NZBHydra 1 and supports migrating from V1. Be wary that there may be some compatibility issues for those migrating from V1 to V2, so ensure you back up your old configuration before moving over to the new version. **NOTE:** The last version that supports migration is `linuxserver/nzbhydra2:v2.10.2-ls49`\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"dev","desc":"Prereleases from their GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where nzbhydra2 should store config files."},{"vol_path":"/downloads","vol_host_path":"/nzb/download","desc":"NZB download folder."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5076","internal_port":"5076","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"The web interface is at `<your ip>:5076` , to set up indexers and connections to your nzb download applications.\n","changelogs":[{"date":"22.01.23:","desc":"Update release URL for arch-specific packages."},{"date":"20.01.23:","desc":"Update dependencies for v5."},{"date":"10.12.22:","desc":"Bump master JRE to v17. Default mapIpToHost to false."},{"date":"11.09.22:","desc":"Migrate to s6v3."},{"date":"03.05.22:","desc":"Rebase to Jammy."},{"date":"18.04.22:","desc":"Rebase to Alpine 3.15."},{"date":"01.05.20:","desc":"Reorganize container, Relocate app to /app/nzbhydra2/bin, Create /app/nzbhydra2/package_info, Use nzbhydra2wrapperPy3.py from zip."},{"date":"14.04.20:","desc":"Correct Name, Hydra2 -> NZBHydra2."},{"date":"08.01.20:","desc":"Switch to python3."},{"date":"05.01.20:","desc":"Add dev tag for prereleases."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.08.18:","desc":"Bump java version to 10, (bionic currently refers to it as version 11)."},{"date":"10.08.18:","desc":"Rebase to ubuntu bionic."},{"date":"15.04.18:","desc":"Change to port 5076 in the Dockerfile."},{"date":"11.01.18:","desc":"Initial Release."}]}},"setup":"The web interface is at `<your ip>:5076` , to set up indexers and connections to your nzb download applications.\n","_id":"content:apps:nzbhydra2.json","_type":"json","title":"Nzbhydra2","_source":"content","_file":"apps/nzbhydra2.json","_extension":"json"},{"_path":"/apps/ombi","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ombi","name":"ombi","description":"[{{ project_name|capitalize }}]({{ project_url }}) allows you to host your own Plex Request and user management system.\nIf you are sharing your Plex server with other users, allow them to request new content using an easy to manage interface!\nManage all your requests for Movies and TV with ease, leave notes for the user and get notification when a user requests something.\nAllow your users to post issues against their requests so you know there is a problem with the audio etc.\nEven automatically send them weekly newsletters of new content that has been added to your Plex server!","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ombi.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ombi"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ombi"}],"containers":[{"name":"ombi","image":"linuxserver/ombi","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"BASE_URL","default":"/ombi","description":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"3579","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ombi","project_url":"https://ombi.io","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ombi.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) allows you to host your own Plex Request and user management system.\nIf you are sharing your Plex server with other users, allow them to request new content using an easy to manage interface!\nManage all your requests for Movies and TV with ease, leave notes for the user and get notification when a user requests something.\nAllow your users to post issues against their requests so you know there is a problem with the audio etc.\nEven automatically send them weekly newsletters of new content that has been added to your Plex server!","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Ombi releases"},{"tag":"development","desc":"Releases from the `develop` branch of Ombi"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3579","internal_port":"3579","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"BASE_URL","env_value":"/ombi","desc":"Subfolder can optionally be defined as an env variable for reverse proxies. Keep in mind that once this value is defined, the gui setting for base url no longer works. To use the gui setting, remove this env variable."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:3579`. Follow the setup wizard on initial install.  Then configure the required services.\n","changelogs":[{"date":"11.09.22:","desc":"Migrate to s6v3."},{"date":"01.05.22:","desc":"Rebase to Jammy."},{"date":"26.04.21:","desc":"Update tarball name, allow for v4 builds in stable."},{"date":"18.01.21:","desc":"Update upstream repo. Deprecate `v4-preview` tag, which is merged to `development` tag upstream."},{"date":"14.04.20:","desc":"Add Ombi donate links."},{"date":"10.05.19:","desc":"Added an optional env variable for base url setting."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Clarify info on tags and development builds."},{"date":"25.01.19:","desc":"Add info on tags and development builds."},{"date":"09.01.19:","desc":"Switch to multi-arch builds and add aarch64 image."},{"date":"11.03.18:","desc":"Add HOME env to Dockerfile."},{"date":"05.03.18:","desc":"Switch to Ombi v3 stable based on .net core."},{"date":"26.01.18:","desc":"Fix continuation lines."},{"date":"16.04.17:","desc":"Switch to using inhouse mono baseimage."},{"date":"17.02.17:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:3579`. Follow the setup wizard on initial install.  Then configure the required services.\n","_id":"content:apps:ombi.json","_type":"json","title":"Ombi","_source":"content","_file":"apps/ombi.json","_extension":"json"},{"_path":"/apps/openssh-server","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"openssh-server","name":"openssh-server","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a sandboxed environment that allows ssh access without giving keys to the entire server.\nGiving ssh access via private key often means giving full access to the server. This container creates a limited and sandboxed environment that others can ssh into.\nThe users only have access to the folders mapped and the processes running inside this container.","icon":"https://upload.wikimedia.org/wikipedia/en/6/65/OpenSSH_logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/openssh-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-openssh-server"}],"containers":[{"name":"openssh-server","image":"linuxserver/openssh-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"PUBLIC_KEY","default":"yourpublickey","description":"Optional ssh public key, which will automatically be added to authorized_keys."},{"id":"PUBLIC_KEY_FILE","default":"/path/to/file","description":"Optionally specify a file containing the public key (works with docker secrets)."},{"id":"PUBLIC_KEY_DIR","default":"/path/to/directory/containing/_only_/pubkeys","description":"Optionally specify a directory containing the public keys (works with docker secrets)."},{"id":"PUBLIC_KEY_URL","default":"https://github.com/username.keys","description":"Optionally specify a URL containing the public key."},{"id":"SUDO_ACCESS","default":"false","description":"Set to `true` to allow `linuxserver.io`, the ssh user, sudo access. Without `USER_PASSWORD` set, this will allow passwordless sudo access."},{"id":"PASSWORD_ACCESS","default":"false","description":"Set to `true` to allow user/password ssh access. You will want to set `USER_PASSWORD` or `USER_PASSWORD_FILE` as well."},{"id":"USER_PASSWORD","default":"password","description":"Optionally set a sudo password for `linuxserver.io`, the ssh user. If this or `USER_PASSWORD_FILE` are not set but `SUDO_ACCESS` is set to true, the user will have passwordless sudo access."},{"id":"USER_PASSWORD_FILE","default":"/path/to/file","description":"Optionally specify a file that contains the password. This setting supersedes the `USER_PASSWORD` option (works with docker secrets)."},{"id":"USER_NAME","default":"linuxserver.io","description":"Optionally specify a user name (Default:`linuxserver.io`)"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"2222","description":"ssh port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"openssh-server","project_url":"https://www.openssh.com/","project_logo":"https://upload.wikimedia.org/wikipedia/en/6/65/OpenSSH_logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a sandboxed environment that allows ssh access without giving keys to the entire server.\nGiving ssh access via private key often means giving full access to the server. This container creates a limited and sandboxed environment that others can ssh into.\nThe users only have access to the folders mapped and the processes running inside this container.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":"optional","param_hostname":"{{ project_name }}","param_hostname_desc":"Optionally the hostname can be defined.","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"2222","internal_port":"2222","port_desc":"ssh port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PUBLIC_KEY","env_value":"yourpublickey","desc":"Optional ssh public key, which will automatically be added to authorized_keys."},{"env_var":"PUBLIC_KEY_FILE","env_value":"/path/to/file","desc":"Optionally specify a file containing the public key (works with docker secrets)."},{"env_var":"PUBLIC_KEY_DIR","env_value":"/path/to/directory/containing/_only_/pubkeys","desc":"Optionally specify a directory containing the public keys (works with docker secrets)."},{"env_var":"PUBLIC_KEY_URL","env_value":"https://github.com/username.keys","desc":"Optionally specify a URL containing the public key."},{"env_var":"SUDO_ACCESS","env_value":"false","desc":"Set to `true` to allow `linuxserver.io`, the ssh user, sudo access. Without `USER_PASSWORD` set, this will allow passwordless sudo access."},{"env_var":"PASSWORD_ACCESS","env_value":"false","desc":"Set to `true` to allow user/password ssh access. You will want to set `USER_PASSWORD` or `USER_PASSWORD_FILE` as well."},{"env_var":"USER_PASSWORD","env_value":"password","desc":"Optionally set a sudo password for `linuxserver.io`, the ssh user. If this or `USER_PASSWORD_FILE` are not set but `SUDO_ACCESS` is set to true, the user will have passwordless sudo access."},{"env_var":"USER_PASSWORD_FILE","env_value":"/path/to/file","desc":"Optionally specify a file that contains the password. This setting supersedes the `USER_PASSWORD` option (works with docker secrets)."},{"env_var":"USER_NAME","env_value":"linuxserver.io","desc":"Optionally specify a user name (Default:`linuxserver.io`)"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"If `PUBLIC_KEY` or `PUBLIC_KEY_FILE`, or `PUBLIC_KEY_DIR` variables are set, the specified keys will automatically be added to `authorized_keys`. If not, the keys can manually be added to `/config/.ssh/authorized_keys` and the container should be restarted.\nRemoving `PUBLIC_KEY` or `PUBLIC_KEY_FILE` variables from docker run environment variables will not remove the keys from `authorized_keys`. `PUBLIC_KEY_FILE` and `PUBLIC_KEY_DIR` can be used with docker secrets.\n\nWe provide the ability to set and allow password based access via the `PASSWORD_ACCESS` and `USER_PASSWORD` variables, though we as an organization discourage using password auth for public facing ssh endpoints.\n\nConnect to server via `ssh -i /path/to/private/key -p PORT USER_NAME@SERVERIP`\n\nSetting `SUDO_ACCESS` to `true` by itself will allow passwordless sudo. `USER_PASSWORD` and `USER_PASSWORD_FILE` allow setting an optional sudo password.\n\nThe users only have access to the folders mapped and the processes running inside this container.\nAdd any volume mappings you like for the users to have access to.\nTo install packages or services for users to access, use the LinuxServer container customization methods described [in this blog article](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/).\n\nSample use case is when a server admin would like to have automated incoming backups from a remote server to the local server, but they might not want all the other admins of the remote server to have full access to the local server.\nThis container can be set up with a mounted folder for incoming backups, and rsync installed via LinuxServer container customization described above, so that the incoming backups can proceed, but remote server and its admins' access would be limited to the backup folder.\n\nIt is also possible to run multiple copies of this container with different ports mapped, different folders mounted and access to different private keys for compartmentalized access.\n\n#### TIPS\nYou can volume map your own text file to `/etc/motd` to override the message displayed upon connection.\nYou can optionally set the docker argument `hostname`\n\n## Key Generation\n\nThis container has a helper script to generate an ssh private/public key. In order to generate a key please run:\n```\ndocker run --rm -it --entrypoint /keygen.sh linuxserver/openssh-server\n```\n\nThen simply follow the prompts.\nThe keys generated by this script are only displayed on your console output, so make sure to save them somewhere after generation.\n","changelogs":[{"date":"18.10.22:","desc":"Fix wrong behavior of password/passwordless sudo"},{"date":"11.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"15.09.22:","desc":"add netcat-openbsd with support for proxies."},{"date":"18.07.22:","desc":"Fix service perms to comply with upgrade to s6 v3."},{"date":"16.04.22:","desc":"Rebase to alpine 3.15."},{"date":"16.11.21:","desc":"Add PUBLIC_KEY_URL option"},{"date":"28.06.21:","desc":"Rebasing to alpine 3.14. Add support for PAM."},{"date":"10.02.21:","desc":"Rebasing to alpine 3.13. Add openssh-client for scp."},{"date":"21.10.20:","desc":"Implement s6-log for openssh, which adds local timestamps to logs and can be used with a log parser like fail2ban."},{"date":"20.10.20:","desc":"Set umask for sftp."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.01.20:","desc":"Add key generation script."},{"date":"13.01.20:","desc":"Add openssh-sftp-server."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"17.10.19:","desc":"Initial Release."}]}},"setup":"If `PUBLIC_KEY` or `PUBLIC_KEY_FILE`, or `PUBLIC_KEY_DIR` variables are set, the specified keys will automatically be added to `authorized_keys`. If not, the keys can manually be added to `/config/.ssh/authorized_keys` and the container should be restarted.\nRemoving `PUBLIC_KEY` or `PUBLIC_KEY_FILE` variables from docker run environment variables will not remove the keys from `authorized_keys`. `PUBLIC_KEY_FILE` and `PUBLIC_KEY_DIR` can be used with docker secrets.\n\nWe provide the ability to set and allow password based access via the `PASSWORD_ACCESS` and `USER_PASSWORD` variables, though we as an organization discourage using password auth for public facing ssh endpoints.\n\nConnect to server via `ssh -i /path/to/private/key -p PORT USER_NAME@SERVERIP`\n\nSetting `SUDO_ACCESS` to `true` by itself will allow passwordless sudo. `USER_PASSWORD` and `USER_PASSWORD_FILE` allow setting an optional sudo password.\n\nThe users only have access to the folders mapped and the processes running inside this container.\nAdd any volume mappings you like for the users to have access to.\nTo install packages or services for users to access, use the LinuxServer container customization methods described [in this blog article](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/).\n\nSample use case is when a server admin would like to have automated incoming backups from a remote server to the local server, but they might not want all the other admins of the remote server to have full access to the local server.\nThis container can be set up with a mounted folder for incoming backups, and rsync installed via LinuxServer container customization described above, so that the incoming backups can proceed, but remote server and its admins' access would be limited to the backup folder.\n\nIt is also possible to run multiple copies of this container with different ports mapped, different folders mounted and access to different private keys for compartmentalized access.\n\n#### TIPS\nYou can volume map your own text file to `/etc/motd` to override the message displayed upon connection.\nYou can optionally set the docker argument `hostname`\n\n## Key Generation\n\nThis container has a helper script to generate an ssh private/public key. In order to generate a key please run:\n```\ndocker run --rm -it --entrypoint /keygen.sh linuxserver/openssh-server\n```\n\nThen simply follow the prompts.\nThe keys generated by this script are only displayed on your console output, so make sure to save them somewhere after generation.\n","_id":"content:apps:openssh-server.json","_type":"json","title":"Openssh Server","_source":"content","_file":"apps/openssh-server.json","_extension":"json"},{"_path":"/apps/openvscode-server","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"openvscode-server","name":"openvscode-server","description":"[{{ project_name|capitalize }}]({{ project_url }}) provides a version of VS Code that runs a server on a remote machine and allows access through a modern web browser.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/openvscode-server-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/openvscode-server"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-openvscode-server"}],"containers":[{"name":"openvscode-server","image":"linuxserver/openvscode-server","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use."},{"id":"CONNECTION_TOKEN","default":"","description":"Optional security token for accessing the Web UI (ie. `supersecrettoken`)."},{"id":"CONNECTION_SECRET","default":"","description":"Optional path to a file inside the container that contains the security token for accessing the Web UI (ie. `/path/to/file`). Overrides `CONNECTION_TOKEN`."},{"id":"SUDO_PASSWORD","default":"password","description":"If this optional variable is set, user will have sudo access in the openvscode-server terminal with the specified password."},{"id":"SUDO_PASSWORD_HASH","default":"","description":"Optionally set sudo password via hash (takes priority over `SUDO_PASSWORD` var). Format is `$type$salt$hashed`."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"3000","description":"Web UI port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"openvscode-server","project_url":"https://github.com/gitpod-io/openvscode-server","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/openvscode-server-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) provides a version of VS Code that runs a server on a remote machine and allows access through a modern web browser.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"insiders","desc":"Insiders releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web UI port."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"CONNECTION_TOKEN","env_value":"","desc":"Optional security token for accessing the Web UI (ie. `supersecrettoken`)."},{"env_var":"CONNECTION_SECRET","env_value":"","desc":"Optional path to a file inside the container that contains the security token for accessing the Web UI (ie. `/path/to/file`). Overrides `CONNECTION_TOKEN`."},{"env_var":"SUDO_PASSWORD","env_value":"password","desc":"If this optional variable is set, user will have sudo access in the openvscode-server terminal with the specified password."},{"env_var":"SUDO_PASSWORD_HASH","env_value":"","desc":"Optionally set sudo password via hash (takes priority over `SUDO_PASSWORD` var). Format is `$type$salt$hashed`."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"If `CONNECTION_TOKEN` or `CONNECTION_SECRET` env vars are set, you can access the webui at `http://<your-ip>:3000/?tkn=supersecrettoken` (replace `supersecrettoken` with the value set). If not, you can access the webui at `http://<your-ip>:3000`.\n\nFor github integration, drop your ssh key in to `/config/.ssh`.\nThen open a terminal from the top menu and set your github username and email via the following commands\n\n```bash\ngit config --global user.name \"username\"\ngit config --global user.email \"email address\"\n```\n\nWhen reverse proxied through SWAG, custom services running on specific ports inside openvscode-server can be accessed at `https://PORT.openvscode-server.domain.com` very much like how code-server's port proxy function is handled. For that, a wildcard CNAME `*.openvscode-server.domain.com` needs to be created and the SWAG cert needs to cover those subdomains.\n","changelogs":[{"date":"29.09.22:","desc":"Rebase to jammy, switch to s6v3. Fix chown logic to skip `/config/workspace` contents."},{"date":"12.02.22:","desc":"Update `install-extension` helper to compensate for upstream changes."},{"date":"04.02.22:","desc":"Update binary for 1.64.0+. Allow for no token set when both toekn env vars are unset. Add libsecret for keytar."},{"date":"29.12.21:","desc":"Add `install-extension` as a helper for mods to install extensions."},{"date":"10.12.21:","desc":"Update deprecated connectionToken arg."},{"date":"30.11.21:","desc":"Fix app folder permissions, add the optional sudo password vars."},{"date":"29.11.21:","desc":"Create `.profile` and `.bashrc` for the user."},{"date":"29.11.21:","desc":"Release `insiders` tag."},{"date":"28.11.21:","desc":"Initial Release."}]}},"setup":"If `CONNECTION_TOKEN` or `CONNECTION_SECRET` env vars are set, you can access the webui at `http://<your-ip>:3000/?tkn=supersecrettoken` (replace `supersecrettoken` with the value set). If not, you can access the webui at `http://<your-ip>:3000`.\n\nFor github integration, drop your ssh key in to `/config/.ssh`.\nThen open a terminal from the top menu and set your github username and email via the following commands\n\n```bash\ngit config --global user.name \"username\"\ngit config --global user.email \"email address\"\n```\n\nWhen reverse proxied through SWAG, custom services running on specific ports inside openvscode-server can be accessed at `https://PORT.openvscode-server.domain.com` very much like how code-server's port proxy function is handled. For that, a wildcard CNAME `*.openvscode-server.domain.com` needs to be created and the SWAG cert needs to cover those subdomains.\n","_id":"content:apps:openvscode-server.json","_type":"json","title":"Openvscode Server","_source":"content","_file":"apps/openvscode-server.json","_extension":"json"},{"_path":"/apps/oscam","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"oscam","name":"oscam","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an Open Source Conditional Access Module software used for descrambling DVB transmissions using smart cards. It's both a server and a client.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/oscam-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/oscam"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-oscam"}],"containers":[{"name":"oscam","image":"linuxserver/oscam","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where oscam should store config files and logs.","key":"config"}],"ports":[{"container":"8888","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"oscam","project_url":"http://www.streamboard.tv/oscam/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/oscam-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an Open Source Conditional Access Module software used for descrambling DVB transmissions using smart cards. It's both a server and a client.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where oscam should store config files and logs."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"WebUI"}],"param_device_map":true,"param_devices":[{"device_path":"/dev/ttyUSB0","device_host_path":"/dev/ttyUSB0","desc":"For passing through smart card readers."}],"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["### Passing through Smart Card Readers\n\nIf you want to pass through a smart card reader, you need to specify the reader with the `--device=` tag. The method used depends on how the reader is recognized.\nThe first is /dev/ttyUSBX. To find the correct device, connect the reader and run `dmesg | tail` on the host. In the output you will find /dev/ttyUSBX, where X is the number of the device. If this is the first reader you connect to your host, it will be /dev/ttyUSB0. If you add one more it will be /dev/ttyUSB1.\n\nIf there are no /dev/ttyUSBX device in `dmesg | tail`, you have to use the USB bus path. It will look similar to the below.\n\n`/dev/bus/usb/001/001`\n\nThe important parts are the two numbers in the end. The first one is the Bus number, the second is the Device number. To find the Bus and Device number you have to run `lsusb` on the host, then find your USB device in the list and note the Bus and Device numbers.\n\nHere is an example of how to find the Bus and Device. The output of the lsusb command is below.\n\n`Bus 002 Device 005: ID 076b:6622 OmniKey AG CardMan 6121`\n\nThe first number, the Bus, is 002. The second number, the Device, is 005. This will look like below in the `--device=` tag.\n\n`--device=/dev/bus/usb/002/005`\n\nIf you have multiple smart card readers, you add one `--device=` tag for each reader.\n"],"app_setup_block_enabled":true,"app_setup_block":"To set up oscam there are numerous guides on the internet. There are too many scenarios to make a quick guide.\nThe web interface is at port 8888.\n","changelogs":[{"date":"03.11.22:","desc":"Rebasing to alpine 3.16 and s6v3. Update pcsd driver link."},{"date":"13.02.22:","desc":"Rebasing to alpine 3.15."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"29.04.19:","desc":"Add revision check, so pipeline can build new revisions."},{"date":"28.04.19:","desc":"Switch back to streamboard svn to fix version not showing in UI."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"19.02.19:","desc":"Add pipeline logic and multi arch, rebase to Alpine 3.8."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"19.10.17:","desc":"Add ccid package for usb card readers."},{"date":"17.10.17:","desc":"Switch to using bzr for source code, streamboard awol."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"02.10.16:","desc":"Add info on passing through devices to README."},{"date":"25.09.16:","desc":"Initial release."}]}},"setup":"To set up oscam there are numerous guides on the internet. There are too many scenarios to make a quick guide.\nThe web interface is at port 8888.\n","_id":"content:apps:oscam.json","_type":"json","title":"Oscam","_source":"content","_file":"apps/oscam.json","_extension":"json"},{"_path":"/apps/overseerr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"overseerr","name":"overseerr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a request management and media discovery tool built to work with your existing Plex ecosystem.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/overseerr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/overseerr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-overseerr"}],"containers":[{"name":"overseerr","image":"linuxserver/overseerr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"5055","description":"Port for Overseerr's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"overseerr","project_url":"https://overseerr.dev/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/overseerr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a request management and media discovery tool built to work with your existing Plex ecosystem.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from GitHub"},{"tag":"develop","desc":"Development releases from commits in upstream develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"5055","internal_port":"5055","port_desc":"Port for Overseerr's web interface."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_vols":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:5055`, for more information check out [Overseerr](https://overseerr.dev/).\n","changelogs":[{"date":"18.12.22:","desc":"Rebase main to 3.17."},{"date":"27.10.22:","desc":"Rebase main to 3.16, migrate to s6v3."},{"date":"20.08.22:","desc":"Don't install cypress."},{"date":"01.04.22:","desc":"Rebase main branch to Alpine 3.15."},{"date":"27.01.22:","desc":"Rebase develop branch to Alpine 3.15."},{"date":"04.01.22:","desc":"Remove cached files."},{"date":"10.10.21:","desc":"Add additional post-build cleanup."},{"date":"19.09.21:","desc":"Rebase to alpine 3.14. Update code formatting. Increase js mem limit."},{"date":"05.04.21:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:5055`, for more information check out [Overseerr](https://overseerr.dev/).\n","_id":"content:apps:overseerr.json","_type":"json","title":"Overseerr","_source":"content","_file":"apps/overseerr.json","_extension":"json"},{"_path":"/apps/papermerge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"papermerge","name":"papermerge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an open source document management system (DMS) primarily designed for archiving and retrieving your digital documents. Instead of having piles of paper documents all over your desk, office or drawers - you can quickly scan them and configure your scanner to directly upload to Papermerge DMS.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/papermerge-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/papermerge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-papermerge"}],"containers":[{"name":"papermerge","image":"linuxserver/papermerge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"REDIS_URL","default":"","description":"Specify an external redis instance to use. Can optionally include a port (`redis:6379`) and/or db (`redis/foo`). If left blank or not included, will use a built-in redis instance. If changed after initial setup will also require manual modification of /config/settings.py"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/data","description":"Storage location for all papermerge data files."}],"ports":[{"container":"8000","description":"http gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"papermerge","project_url":"https://www.papermerge.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/papermerge-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an open source document management system (DMS) primarily designed for archiving and retrieving your digital documents. Instead of having piles of paper documents all over your desk, office or drawers - you can quickly scan them and configure your scanner to directly upload to Papermerge DMS.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Contains all relevant configuration files."},{"vol_path":"/data","vol_host_path":"</path/to/appdata/data>","desc":"Storage location for all papermerge data files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"http gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"REDIS_URL","env_value":"","desc":"Specify an external redis instance to use. Can optionally include a port (`redis:6379`) and/or db (`redis/foo`). If left blank or not included, will use a built-in redis instance. If changed after initial setup will also require manual modification of /config/settings.py"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Default login is admin:admin via the webui, accessible at http://SERVERIP:PORT\nMore info at [papermerge]({{ project_url }}).\n\nIf you need non-English OCR language support, you can use [this mod](https://github.com/linuxserver/docker-mods/tree/papermerge-multilangocr).\n","changelogs":[{"date":"15.07.22:","desc":"Don't install development python packages"},{"date":"13.04.21:","desc":"Handle upstream stapler change"},{"date":"13.03.21:","desc":"Fixed mglib dependency per issue 32"},{"date":"25.02.21:","desc":"Updated dependencies for v2"},{"date":"07.02.21:","desc":"Support external MySQL/PSQL DBs."},{"date":"01.02.21:","desc":"Add redis."},{"date":"09.12.20:","desc":"Fix locales."},{"date":"08.08.20:","desc":"Initial Release."}]}},"setup":"Default login is admin:admin via the webui, accessible at http://SERVERIP:PORT\nMore info at [papermerge]({{ project_url }}).\n\nIf you need non-English OCR language support, you can use [this mod](https://github.com/linuxserver/docker-mods/tree/papermerge-multilangocr).\n","_id":"content:apps:papermerge.json","_type":"json","title":"Papermerge","_source":"content","_file":"apps/papermerge.json","_extension":"json"},{"_path":"/apps/phpmyadmin","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"phpmyadmin","name":"phpmyadmin","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/phpmyadmin-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/phpmyadmin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-phpmyadmin"}],"containers":[{"name":"phpmyadmin","image":"linuxserver/phpmyadmin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"},{"id":"PMA_ARBITRARY","default":"1","description":"Set to `1` to allow you to connect to any server. Setting to `0` will only allow you to connect to specified hosts (See Application Setup)"},{"id":"PMA_ABSOLUTE_URI","default":"https://phpmyadmin.example.com","description":"Set the URL you will use to access the web frontend"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"80","description":"Port for web frontend","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"phpmyadmin","project_url":"https://github.com/phpmyadmin/phpmyadmin/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/phpmyadmin-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PMA_ARBITRARY","env_value":"1","desc":"Set to `1` to allow you to connect to any server. Setting to `0` will only allow you to connect to specified hosts (See Application Setup)"},{"env_var":"PMA_ABSOLUTE_URI","env_value":"https://phpmyadmin.example.com","desc":"Set the URL you will use to access the web frontend"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Port for web frontend"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"app_setup_block_enabled":true,"app_setup_block":"This image uses nginx, in contrast to the official images which offer fpm-only or Apache variants.\n\nWe support all of the official [environment variables](https://docs.phpmyadmin.net/en/latest/setup.html#docker-environment-variables) for configuration as well as directly editing the config files.\n\nFor more information check out the [phpmyadmin documentation](https://www.phpmyadmin.net/docs/).\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"18.11.22:","desc":"Rebasing to Alpine 3.16, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to Alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"23.01.22:","desc":"Pin versions to 5.x.x."},{"date":"14.06.21:","desc":"Initial Release."}]}},"setup":"This image uses nginx, in contrast to the official images which offer fpm-only or Apache variants.\n\nWe support all of the official [environment variables](https://docs.phpmyadmin.net/en/latest/setup.html#docker-environment-variables) for configuration as well as directly editing the config files.\n\nFor more information check out the [phpmyadmin documentation](https://www.phpmyadmin.net/docs/).\n","_id":"content:apps:phpmyadmin.json","_type":"json","title":"Phpmyadmin","_source":"content","_file":"apps/phpmyadmin.json","_extension":"json"},{"_path":"/apps/pidgin","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"pidgin","name":"pidgin","description":"[Pidgin]({{ project_url }}) is a chat program which lets you log into accounts on multiple chat networks simultaneously. This means that you can be chatting with friends on XMPP and sitting in an IRC channel at the same time.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/pidgin-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pidgin"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pidgin"}],"containers":[{"name":"pidgin","image":"linuxserver/pidgin","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores local files and settings","key":"config"}],"ports":[{"container":"3000","description":"Pidgin desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pidgin","project_url":"https://pidgin.im/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/pidgin-logo.png","project_blurb":"[Pidgin]({{ project_url }}) is a chat program which lets you log into accounts on multiple chat networks simultaneously. This means that you can be chatting with friends on XMPP and sitting in an IRC channel at the same time.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores local files and settings"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Pidgin desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nThis Pidgin installation comes with default chat plugins plus a series of third party ones. **Please note that the third party plugins for the most part are not simply plug and play, you will need to reference their documentation and possibly generate oauth tokens along with other workarounds**. Third party plugins are always in a state of constant development do not expect every single native feature to work flawlessly. To ease integration with some third party plugins we include Firefox in this image to allow you to fill out captchas or pre-auth before loading your credentials into the program, simply right click the desktop to launch it. \n\n* Bonjour- Default XMPP style plugin\n* Discord- Provided by [purple-discord](https://github.com/EionRobb/purple-discord)\n* Facebook- Provided by [purple-facebook](https://github.com/dequis/purple-facebook)\n* Gadu-Gadu- Default libgadu plugin\n* Google Talk- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* GroupWise- Default GroupWise plugin\n* Hangouts- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* ICQ (WIM)- Provided by [icyque](https://github.com/EionRobb/icyque)\n* IRC- Default IRC plugin\n* Instagram- Provided by [purple-instagram](https://github.com/EionRobb/purple-instagram)\n* Office Comminicator (SIPE)- Provided by [SIPE Project](https://sipe.sourceforge.io/)\n* Rocket.chat- Provided by [purple-rocketchat](https://github.com/EionRobb/purple-rocketchat)\n* SIMPLE- Default plugin\n* Skype (HTTP)- Provided by [skype4pidgin](https://github.com/EionRobb/skype4pidgin)\n* Slack- Provided by [slack-libpurple](https://github.com/EionRobb/slack-libpurple)\n* Telegram- Provided by [telegram-purple](https://github.com/majn/telegram-purple)\n* XMPP- Default XMPP plugin\n* Zephyr- Default project Athena plugin\n","changelogs":[{"date":"21.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"15.02.22:","desc":"Add build deps for discord."},{"date":"23.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"26.09.21:","desc":"Rebase to Alpine 3.14."},{"date":"14.05.21:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nThis Pidgin installation comes with default chat plugins plus a series of third party ones. **Please note that the third party plugins for the most part are not simply plug and play, you will need to reference their documentation and possibly generate oauth tokens along with other workarounds**. Third party plugins are always in a state of constant development do not expect every single native feature to work flawlessly. To ease integration with some third party plugins we include Firefox in this image to allow you to fill out captchas or pre-auth before loading your credentials into the program, simply right click the desktop to launch it. \n\n* Bonjour- Default XMPP style plugin\n* Discord- Provided by [purple-discord](https://github.com/EionRobb/purple-discord)\n* Facebook- Provided by [purple-facebook](https://github.com/dequis/purple-facebook)\n* Gadu-Gadu- Default libgadu plugin\n* Google Talk- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* GroupWise- Default GroupWise plugin\n* Hangouts- Provided by [purple-hangouts](https://github.com/EionRobb/purple-hangouts)\n* ICQ (WIM)- Provided by [icyque](https://github.com/EionRobb/icyque)\n* IRC- Default IRC plugin\n* Instagram- Provided by [purple-instagram](https://github.com/EionRobb/purple-instagram)\n* Office Comminicator (SIPE)- Provided by [SIPE Project](https://sipe.sourceforge.io/)\n* Rocket.chat- Provided by [purple-rocketchat](https://github.com/EionRobb/purple-rocketchat)\n* SIMPLE- Default plugin\n* Skype (HTTP)- Provided by [skype4pidgin](https://github.com/EionRobb/skype4pidgin)\n* Slack- Provided by [slack-libpurple](https://github.com/EionRobb/slack-libpurple)\n* Telegram- Provided by [telegram-purple](https://github.com/majn/telegram-purple)\n* XMPP- Default XMPP plugin\n* Zephyr- Default project Athena plugin\n","_id":"content:apps:pidgin.json","_type":"json","title":"Pidgin","_source":"content","_file":"apps/pidgin.json","_extension":"json"},{"_path":"/apps/piwigo","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"piwigo","name":"piwigo","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a photo gallery software for the web that comes with powerful features to publish and manage your collection of pictures.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/piwigo-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/piwigo"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-piwigo"}],"containers":[{"name":"piwigo","image":"linuxserver/piwigo","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/gallery","description":"Image storage for Piwigo"}],"ports":[{"container":"80","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"piwigo","project_url":"http://piwigo.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/piwigo-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a photo gallery software for the web that comes with powerful features to publish and manage your collection of pictures.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."},{"vol_path":"/gallery","vol_host_path":"/path/to/appdata/gallery","desc":"Image storage for Piwigo"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"* You must create a user and database for piwigo to use in a mysql/mariadb server. \n\n* Self-signed keys are generated the first time you run the container and can be found in `/config/keys`, if needed, you can replace them with your own.\n\n* The easiest way to edit the configuration file is to enable local files editor from the plugins page and use it to configure email settings etc.\"\n","changelogs":[{"date":"16.01.23:","desc":"Fix broken custom template persistence."},{"date":"08.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3. Move application install to /app/www/public, add migration for existing users. Container updates should now update the application correctly."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"29.06.21:","desc":"Rebase to 3.14, Add php7-zip package"},{"date":"20.05.21:","desc":"Create separate volume for image data"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"12.12.20:","desc":"Increased upload_max_filesize in php.ini"},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"12.06.19:","desc":"Add ffmpeg and other deps as needed by popular plugins."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.03.19:","desc":"Add php-ctype & php-curl."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9, add php-ldap."},{"date":"28.01.19:","desc":"Rebase to alpine linux 3.8 , add pipeline logic and multi arch."},{"date":"25.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"03.05.17:","desc":"Use repo pinning to better solve dependencies, use repo version of php7-imagick."},{"date":"20.04.17:","desc":"Add php7-exif package, thanks iiska"},{"date":"23.02.17:","desc":"Rebase to alpine linux 3.5 and nginx."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"29.08.15:","desc":"Initial Release."}]}},"setup":"* You must create a user and database for piwigo to use in a mysql/mariadb server. \n\n* Self-signed keys are generated the first time you run the container and can be found in `/config/keys`, if needed, you can replace them with your own.\n\n* The easiest way to edit the configuration file is to enable local files editor from the plugins page and use it to configure email settings etc.\"\n","_id":"content:apps:piwigo.json","_type":"json","title":"Piwigo","_source":"content","_file":"apps/piwigo.json","_extension":"json"},{"_path":"/apps/plex-meta-manager","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"plex-meta-manager","name":"plex-meta-manager","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a Python 3 script that can be continuously run using YAML configuration files to update on a schedule the metadata of the movies, shows, and collections in your libraries as well as automatically build collections based on various methods all detailed in the wiki.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/plex-meta-manager-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/plex-meta-manager"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-plex-meta-manager"}],"containers":[{"name":"plex-meta-manager","image":"linuxserver/plex-meta-manager","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"PMM_CONFIG","default":"/config/config.yml","description":"Specify a custom config file to use."},{"id":"PMM_TIME","default":"03:00","description":"Comma-separated list of times to update each day. Format: `HH:MM`."},{"id":"PMM_RUN","default":"False","description":"Set to `True` to run without the scheduler."},{"id":"PMM_TEST","default":"False","description":"Set to `True` to run in debug mode with only collections that have `test: true`."},{"id":"PMM_NO_MISSING","default":"False","description":"Set to `True` to run without any of the missing movie/show functions."}],"volumes":[{"container":"/config","description":"Local path for plex-meta-manager config files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"plex-meta-manager","project_url":"https://github.com/meisnate12/Plex-Meta-Manager","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/plex-meta-manager-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a Python 3 script that can be continuously run using YAML configuration files to update on a schedule the metadata of the movies, shows, and collections in your libraries as well as automatically build collections based on various methods all detailed in the wiki.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"develop","desc":"Latest commits from the develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Local path for plex-meta-manager config files."}],"param_usage_include_ports":false,"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"PMM_CONFIG","env_value":"/config/config.yml","desc":"Specify a custom config file to use."},{"env_var":"PMM_TIME","env_value":"03:00","desc":"Comma-separated list of times to update each day. Format: `HH:MM`."},{"env_var":"PMM_RUN","env_value":"False","desc":"Set to `True` to run without the scheduler."},{"env_var":"PMM_TEST","env_value":"False","desc":"Set to `True` to run in debug mode with only collections that have `test: true`."},{"env_var":"PMM_NO_MISSING","env_value":"False","desc":"Set to `True` to run without any of the missing movie/show functions."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"There is a [walkthrough](https://metamanager.wiki/en/latest/home/guides/docker.html#setting-up-the-initial-config-file) available to help get you up and running.\n\nThis image supports all of the environment variables listed [here](https://metamanager.wiki/en/latest/home/environmental.html) and all commandline arguments.\n\nTo perform a one-time run use `docker run` (or `docker-compose run`) with the `--rm` and `-e PMM_RUN=True` arguments. This will cause the container to process your config immediately instead of waiting for the scheduled time, and delete the old container after completion.\n\nFor more information see the [official wiki](https://metamanager.wiki).\n","changelogs":[{"date":"11.12.22:","desc":"Rebase master to Alpine 3.17."},{"date":"08.11.22:","desc":"Add develop branch."},{"date":"25.10.22:","desc":"Support commandline args and relative paths."},{"date":"03.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"30.01.22:","desc":"Initial Release."}]}},"setup":"There is a [walkthrough](https://metamanager.wiki/en/latest/home/guides/docker.html#setting-up-the-initial-config-file) available to help get you up and running.\n\nThis image supports all of the environment variables listed [here](https://metamanager.wiki/en/latest/home/environmental.html) and all commandline arguments.\n\nTo perform a one-time run use `docker run` (or `docker-compose run`) with the `--rm` and `-e PMM_RUN=True` arguments. This will cause the container to process your config immediately instead of waiting for the scheduled time, and delete the old container after completion.\n\nFor more information see the [official wiki](https://metamanager.wiki).\n","_id":"content:apps:plex-meta-manager.json","_type":"json","title":"Plex Meta Manager","_source":"content","_file":"apps/plex-meta-manager.json","_extension":"json"},{"_path":"/apps/plex","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"plex","name":"plex","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/plex.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/plex"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-plex"}],"containers":[{"name":"plex","image":"linuxserver/plex","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"param_usage_include_ports":false,"param_usage_include_vols":false,"param_usage_include_env":false,"param_volumes":[],"param_ports":[],"param_env_vars":[]}},"_id":"content:apps:plex.json","_type":"json","title":"Plex","_source":"content","_file":"apps/plex.json","_extension":"json"},{"_path":"/apps/projectsend","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"projectsend","name":"projectsend","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-hosted application that lets you upload files and assign them to specific clients that you create yourself. Secure, private and easy. No more depending on external services or e-mail to send those files.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/projectsend.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/projectsend"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-projectsend"}],"containers":[{"name":"projectsend","image":"linuxserver/projectsend","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MAX_UPLOAD","default":"5000","description":"To set maximum upload size (in MB), default if unset is 5000."}],"volumes":[{"container":"/config","description":"Where to store projectsend config files.","key":"config"},{"container":"/data","description":"Where to store files to share."}],"ports":[{"container":"80","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"projectsend","project_url":"http://www.projectsend.org","project_logo":"http://www.projectsend.org/wp-content/themes/projectsend/img/screenshots.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-hosted application that lets you upload files and assign them to specific clients that you create yourself. Secure, private and easy. No more depending on external services or e-mail to send those files.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"MAX_UPLOAD","env_value":"5000","desc":"To set maximum upload size (in MB), default if unset is 5000."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where to store projectsend config files."},{"vol_path":"/data","vol_host_path":"<path to data>","desc":"Where to store files to share."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"*IMPORTANT* This image no longer supports MSSQL since being migrated to PHP7, if you want MSSQL support please use the tag `linuxserver/projectsend:r1053-ls27`\n\nRequires a user and database in either mysql or mariadb.\n\nTo use translations, follow the instructions [here](https://www.projectsend.org/how-to-use-translation-files/). The necessary paths are symlinked under `/config/translations` (note that the \"templates\" paths don't need `lang` subdirectories).\n\nMore info at [ProjectSend]({{ project_url }}).\n","changelogs":[{"date":"23.08.22:","desc":"Add translation support"},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"24.06.21:","desc":"Rebasing to alpine 3.14, switch to nginx"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"31.12.19:","desc":"Rebase to Alpine 3.11 and upgrade to PHP7."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"11.06.17:","desc":"Fetch version from github."},{"date":"09.12.17:","desc":"Rebase to alpine 3.7."},{"date":"13.06.17:","desc":"Initial Release."}]}},"setup":"*IMPORTANT* This image no longer supports MSSQL since being migrated to PHP7, if you want MSSQL support please use the tag `linuxserver/projectsend:r1053-ls27`\n\nRequires a user and database in either mysql or mariadb.\n\nTo use translations, follow the instructions [here](https://www.projectsend.org/how-to-use-translation-files/). The necessary paths are symlinked under `/config/translations` (note that the \"templates\" paths don't need `lang` subdirectories).\n\nMore info at [ProjectSend]({{ project_url }}).\n","_id":"content:apps:projectsend.json","_type":"json","title":"Projectsend","_source":"content","_file":"apps/projectsend.json","_extension":"json"},{"_path":"/apps/prowlarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"prowlarr","name":"prowlarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Sonarr, Radarr, Lidarr, and Readarr offering complete management of your indexers with no per app Indexer setup required (we do it all).\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/prowlarr-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/prowlarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-prowlarr"}],"containers":[{"name":"prowlarr","image":"linuxserver/prowlarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Prowlarr"}],"volumes":[{"container":"/config","description":"Database and Prowlarr configs","key":"config"}],"ports":[{"container":"9696","description":"The port for the Prowlarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"prowlarr","project_url":"https://github.com/Prowlarr/Prowlarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/prowlarr-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Sonarr, Radarr, Lidarr, and Readarr offering complete management of your indexers with no per app Indexer setup required (we do it all).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Prowlarr stable releases"},{"tag":"develop","desc":"Prowlarr releases from their develop branch"},{"tag":"nightly","desc":"Prowlarr releases from their nightly branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and Prowlarr configs"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9696","internal_port":"9696","port_desc":"The port for the Prowlarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Prowlarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:9696`, for more information check out [Prowlarr](https://github.com/Prowlarr/Prowlarr).\n\nSetup info can be found [here](https://wikijs.servarr.com/prowlarr/quick-start-guide).\n","changelogs":[{"date":"03.01.23:","desc":"Publish stable release."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine."},{"date":"06.06.21:","desc":"Initial realease."}]}},"setup":"Access the webui at `<your-ip>:9696`, for more information check out [Prowlarr](https://github.com/Prowlarr/Prowlarr).\n\nSetup info can be found [here](https://wikijs.servarr.com/prowlarr/quick-start-guide).\n","_id":"content:apps:prowlarr.json","_type":"json","title":"Prowlarr","_source":"content","_file":"apps/prowlarr.json","_extension":"json"},{"_path":"/apps/pwndrop","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"pwndrop","name":"pwndrop","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-deployable file hosting service for sending out red teaming payloads or securely sharing your private files over HTTP and WebDAV.","icon":"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-logo-512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pwndrop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pwndrop"}],"containers":[{"name":"pwndrop","image":"linuxserver/pwndrop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SECRET_PATH","default":"/pwndrop","description":"Secret path for admin access. Defaults to `/pwndrop`. This parameter only takes effect during initial install; it can later be changed in the web gui."}],"volumes":[{"container":"/config","description":"Contains all relevant configuration and data.","key":"config"}],"ports":[{"container":"8080","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pwndrop","project_url":"https://github.com/kgretzky/pwndrop","project_logo":"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-logo-512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a self-deployable file hosting service for sending out red teaming payloads or securely sharing your private files over HTTP and WebDAV.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"},{"tag":"development","desc":"Prereleases from their GitHub"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration and data."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SECRET_PATH","env_value":"/pwndrop","desc":"Secret path for admin access. Defaults to `/pwndrop`. This parameter only takes effect during initial install; it can later be changed in the web gui."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Access the web gui at `http://<your-ip>:8080/pwndrop` (replace `/pwndrop` with your SECRET_PATH if you set one).\n","changelogs":[{"date":"19.09.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"17.04.20:","desc":"Initial Release."}]}},"setup":"Access the web gui at `http://<your-ip>:8080/pwndrop` (replace `/pwndrop` with your SECRET_PATH if you set one).\n","_id":"content:apps:pwndrop.json","_type":"json","title":"Pwndrop","_source":"content","_file":"apps/pwndrop.json","_extension":"json"},{"_path":"/apps/pydio-cells","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"pydio-cells","name":"pydio-cells","description":"[{{ project_name|capitalize }}]({{ project_url }}) is the nextgen file sharing platform for organizations. It is a full rewrite of the Pydio project using the Go language following a micro-service architecture.","icon":"https://raw.githubusercontent.com/wiki/pydio/cells/images/PydioCellsColor.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pydio-cells"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pydio-cells"}],"containers":[{"name":"pydio-cells","image":"linuxserver/pydio-cells","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"EXTERNALURL","default":"yourdomain.url","description":"The external url you would like to use to access Pydio Cells (Can be https://domain.url or https://IP:PORT)."},{"id":"SERVER_IP","default":"0.0.0.0","description":"Enter the LAN IP of the docker server. Required for local access by IP, added to self signed cert as SAN (not required if accessing only through reverse proxy)."}],"volumes":[{"container":"/config","description":"Folder where configuration and data files reside.","key":"config"},{"container":"/config","description":"All the config files reside here.","key":"config"}],"ports":[{"container":"8080","description":"Http port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pydio-cells","project_url":"https://pydio.com/","project_logo":"https://raw.githubusercontent.com/wiki/pydio/cells/images/PydioCellsColor.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is the nextgen file sharing platform for organizations. It is a full rewrite of the Pydio project using the Go language following a micro-service architecture.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Pydio Cells releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":true,"param_hostname":"{{ project_name }}","param_hostname_desc":"Pydio Cells uses the hostname to verify local files. This setting is required and should not be changed after it has been set.","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"EXTERNALURL","env_value":"yourdomain.url","desc":"The external url you would like to use to access Pydio Cells (Can be https://domain.url or https://IP:PORT)."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"All the config files reside here."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"Http port"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":false,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SERVER_IP","env_value":"0.0.0.0","desc":"Enter the LAN IP of the docker server. Required for local access by IP, added to self signed cert as SAN (not required if accessing only through reverse proxy)."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Folder where configuration and data files reside."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"33060","internal_port":"33060","port_desc":"gRPC port (required for CellsSync)."}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"You must first create a mysql database for Pydio Cells. Using our [mariadb image](https://hub.docker.com/r/linuxserver/mariadb) is recommended.  \n\nThen access the web gui setup wizard at `https://SERVER_IP:8080` if accessing locally (must set `SERVER_IP` env var), or at `https://pydio-cells.domain.com` if reverse proxying.\n","changelogs":[{"date":"01.12.22:","desc":"Rebasing to alpine 3.17. Adding multi-arch support. Updating cli arguments for v4 compatibility."},{"date":"19.10.22:","desc":"Rebasing to alpine 3.16. Upgrading to s6v3. Updating build instructions for v4."},{"date":"19.09.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"18.04.20:","desc":"Switch to https as default (only affects new installs). Add self signed cert, add `SERVER_IP` var for adding to cert as SAN. Add optional gRPC port mapping for CellsSync."},{"date":"17.04.20:","desc":"Update compile options, previous release was broken for new installs."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"12.12.19:","desc":"Initial Release"}]}},"setup":"You must first create a mysql database for Pydio Cells. Using our [mariadb image](https://hub.docker.com/r/linuxserver/mariadb) is recommended.  \n\nThen access the web gui setup wizard at `https://SERVER_IP:8080` if accessing locally (must set `SERVER_IP` env var), or at `https://pydio-cells.domain.com` if reverse proxying.\n","_id":"content:apps:pydio-cells.json","_type":"json","title":"Pydio Cells","_source":"content","_file":"apps/pydio-cells.json","_extension":"json"},{"_path":"/apps/pyload-ng","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"pyload-ng","name":"pyload-ng","description":"[pyLoad]({{ project_url }}) is a Free and Open Source download manager written in Python and designed to be extremely lightweight, easily extensible and fully manageable via web.","icon":"https://pyload.net/img/banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pyload-ng"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pyload-ng"}],"containers":[{"name":"pyload-ng","image":"linuxserver/pyload-ng","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"pyLoad Configuration and files database","key":"config"},{"container":"/downloads","description":"Destination of pyLoad downloads"}],"ports":[{"container":"8000","description":"Allows HTTP access to the application","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pyload-ng","project_url":"https://pyload.net/","project_logo":"https://pyload.net/img/banner.png","project_blurb":"[pyLoad]({{ project_url }}) is a Free and Open Source download manager written in Python and designed to be extremely lightweight, easily extensible and fully manageable via web.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from pyLoad Next"},{"tag":"develop","desc":"Releases from pyload Next develop branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"pyLoad Configuration and files database"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Destination of pyLoad downloads"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8000","internal_port":"8000","port_desc":"Allows HTTP access to the application"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"9666","internal_port":"9666","port_desc":"Click'n'Load port."}],"app_setup_block_enabled":true,"app_setup_block":"Access the web interface at `http://your-ip:8000` the default login is: \nusername - **pyload**\npassword - **pyload**\n\nFor general usage please see the pyLoad wiki [here](https://github.com/pyload/pyload/wiki) .\n","changelogs":[{"date":"02.02.22:","desc":"Rebase master to alpine 3.17."},{"date":"02.02.22:","desc":"Add ffmpeg for the Youtube plugin."},{"date":"24.01.22:","desc":"Replace unrar with p7zip."},{"date":"24.01.22:","desc":"Initial release."}]}},"setup":"Access the web interface at `http://your-ip:8000` the default login is: \nusername - **pyload**\npassword - **pyload**\n\nFor general usage please see the pyLoad wiki [here](https://github.com/pyload/pyload/wiki) .\n","_id":"content:apps:pyload-ng.json","_type":"json","title":"Pyload Ng","_source":"content","_file":"apps/pyload-ng.json","_extension":"json"},{"_path":"/apps/pylon","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"pylon","name":"pylon","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web based integrated development environment built with Node.js as a backend and with a supercharged JavaScript/HTML5 frontend, licensed under GPL version 3. This project originates from Cloud9 v2 project.\n","icon":"https://raw.githubusercontent.com/pylonide/pylon/master/doc/screenshot02.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/pylon"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-pylon"}],"containers":[{"name":"pylon","image":"linuxserver/pylon","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"GITURL","default":"https://github.com/linuxserver/docker-pylon.git","description":"Specify a git repo to checkout on first startup"},{"id":"PYUSER","default":"myuser","description":"Specify a basic auth user."},{"id":"PYPASS","default":"mypass","description":"Specify a basic auth password."}],"ports":[{"container":"3131","description":"The port for the Pylon web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"pylon","project_url":"https://github.com/pylonide/pylon","project_logo":"https://raw.githubusercontent.com/pylonide/pylon/master/doc/screenshot02.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web based integrated development environment built with Node.js as a backend and with a supercharged JavaScript/HTML5 frontend, licensed under GPL version 3. This project originates from Cloud9 v2 project.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_ports":true,"param_ports":[{"external_port":"3131","internal_port":"3131","port_desc":"The port for the Pylon web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/code","vol_host_path":"<path to your code>","desc":"Optionally if you want the bind mount your own code and have changes survive container upgrades."}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"GITURL","env_value":"https://github.com/linuxserver/docker-pylon.git","desc":"Specify a git repo to checkout on first startup"},{"env_var":"PYUSER","env_value":"myuser","desc":"Specify a basic auth user."},{"env_var":"PYPASS","env_value":"mypass","desc":"Specify a basic auth password."}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://your-ip:3131, more information [here](https://github.com/pylonide/pylon).\n","changelogs":[{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"19.09.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://your-ip:3131, more information [here](https://github.com/pylonide/pylon).\n","_id":"content:apps:pylon.json","_type":"json","title":"Pylon","_source":"content","_file":"apps/pylon.json","_extension":"json"},{"_path":"/apps/qbittorrent","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"qbittorrent","name":"qbittorrent","description":"The [{{ project_name|capitalize }}]({{ project_url }}) project aims to provide an open-source software alternative to Torrent. qBittorrent is based on the Qt toolkit and libtorrent-rasterbar library.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/qbittorrent-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/qbittorrent"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-qbittorrent"}],"containers":[{"name":"qbittorrent","image":"linuxserver/qbittorrent","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"WEBUI_PORT","default":"8080","description":"for changing the port of the webui, see below for explanation"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"},{"container":"/downloads","description":"Location of downloads on disk."}],"ports":[{"container":"8080","description":"WebUI","protocol":"tcp","web":false},{"container":"6881","description":"tcp connection port","protocol":"tcp","web":false},{"container":"6881/udp","description":"udp connection port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"qbittorrent","project_url":"https://www.qbittorrent.org/","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/qbittorrent-icon.png","project_blurb":"The [{{ project_name|capitalize }}]({{ project_url }}) project aims to provide an open-source software alternative to Torrent. qBittorrent is based on the Qt toolkit and libtorrent-rasterbar library.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable qbittorrent releases"},{"tag":"libtorrentv1","desc":"Static qbittorrent builds using libtorrent v1"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Location of downloads on disk."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"WebUI"},{"external_port":"6881","internal_port":"6881","port_desc":"tcp connection port"},{"external_port":"6881","internal_port":"6881/udp","port_desc":"udp connection port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"},{"env_var":"WEBUI_PORT","env_value":"8080","desc":"for changing the port of the webui, see below for explanation"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The webui is at `<your-ip>:8080` and the default username/password is `admin/adminadmin`.  \n\nChange username/password via the webui in the webui section of settings.  \n\n### WEBUI_PORT variable\n\nDue to issues with CSRF and port mapping, should you require to alter the port for the webui you need to change both sides of the -p 8080 switch AND set the WEBUI_PORT variable to the new port.  \n\nFor example, to set the port to 8090 you need to set -p 8090:8090 and -e WEBUI_PORT=8090  \n\nThis should alleviate the \"white screen\" issue.  \n\nIf you have no webui , check the file /config/qBittorrent/qBittorrent.conf  \n\nedit or add the following lines  \n\n```text\nWebUI\\Address=*\n\nWebUI\\ServerDomains=*\n```\n\nIf you are running a very old (3.x) kernel you may run into [this issue](https://github.com/linuxserver/docker-qbittorrent/issues/103) which can be worked around using [this method](https://github.com/linuxserver/docker-qbittorrent/issues/103#issuecomment-831238484)\n","changelogs":[{"date":"29.11.22:","desc":"Add openssl1.1-compat for qbittorrent-cli."},{"date":"31.10.22:","desc":"Add libtorrentv1 branch."},{"date":"31.08.22:","desc":"Rebase to Alpine Edge again to follow latest releases."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"16.06.22:","desc":"Rebase to Alpine 3.16 from edge."},{"date":"25.05.22:","desc":"Fetch qbitorrent-cli from upstream repo."},{"date":"02.03.22:","desc":"Add unrar, 7zip, and qbitorrent-cli."},{"date":"01.03.22:","desc":"Add python for search plugin support."},{"date":"23.02.22:","desc":"Rebase to Alpine Edge, install from Alpine repos."},{"date":"19.02.22:","desc":"Add jq to build-stage"},{"date":"07.01.22:","desc":"Rebase to Alpine, build from source."},{"date":"06.01.22:","desc":"Deprecate unstable branch."},{"date":"10.02.21:","desc":"Rebase to focal."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"12.11.20:","desc":"Stop creating /config/data directory on startup"},{"date":"03.04.20:","desc":"Fix adding search engine plugin"},{"date":"02.08.19:","desc":"Add qbitorrent-cli for processing scripts."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"14.01.19:","desc":"Rebase to Ubuntu, add multi arch and pipeline logic."},{"date":"25.09.18:","desc":"Use buildstage type build, bump qbitorrent to 4.1.3."},{"date":"14.08.18:","desc":"Rebase to alpine 3.8, bump libtorrent to 1.1.9 and qbitorrent to 4.1.2."},{"date":"08.06.18:","desc":"Bump qbitorrent to 4.1.1."},{"date":"26.04.18:","desc":"Bump libtorrent to 1.1.7."},{"date":"02.03.18:","desc":"Bump qbitorrent to 4.0.4 and libtorrent to 1.1.6."},{"date":"02.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"19.12.17:","desc":"Update to v4.0.3."},{"date":"09.02.17:","desc":"Rebase to alpine 3.7"},{"date":"01.12.17:","desc":"Update to v4.0.2."},{"date":"27.11.17:","desc":"Update to v4 and use cpu_core routine to speed up builds."},{"date":"16.09.17:","desc":"Bump to 3.3.16, Add WEBUI_PORT variable and notes to README to allow changing port of webui."},{"date":"01.08.17:","desc":"Initial Release."},{"date":"12.02.18:","desc":"Initial Release."}]}},"setup":"The webui is at `<your-ip>:8080` and the default username/password is `admin/adminadmin`.  \n\nChange username/password via the webui in the webui section of settings.  \n\n### WEBUI_PORT variable\n\nDue to issues with CSRF and port mapping, should you require to alter the port for the webui you need to change both sides of the -p 8080 switch AND set the WEBUI_PORT variable to the new port.  \n\nFor example, to set the port to 8090 you need to set -p 8090:8090 and -e WEBUI_PORT=8090  \n\nThis should alleviate the \"white screen\" issue.  \n\nIf you have no webui , check the file /config/qBittorrent/qBittorrent.conf  \n\nedit or add the following lines  \n\n```text\nWebUI\\Address=*\n\nWebUI\\ServerDomains=*\n```\n\nIf you are running a very old (3.x) kernel you may run into [this issue](https://github.com/linuxserver/docker-qbittorrent/issues/103) which can be worked around using [this method](https://github.com/linuxserver/docker-qbittorrent/issues/103#issuecomment-831238484)\n","_id":"content:apps:qbittorrent.json","_type":"json","title":"Qbittorrent","_source":"content","_file":"apps/qbittorrent.json","_extension":"json"},{"_path":"/apps/qdirstat","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"qdirstat","name":"qdirstat","description":"[QDirStat]({{ project_url }}) Qt-based directory statistics: KDirStat without any KDE -- from the author of the original KDirStat.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/qdirstat-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/qdirstat"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-qdirstat"}],"containers":[{"name":"qdirstat","image":"linuxserver/qdirstat","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores qdirstat settings and scans.","key":"config"},{"container":"/data","description":"Data you want to analyze disk usage information of."}],"ports":[{"container":"3000","description":"QdirStat desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"qdirstat","project_url":"https://github.com/shundhammer/qdirstat","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/qdirstat-logo.png","project_blurb":"[QDirStat]({{ project_url }}) Qt-based directory statistics: KDirStat without any KDE -- from the author of the original KDirStat.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores qdirstat settings and scans."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Data you want to analyze disk usage information of."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"QdirStat desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.12.22:","desc":"Rebase to Jammy."},{"date":"06.04.22:","desc":"Add xfce terminal."},{"date":"13.01.22:","desc":"Compile from source."},{"date":"11.01.22:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:qdirstat.json","_type":"json","title":"Qdirstat","_source":"content","_file":"apps/qdirstat.json","_extension":"json"},{"_path":"/apps/quassel-core","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"quassel-core","name":"quassel-core","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a modern, cross-platform, distributed IRC client, meaning that one (or multiple) client(s) can attach to and detach from a central core.\n\nThis container handles the IRC connection (quasselcore) and requires a desktop client (quasselclient) to be used and configured. It is designed to be always on and will keep your identity present in IRC even when your clients cannot be online. Backlog (history) is downloaded by your client upon reconnection allowing infinite scrollback through time.\n","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/quasselcore.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/quassel-core"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-quassel-core"}],"containers":[{"name":"quassel-core","image":"linuxserver/quassel-core","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"--config-from-environment","description":"Custom CLI options for Quassel"}],"volumes":[{"container":"/config","description":"Database and quassel-core configuration storage.","key":"config"}],"ports":[{"container":"4242","description":"The port quassel-core listens for connections on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"quassel-core","project_url":"http://quassel-irc.org/","project_logo":"http://icons.iconarchive.com/icons/oxygen-icons.org/oxygen/256/Apps-quassel-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a modern, cross-platform, distributed IRC client, meaning that one (or multiple) client(s) can attach to and detach from a central core.\n\nThis container handles the IRC connection (quasselcore) and requires a desktop client (quasselclient) to be used and configured. It is designed to be always on and will keep your identity present in IRC even when your clients cannot be online. Backlog (history) is downloaded by your client upon reconnection allowing infinite scrollback through time.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Database and quassel-core configuration storage."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4242","internal_port":"4242","port_desc":"The port quassel-core listens for connections on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"RUN_OPTS","env_value":"--config-from-environment","desc":"Custom CLI options for Quassel"}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"113","internal_port":"10113","port_desc":"Optional Ident Port"}],"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Quassel wiki: [quassel](http://bugs.quassel-irc.org/projects/quassel-irc/wiki)\n\nA great place to host a quassel instance is a VPS, such as [DigitalOcean](https://www.digitalocean.com/?refcode=501c48b34b8c). For $5 a month you can have a 24/7 IRC connection and be up and running in under 55 seconds (or so they claim).\n\nOnce you have the container running, fire up a quassel desktop client and connect to your new core instance using your droplets public IP address and the port you specified in your `docker run` command *default: 4242*. Create an admin user, select SQLite as your storage backend (Quassel limitation). Setup your real name and nick, then press `Save & Connect`.\n\nYou're now connected to IRC. Let's add you to our [IRC](http://www.linuxserver.io/index.php/irc/) `#linuxserver.io` room on Freenode. Click 'File' > 'Networks' > 'Configure Networks' > 'Add' (under Networks section, not Servers) > 'Use preset' > Select 'Freenode' and then configure your identity using the tabs in the 'Network details' section. Once connected to Freenode, click `#join` and enter `#linuxserver.io`. That's it, you're done.\n\n## Stateless usage\n\nTo use Quassel in stateless mode, where it needs to be configured through\nenvironment arguments, run it with the `--config-from-environment` RUN_OPTS environment setting.\n\n| Env | Usage |\n| :----: | --- |\n| DB_BACKEND | `SQLite` or `PostgreSQL` |\n| DB_PGSQL_USERNAME | PostgreSQL User |\n| DB_PGSQL_PASSWORD | PostgreSQL Password |\n| DB_PGSQL_HOSTNAME | PostgreSQL Host |\n| DB_PGSQL_PORT | PostgreSQL Port |\n| AUTH_AUTHENTICATOR | `Database` or `LDAP` |\n| AUTH_LDAP_HOSTNAME | LDAP Host |\n| AUTH_LDAP_PORT | LDAP Port |\n| AUTH_LDAP_BIND_DN | LDAP Bind Domain |\n| AUTH_LDAP_BIND_PASSWORD | LDAP Password |\n| AUTH_LDAP_FILTER | LDAP Authentication Filters |\n| AUTH_LDAP_UID_ATTRIBUTE | LDAP UID |\n\nAdditionally you have RUN_OPTS that can be used to customize pathing and behvior.\n\n| Option | Example |\n| :----: | --- |\n| --strict-ident | strictly bool `--strict-ident` |\n| --ident-daemon | strictly bool `--ident-daemon` |\n| --ident-port | `--ident-port \"10113\"` |\n| --ident-listen | `--ident-listen \"::,0.0.0.0\"` |\n| --ssl-cert | `--ssl-cert /config/keys/cert.crt` |\n| --ssl-key | `--ssl-key /config/keys/cert.key` |\n| --require-ssl | strictly bool `--require-ssl` |\n\nMinimal example with SQLite:\n\n```\ndocker create \\\n  --name=quassel-core \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e RUN_OPTS='--config-from-environment' \\\n  -e DB_BACKEND=SQLite \\\n  -e AUTH_AUTHENTICATOR=Database \\\n  -p 4242:4242 \\\n  -v <path to data>:/config \\\n  --restart unless-stopped \\\n  linuxserver/quassel-core\n```\n","changelogs":[{"date":"03.01.22:","desc":"Rebase to alpine 3.15. Add new build deps and apply other fixes for 0.14."},{"date":"07.08.21:","desc":"Fixing incorrect database password variable operator."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"20.03.19:","desc":"Make stateless operation an option, with input from one of the quassel team."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"08.01.19:","desc":"Rebase to Ubuntu Bionic and upgrade to Quassel`0.13.0` See [here.](https://quassel-irc.org/node/134)."},{"date":"30.07.18:","desc":"Rebase to alpine:3.8 and use buildstage."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"09.12.17:","desc":"Rebase to alpine:3.7."},{"date":"26.11.17:","desc":"Use cpu core counting routine to speed up build time."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"27.05.17:","desc":"Rebase to alpine:3.6."},{"date":"13.05.17:","desc":"Switch to git source."},{"date":"28.12.16:","desc":"Rebase to alpine:3.5."},{"date":"23.11.16:","desc":"Rebase to alpine:edge."},{"date":"23.09.16:","desc":"Use QT5 dependencies (thanks bauerj)."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"10.08.16:","desc":"Rebase to xenial."},{"date":"14.10.15:","desc":"Removed the webui, turned out to be to unstable for most usecases."},{"date":"01.09.15:","desc":"Fixed mistake in README."},{"date":"30.07.15:","desc":"Switched to internal baseimage, and fixed a bug with updating the webinterface."},{"date":"06.07.15:","desc":"Enabled BLOWFISH encryption and added a (optional) webinterface, for the times you dont have access to your client."}]}},"setup":"Quassel wiki: [quassel](http://bugs.quassel-irc.org/projects/quassel-irc/wiki)\n\nA great place to host a quassel instance is a VPS, such as [DigitalOcean](https://www.digitalocean.com/?refcode=501c48b34b8c). For $5 a month you can have a 24/7 IRC connection and be up and running in under 55 seconds (or so they claim).\n\nOnce you have the container running, fire up a quassel desktop client and connect to your new core instance using your droplets public IP address and the port you specified in your `docker run` command *default: 4242*. Create an admin user, select SQLite as your storage backend (Quassel limitation). Setup your real name and nick, then press `Save & Connect`.\n\nYou're now connected to IRC. Let's add you to our [IRC](http://www.linuxserver.io/index.php/irc/) `#linuxserver.io` room on Freenode. Click 'File' > 'Networks' > 'Configure Networks' > 'Add' (under Networks section, not Servers) > 'Use preset' > Select 'Freenode' and then configure your identity using the tabs in the 'Network details' section. Once connected to Freenode, click `#join` and enter `#linuxserver.io`. That's it, you're done.\n\n## Stateless usage\n\nTo use Quassel in stateless mode, where it needs to be configured through\nenvironment arguments, run it with the `--config-from-environment` RUN_OPTS environment setting.\n\n| Env | Usage |\n| :----: | --- |\n| DB_BACKEND | `SQLite` or `PostgreSQL` |\n| DB_PGSQL_USERNAME | PostgreSQL User |\n| DB_PGSQL_PASSWORD | PostgreSQL Password |\n| DB_PGSQL_HOSTNAME | PostgreSQL Host |\n| DB_PGSQL_PORT | PostgreSQL Port |\n| AUTH_AUTHENTICATOR | `Database` or `LDAP` |\n| AUTH_LDAP_HOSTNAME | LDAP Host |\n| AUTH_LDAP_PORT | LDAP Port |\n| AUTH_LDAP_BIND_DN | LDAP Bind Domain |\n| AUTH_LDAP_BIND_PASSWORD | LDAP Password |\n| AUTH_LDAP_FILTER | LDAP Authentication Filters |\n| AUTH_LDAP_UID_ATTRIBUTE | LDAP UID |\n\nAdditionally you have RUN_OPTS that can be used to customize pathing and behvior.\n\n| Option | Example |\n| :----: | --- |\n| --strict-ident | strictly bool `--strict-ident` |\n| --ident-daemon | strictly bool `--ident-daemon` |\n| --ident-port | `--ident-port \"10113\"` |\n| --ident-listen | `--ident-listen \"::,0.0.0.0\"` |\n| --ssl-cert | `--ssl-cert /config/keys/cert.crt` |\n| --ssl-key | `--ssl-key /config/keys/cert.key` |\n| --require-ssl | strictly bool `--require-ssl` |\n\nMinimal example with SQLite:\n\n```\ndocker create \\\n  --name=quassel-core \\\n  -e PUID=1000 \\\n  -e PGID=1000 \\\n  -e TZ=Europe/London \\\n  -e RUN_OPTS='--config-from-environment' \\\n  -e DB_BACKEND=SQLite \\\n  -e AUTH_AUTHENTICATOR=Database \\\n  -p 4242:4242 \\\n  -v <path to data>:/config \\\n  --restart unless-stopped \\\n  linuxserver/quassel-core\n```\n","_id":"content:apps:quassel-core.json","_type":"json","title":"Quassel Core","_source":"content","_file":"apps/quassel-core.json","_extension":"json"},{"_path":"/apps/quassel-web","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"quassel-web","name":"quassel-web","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a web client for Quassel.  Note that a Quassel-Core instance is required, we have a container available [here.](https://hub.docker.com/r/linuxserver/quassel-core/) \n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/quassel-web-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/quassel-web"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-quassel-web"}],"containers":[{"name":"quassel-web","image":"linuxserver/quassel-web","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"QUASSEL_CORE","default":"192.168.1.10","description":"specify the URL or IP address of your Quassel Core instance"},{"id":"QUASSEL_PORT","default":"4242","description":"specify the port of your Quassel Core instance"},{"id":"URL_BASE","default":"/quassel","description":"Specify a url-base in reverse proxy setups ie. `/quassel`"}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"}],"ports":[{"container":"64443","description":"Quassel-web https webui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"quassel-web","project_url":"https://github.com/magne4000/quassel-webserver","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/quassel-web-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a web client for Quassel.  Note that a Quassel-Core instance is required, we have a container available [here.](https://hub.docker.com/r/linuxserver/quassel-core/) \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v6-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store config on the docker host"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"QUASSEL_CORE","env_value":"192.168.1.10","desc":"specify the URL or IP address of your Quassel Core instance"},{"env_var":"QUASSEL_PORT","env_value":"4242","desc":"specify the port of your Quassel Core instance"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"64443","internal_port":"64443","port_desc":"Quassel-web https webui"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"URL_BASE","env_value":"/quassel","desc":"Specify a url-base in reverse proxy setups ie. `/quassel`"}],"app_setup_block_enabled":true,"app_setup_block":"By default this container webui will be available on `https://$SERVER_IP:64443`. To setup this container you can either use the envrionment variables we recommend or manually setup the configuration file by leaving out the `QUASSEL_CORE` environment variable among others. \nThe configuration file using this method can be found at:\n```\n/config/settings-user.js\n```\n","changelogs":[{"date":"12.02.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"18.05.19:","desc":"Reconfigure environmental variable setup."},{"date":"28.04.19:","desc":"Initial Release."}]}},"setup":"By default this container webui will be available on `https://$SERVER_IP:64443`. To setup this container you can either use the envrionment variables we recommend or manually setup the configuration file by leaving out the `QUASSEL_CORE` environment variable among others. \nThe configuration file using this method can be found at:\n```\n/config/settings-user.js\n```\n","_id":"content:apps:quassel-web.json","_type":"json","title":"Quassel Web","_source":"content","_file":"apps/quassel-web.json","_extension":"json"},{"_path":"/apps/radarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"radarr","name":"radarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) - A fork of Sonarr to work with movies  la Couchpotato.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/radarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/radarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-radarr"}],"containers":[{"name":"radarr","image":"linuxserver/radarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Radarr"}],"volumes":[{"container":"/movies","description":"Location of Movie library on disk (See note in Application setup)"},{"container":"/downloads","description":"Location of download managers output directory (See note in Application setup)"},{"container":"/config","description":"Database and Radarr configs","key":"config"}],"ports":[{"container":"7878","description":"The port for the Radarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"radarr","project_url":"https://github.com/Radarr/Radarr","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/radarr.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - A fork of Sonarr to work with movies  la Couchpotato.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Radarr releases"},{"tag":"develop","desc":"Radarr releases from their develop branch"},{"tag":"nightly","desc":"Radarr releases from their nightly branch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and Radarr configs"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/movies","vol_host_path":"/path/to/movies","desc":"Location of Movie library on disk (See note in Application setup)"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloadclient-downloads","desc":"Location of download managers output directory (See note in Application setup)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"7878","internal_port":"7878","port_desc":"The port for the Radarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Radarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:7878`, for more information check out [Radarr](https://github.com/Radarr/Radarr).\n\n### Media folders\n\nWe have set `/movies` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"17.01.23:","desc":"Rebase master branch to Alpine 3.17, migrate to s6v3."},{"date":"06.06.22:","desc":"Rebase master branch to Alpine 3.15."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine."},{"date":"04.02.22:","desc":"Rebase nightly branch to Alpine and deprecate nightly-alpine branch."},{"date":"27.12.21:","desc":"Add nightly-alpine branch."},{"date":"17.10.21:","desc":"Remove `UMASK_SET`."},{"date":"08.05.21:","desc":"Make the paths clearer to the user"},{"date":"17.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"11.30.20:","desc":"Publish `develop` tag."},{"date":"11.28.20:","desc":"Switch to v3 .NET CORE builds (no more mono, `5.14` tag is deprecated). Rebase to Focal (for issues on arm32v7, [see here](https://docs.linuxserver.io/faq#my-host-is-incompatible-with-images-based-on-ubuntu-focal))."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"10.05.19:","desc":"Rebase to Bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"09.09.18:","desc":"Add pipeline build process."},{"date":"24.02.18:","desc":"Add nightly branch."},{"date":"06.02.18:","desc":"Radarr repo changed owner."},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, adds python also."},{"date":"13.04.17:","desc":"Switch to official mono repository."},{"date":"10.01.17:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:7878`, for more information check out [Radarr](https://github.com/Radarr/Radarr).\n\n### Media folders\n\nWe have set `/movies` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","_id":"content:apps:radarr.json","_type":"json","title":"Radarr","_source":"content","_file":"apps/radarr.json","_extension":"json"},{"_path":"/apps/raneto","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"raneto","name":"raneto","description":"[{{ project_name|capitalize }}]({{ project_url }}) - is an open source Knowledgebase platform that uses static Markdown files to power your Knowledgebase.","icon":"https://raw.githubusercontent.com/gilbitron/Raneto/master/logo/logo_readme.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/raneto"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-raneto"}],"containers":[{"name":"raneto","image":"linuxserver/raneto","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Raneto config and Markdown files","key":"config"}],"ports":[{"container":"3000","description":"The port for the Raneto web interface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"raneto","project_url":"http://raneto.com/","project_logo":"https://raw.githubusercontent.com/gilbitron/Raneto/master/logo/logo_readme.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - is an open source Knowledgebase platform that uses static Markdown files to power your Knowledgebase.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Raneto config and Markdown files"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"The port for the Raneto web interface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at http://<your-ip>:3000\n\nThe default username and password is *admin/password*\n\nThis application can only be configured through file storage the web interface is only for editing Markdown files.\nYou need to understand the following paths and the role they play for the application:\n\n* /config/config.default.js - Main configuration file to setup your user, site name, etc.\n* /config/content - All of your Markdown files go here [more info](http://docs.raneto.com/usage/creating-pages).\n* /config/images - This folder will serve content on http://<your-ip>:3000/images/<image name>.png you can put anything in here but it is specifically for image files so you can embed them in your Markdown files without using external hosting.\n","changelogs":[{"date":"18.01.23:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"10.08.22:","desc":"Rebasing to alpine 3.15."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.11."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"01.06.19:","desc":"Initial Release."}]}},"setup":"Access the webui at http://<your-ip>:3000\n\nThe default username and password is *admin/password*\n\nThis application can only be configured through file storage the web interface is only for editing Markdown files.\nYou need to understand the following paths and the role they play for the application:\n\n* /config/config.default.js - Main configuration file to setup your user, site name, etc.\n* /config/content - All of your Markdown files go here [more info](http://docs.raneto.com/usage/creating-pages).\n* /config/images - This folder will serve content on http://<your-ip>:3000/images/<image name>.png you can put anything in here but it is specifically for image files so you can embed them in your Markdown files without using external hosting.\n","_id":"content:apps:raneto.json","_type":"json","title":"Raneto","_source":"content","_file":"apps/raneto.json","_extension":"json"},{"_path":"/apps/rdesktop","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"rdesktop","name":"rdesktop","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Containers containing full desktop environments in many popular flavors for Alpine, Ubuntu, Arch, and Fedora accessible via RDP.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rdesktop.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/rdesktop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-rdesktop"}],"containers":[{"name":"rdesktop","image":"linuxserver/rdesktop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"ports":[{"container":"3389","description":"RDP access port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"rdesktop","project_url":"http://xrdp.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rdesktop.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Containers containing full desktop environments in many popular flavors for Alpine, Ubuntu, Arch, and Fedora accessible via RDP.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"XFCE Alpine"},{"tag":"ubuntu-xfce","desc":"XFCE Ubuntu"},{"tag":"fedora-xfce","desc":"XFCE Fedora"},{"tag":"arch-xfce","desc":"XFCE Arch"},{"tag":"alpine-kde","desc":"KDE Alpine"},{"tag":"ubuntu-kde","desc":"KDE Ubuntu"},{"tag":"fedora-kde","desc":"KDE Fedora"},{"tag":"arch-kde","desc":"KDE Arch"},{"tag":"alpine-mate","desc":"MATE Alpine"},{"tag":"ubuntu-mate","desc":"MATE Ubuntu"},{"tag":"fedora-mate","desc":"MATE Fedora"},{"tag":"arch-mate","desc":"MATE Arch"},{"tag":"alpine-i3","desc":"i3 Alpine"},{"tag":"ubuntu-i3","desc":"i3 Ubuntu"},{"tag":"fedora-i3","desc":"i3 Fedora"},{"tag":"arch-i3","desc":"i3 Arch"},{"tag":"alpine-openbox","desc":"Openbox Alpine"},{"tag":"ubuntu-openbox","desc":"Openbox Ubuntu"},{"tag":"fedora-openbox","desc":"Openbox Fedora"},{"tag":"arch-openbox","desc":"Openbox Arch"},{"tag":"alpine-icewm","desc":"IceWM Alpine"},{"tag":"ubuntu-icewm","desc":"IceWM Ubuntu"},{"tag":"fedora-icewm","desc":"IceWM Fedora"},{"tag":"arch-icewm","desc":"IceWM Arch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_usage_include_ports":true,"param_ports":[{"external_port":"3389","internal_port":"3389","port_desc":"RDP access port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/run/docker.sock","vol_host_path":"/var/run/docker.sock","desc":"Docker Socket on the system, if you want to use Docker in the container"},{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"abc users home directory"}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"We set this to 1 gig to prevent modern web browsers from crashing"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function as syscalls are unkown to Docker"}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for GL support (Linux hosts only)"}],"app_setup_block_enabled":true,"app_setup_block":"**The Default USERNAME and PASSWORD is: abc/abc**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\nYou will need a Remote Desktop client to access this container [Wikipedia List](https://en.wikipedia.org/wiki/Comparison_of_remote_desktop_software), by default it listens on 3389, but you can change that port to whatever you wish on the host side IE `3390:3389`.\nThe first thing you should do when you login to the container is to change the abc users password by issuing the `passwd` command.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it rdesktop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt.\n","changelogs":[{"date":"27.10.22:","desc":"Rebase all Ubuntu images to Jammy 22.04."},{"date":"26.10.22:","desc":"Rebase Alpine xfce to 3.16, migrate to s6v3."},{"date":"05.03.22:","desc":"Organize tags differently to run Ubuntu at latest LTS, make Alpine latest, add docs about GPU accel."},{"date":"05.05.21:","desc":"Reduce default packages to their flavor specific basics."},{"date":"05.04.21:","desc":"Add Alpine flavor."},{"date":"06.04.20:","desc":"Start PulseAudio in images to support audio"},{"date":"28.02.20:","desc":"Initial Releases"}]}},"setup":"**The Default USERNAME and PASSWORD is: abc/abc**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\nYou will need a Remote Desktop client to access this container [Wikipedia List](https://en.wikipedia.org/wiki/Comparison_of_remote_desktop_software), by default it listens on 3389, but you can change that port to whatever you wish on the host side IE `3390:3389`.\nThe first thing you should do when you login to the container is to change the abc users password by issuing the `passwd` command.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it rdesktop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt.\n","_id":"content:apps:rdesktop.json","_type":"json","title":"Rdesktop","_source":"content","_file":"apps/rdesktop.json","_extension":"json"},{"_path":"/apps/readarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"readarr","name":"readarr","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/readarr.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/readarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-readarr"}],"containers":[{"name":"readarr","image":"linuxserver/readarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"404":"Not Found"}},"_id":"content:apps:readarr.json","_type":"json","title":"Readarr","_source":"content","_file":"apps/readarr.json","_extension":"json"},{"_path":"/apps/remmina","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"remmina","name":"remmina","description":"[Remmina]({{ project_url }}) is a remote desktop client written in GTK, aiming to be useful for system administrators and travellers, who need to work with lots of remote computers in front of either large or tiny screens. Remmina supports multiple network protocols, in an integrated and consistent user interface. Currently RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC are supported.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/remmina-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/remmina"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-remmina"}],"containers":[{"name":"remmina","image":"linuxserver/remmina","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings.","key":"config"}],"ports":[{"container":"3000","description":"Remmina desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"remmina","project_url":"https://remmina.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/remmina-icon.png","project_blurb":"[Remmina]({{ project_url }}) is a remote desktop client written in GTK, aiming to be useful for system administrators and travellers, who need to work with lots of remote computers in front of either large or tiny screens. Remmina supports multiple network protocols, in an integrated and consistent user interface. Currently RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC are supported.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Remmina desktop gui."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","changelogs":[{"date":"16.12.22:","desc":"Rebase to Jammy. Drop nx, xdmcp plugins due to lack of packages. Add Kiosk, Secret, x2go plugins."},{"date":"19.06.22:","desc":"Rebase to Focal. Drop Telepathy plugin due to lack of packages."},{"date":"27.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n","_id":"content:apps:remmina.json","_type":"json","title":"Remmina","_source":"content","_file":"apps/remmina.json","_extension":"json"},{"_path":"/apps/requestrr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"requestrr","name":"requestrr","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat.","icon":"https://github.com/darkalfx/requestrr/raw/master/Logos/requestrr_discord_Icon_512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/requestrr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-requestrr"}],"containers":[{"name":"requestrr","image":"linuxserver/requestrr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"4545","description":"web gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"requestrr","project_url":"https://github.com/darkalfx/requestrr","project_logo":"https://github.com/darkalfx/requestrr/raw/master/Logos/requestrr_discord_Icon_512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_deprecation_status":true,"project_deprecation_message":"The upstream dev has ended development.\n","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable Requestrr releases."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"4545","internal_port":"4545","port_desc":"web gui"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"\nAccess the webui at `<your-ip>:4545`, for more information check out [Requestrr]({{ project_url }}).\n","changelogs":[{"date":"20.12.21:","desc":"Deprecate."},{"date":"27.09.21:","desc":"Allow app to write to tmp folder."},{"date":"21.02.21:","desc":"Initial Release."}]}},"setup":"\nAccess the webui at `<your-ip>:4545`, for more information check out [Requestrr]({{ project_url }}).\n","_id":"content:apps:requestrr.json","_type":"json","title":"Requestrr","_source":"content","_file":"apps/requestrr.json","_extension":"json"},{"_path":"/apps/resilio-sync","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"resilio-sync","name":"resilio-sync","description":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly BitTorrent Sync) uses the BitTorrent protocol to sync files and folders between all of your devices. There are both free and paid versions, this container supports both. There is an official sync image but we created this one as it supports user mapping to simplify permissions for volumes.","icon":"https://www.resilio.com/img/individual/freeproduct.jpg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/resilio-sync"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-resilio-sync"}],"containers":[{"name":"resilio-sync","image":"linuxserver/resilio-sync","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where resilio-sync should store its config file.","key":"config"},{"container":"/downloads","description":"Folder for downloads/cache."},{"container":"/sync","description":"Sync folders root."}],"ports":[{"container":"8888","description":"WebUI","protocol":"tcp","web":false},{"container":"55555","description":"Sync Port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"resilio-sync","project_url":"https://www.resilio.com/individuals/","project_logo":"https://www.resilio.com/img/individual/freeproduct.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly BitTorrent Sync) uses the BitTorrent protocol to sync files and folders between all of your devices. There are both free and paid versions, this container supports both. There is an official sync image but we created this one as it supports user mapping to simplify permissions for volumes.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"opt_param_usage_include_env":false,"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where resilio-sync should store its config file."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Folder for downloads/cache."},{"vol_path":"/sync","vol_host_path":"/path/to/data","desc":"Sync folders root."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8888","internal_port":"8888","port_desc":"WebUI"},{"external_port":"55555","internal_port":"55555","port_desc":"Sync Port."}],"param_device_map":false,"cap_add_param":false,"app_setup_block_enabled":true,"app_setup_block":"* Webui is at `<your-ip>:8888`, for account creation and configuration.\n* More info on setup at [Resilio Sync]({{ project_url }})\n","changelogs":[{"date":"14.12.22:","desc":"Rebase to Jammy, migrate to s6v3."},{"date":"03.10.21:","desc":"Use upstream apt repo to install. Rebase to focal."},{"date":"20.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"11.02.19:","desc":"Rebase to bionic, add pipeline logic and multi arch."},{"date":"05.02.18:","desc":"Add downloads volume mount."},{"date":"28.01.18:","desc":"Add /sync to dir whitelist."},{"date":"26.01.18:","desc":"Use variable for arch to bring in line with armhf arch repo."},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"02.06.17:","desc":"Rebase to ubuntu xenial, alpine linux no longer works with resilio."},{"date":"22.05.17:","desc":"Add variable for user defined umask."},{"date":"14.05.17:","desc":"Use fixed version instead of latest, while 2.5.0 is broken on non glibc (alpine)."},{"date":"08.02.17:","desc":"Rebase to alpine 3.5."},{"date":"02.11.16:","desc":"Initial Release."}]}},"setup":"* Webui is at `<your-ip>:8888`, for account creation and configuration.\n* More info on setup at [Resilio Sync]({{ project_url }})\n","_id":"content:apps:resilio-sync.json","_type":"json","title":"Resilio Sync","_source":"content","_file":"apps/resilio-sync.json","_extension":"json"},{"_path":"/apps/rsnapshot","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"rsnapshot","name":"rsnapshot","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required.\"\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rsnapshot.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/rsnapshot"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-rsnapshot"}],"containers":[{"name":"rsnapshot","image":"linuxserver/rsnapshot","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"America/New_York","description":"Specify a timezone to use EG America/New_York"}],"volumes":[{"container":"/.snapshots","description":"Storage location for all snapshots."},{"container":"/data","description":"Storage location for data to be backed up."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"rsnapshot","project_url":"http://www.rsnapshot.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/rsnapshot.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required.\"\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata","desc":"Contains all relevant configuration files."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"America/New_York","desc":"Specify a timezone to use EG America/New_York"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/.snapshots","vol_host_path":"/path/to/snapshots","desc":"Storage location for all snapshots."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Storage location for data to be backed up."}],"app_setup_block_enabled":true,"app_setup_block":"### IMPORTANT NOTES:\nAfter starting the container you will need to edit `/config/rsnapshot.conf`.\n\n#### SNAPSHOT ROOT DIRECTORY\n\nrsnapshot is configured to backup data to the `/.snapshots` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n#### BACKUP LEVELS / INTERVALS\n\nrsnapshot retains backups based on configurations in this section.\nPlease see the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration) for more information.\n\n#### BACKUP POINTS\n\nrsnapshot is configured to backup data from the `/data` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n### cron\n\nYou will then need to edit `/config/crontabs/root` to set cron jobs to run rsnapshot.\nBy default no cron jobs are enabled. Examples are includes based on information from the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration).\n","changelogs":[{"date":"15.12.22:","desc":"Rebase to alpine 3.17."},{"date":"11.10.22:","desc":"Rebase to alpine 3.16, migrate to s6v3."},{"date":"10.10.21:","desc":"Rebase to alpine 3.14."},{"date":"20.08.20:","desc":"Initial Release."}]}},"setup":"### IMPORTANT NOTES:\nAfter starting the container you will need to edit `/config/rsnapshot.conf`.\n\n#### SNAPSHOT ROOT DIRECTORY\n\nrsnapshot is configured to backup data to the `/.snapshots` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n#### BACKUP LEVELS / INTERVALS\n\nrsnapshot retains backups based on configurations in this section.\nPlease see the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration) for more information.\n\n#### BACKUP POINTS\n\nrsnapshot is configured to backup data from the `/data` volume by default.\nThis can be changed in the config, but be sure you mount a volume to the container to match.\n\n### cron\n\nYou will then need to edit `/config/crontabs/root` to set cron jobs to run rsnapshot.\nBy default no cron jobs are enabled. Examples are includes based on information from the [rsnapshot readme](https://github.com/rsnapshot/rsnapshot/blob/master/README.md#configuration).\n","_id":"content:apps:rsnapshot.json","_type":"json","title":"Rsnapshot","_source":"content","_file":"apps/rsnapshot.json","_extension":"json"},{"_path":"/apps/sabnzbd","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"sabnzbd","name":"sabnzbd","description":"[{{ project_name|capitalize }}]({{ project_url }}) makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sabnzbd-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sabnzbd"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sabnzbd"}],"containers":[{"name":"sabnzbd","image":"linuxserver/sabnzbd","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/downloads","description":"Local path for finished downloads."},{"container":"/incomplete-downloads","description":"Local path for incomplete-downloads."},{"container":"/config","description":"Local path for sabnzbd config files.","key":"config"}],"ports":[{"container":"8080","description":"HTTP port for the WebUI.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sabnzbd","project_url":"http://sabnzbd.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sabnzbd-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable SABnzbd releases"},{"tag":"unstable","desc":"Pre-releases from the develop branch"},{"tag":"nightly","desc":"Latest commits from the develop branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Local path for sabnzbd config files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"8080","port_desc":"HTTP port for the WebUI."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Local path for finished downloads."},{"vol_path":"/incomplete-downloads","vol_host_path":"/path/to/incomplete/downloads","desc":"Local path for incomplete-downloads."}],"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Initial setup is done from the http port.\n\nSee the [SABnzbd wiki](https://sabnzbd.org/wiki/) for more information.\n\n### nzb-notify\n\nnzb-notify is included with this image as a convenience script. To use it set the Scripts folder in the Folder settings to /app/nzbnotify and then configure it under Notifications. See [nzb-notify](https://github.com/caronc/nzb-notify/) for more information.\n\n### Download folders\n\nIn Sabnzbd gui settings, under `Folders`, make sure to set the `Completed Download Folder` as `/downloads` and the `Temporary Download Folder` as `/incomplete-downloads`\n\nWe have set `/incomplete-downloads` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves. \n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","changelogs":[{"date":"03.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"31.07.22:","desc":"Add nightly tag."},{"date":"10.03.22:","desc":"Add nzb-notify."},{"date":"22.02.22:","desc":"Rebase master branch to Alpine, build unrar from source, deprecate Alpine branch."},{"date":"25.01.22:","desc":"Rebase Unstable branch to Alpine."},{"date":"13.01.22:","desc":"Add alpine branch"},{"date":"08.08.21:","desc":"Bump to focal, dont enforce binding to ipv4 port 8080"},{"date":"24.07.21:","desc":"Add python3-setuptools."},{"date":"14.05.21:","desc":"Use linuxserver.io wheel index for pip packages."},{"date":"12.02.21:","desc":"Clean up rust/cargo and pip cache."},{"date":"17.08.20:","desc":"Run from source with python3 instead of ppa, remove python2 completely, symlink `python` to `python3`."},{"date":"02.01.20:","desc":"Add python3 on top of python2 to image during transition."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"25.02.19:","desc":"Rebase to Bionic, add python deps for scripts."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"13.12.17:","desc":"Fix continuation lines."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"10.04.17:","desc":"Bump to 2.0 Release."},{"date":"25.02.17:","desc":"Switch to nobetas repo for master/latest branch and add unstable branch."},{"date":"08.02.17:","desc":"Add pythonioenconding=utf8 as env."},{"date":"15.09.16:","desc":"Compile par2 multicore as per latest info sabnzbd git [readme](https://github.com/sabnzbd/sabnzbd#resolving-dependencies)."},{"date":"11.09.16:","desc":"Bump to release of 1.10."},{"date":"09.09.16:","desc":"Rebase back to xenial, issues with alpine version of python and 1.10 branch of sab."},{"date":"28.08.16:","desc":"Rebase to alpine, using git version of sab."},{"date":"17.03.16:","desc":"Bump to install 1.0 final at startup."},{"date":"14.03.16:","desc":"Refresh image to pick up latest RC."},{"date":"23.01.15:","desc":"Refresh image."},{"date":"14.12.15:","desc":"Refresh image to pick up latest beta."},{"date":"21.08.15:","desc":"Initial Release."}]}},"setup":"Initial setup is done from the http port.\n\nSee the [SABnzbd wiki](https://sabnzbd.org/wiki/) for more information.\n\n### nzb-notify\n\nnzb-notify is included with this image as a convenience script. To use it set the Scripts folder in the Folder settings to /app/nzbnotify and then configure it under Notifications. See [nzb-notify](https://github.com/caronc/nzb-notify/) for more information.\n\n### Download folders\n\nIn Sabnzbd gui settings, under `Folders`, make sure to set the `Completed Download Folder` as `/downloads` and the `Temporary Download Folder` as `/incomplete-downloads`\n\nWe have set `/incomplete-downloads` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves. \n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/docker-guide#consistent-and-well-planned-paths) on how to get started with this.\n","_id":"content:apps:sabnzbd.json","_type":"json","title":"Sabnzbd","_source":"content","_file":"apps/sabnzbd.json","_extension":"json"},{"_path":"/apps/sickchill","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"sickchill","name":"sickchill","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an Automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. \n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sickchill-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sickchill"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sickchill"}],"containers":[{"name":"sickchill","image":"linuxserver/sickchill","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"specify your TimeZone e.g. Europe/London"}],"volumes":[{"container":"/config","description":"this will store config on the docker host","key":"config"},{"container":"/downloads","description":"this will store any downloaded data on the docker host"},{"container":"/tv","description":"this will allow sickchill to view what you already have"}],"ports":[{"container":"8081","description":"will map the container's port 8081 to port 8081 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sickchill","project_url":"https://github.com/SickChill/SickChill","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sickchill-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an Automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. \n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store config on the docker host"},{"vol_path":"/downloads","vol_host_path":"/path/to/data","desc":"this will store any downloaded data on the docker host"},{"vol_path":"/tv","vol_host_path":"/path/to/data","desc":"this will allow sickchill to view what you already have"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"specify your TimeZone e.g. Europe/London"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"will map the container's port 8081 to port 8081 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"Web interface is at `<your ip>:8081` , set paths for downloads, tv-shows to match docker mappings via the webui.\n","changelogs":[{"date":"17.02.22:","desc":"Rebase to alpine 3.17."},{"date":"17.02.22:","desc":"Rebase to alpine 3.15."},{"date":"20.11.21:","desc":"Modify binary usage from SickChill.py to SickChill."},{"date":"14.05.21:","desc":"Add linuxserver wheel index."},{"date":"12.02.21:","desc":"Rebasing to alpine 3.13. Add python certifi."},{"date":"17.09.20:","desc":"Update dependencies."},{"date":"06.09.20:","desc":"Switch to python3, install pip package."},{"date":"22.04.20:","desc":"Switch to git clone and using git tags for versioning."},{"date":"09.01.20:","desc":"Remove creating data volumes, fix build args for armhf and aarch64."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"17.04.19:","desc":"Adding Nodejs dependancy."},{"date":"31.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.10.18:","desc":"Initial Release."}]}},"setup":"Web interface is at `<your ip>:8081` , set paths for downloads, tv-shows to match docker mappings via the webui.\n","_id":"content:apps:sickchill.json","_type":"json","title":"Sickchill","_source":"content","_file":"apps/sickchill.json","_extension":"json"},{"_path":"/apps/sickgear","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"sickgear","name":"sickgear","description":"[SickGear]({{ project_url }}) provides management of TV shows and/or Anime, it detects new episodes, links downloader apps, and more..\n\nFor more information on SickGear visit their website and check it out: https://github.com/SickGear/SickGear\n","icon":"https://raw.githubusercontent.com/wiki/SickGear/SickGear.Wiki/images/SickGearLogo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sickgear"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sickgear"}],"containers":[{"name":"sickgear","image":"linuxserver/sickgear","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"this will store any uploaded data on the docker host","key":"config"},{"container":"/tv","description":"where you store your tv shows"},{"container":"/downloads","description":"your downloads folder for post processing (must not be download in progress)"}],"ports":[{"container":"8081","description":"will map the container's port 8081 to port 8081 on the host","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sickgear","project_url":"https://github.com/sickgear/sickgear","project_logo":"https://raw.githubusercontent.com/wiki/SickGear/SickGear.Wiki/images/SickGearLogo.png","project_blurb":"[SickGear]({{ project_url }}) provides management of TV shows and/or Anime, it detects new episodes, links downloader apps, and more..\n\nFor more information on SickGear visit their website and check it out: https://github.com/SickGear/SickGear\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"this will store any uploaded data on the docker host"},{"vol_path":"/tv","vol_host_path":"/path/to/data","desc":"where you store your tv shows"},{"vol_path":"/downloads","vol_host_path":"/path/to/data","desc":"your downloads folder for post processing (must not be download in progress)"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8081","internal_port":"8081","port_desc":"will map the container's port 8081 to port 8081 on the host"}],"app_setup_block_enabled":true,"app_setup_block":"## Setting up the application\n\nAccess the webui at `<your-ip>:8081`, for more information check out [SickGear]({{ project_url }}).\n\n## Migration\n\nNon linuxserver.io containers are known to have the following configuration differences and may need SickGear or docker changes to migrate an existing setup\n\n* The post processing directory which is volume mounted as `downloads` within this container may be `incoming` in other versions.\n\n* The permissions environmental variables which are defined as `PGID` and `PUID` within this container may have been `APP_UID` and `APP_UID` in other versions.\n\n* The configuration file directory which is volume mounted as `config` within this container may be set as the environmetal variable `APP_DATA` in other versions.\n\n* The cache directory which is set in `config.ini` may be configured as a fixed path `cache_dir = /data/cache`.\nSymptoms of this issue include port usage problems and a failure to start the web server log entries.\nWhilst the container is stopped alter this directive to `cache_dir = cache` which will allow SickGear to look for the folder relative to the volume mounted `/config` directory.\n\nIt is recommended that a clean install be completed, rather than a migration, however if migration is necessary:\n\n* start a new instance of this image\n\n* compare and align SickGear version numbers bewteen old and new. Ideally they should match but at a minumum the old vesion should be a lower version number to allow SickGear itself to try and migrate\n\n* stop both containers\n\n* notice the configuration difference and migrate copies of the old settings into the new app\n\n* start the new container and test\n","changelogs":[{"date":"18.11.22:","desc":"Update service file from legacy SickBeard.py to sickgear.py."},{"date":"10.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15. Build unrar from source."},{"date":"31.01.21:","desc":"Add unrar."},{"date":"29.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"03.06.20:","desc":"Rebasing to alpine 3.12, switch to python3."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"07.11.18:","desc":"Pipeline prep"},{"date":"07.07.18:","desc":"Initial draft release"}]}},"setup":"## Setting up the application\n\nAccess the webui at `<your-ip>:8081`, for more information check out [SickGear]({{ project_url }}).\n\n## Migration\n\nNon linuxserver.io containers are known to have the following configuration differences and may need SickGear or docker changes to migrate an existing setup\n\n* The post processing directory which is volume mounted as `downloads` within this container may be `incoming` in other versions.\n\n* The permissions environmental variables which are defined as `PGID` and `PUID` within this container may have been `APP_UID` and `APP_UID` in other versions.\n\n* The configuration file directory which is volume mounted as `config` within this container may be set as the environmetal variable `APP_DATA` in other versions.\n\n* The cache directory which is set in `config.ini` may be configured as a fixed path `cache_dir = /data/cache`.\nSymptoms of this issue include port usage problems and a failure to start the web server log entries.\nWhilst the container is stopped alter this directive to `cache_dir = cache` which will allow SickGear to look for the folder relative to the volume mounted `/config` directory.\n\nIt is recommended that a clean install be completed, rather than a migration, however if migration is necessary:\n\n* start a new instance of this image\n\n* compare and align SickGear version numbers bewteen old and new. Ideally they should match but at a minumum the old vesion should be a lower version number to allow SickGear itself to try and migrate\n\n* stop both containers\n\n* notice the configuration difference and migrate copies of the old settings into the new app\n\n* start the new container and test\n","_id":"content:apps:sickgear.json","_type":"json","title":"Sickgear","_source":"content","_file":"apps/sickgear.json","_extension":"json"},{"_path":"/apps/smokeping","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"smokeping","name":"smokeping","description":"[{{ project_name|capitalize }}]({{ project_url }}) keeps track of your network latency. For a full example of what this application is capable of visit [UCDavis](http://smokeping.ucdavis.edu/cgi-bin/smokeping.fcgi).","icon":"https://camo.githubusercontent.com/e0694ef783e3fd1d74e6776b28822ced01c7cc17/687474703a2f2f6f73732e6f6574696b65722e63682f736d6f6b6570696e672f696e632f736d6f6b6570696e672d6c6f676f2e706e67","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/smokeping"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-smokeping"}],"containers":[{"name":"smokeping","image":"linuxserver/smokeping","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Configure the `Targets` file here","key":"config"},{"container":"/data","description":"Storage location for db and application data (graphs etc)"}],"ports":[{"container":"80","description":"Allows HTTP access to the internal webserver.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"smokeping","project_url":"https://oss.oetiker.ch/smokeping/","project_logo":"https://camo.githubusercontent.com/e0694ef783e3fd1d74e6776b28822ced01c7cc17/687474703a2f2f6f73732e6f6574696b65722e63682f736d6f6b6570696e672f696e632f736d6f6b6570696e672d6c6f676f2e706e67","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) keeps track of your network latency. For a full example of what this application is capable of visit [UCDavis](http://smokeping.ucdavis.edu/cgi-bin/smokeping.fcgi).","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/smokeping/config","desc":"Configure the `Targets` file here"},{"vol_path":"/data","vol_host_path":"/path/to/{{ project_name }}/data","desc":"Storage location for db and application data (graphs etc)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Allows HTTP access to the internal webserver."}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"app_setup_block_enabled":true,"app_setup_block":"* Once running the URL will be `http://<host-ip>/smokeping/smokeping.cgi`. For example a full URL might look like `https://smokeping.yourdomain.com/smokeping/smokeping.cgi`.\n* Basics are, edit the `Targets` file to ping the hosts you're interested in to match the format found there.\n* Wait 10 minutes.\n","changelogs":[{"date":"22.01.23:","desc":"Revert to using Apache due to latency issues with nginx and fcgiwrap."},{"date":"12.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3, switch to nginx and fcgiwrap."},{"date":"29.03.21:","desc":"Dockerfile: Install curl before we call it"},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"14.11.18:","desc":"Allow access without /smokeping in URL."},{"date":"28.04.18:","desc":"Rebase to alpine 3.8."},{"date":"09.04.18:","desc":"Add bc package."},{"date":"08.04.18:","desc":"Add tccping script and tcptraceroute package (thanks rcarmo)."},{"date":"13.12.17:","desc":"Expose httpd_conf to /config."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"24.07.17:","desc":"Add :unraid tag for hosts without ipv6."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"07.05.17:","desc":"Expose smokeping.conf in /config/site-confs to allow user customisations"},{"date":"12.04.17:","desc":"Fix cropper.js path, thanks nibbledeez."},{"date":"09.02.17:","desc":"Rebase to alpine 3.5."},{"date":"17.10.16:","desc":"Add ttf-dejavu package as per [LT forum](http://lime-technology.com/forum/index.php?topic=43602.msg507875#msg507875)."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.09.16:","desc":"Add curl package."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"25.07.16:","desc":"Rebase to alpine linux."},{"date":"23.07.16:","desc":"Fix apt script confusion."},{"date":"29.06.15:","desc":"This is the first release, it is mostly stable, but may contain minor defects. (thus a beta tag)"}]}},"setup":"* Once running the URL will be `http://<host-ip>/smokeping/smokeping.cgi`. For example a full URL might look like `https://smokeping.yourdomain.com/smokeping/smokeping.cgi`.\n* Basics are, edit the `Targets` file to ping the hosts you're interested in to match the format found there.\n* Wait 10 minutes.\n","_id":"content:apps:smokeping.json","_type":"json","title":"Smokeping","_source":"content","_file":"apps/smokeping.json","_extension":"json"},{"_path":"/apps/snapdrop","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"snapdrop","name":"snapdrop","description":"[{{ project_name|capitalize }}]({{ project_url }}) A local file sharing in your browser. Inspired by Apple's Airdrop.","icon":"https://raw.githubusercontent.com/RobinLinus/snapdrop/master/client/images/logo_transparent_512x512.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/snapdrop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-snapdrop"}],"containers":[{"name":"snapdrop","image":"linuxserver/snapdrop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Persistent configs and logs.","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"snapdrop","project_url":"https://github.com/RobinLinus/snapdrop","project_logo":"https://raw.githubusercontent.com/RobinLinus/snapdrop/master/client/images/logo_transparent_512x512.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A local file sharing in your browser. Inspired by Apple's Airdrop.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to config>","desc":"Persistent configs and logs."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"Webui is accessible at http://SERVERIP:PORT\n\nIf you intend to expose Snapdrop to the internet, edit /config/nginx/site-confs/default.conf and uncomment the real_ip settings\n","changelogs":[{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"09.08.21:","desc":"Rebase to Alpine 3.14. Add real_ip block to nginx default site config."},{"date":"15.09.20:","desc":"Initial Release."}]}},"setup":"Webui is accessible at http://SERVERIP:PORT\n\nIf you intend to expose Snapdrop to the internet, edit /config/nginx/site-confs/default.conf and uncomment the real_ip settings\n","_id":"content:apps:snapdrop.json","_type":"json","title":"Snapdrop","_source":"content","_file":"apps/snapdrop.json","_extension":"json"},{"_path":"/apps/snipe-it","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"snipe-it","name":"snipe-it","description":"[{{ project_name|capitalize }}]({{ project_url }}) makes asset management easy. It was built by people solving real-world IT and asset management problems, and a solid UX has always been a top priority. Straightforward design and bulk actions mean getting things done faster.","icon":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/snipe-it-logo500x500.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/snipe-it"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-snipe-it"}],"containers":[{"name":"snipe-it","image":"linuxserver/snipe-it","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"APP_URL","default":"http://localhost:8080","description":"Hostname or IP and port if applicable, be sure to define https/http"},{"id":"MYSQL_PORT_3306_TCP_ADDR","default":"","description":"Mysql hostname or IP to use"},{"id":"MYSQL_PORT_3306_TCP_PORT","default":"","description":"Mysql port to use"},{"id":"MYSQL_DATABASE","default":"","description":"Mysql database to use"},{"id":"MYSQL_USER","default":"","description":"Mysql user to use"},{"id":"MYSQL_PASSWORD","default":"","description":"Mysql password to use"},{"id":"TZ","default":"US/Pacific","description":"Specify a timezone to use EG Europe/London, this is required to run snipe-it"}],"volumes":[{"container":"/config","description":"Contains your config files and data storage for Snipe-IT","key":"config"}],"ports":[{"container":"80","description":"Snipe-IT Web UI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"snipe-it","project_url":"https://github.com/snipe/snipe-it","project_logo":"https://s3-us-west-2.amazonaws.com/linuxserver-docs/images/snipe-it-logo500x500.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) makes asset management easy. It was built by people solving real-world IT and asset management problems, and a solid UX has always been a top priority. Straightforward design and bulk actions mean getting things done faster.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Contains your config files and data storage for Snipe-IT"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8080","internal_port":"80","port_desc":"Snipe-IT Web UI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"APP_URL","env_value":"http://localhost:8080","desc":"Hostname or IP and port if applicable, be sure to define https/http"},{"env_var":"MYSQL_PORT_3306_TCP_ADDR","env_value":"","desc":"Mysql hostname or IP to use"},{"env_var":"MYSQL_PORT_3306_TCP_PORT","env_value":"","desc":"Mysql port to use"},{"env_var":"MYSQL_DATABASE","env_value":"","desc":"Mysql database to use"},{"env_var":"MYSQL_USER","env_value":"","desc":"Mysql user to use"},{"env_var":"MYSQL_PASSWORD","env_value":"","desc":"Mysql password to use"},{"env_var":"TZ","env_value":"US/Pacific","desc":"Specify a timezone to use EG Europe/London, this is required to run snipe-it"}],"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8080`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n**This container requires a MySQL or MariaDB server to connect to, we reccomend [ours](https://github.com/linuxserver/docker-mariadb)**\n\nThis container also generates an SSL certificate and stores it in\n```\n/config/keys/cert.crt\n/config/keys/cert.key\n```\nTo use your own certificate swap these files with yours. To use SSL forward your port to 443 inside the container IE:\n\n```\n-p 443:443\n```\n\nThe application accepts a series of environment variables to further customize itself on boot:\n\n| Parameter | Function |\n| :---: | --- |\n| `-e APP_ENV=` | Default is production but can use testing or develop|\n| `-e APP_DEBUG=` | Set to true to see debugging output in the web UI|\n| `-e APP_LOCALE=` | Default is en set to the language preferred full list [here](https://snipe-it.readme.io/docs/configuration#section-setting-a-language)|\n| `-e MAIL_PORT_587_TCP_ADDR=` | SMTP mailserver ip or hostname|\n| `-e MAIL_PORT_587_TCP_PORT=` | SMTP mailserver port|\n| `-e MAIL_ENV_FROM_ADDR=` | The email address mail should be replied to and listed when sent|\n| `-e MAIL_ENV_FROM_NAME=` | The name listed on email sent from the default account on the system|\n| `-e MAIL_ENV_ENCRYPTION=` | Mail encryption to use IE tls |\n| `-e MAIL_ENV_USERNAME=` | SMTP server login username|\n| `-e MAIL_ENV_PASSWORD=` | SMTP server login password|\n\n### PHP customization\n\nThis image uses our NGINX base image all configuration files for PHP and NGINX are located in `/config/php`. To overide any defaults please modify `/config/php/php-local.ini` IE for upload size: \n\n```\nupload_max_filesize = 16\npost_max_size = 16M\n```\n","changelogs":[{"date":"28.12.22:","desc":"Rebase to Alpine 3.17, migrate to s6v3."},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"14.05.22:","desc":"Add php7-sodium for v6."},{"date":"12.04.22:","desc":"Don't build development elements."},{"date":"02.03.22:","desc":"Rework init logic, do not show default compose."},{"date":"29.06.21:","desc":"Rebasing to alpine 3.14."},{"date":"30.04.21:","desc":"Rebasing to alpine 3.13, add artisan migrate on spinup."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"10.04.19:","desc":"Add php deps for V4.7.0, ensure framework directories are available at build time."},{"date":"10.04.19:","desc":"Fix permissions for new bootstrap cache directory."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"31.10.18:","desc":"Rebasing to alpine 3.8"},{"date":"05.08.18:","desc":"Migration to live build server."},{"date":"13.06.18:","desc":"Initial Release."}]}},"setup":"Access the webui at `<your-ip>:8080`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\n**This container requires a MySQL or MariaDB server to connect to, we reccomend [ours](https://github.com/linuxserver/docker-mariadb)**\n\nThis container also generates an SSL certificate and stores it in\n```\n/config/keys/cert.crt\n/config/keys/cert.key\n```\nTo use your own certificate swap these files with yours. To use SSL forward your port to 443 inside the container IE:\n\n```\n-p 443:443\n```\n\nThe application accepts a series of environment variables to further customize itself on boot:\n\n| Parameter | Function |\n| :---: | --- |\n| `-e APP_ENV=` | Default is production but can use testing or develop|\n| `-e APP_DEBUG=` | Set to true to see debugging output in the web UI|\n| `-e APP_LOCALE=` | Default is en set to the language preferred full list [here](https://snipe-it.readme.io/docs/configuration#section-setting-a-language)|\n| `-e MAIL_PORT_587_TCP_ADDR=` | SMTP mailserver ip or hostname|\n| `-e MAIL_PORT_587_TCP_PORT=` | SMTP mailserver port|\n| `-e MAIL_ENV_FROM_ADDR=` | The email address mail should be replied to and listed when sent|\n| `-e MAIL_ENV_FROM_NAME=` | The name listed on email sent from the default account on the system|\n| `-e MAIL_ENV_ENCRYPTION=` | Mail encryption to use IE tls |\n| `-e MAIL_ENV_USERNAME=` | SMTP server login username|\n| `-e MAIL_ENV_PASSWORD=` | SMTP server login password|\n\n### PHP customization\n\nThis image uses our NGINX base image all configuration files for PHP and NGINX are located in `/config/php`. To overide any defaults please modify `/config/php/php-local.ini` IE for upload size: \n\n```\nupload_max_filesize = 16\npost_max_size = 16M\n```\n","_id":"content:apps:snipe-it.json","_type":"json","title":"Snipe It","_source":"content","_file":"apps/snipe-it.json","_extension":"json"},{"_path":"/apps/sonarr","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"sonarr","name":"sonarr","description":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly NZBdrone) is a PVR for usenet and bittorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sonarr-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sonarr"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sonarr"}],"containers":[{"name":"sonarr","image":"linuxserver/sonarr","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London, this is required for Sonarr"}],"volumes":[{"container":"/tv","description":"Location of TV library on disk (See note in Application setup)"},{"container":"/downloads","description":"Location of download managers output directory (See note in Application setup)"},{"container":"/config","description":"Database and sonarr configs","key":"config"}],"ports":[{"container":"8989","description":"The port for the Sonarr webinterface","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sonarr","project_url":"https://sonarr.tv/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sonarr-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (formerly NZBdrone) is a PVR for usenet and bittorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases from Sonarr (currently v3)"},{"tag":"develop","desc":"Development releases from Sonarr (currently v4)"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Database and sonarr configs"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/tv","vol_host_path":"/path/to/tvseries","desc":"Location of TV library on disk (See note in Application setup)"},{"vol_path":"/downloads","vol_host_path":"/path/to/downloadclient-downloads","desc":"Location of download managers output directory (See note in Application setup)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8989","internal_port":"8989","port_desc":"The port for the Sonarr webinterface"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London, this is required for Sonarr"}],"opt_param_usage_include_env":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8989`, for more information check out [Sonarr](https://sonarr.tv/).\n\n### Media folders\n\nWe have set `/tv` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/Docker_Guide#Consistent_and_well_planned_paths) on how to get started with this.\n","changelogs":[{"date":"24.11.22:","desc":"Bump develop branch to v4, rebase to Alpine 3.16."},{"date":"03.08.22:","desc":"Deprecate armhf."},{"date":"02.08.22:","desc":"Add armhf deprecation warning."},{"date":"28.04.22:","desc":"Rebase master branch to mono 6.12 base (focal)."},{"date":"20.02.22:","desc":"Rebase develop branch to Alpine, deprecate develop-alpine branch."},{"date":"28.12.21:","desc":"Add develop-alpine branch."},{"date":"11.05.21:","desc":"Make the paths clearer to the user."},{"date":"10.03.21:","desc":"Upgrade to Sonarr v3. Existing users are highly recommended to make a backup prior to update."},{"date":"18.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"05.04.20:","desc":"Move app to /app."},{"date":"01.08.19:","desc":"Rebase to Linuxserver LTS mono version."},{"date":"13.06.19:","desc":"Add env variable for setting umask."},{"date":"10.05.19:","desc":"Rebase to Bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.02.19:","desc":"Multi arch images and pipeline build logic"},{"date":"15.12.17:","desc":"Fix continuation lines."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"17.04.17:","desc":"Switch to using inhouse mono baseimage, adds python also."},{"date":"14.04.17:","desc":"Change to mount /etc/localtime in README, thanks cbgj."},{"date":"13.04.17:","desc":"Switch to official mono repository."},{"date":"30.09.16:","desc":"Fix umask"},{"date":"23.09.16:","desc":"Add cd to /opt fixes redirects with althub (issue #25), make XDG config environment variable"},{"date":"15.09.16:","desc":"Add libcurl3 package."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README."},{"date":"20.07.16:","desc":"Rebase to xenial."},{"date":"31.08.15:","desc":"Cleanup, changed sources to fetch binarys from. also a new baseimage."}]}},"setup":"Access the webui at `<your-ip>:8989`, for more information check out [Sonarr](https://sonarr.tv/).\n\n### Media folders\n\nWe have set `/tv` and `/downloads` as ***optional paths***, this is because it is the easiest way to get started. While easy to use, it has some drawbacks. Mainly losing the ability to hardlink (TL;DR a way for a file to exist in multiple places on the same file system while only consuming one file worth of space), or atomic move (TL;DR instant file moves, rather than copy+delete) files while processing content.\n\nUse the optional paths if you dont understand, or dont want hardlinks/atomic moves.\n\nThe folks over at servarr.com wrote a good [write-up](https://wiki.servarr.com/Docker_Guide#Consistent_and_well_planned_paths) on how to get started with this.\n","_id":"content:apps:sonarr.json","_type":"json","title":"Sonarr","_source":"content","_file":"apps/sonarr.json","_extension":"json"},{"_path":"/apps/sqlitebrowser","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"sqlitebrowser","name":"sqlitebrowser","description":"[DB Browser for SQLite]({{ project_url }}) is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sqlitebrowser-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/sqlitebrowser"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-sqlitebrowser"}],"containers":[{"name":"sqlitebrowser","image":"linuxserver/sqlitebrowser","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and potentially dump files.","key":"config"}],"ports":[{"container":"3000","description":"Sqlitebrowser desktop gui.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"sqlitebrowser","project_url":"https://sqlitebrowser.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/sqlitebrowser-banner.png","project_blurb":"[DB Browser for SQLite]({{ project_url }}) is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and potentially dump files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Sqlitebrowser desktop gui."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"16.02.22:","desc":"Rebase to Alpine."},{"date":"20.01.21:","desc":"Remove Wireshark reference."},{"date":"29.07.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n","_id":"content:apps:sqlitebrowser.json","_type":"json","title":"Sqlitebrowser","_source":"content","_file":"apps/sqlitebrowser.json","_extension":"json"},{"_path":"/apps/swag","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"swag","name":"swag","description":"SWAG - Secure Web Application Gateway (formerly known as letsencrypt, no relation to Let's Encrypt) sets up an Nginx webserver and reverse proxy with php support and a built-in certbot client that automates free SSL server certificate generation and renewal processes (Let's Encrypt and ZeroSSL). It also contains fail2ban for intrusion prevention.","icon":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/swag.gif","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/swag"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-swag"}],"containers":[{"name":"swag","image":"linuxserver/swag","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"URL","default":"yourdomain.url","description":"Top url you have control over (`customdomain.com` if you own it, or `customsubdomain.ddnsprovider.com` if dynamic dns)."},{"id":"VALIDATION","default":"http","description":"Certbot validation method to use, options are `http` or `dns` (`dns` method also requires `DNSPLUGIN` variable set)."},{"id":"SUBDOMAINS","default":"www,","description":"Subdomains you'd like the cert to cover (comma separated, no spaces) ie. `www,ftp,cloud`. For a wildcard cert, set this *exactly* to `wildcard` (wildcard cert is available via `dns` validation only)"},{"id":"CERTPROVIDER","default":"","description":"Optionally define the cert provider. Set to `zerossl` for ZeroSSL certs (requires existing [ZeroSSL account](https://app.zerossl.com/signup) and the e-mail address entered in `EMAIL` env var). Otherwise defaults to Let's Encrypt."},{"id":"DNSPLUGIN","default":"cloudflare","description":"Required if `VALIDATION` is set to `dns`. Options are `acmedns`, `aliyun`, `azure`, `cloudflare`, `cpanel`, `desec`, `digitalocean`, `directadmin`, `dnsimple`, `dnsmadeeasy`, `dnspod`, `do`, `domeneshop`, `duckdns`, `dynu`, `gandi`, `gehirn`, `godaddy`, `google`, `he`, `hetzner`, `infomaniak`, `inwx`, `ionos`, `linode`, `loopia`, `luadns`, `netcup`, `njalla`, `nsone`, `ovh`, `porkbun`, `rfc2136`, `route53`, `sakuracloud`, `standalone`, `transip`, and `vultr`. Also need to enter the credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`."},{"id":"PROPAGATION","default":"","description":"Optionally override (in seconds) the default propagation time for the dns plugins."},{"id":"EMAIL","default":"","description":"Optional e-mail address used for cert expiration notifications (Required for ZeroSSL)."},{"id":"ONLY_SUBDOMAINS","default":"false","description":"If you wish to get certs only for certain subdomains, but not the main domain (main domain may be hosted on another machine and cannot be validated), set this to `true`"},{"id":"EXTRA_DOMAINS","default":"","description":"Additional fully qualified domain names (comma separated, no spaces) ie. `extradomain.com,subdomain.anotherdomain.org,*.anotherdomain.org`"},{"id":"STAGING","default":"false","description":"Set to `true` to retrieve certs in staging mode. Rate limits will be much higher, but the resulting cert will not pass the browser's security test. Only to be used for testing purposes."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/config","description":"All the config files including the webroot reside here.","key":"config"}],"ports":[{"container":"443","description":"Https port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"swag","project_url":"https://linuxserver.io","project_logo":"https://github.com/linuxserver/docker-templates/raw/master/linuxserver.io/img/swag.gif","project_blurb":"SWAG - Secure Web Application Gateway (formerly known as letsencrypt, no relation to Let's Encrypt) sets up an Nginx webserver and reverse proxy with php support and a built-in certbot client that automates free SSL server certificate generation and renewal processes (Let's Encrypt and ZeroSSL). It also contains fail2ban for intrusion prevention.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Stable releases"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_net":"host","param_net_desc":"Shares host networking with container.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"URL","env_value":"yourdomain.url","desc":"Top url you have control over (`customdomain.com` if you own it, or `customsubdomain.ddnsprovider.com` if dynamic dns)."},{"env_var":"VALIDATION","env_value":"http","desc":"Certbot validation method to use, options are `http` or `dns` (`dns` method also requires `DNSPLUGIN` variable set)."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"All the config files including the webroot reside here."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"443","internal_port":"443","port_desc":"Https port"}],"param_device_map":false,"param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBDOMAINS","env_value":"www,","desc":"Subdomains you'd like the cert to cover (comma separated, no spaces) ie. `www,ftp,cloud`. For a wildcard cert, set this *exactly* to `wildcard` (wildcard cert is available via `dns` validation only)"},{"env_var":"CERTPROVIDER","env_value":"","desc":"Optionally define the cert provider. Set to `zerossl` for ZeroSSL certs (requires existing [ZeroSSL account](https://app.zerossl.com/signup) and the e-mail address entered in `EMAIL` env var). Otherwise defaults to Let's Encrypt."},{"env_var":"DNSPLUGIN","env_value":"cloudflare","desc":"Required if `VALIDATION` is set to `dns`. Options are `acmedns`, `aliyun`, `azure`, `cloudflare`, `cpanel`, `desec`, `digitalocean`, `directadmin`, `dnsimple`, `dnsmadeeasy`, `dnspod`, `do`, `domeneshop`, `duckdns`, `dynu`, `gandi`, `gehirn`, `godaddy`, `google`, `he`, `hetzner`, `infomaniak`, `inwx`, `ionos`, `linode`, `loopia`, `luadns`, `netcup`, `njalla`, `nsone`, `ovh`, `porkbun`, `rfc2136`, `route53`, `sakuracloud`, `standalone`, `transip`, and `vultr`. Also need to enter the credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`."},{"env_var":"PROPAGATION","env_value":"","desc":"Optionally override (in seconds) the default propagation time for the dns plugins."},{"env_var":"EMAIL","env_value":"","desc":"Optional e-mail address used for cert expiration notifications (Required for ZeroSSL)."},{"env_var":"ONLY_SUBDOMAINS","env_value":"false","desc":"If you wish to get certs only for certain subdomains, but not the main domain (main domain may be hosted on another machine and cannot be validated), set this to `true`"},{"env_var":"EXTRA_DOMAINS","env_value":"","desc":"Additional fully qualified domain names (comma separated, no spaces) ie. `extradomain.com,subdomain.anotherdomain.org,*.anotherdomain.org`"},{"env_var":"STAGING","env_value":"false","desc":"Set to `true` to retrieve certs in staging mode. Rate limits will be much higher, but the resulting cert will not pass the browser's security test. Only to be used for testing purposes."}],"opt_param_usage_include_vols":false,"opt_param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"80","internal_port":"80","port_desc":"Http port (required for http validation and http -> https redirect)"}],"opt_param_device_map":false,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"For hardware transcoding"}],"opt_cap_add_param":false,"opt_cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"### Validation and initial setup\n\n* Before running this container, make sure that the url and subdomains are properly forwarded to this container's host, and that port 443 (and/or 80) is not being used by another service on the host (NAS gui, another webserver, etc.).\n* If you need a dynamic dns provider, you can use the free provider duckdns.org where the `URL` will be `yoursubdomain.duckdns.org` and the `SUBDOMAINS` can be `www,ftp,cloud` with http validation, or `wildcard` with dns validation. You can use our [duckdns image](https://hub.docker.com/r/linuxserver/duckdns/) to update your IP on duckdns.org.\n* For `http` validation, port 80 on the internet side of the router should be forwarded to this container's port 80\n* For `dns` validation, make sure to enter your credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`\n  * Cloudflare provides free accounts for managing dns and is very easy to use with this image. Make sure that it is set up for \"dns only\" instead of \"dns + proxy\"\n  * Google dns plugin is meant to be used with \"Google Cloud DNS\", a paid enterprise product, and not for \"Google Domains DNS\"\n  * DuckDNS only supoprts two types of DNS validated certificates (not both at the same time):\n    1. Certs that only cover your main subdomain (ie. `yoursubdomain.duckdns.org`, leave the `SUBDOMAINS` variable empty)\n    2. Certs that cover sub-subdomains of your main subdomain (ie. `*.yoursubdomain.duckdns.org`, set the `SUBDOMAINS` variable to `wildcard`)\n* `--cap-add=NET_ADMIN` is required for fail2ban to modify iptables\n* After setup, navigate to `https://yourdomain.url` to access the default homepage (http access through port 80 is disabled by default, you can enable it by editing the default site config at `/config/nginx/site-confs/default.conf`).\n* Certs are checked nightly and if expiration is within 30 days, renewal is attempted. If your cert is about to expire in less than 30 days, check the logs under `/config/log/letsencrypt` to see why the renewals have been failing. It is recommended to input your e-mail in docker parameters so you receive expiration notices from Let's Encrypt in those circumstances.\n\n### Security and password protection\n\n* The container detects changes to url and subdomains, revokes existing certs and generates new ones during start.\n* Per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919), the container is shipping [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) as the `dhparams.pem`.\n* If you'd like to password protect your sites, you can use htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it swag htpasswd -c /config/nginx/.htpasswd <username>`\n* You can add multiple user:pass to `.htpasswd`. For the first user, use the above command, for others, use the above command without the `-c` flag, as it will force deletion of the existing `.htpasswd` and creation of a new one\n* You can also use ldap auth for security and access control. A sample, user configurable ldap.conf is provided, and it requires the separate image [linuxserver/ldap-auth](https://hub.docker.com/r/linuxserver/ldap-auth/) to communicate with an ldap server.\n\n### Site config and reverse proxy\n\n* The default site config resides at `/config/nginx/site-confs/default.conf`. Feel free to modify this file, and you can add other conf files to this directory. However, if you delete the `default` file, a new default will be created on container start.\n* Preset reverse proxy config files are added for popular apps. See the `README.md` file under `/config/nginx/proxy_confs` for instructions on how to enable them. The preset confs reside in and get imported from [this repo](https://github.com/linuxserver/reverse-proxy-confs).\n* If you wish to hide your site from search engine crawlers, you may find it useful to add this configuration line to your site config, within the server block, above the line where ssl.conf is included\n`add_header X-Robots-Tag \"noindex, nofollow, nosnippet, noarchive\";`\nThis will *ask* Google et al not to index and list your site. Be careful with this, as you will eventually be de-listed if you leave this line in on a site you wish to be present on search engines\n* If you wish to redirect http to https, you must expose port 80\n\n### Using certs in other containers\n\n* This container includes auto-generated pfx and private-fullchain-bundle pem certs that are needed by other apps like Emby and Znc.\n  * To use these certs in other containers, do either of the following:\n  1. *(Easier)* Mount the container's config folder in other containers (ie. `-v /path-to-swag-config:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/keys/letsencrypt/`\n  2. *(More secure)* Mount the SWAG folder `etc` that resides under `/config` in other containers (ie. `-v /path-to-swag-config/etc:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/letsencrypt/live/<your.domain.url>/` (This is more secure because the first method shares the entire SWAG config folder with other containers, including the www files, whereas the second method only shares the ssl certs)\n  * These certs include:\n  1. `cert.pem`, `chain.pem`, `fullchain.pem` and `privkey.pem`, which are generated by Certbot and used by nginx and various other apps\n  2. `privkey.pfx`, a format supported by Microsoft and commonly used by dotnet apps such as Emby Server (no password)\n  3. `priv-fullchain-bundle.pem`, a pem cert that bundles the private key and the fullchain, used by apps like ZNC\n\n### Using fail2ban\n\n* This container includes fail2ban set up with 5 jails by default:\n  1. nginx-http-auth\n  2. nginx-badbots\n  3. nginx-botsearch\n  4. nginx-deny\n  5. nginx-unauthorized\n* To enable or disable other jails, modify the file `/config/fail2ban/jail.local`\n* To modify filters and actions, instead of editing the `.conf` files, create `.local` files with the same name and edit those because .conf files get overwritten when the actions and filters are updated. `.local` files will append whatever's in the `.conf` files (ie. `nginx-http-auth.conf` --> `nginx-http-auth.local`)\n* You can check which jails are active via `docker exec -it swag fail2ban-client status`\n* You can check the status of a specific jail via `docker exec -it swag fail2ban-client status <jail name>`\n* You can unban an IP via `docker exec -it swag fail2ban-client set <jail name> unbanip <IP>`\n* A list of commands can be found here: <https://www.fail2ban.org/wiki/index.php/Commands>\n\n### Updating configs\n\n* This container creates a number of configs for nginx, proxy samples, etc.\n* Config updates are noted in the changelog but not automatically applied to your files.\n* If you have modified a file with noted changes in the changelog:\n  1. Keep your existing configs as is (not broken, don't fix)\n  2. Review our repository commits and apply the new changes yourself\n  3. Delete the modified config file with listed updates, restart the container, reapply your changes\n* If you have NOT modified a file with noted changes in the changelog:\n  1. Delete the config file with listed updates, restart the container\n* Proxy sample updates are not listed in the changelog. See the changes here: [https://github.com/linuxserver/reverse-proxy-confs/commits/master](https://github.com/linuxserver/reverse-proxy-confs/commits/master)\n* Proxy sample files WILL be updated, however your renamed (enabled) proxy files will not.\n* You can check the new sample and adjust your active config as needed.\n\n### Migration from the old `linuxserver/letsencrypt` image\n\nPlease follow the instructions [on this blog post](https://www.linuxserver.io/blog/2020-08-21-introducing-swag#migrate).\n","changelogs":[{"date":"21.01.23:","desc":"Unpin certbot version (allow certbot 2.x). !!BREAKING CHANGE!! We are temporarily removing the certbot porkbun plugin until a new version is released that is compatible with certbot 2.x."},{"date":"20.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"16.01.23:","desc":"Remove nchan module because it keeps causing crashes."},{"date":"08.12.22:","desc":"Revamp certbot init."},{"date":"03.12.22:","desc":"Remove defunct cloudxns plugin."},{"date":"22.11.22:","desc":"Pin acme to the same version as certbot."},{"date":"22.11.22:","desc":"Pin certbot to 1.32.0 until plugin compatibility improves."},{"date":"05.11.22:","desc":"Update acmedns plugin handling."},{"date":"06.10.22:","desc":"Switch to certbot-dns-duckdns. Update cpanel and gandi dns plugin handling. Minor adjustments to init logic."},{"date":"05.10.22:","desc":"Use certbot file hooks instead of command line hooks"},{"date":"04.10.22:","desc":"Add godaddy and porkbun dns plugins."},{"date":"03.10.22:","desc":"Add default_server back to default site conf's https listen."},{"date":"22.09.22:","desc":"Added support for DO DNS validation."},{"date":"22.09.22:","desc":"Added certbot-dns-acmedns for DNS01 validation."},{"date":"20.08.22:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf - Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"10.08.22:","desc":"Added support for Dynu DNS validation."},{"date":"18.05.22:","desc":"Added support for Azure DNS validation."},{"date":"09.04.22:","desc":"Added certbot-dns-loopia for DNS01 validation."},{"date":"05.04.22:","desc":"Added support for standalone DNS validation."},{"date":"28.03.22:","desc":"created a logfile for fail2ban nginx-unauthorized in /etc/cont-init.d/50-config"},{"date":"09.01.22:","desc":"Added a fail2ban jail for nginx unauthorized"},{"date":"21.12.21:","desc":"Fixed issue with iptables not working as expected"},{"date":"30.11.21:","desc":"Move maxmind to a [new mod](https://github.com/linuxserver/docker-mods/tree/swag-maxmind)"},{"date":"22.11.21:","desc":"Added support for Infomaniak DNS for certificate generation."},{"date":"20.11.21:","desc":"Added support for dnspod validation."},{"date":"15.11.21:","desc":"Added support for deSEC DNS for wildcard certificate generation."},{"date":"26.10.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) proxy.conf - Mitigate <https://httpoxy.org/> vulnerabilities. Ref: <https://www.nginx.com/blog/mitigating-the-httpoxy-vulnerability-with-nginx#Defeating-the-Attack-using-NGINX-and-NGINX-Plus>"},{"date":"23.10.21:","desc":"Fix Hurricane Electric (HE) DNS validation."},{"date":"12.10.21:","desc":"Fix deprecated LE root cert check to fix failures when using `STAGING=true`, and failures in revoking."},{"date":"06.10.21:","desc":"Added support for Hurricane Electric (HE) DNS validation. Added lxml build deps."},{"date":"01.10.21:","desc":"Check if the cert uses the old LE root cert, revoke and regenerate if necessary. [Here's more info](https://twitter.com/letsencrypt/status/1443621997288767491) on LE root cert expiration"},{"date":"19.09.21:","desc":"Add an optional header to opt out of Google FLoC in `ssl.conf`."},{"date":"17.09.21:","desc":"Mark `SUBDOMAINS` var as optional."},{"date":"01.08.21:","desc":"Add support for ionos dns validation."},{"date":"15.07.21:","desc":"Fix libmaxminddb issue due to upstream change."},{"date":"07.07.21:","desc":"Rebase to alpine 3.14."},{"date":"24.06.21:","desc":"Update default nginx conf folder."},{"date":"28.05.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) authelia-server.conf - Use `resolver.conf` and patch for `CVE-2021-32637`."},{"date":"20.05.21:","desc":"Modify resolver.conf generation to detect and ignore ipv6."},{"date":"14.05.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, ssl.conf, proxy.conf, and the default site-conf - Rework nginx.conf to be inline with alpine upstream and relocate lines from other files. Use linuxserver.io wheel index for pip packages. Switch to using [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) for `dhparams.pem` per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919). Added `worker_processes.conf`, which sets the number of nginx workers, and `resolver.conf`, which sets the dns resolver. Both conf files are auto-generated only on first start and can be user modified later."},{"date":"21.04.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) authelia-server.conf and authelia-location.conf - Add remote name/email headers and pass http method."},{"date":"12.04.21:","desc":"Add php7-gmp and php7-pecl-mailparse."},{"date":"12.04.21:","desc":"Add support for vultr dns validation."},{"date":"14.03.21:","desc":"Add support for directadmin dns validation."},{"date":"12.02.21:","desc":"Clean up rust/cargo cache, which ballooned the image size in the last couple of builds."},{"date":"10.02.21:","desc":"Fix aliyun, domeneshop, inwx and transip dns confs for existing users."},{"date":"09.02.21:","desc":"Rebasing to alpine 3.13. Add nginx mods brotli and dav-ext. Remove nginx mods lua and lua-upstream (due to regression over the last couple of years)."},{"date":"26.01.21:","desc":"Add support for hetzner dns validation."},{"date":"20.01.21:","desc":"Add check for ZeroSSL EAB retrieval."},{"date":"08.01.21:","desc":"Add support for getting certs from [ZeroSSL](https://zerossl.com/) via optional `CERTPROVIDER` env var. Update aliyun, domeneshop, inwx and transip dns plugins with the new plugin names. Hide `donoteditthisfile.conf` because users were editing it despite its name. Suppress harmless error when no proxy confs are enabled."},{"date":"03.01.21:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) /config/nginx/site-confs/default.conf - Add helper pages to aid troubleshooting"},{"date":"10.12.20:","desc":"Add support for njalla dns validation"},{"date":"09.12.20:","desc":"Check for template/conf updates and notify in the log. Add support for gehirn and sakuracloud dns validation."},{"date":"01.11.20:","desc":"Add support for netcup dns validation"},{"date":"29.10.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) ssl.conf - Add frame-ancestors to Content-Security-Policy."},{"date":"04.10.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, proxy.conf, and ssl.conf - Minor cleanups and reordering."},{"date":"20.09.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf - Added geoip2 configs. Added MAXMINDDB_LICENSE_KEY variable to readme."},{"date":"08.09.20:","desc":"Add php7-xsl."},{"date":"01.09.20:","desc":"[Existing users should update:](https://github.com/linuxserver/docker-swag/blob/master/README.md#updating-configs) nginx.conf, proxy.conf, and various proxy samples - Global websockets across all configs."},{"date":"03.08.20:","desc":"Initial release."}]}},"setup":"### Validation and initial setup\n\n* Before running this container, make sure that the url and subdomains are properly forwarded to this container's host, and that port 443 (and/or 80) is not being used by another service on the host (NAS gui, another webserver, etc.).\n* If you need a dynamic dns provider, you can use the free provider duckdns.org where the `URL` will be `yoursubdomain.duckdns.org` and the `SUBDOMAINS` can be `www,ftp,cloud` with http validation, or `wildcard` with dns validation. You can use our [duckdns image](https://hub.docker.com/r/linuxserver/duckdns/) to update your IP on duckdns.org.\n* For `http` validation, port 80 on the internet side of the router should be forwarded to this container's port 80\n* For `dns` validation, make sure to enter your credentials into the corresponding ini (or json for some plugins) file under `/config/dns-conf`\n  * Cloudflare provides free accounts for managing dns and is very easy to use with this image. Make sure that it is set up for \"dns only\" instead of \"dns + proxy\"\n  * Google dns plugin is meant to be used with \"Google Cloud DNS\", a paid enterprise product, and not for \"Google Domains DNS\"\n  * DuckDNS only supoprts two types of DNS validated certificates (not both at the same time):\n    1. Certs that only cover your main subdomain (ie. `yoursubdomain.duckdns.org`, leave the `SUBDOMAINS` variable empty)\n    2. Certs that cover sub-subdomains of your main subdomain (ie. `*.yoursubdomain.duckdns.org`, set the `SUBDOMAINS` variable to `wildcard`)\n* `--cap-add=NET_ADMIN` is required for fail2ban to modify iptables\n* After setup, navigate to `https://yourdomain.url` to access the default homepage (http access through port 80 is disabled by default, you can enable it by editing the default site config at `/config/nginx/site-confs/default.conf`).\n* Certs are checked nightly and if expiration is within 30 days, renewal is attempted. If your cert is about to expire in less than 30 days, check the logs under `/config/log/letsencrypt` to see why the renewals have been failing. It is recommended to input your e-mail in docker parameters so you receive expiration notices from Let's Encrypt in those circumstances.\n\n### Security and password protection\n\n* The container detects changes to url and subdomains, revokes existing certs and generates new ones during start.\n* Per [RFC7919](https://datatracker.ietf.org/doc/html/rfc7919), the container is shipping [ffdhe4096](https://ssl-config.mozilla.org/ffdhe4096.txt) as the `dhparams.pem`.\n* If you'd like to password protect your sites, you can use htpasswd. Run the following command on your host to generate the htpasswd file `docker exec -it swag htpasswd -c /config/nginx/.htpasswd <username>`\n* You can add multiple user:pass to `.htpasswd`. For the first user, use the above command, for others, use the above command without the `-c` flag, as it will force deletion of the existing `.htpasswd` and creation of a new one\n* You can also use ldap auth for security and access control. A sample, user configurable ldap.conf is provided, and it requires the separate image [linuxserver/ldap-auth](https://hub.docker.com/r/linuxserver/ldap-auth/) to communicate with an ldap server.\n\n### Site config and reverse proxy\n\n* The default site config resides at `/config/nginx/site-confs/default.conf`. Feel free to modify this file, and you can add other conf files to this directory. However, if you delete the `default` file, a new default will be created on container start.\n* Preset reverse proxy config files are added for popular apps. See the `README.md` file under `/config/nginx/proxy_confs` for instructions on how to enable them. The preset confs reside in and get imported from [this repo](https://github.com/linuxserver/reverse-proxy-confs).\n* If you wish to hide your site from search engine crawlers, you may find it useful to add this configuration line to your site config, within the server block, above the line where ssl.conf is included\n`add_header X-Robots-Tag \"noindex, nofollow, nosnippet, noarchive\";`\nThis will *ask* Google et al not to index and list your site. Be careful with this, as you will eventually be de-listed if you leave this line in on a site you wish to be present on search engines\n* If you wish to redirect http to https, you must expose port 80\n\n### Using certs in other containers\n\n* This container includes auto-generated pfx and private-fullchain-bundle pem certs that are needed by other apps like Emby and Znc.\n  * To use these certs in other containers, do either of the following:\n  1. *(Easier)* Mount the container's config folder in other containers (ie. `-v /path-to-swag-config:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/keys/letsencrypt/`\n  2. *(More secure)* Mount the SWAG folder `etc` that resides under `/config` in other containers (ie. `-v /path-to-swag-config/etc:/swag-ssl`) and in the other containers, use the cert location `/swag-ssl/letsencrypt/live/<your.domain.url>/` (This is more secure because the first method shares the entire SWAG config folder with other containers, including the www files, whereas the second method only shares the ssl certs)\n  * These certs include:\n  1. `cert.pem`, `chain.pem`, `fullchain.pem` and `privkey.pem`, which are generated by Certbot and used by nginx and various other apps\n  2. `privkey.pfx`, a format supported by Microsoft and commonly used by dotnet apps such as Emby Server (no password)\n  3. `priv-fullchain-bundle.pem`, a pem cert that bundles the private key and the fullchain, used by apps like ZNC\n\n### Using fail2ban\n\n* This container includes fail2ban set up with 5 jails by default:\n  1. nginx-http-auth\n  2. nginx-badbots\n  3. nginx-botsearch\n  4. nginx-deny\n  5. nginx-unauthorized\n* To enable or disable other jails, modify the file `/config/fail2ban/jail.local`\n* To modify filters and actions, instead of editing the `.conf` files, create `.local` files with the same name and edit those because .conf files get overwritten when the actions and filters are updated. `.local` files will append whatever's in the `.conf` files (ie. `nginx-http-auth.conf` --> `nginx-http-auth.local`)\n* You can check which jails are active via `docker exec -it swag fail2ban-client status`\n* You can check the status of a specific jail via `docker exec -it swag fail2ban-client status <jail name>`\n* You can unban an IP via `docker exec -it swag fail2ban-client set <jail name> unbanip <IP>`\n* A list of commands can be found here: <https://www.fail2ban.org/wiki/index.php/Commands>\n\n### Updating configs\n\n* This container creates a number of configs for nginx, proxy samples, etc.\n* Config updates are noted in the changelog but not automatically applied to your files.\n* If you have modified a file with noted changes in the changelog:\n  1. Keep your existing configs as is (not broken, don't fix)\n  2. Review our repository commits and apply the new changes yourself\n  3. Delete the modified config file with listed updates, restart the container, reapply your changes\n* If you have NOT modified a file with noted changes in the changelog:\n  1. Delete the config file with listed updates, restart the container\n* Proxy sample updates are not listed in the changelog. See the changes here: [https://github.com/linuxserver/reverse-proxy-confs/commits/master](https://github.com/linuxserver/reverse-proxy-confs/commits/master)\n* Proxy sample files WILL be updated, however your renamed (enabled) proxy files will not.\n* You can check the new sample and adjust your active config as needed.\n\n### Migration from the old `linuxserver/letsencrypt` image\n\nPlease follow the instructions [on this blog post](https://www.linuxserver.io/blog/2020-08-21-introducing-swag#migrate).\n","_id":"content:apps:swag.json","_type":"json","title":"Swag","_source":"content","_file":"apps/swag.json","_extension":"json"},{"_path":"/apps/synclounge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"synclounge","name":"synclounge","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a third party tool that allows you to watch Plex in sync with your friends/family, wherever you are.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/synclounge-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/synclounge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-synclounge"}],"containers":[{"name":"synclounge","image":"linuxserver/synclounge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"AUTH_LIST","default":"plexuser1,plexuser2,email1,machineid1","description":"If set, only the users defined here and the users of the plex servers defined here will be able to access the server. Use e-mails, plex usernames and/or plex server machine ids, comma separated, no spaces."},{"id":"AUTOJOIN_ENABLED","default":"false","description":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set to `true` to let users autojoin the server and a room (specified by the `AUTOJOIN_ROOM` var)."},{"id":"AUTOJOIN_ROOM","default":"roomname","description":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set the room name for auto joining (requires `AUTOJOIN_ENABLED` set to `true`)."}],"ports":[{"container":"8088","description":"Web app and server port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"synclounge","project_url":"https://github.com/samcm/synclounge","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/synclounge-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a third party tool that allows you to watch Plex in sync with your friends/family, wherever you are.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":false,"param_volumes":null,"param_usage_include_ports":true,"param_ports":[{"external_port":"8088","internal_port":"8088","port_desc":"Web app and server port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"AUTH_LIST","env_value":"plexuser1,plexuser2,email1,machineid1","desc":"If set, only the users defined here and the users of the plex servers defined here will be able to access the server. Use e-mails, plex usernames and/or plex server machine ids, comma separated, no spaces."},{"env_var":"AUTOJOIN_ENABLED","env_value":"false","desc":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set to `true` to let users autojoin the server and a room (specified by the `AUTOJOIN_ROOM` var)."},{"env_var":"AUTOJOIN_ROOM","env_value":"roomname","desc":"DEPRECATED - (Still works but will be removed in the future in favor of the built-in var `autojoin__room`) - Set the room name for auto joining (requires `AUTOJOIN_ENABLED` set to `true`)."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"The web app and the server are both accessible at `http://SERVERIP:8088`.\n\nNote: It is recommended to use `http` as the external proto with a reverse proxy due to `https` not working with external plex clients.\n","changelogs":[{"date":"29.11.22:","desc":"Rebase to alpine 3.17, upgrade to s6v3."},{"date":"19.09.22:","desc":"Rebase to alpine 3.15."},{"date":"12.02.21:","desc":"Fix optional dependency builds in aarch64 image."},{"date":"12.02.21:","desc":"Rebasing to alpine 3.13."},{"date":"28.10.20:","desc":"Update to v4. Env vars `EXTERNAL_URL`, `EXTERNAL_SERVER_PORT` and `AUTOJOIN_PASSWORD` are deprecated and no longer have any effect. Env vars `AUTOJOIN_ENABLED` and `AUTOJOIN_ROOM` are still working but will be removed in the future in favor of synclounge's built-in var `autojoin__room`. If you are reverse proxying, do not forget to update your proxy settings ([here](https://github.com/linuxserver/reverse-proxy-confs/blob/master/synclounge.subdomain.conf.sample) and [here](https://github.com/linuxserver/reverse-proxy-confs/blob/master/synclounge.subfolder.conf.sample)) as the server port and addresses are changed."},{"date":"11.10.20:","desc":"Pin builds to upstream commit `6aecc9bd` while evaluating the breaking changes upstream."},{"date":"27.09.20:","desc":"Updating the external repo endpoint."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"11.05.20:","desc":"Initial Release."}]}},"setup":"The web app and the server are both accessible at `http://SERVERIP:8088`.\n\nNote: It is recommended to use `http` as the external proto with a reverse proxy due to `https` not working with external plex clients.\n","_id":"content:apps:synclounge.json","_type":"json","title":"Synclounge","_source":"content","_file":"apps/synclounge.json","_extension":"json"},{"_path":"/apps/syncthing","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"syncthing","name":"syncthing","description":"[{{ project_name|capitalize }}]({{ project_url }}) replaces proprietary sync and cloud services with something open, trustworthy and decentralized. Your data is your data alone and you deserve to choose where it is stored, if it is shared with some third party and how it's transmitted over the Internet.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syncthing-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/syncthing"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-syncthing"}],"containers":[{"name":"syncthing","image":"linuxserver/syncthing","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"},{"container":"/data1","description":"Data1"},{"container":"/data2","description":"Data2"}],"ports":[{"container":"8384","description":"Application WebUI","protocol":"tcp","web":false},{"container":"22000/tcp","description":"Listening port (TCP)","protocol":"tcp","web":false},{"container":"22000/udp","description":"Listening port (UDP)","protocol":"tcp","web":false},{"container":"21027/udp","description":"Protocol discovery","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"syncthing","project_url":"https://syncthing.net","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syncthing-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) replaces proprietary sync and cloud services with something open, trustworthy and decentralized. Your data is your data alone and you deserve to choose where it is stored, if it is shared with some third party and how it's transmitted over the Internet.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":"optional","param_hostname":"{{ project_name }}","param_hostname_desc":"Optionally the hostname can be defined.","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Configuration files."},{"vol_path":"/data1","vol_host_path":"/path/to/data1","desc":"Data1"},{"vol_path":"/data2","vol_host_path":"/path/to/data2","desc":"Data2"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8384","internal_port":"8384","port_desc":"Application WebUI"},{"external_port":"22000","internal_port":"22000/tcp","port_desc":"Listening port (TCP)"},{"external_port":"22000","internal_port":"22000/udp","port_desc":"Listening port (UDP)"},{"external_port":"21027","internal_port":"21027/udp","port_desc":"Protocol discovery"}],"app_setup_block_enabled":true,"app_setup_block":"**Note: ** The Syncthing devs highly suggest setting a password for this container as it listens on 0.0.0.0. To do this go to `Actions -> Settings -> set user/password` for the webUI.","changelogs":[{"date":"17.08.22:","desc":"Build on alpine 3.16 for go 1.18)."},{"date":"03.05.22:","desc":"Rebase to alpine 3.15 (builds on edge for go 1.18)."},{"date":"05.10.21:","desc":"Rebase to alpine 3.14."},{"date":"12.05.21:","desc":"Remove sysctl parameter again"},{"date":"03.05.21:","desc":"Raise maximum UDP buffer size."},{"date":"03.05.21:","desc":"Add port mapping for 22000/udp."},{"date":"29.01.21:","desc":"Deprecate `UMASK_SET` in favor of UMASK in baseimage, see above for more information."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"15.09.20:","desc":"Use go from alpine edge repo to compile. Remove duplicate UMASK env var. Add hostname setting."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"05.03.19:","desc":"Update Build process for v1.1.0 release."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"16.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"30.07.18:","desc":"Rebase to alpine 3.8 and use buildstage."},{"date":"13.12.17:","desc":"Rebase to alpine 3.7."},{"date":"25.10.17:","desc":"Add env for manual setting of umask."},{"date":"29.07.17:","desc":"Simplify build structure as symlinks failing on > 0.14.32"},{"date":"28.05.17:","desc":"Rebase to alpine 3.6."},{"date":"08.02.17:","desc":"Rebase to alpine 3.5."},{"date":"01.11.16:","desc":"Switch to compiling latest version from git source."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"11.08.16:","desc":"Rebase to alpine linux."},{"date":"18.12.15:","desc":"Initial testing / release (IronicBadger)"},{"date":"24.09.15:","desc":"Inital dev complete (Lonix)"}]}},"setup":"**Note: ** The Syncthing devs highly suggest setting a password for this container as it listens on 0.0.0.0. To do this go to `Actions -> Settings -> set user/password` for the webUI.","_id":"content:apps:syncthing.json","_type":"json","title":"Syncthing","_source":"content","_file":"apps/syncthing.json","_extension":"json"},{"_path":"/apps/syslog-ng","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"syslog-ng","name":"syslog-ng","description":"[syslog-ng]({{ project_url }}) allows you to flexibly collect, parse, classify, rewrite and correlate logs from across your infrastructure and store or route them to log analysis tools.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syslog-ng-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/syslog-ng"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-syslog-ng"}],"containers":[{"name":"syslog-ng","image":"linuxserver/syslog-ng","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/var/log","description":"Stores logs collected by the syslog-ng service"},{"container":"/config","description":"Stores config and application files","key":"config"}],"ports":[{"container":"5514/udp","description":"Syslog UDP","protocol":"tcp","web":false},{"container":"6601/tcp","description":"Syslog TCP","protocol":"tcp","web":false},{"container":"6514/tcp","description":"Syslog TLS","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"syslog-ng","project_url":"https://www.syslog-ng.com/products/open-source-log-management/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/syslog-ng-logo.png","project_blurb":"[syslog-ng]({{ project_url }}) allows you to flexibly collect, parse, classify, rewrite and correlate logs from across your infrastructure and store or route them to log analysis tools.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Stores config and application files"}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/log","vol_host_path":"/path/to/log","desc":"Stores logs collected by the syslog-ng service"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"514","internal_port":"5514/udp","port_desc":"Syslog UDP"},{"external_port":"601","internal_port":"6601/tcp","port_desc":"Syslog TCP"},{"external_port":"6514","internal_port":"6514/tcp","port_desc":"Syslog TLS"}],"app_setup_block_enabled":true,"app_setup_block":"Edit `/config/syslog-ng.conf` to configure your logging sources and destinations. Note: As the application does not run as root you cannot listen on ports < 1024.\n\nThe application pid, control file, etc. are all kept in /config so when using tools such as `syslog-ng-ctl` you need to specify the path e.g. `syslog-ng-ctl reload -c /config/syslog-ng.ctl`\n\nMore info at [syslog-ng](https://www.syslog-ng.com/technical-documents/list/syslog-ng-open-source-edition).\n","changelogs":[{"date":"10.01.23:","desc":"Add paho-mqtt-c library as required by the syslog-ng documentation"},{"date":"30.12.22:","desc":"Rebase to Alpine 3.17, add libdbi-drivers for SQL support."},{"date":"01.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"18.12.21:","desc":"Rebase to Alpine 3.15."},{"date":"01.07.21:","desc":"Rebase to Alpine 3.14."},{"date":"26.05.21:","desc":"Initial release."}]}},"setup":"Edit `/config/syslog-ng.conf` to configure your logging sources and destinations. Note: As the application does not run as root you cannot listen on ports < 1024.\n\nThe application pid, control file, etc. are all kept in /config so when using tools such as `syslog-ng-ctl` you need to specify the path e.g. `syslog-ng-ctl reload -c /config/syslog-ng.ctl`\n\nMore info at [syslog-ng](https://www.syslog-ng.com/technical-documents/list/syslog-ng-open-source-edition).\n","_id":"content:apps:syslog-ng.json","_type":"json","title":"Syslog Ng","_source":"content","_file":"apps/syslog-ng.json","_extension":"json"},{"_path":"/apps/tautulli","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"tautulli","name":"tautulli","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a python based web application for monitoring, analytics and notifications for Plex Media Server.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tautulli-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/tautulli"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-tautulli"}],"containers":[{"name":"tautulli","image":"linuxserver/tautulli","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Contains tautulli config and database.","key":"config"}],"ports":[{"container":"8181","description":"WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"tautulli","project_url":"http://tautulli.com","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tautulli-icon.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a python based web application for monitoring, analytics and notifications for Plex Media Server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable Tautulli releases"},{"tag":"develop","desc":"Built at head of Tautulli nightly branch"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Contains tautulli config and database."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8181","internal_port":"8181","port_desc":"WebUI"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Access the webui at `<your-ip>:8181`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\nTo use the build-in Plex LogViewer you have to add a volume, preferably ReadOnly. Then in tautulli gui settings, under `Plex Media Server`, turn on `Show Advanced` and set the `Logs Folder` to the folder you mapped.\n","changelogs":[{"date":"15.12.22:","desc":"Rebase master branch to Alpine 3.17."},{"date":"04.10.22:","desc":"Rebase master branch to Alpine 3.16, migrate to s6v3."},{"date":"10.01.22:","desc":"Rebase to Alpine 3.15."},{"date":"11.07.21:","desc":"Add curl package."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"11.07.20:","desc":"Add py3-openssl."},{"date":"05.06.20:","desc":"Rebasing to alpine 3.12. Rework to python3."},{"date":"12.04.20:","desc":"Added mock from pip and donate links."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"26.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"23.10.18:","desc":"Update plex logs info in readm."},{"date":"16.08.18:","desc":"Rebase to alpine 3.8."},{"date":"10.03.18:","desc":"Rebrand to tautulli."},{"date":"12.12.17:","desc":"Rebase to alpine 3.7."},{"date":"21.07.17:","desc":"Internal git pull instead of at runtime."},{"date":"12.07.17:","desc":"Add inspect commands to README, move to jenkins build and push."},{"date":"25.05.17:","desc":"Rebase to alpine 3.6."},{"date":"20.04.17:","desc":"Add pycryptodomex pip package."},{"date":"07.02.17:","desc":"Rebase to alpine 3.5."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"27.08.16:","desc":"Add badges to README."},{"date":"08.08.16:","desc":"Rebase to alpine linux."},{"date":"16.07.15:","desc":"Inital Release."}]}},"setup":"Access the webui at `<your-ip>:8181`, for more information check out [{{ project_name|capitalize }}]({{ project_url }}).\nTo use the build-in Plex LogViewer you have to add a volume, preferably ReadOnly. Then in tautulli gui settings, under `Plex Media Server`, turn on `Show Advanced` and set the `Logs Folder` to the folder you mapped.\n","_id":"content:apps:tautulli.json","_type":"json","title":"Tautulli","_source":"content","_file":"apps/tautulli.json","_extension":"json"},{"_path":"/apps/thelounge","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"thelounge","name":"thelounge","description":"[{{ project_name|capitalize }}]({{ project_url }}) (a fork of shoutIRC) is a web IRC client that you host on your own server.","icon":"https://raw.githubusercontent.com/thelounge/thelounge/master/client/img/logo-vertical-transparent-bg.svg?sanitize=true","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/thelounge"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-thelounge"}],"containers":[{"name":"thelounge","image":"linuxserver/thelounge","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Configuration files.","key":"config"}],"ports":[{"container":"9000","description":"Application WebUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"thelounge","project_url":"https://thelounge.github.io/","project_logo":"https://raw.githubusercontent.com/thelounge/thelounge/master/client/img/logo-vertical-transparent-bg.svg?sanitize=true","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) (a fork of shoutIRC) is a web IRC client that you host on your own server.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases."},{"tag":"next","desc":"Next Pre-Releases."},{"tag":"nightly","desc":"Nightly images from commits in master."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"</path/to/appdata/config>","desc":"Configuration files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9000","internal_port":"9000","port_desc":"Application WebUI"}],"app_setup_block_enabled":true,"app_setup_block":"* When the application first runs, it will populate its /config\n\n* Stop the container\n\n* Now from the host, edit `/config/config.js`, wherever you've mapped it\n\n* In most cases you want the value `public: false` to allow named users only\n\n* Setting the two prefetch values to true improves usability, but uses more storage\n\n* Once you have the configuration you want, save it and start the container again\n\n* For each user, run the command\n\n* `docker exec -it thelounge s6-setuidgid abc thelounge add <user>`\n\n* You will be prompted to enter a password that will not be echoed.\n\n* Saving logs to disk is the default, this consumes more space but allows scrollback.\n\n* To log in to the application, browse to `http://<hostip>:9000`\n\n* You should now be prompted for a username and password on the webinterface.\n\n* Once logged in, you can add an IRC network. Some defaults are preset for Freenode\n","changelogs":[{"date":"18.12.22:","desc":"Rebasing master to alpine 3.17."},{"date":"24.10.22:","desc":"Fix sqlite3 build."},{"date":"12.04.22:","desc":"Install from source using yarn."},{"date":"11.04.22:","desc":"Rebasing to alpine 3.15 and switching from python2-dev to python3-dev for building node sqlite on arm."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"15.05.19:","desc":"Update Arm variant images to build sqlite3 module."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"25.08.18:","desc":"Use global install, simplifies adding users."},{"date":"20.08.18:","desc":"Rebase to alpine 3.8."},{"date":"06.01.18:","desc":"Rebase to alpine 3.7."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"14.10.16:","desc":"Bump to pickup 2.10 release."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"31.08.16:","desc":"Initial Release."}]}},"setup":"* When the application first runs, it will populate its /config\n\n* Stop the container\n\n* Now from the host, edit `/config/config.js`, wherever you've mapped it\n\n* In most cases you want the value `public: false` to allow named users only\n\n* Setting the two prefetch values to true improves usability, but uses more storage\n\n* Once you have the configuration you want, save it and start the container again\n\n* For each user, run the command\n\n* `docker exec -it thelounge s6-setuidgid abc thelounge add <user>`\n\n* You will be prompted to enter a password that will not be echoed.\n\n* Saving logs to disk is the default, this consumes more space but allows scrollback.\n\n* To log in to the application, browse to `http://<hostip>:9000`\n\n* You should now be prompted for a username and password on the webinterface.\n\n* Once logged in, you can add an IRC network. Some defaults are preset for Freenode\n","_id":"content:apps:thelounge.json","_type":"json","title":"Thelounge","_source":"content","_file":"apps/thelounge.json","_extension":"json"},{"_path":"/apps/transmission","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"transmission","name":"transmission","description":"[{{ project_name|capitalize }}]({{ project_url }}) is designed for easy, powerful use. Transmission has the features you want from a BitTorrent client: encryption, a web interface, peer exchange, magnet links, DHT, TP, UPnP and NAT-PMP port forwarding, webseed support, watch directories, tracker editing, global and per-torrent speed limits, and more.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/transmission.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/transmission"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-transmission"}],"containers":[{"name":"transmission","image":"linuxserver/transmission","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"TRANSMISSION_WEB_HOME","default":"/combustion-release/","description":"Specify an alternative UI options are [`/combustion-release/`](https://github.com/Secretmapper/combustion), [`/transmission-web-control/`](https://github.com/ronggang/transmission-web-control), [`/kettu/`](https://github.com/endor/kettu), [`/flood-for-transmission/`](https://github.com/johman10/flood-for-transmission), and [`/transmissionic/`](https://github.com/6c65726f79/Transmissionic)."},{"id":"USER","default":"username","description":"Specify an optional username for the interface"},{"id":"PASS","default":"password","description":"Specify an optional password for the interface"},{"id":"WHITELIST","default":"iplist","description":"Specify an optional list of comma separated ip whitelist. Fills rpc-whitelist setting."},{"id":"PEERPORT","default":"peerport","description":"Specify an optional port for torrent TCP/UDP connections. Fills peer-port setting."},{"id":"HOST_WHITELIST","default":"dnsname list","description":"Specify an optional list of comma separated dns name whitelist. Fills rpc-host-whitelist setting."}],"volumes":[{"container":"/config","description":"Where transmission should store config files and logs.","key":"config"},{"container":"/downloads","description":"Local path for downloads."},{"container":"/watch","description":"Watch folder for torrent files."}],"ports":[{"container":"9091","description":"WebUI","protocol":"tcp","web":false},{"container":"51413","description":"Torrent Port TCP","protocol":"tcp","web":false},{"container":"51413/udp","description":"Torrent Port UDP","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"transmission","project_url":"https://www.transmissionbt.com/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/transmission.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is designed for easy, powerful use. Transmission has the features you want from a BitTorrent client: encryption, a web interface, peer exchange, magnet links, DHT, TP, UPnP and NAT-PMP port forwarding, webseed support, watch directories, tracker editing, global and per-torrent speed limits, and more.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where transmission should store config files and logs."},{"vol_path":"/downloads","vol_host_path":"/path/to/downloads","desc":"Local path for downloads."},{"vol_path":"/watch","vol_host_path":"/path/to/watch/folder","desc":"Watch folder for torrent files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9091","internal_port":"9091","port_desc":"WebUI"},{"external_port":"51413","internal_port":"51413","port_desc":"Torrent Port TCP"},{"external_port":"51413","internal_port":"51413/udp","port_desc":"Torrent Port UDP"}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"TRANSMISSION_WEB_HOME","env_value":"/combustion-release/","desc":"Specify an alternative UI options are [`/combustion-release/`](https://github.com/Secretmapper/combustion), [`/transmission-web-control/`](https://github.com/ronggang/transmission-web-control), [`/kettu/`](https://github.com/endor/kettu), [`/flood-for-transmission/`](https://github.com/johman10/flood-for-transmission), and [`/transmissionic/`](https://github.com/6c65726f79/Transmissionic)."},{"env_var":"USER","env_value":"username","desc":"Specify an optional username for the interface"},{"env_var":"PASS","env_value":"password","desc":"Specify an optional password for the interface"},{"env_var":"WHITELIST","env_value":"iplist","desc":"Specify an optional list of comma separated ip whitelist. Fills rpc-whitelist setting."},{"env_var":"PEERPORT","env_value":"peerport","desc":"Specify an optional port for torrent TCP/UDP connections. Fills peer-port setting."},{"env_var":"HOST_WHITELIST","env_value":"dnsname list","desc":"Specify an optional list of comma separated dns name whitelist. Fills rpc-host-whitelist setting."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"Webui is on port 9091, the settings.json file in /config has extra settings not available in the webui. Stop the container before editing it or any changes won't be saved.\n\nIf you choose to use transmission-web-control as your default UI, just note that the origional Web UI will not be available to you despite the button being present.\n\n## Securing the webui with a username/password.\n\nUse the `USER` and `PASS` variables in docker run/create/compose to set authentication. Do not manually edit the `settings.json` to input user/pass, otherwise transmission cannot be stopped cleanly by the s6 supervisor.\n\n## Updating Blocklists Automatically\n\nThis requires `\"blocklist-enabled\": true,` to be set. By setting this to true, it is assumed you have also populated `blocklist-url` with a valid block list.\n\nThe automatic update is a shell script that downloads a blocklist from the url stored in the settings.json, gunzips it, and restarts the transmission daemon.\n\nThe automatic update will run once a day at 3am local server time.\n\n## Using whitelist\n\nUse `WHITELIST` to enable a list of ip as whitelist. This enable support for `rpc-whitelist`. When `WHITELIST` is empty support for whitelist is disabled.\n\nUse `HOST_WHITELIST` to enable an list of dns names as host-whitelist. This enable support for `rpc-host-whitelist`. When `HOST_WHITELIST` is empty support for host-whitelist is disabled.\n\n## Use alternative Transmission torrent ports\n\nUse `PEERPORT` to specify the port(s) Transmission should listen on.  This disables random port selection.  This should be the same as the port mapped in your docker configuration.\n","changelogs":[{"date":"05.01.23:","desc":"Rebase to Alpine 3.17, restore GNU findutils package."},{"date":"02.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"12.08.22:","desc":"Bump unrar to 6.1.7."},{"date":"03.04.22:","desc":"Add Transmissionic as a UI option."},{"date":"21.02.22:","desc":"Build unrar from source, rebase to Alpine 3.15, add symlinks neeeded for TWC. Credit @alexbelgium"},{"date":"09.07.21:","desc":"Wait for the transmission-daemon termination after a caught sigterm."},{"date":"06.03.21:","desc":"Add Flood for Transmission as a UI option."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"02.11.20:","desc":"Add ca-certificates package to allow connecting to https trackers."},{"date":"02.06.20:","desc":"Rebase to alpine 3.12, update to transmission 3.0, remove python2, add python3."},{"date":"11.05.20:","desc":"Remove unnecessary chmod (remnant of previous change)."},{"date":"28.04.20:","desc":"Use transmission-remote to update blocklist."},{"date":"30.03.20:","desc":"Internalize blocklist-update.sh."},{"date":"29.03.20:","desc":"Update auth info in readme."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"04.10.19:","desc":"Update package label."},{"date":"21.08.19:","desc":"Add optional user/pass environment variables, fix transmission shut down if user/pass are set."},{"date":"19.07.19:","desc":"Send SIGTERM in blocklist update to properly close pid."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebase to Alpine 3.9, add themes to baseimage, add python and findutils."},{"date":"22.02.19:","desc":"Catch term and clean exit."},{"date":"07.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.08.18:","desc":"Rebase to alpine linux 3.8."},{"date":"12.02.18:","desc":"Pull transmission from edge repo."},{"date":"10.01.18:","desc":"Rebase to alpine linux 3.7."},{"date":"25.07.17:","desc":"Add rsync package."},{"date":"27.05.17:","desc":"Rebase to alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase to alpine linux 3.5."},{"date":"15.01.17:","desc":"Add p7zip, tar, unrar, and unzip packages."},{"date":"16.10.16:","desc":"Blocklist autoupdate with optional authentication."},{"date":"14.10.16:","desc":"Add version layer informationE."},{"date":"23.09.16:","desc":"Add information about securing the webui to README."},{"date":"21.09.16:","desc":"Add curl package."},{"date":"09.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"09.08.16:","desc":"Rebase to alpine linux."},{"date":"06.12.15:","desc":"Separate mapping for watch folder."},{"date":"16.11.15:","desc":"Initial Release."}]}},"setup":"Webui is on port 9091, the settings.json file in /config has extra settings not available in the webui. Stop the container before editing it or any changes won't be saved.\n\nIf you choose to use transmission-web-control as your default UI, just note that the origional Web UI will not be available to you despite the button being present.\n\n## Securing the webui with a username/password.\n\nUse the `USER` and `PASS` variables in docker run/create/compose to set authentication. Do not manually edit the `settings.json` to input user/pass, otherwise transmission cannot be stopped cleanly by the s6 supervisor.\n\n## Updating Blocklists Automatically\n\nThis requires `\"blocklist-enabled\": true,` to be set. By setting this to true, it is assumed you have also populated `blocklist-url` with a valid block list.\n\nThe automatic update is a shell script that downloads a blocklist from the url stored in the settings.json, gunzips it, and restarts the transmission daemon.\n\nThe automatic update will run once a day at 3am local server time.\n\n## Using whitelist\n\nUse `WHITELIST` to enable a list of ip as whitelist. This enable support for `rpc-whitelist`. When `WHITELIST` is empty support for whitelist is disabled.\n\nUse `HOST_WHITELIST` to enable an list of dns names as host-whitelist. This enable support for `rpc-host-whitelist`. When `HOST_WHITELIST` is empty support for host-whitelist is disabled.\n\n## Use alternative Transmission torrent ports\n\nUse `PEERPORT` to specify the port(s) Transmission should listen on.  This disables random port selection.  This should be the same as the port mapped in your docker configuration.\n","_id":"content:apps:transmission.json","_type":"json","title":"Transmission","_source":"content","_file":"apps/transmission.json","_extension":"json"},{"_path":"/apps/tvheadend","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"tvheadend","name":"tvheadend","description":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: is a TV streaming server and recorder for Linux, FreeBSD and Android supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, ISDB-T, IPTV, SAT>IP and HDHomeRun as input sources.\nTvheadend offers the HTTP (VLC, MPlayer), HTSP (Kodi, Movian) and SAT>IP streaming.\nMultiple EPG sources are supported (over-the-air DVB and ATSC including OpenTV DVB extensions, XMLTV, PyXML).\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tvheadend-big.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/tvheadend"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-tvheadend"}],"containers":[{"name":"tvheadend","image":"linuxserver/tvheadend","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"RUN_OPTS","default":"","description":"Optionally specify additional arguments to be passed. See Additional runtime parameters."}],"volumes":[{"container":"/config","description":"Where TVHeadend show store it's config files.","key":"config"},{"container":"/recordings","description":"Where you want the PVR to store recordings."}],"ports":[{"container":"9981","description":"WebUI","protocol":"tcp","web":false},{"container":"9982","description":"HTSP server port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"tvheadend","project_url":"https://www.tvheadend.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/tvheadend-big.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) works as a proxy server: is a TV streaming server and recorder for Linux, FreeBSD and Android supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, ISDB-T, IPTV, SAT>IP and HDHomeRun as input sources.\nTvheadend offers the HTTP (VLC, MPlayer), HTSP (Kodi, Movian) and SAT>IP streaming.\nMultiple EPG sources are supported (over-the-air DVB and ATSC including OpenTV DVB extensions, XMLTV, PyXML).\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":[{"tag":"latest","desc":"Current latest release."},{"tag":"release-4.2","desc":"Latest release from 4.2 branch."}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"Where TVHeadend show store it's config files."},{"vol_path":"/recordings","vol_host_path":"/path/to/recordings","desc":"Where you want the PVR to store recordings."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"9981","internal_port":"9981","port_desc":"WebUI"},{"external_port":"9982","internal_port":"9982","port_desc":"HTSP server port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"RUN_OPTS","env_value":"","desc":"Optionally specify additional arguments to be passed. See Additional runtime parameters."}],"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Only needed if you want to use your AMD/Intel GPU for hardware accelerated video encoding (vaapi)."},{"device_path":"/dev/dvb","device_host_path":"/dev/dvb","desc":"Only needed if you want to pass through a DVB card to the container. If you use IPTV or HDHomeRun you can leave it out."}],"opt_cap_add_param":false,"optional_block_1":true,"optional_block_1_items":["#### Host vs. Bridge\n\nIf you use IPTV, SAT>IP or HDHomeRun, you need to create the container with --net=host and remove the -p flags. This is because to work with these services Tvheadend requires a multicast address of `239.255.255.250` and a UDP port of `1900` which at this time is not possible with docker bridge mode.\nIf you have other host services which also use multicast such as SSDP/DLNA/Emby you may experience stabilty problems. These can be solved by giving tvheadend its own IP using macvlan.\n"],"app_setup_block_enabled":true,"app_setup_block":"The setup depends if you run the one of the stable tags or use latest. Running latest is the easiest as it has a setup wizard.\n\n**Stable**\n\nFirst thing to do is to go to Configuration --> DVB Inputs --> TV adapters and add your LNB/switch info. Then create a new network in the Networks tab and set the correct pre-defined muxes and orbital position.\nGo back to the TV adapters tab and add the newly created network under universal LNB. Go back to the Networks tab and mark the network you created earlier and press the Force Scan button. Tvheadend will now scan the muxes for services.\n\nAfter the scan is done, head to the Services tab and find the services you want as channels, mark them, and press map services. They should now appear under Configuration --> Channel/EPG.\n\n**Latest**\n\nThe first thing to do is to run the setup wizard. If it doesn't pop up at first login, you can find it in Configuration --> General --> Base and click Start Wizard. This will guide you to set up the basic parts of tvheadend.\n\n**Configuring XMLTV grabber**\n\nTo configure the XMLTV grabber, first check if your grabber is listed in Configuration --> Channel/EPG --> EPG Grabber Modules. If it's listed, you will have to configure the grabber before enabling.\nFind the path in the path field of your grabber. We will use the last part. It starts with tv_grab_. Add it after /usr/bin/ in the below command. There should be no space between Usr/bin/ and the part you added.\n\n```\ndocker exec -it -u abc tvheadend /usr/bin/for_you_to_fill_out --configure\n```\n\nNow follow the onscreen progress. If you get asked about cache, just accept the default. After you have configured your grabber, you can go back and enable your grabber.\n\nIf you allready have a configuration file, you can add it in the .xmltv folder where you mapped the /config volume. If it's not created, create it.\n\n**Comskip**\nThis container comes with Comskip for commercial flagging of recordings. This you have to add in the recording config of tvheadend.\nGo to Configuration --> Recording. Change the view level to advanced in the top right corner, and add the below in the Post-processor command field.\n\n```\n/usr/bin/comskip --ini=/config/comskip/comskip.ini \"%f\"\n```\n\nNow comskip will run after each recording is finished. You will find comskip.ini in the comskip folder of your /config volume mapping. See the [Comskip](http://www.kaashoek.com/comskip/) homepage for tuning of the ini file.\n\n\n**FFmpeg**\n\nFFmpeg is installed in /usr/bin/ in case you need to use it with pipe.\n\n**EPG XML file**\n\nIf you have EPG data in XML format from a supplier, you can drop it in the data folder of your /config volume mapping. If it doesn't exist, create it. Then choose the XML file grabber in Configuration --> Channel/EPG --> EPG Grabber Modules.\nIf you use WebGrab+Plus, choose the WebGrab+Plus XML file grabber. The XML file goes in the same path as above.\nThe xml file has to be named guide.xml.\n\nFor advanced setup of tvheadend, go to [Tvheadend][appurl]\n\n**Picons**\n\nWe have added all the picons from [picons](https://github.com/picons/picons) in the folder /picons. To enable the use of these picons, add the path to the Channel icon path in Configuration --> General --> Base.\nYou need to enable minimum advanced view level to see the picons options.\n\n## Additional runtime parameters\n\nIn some cases it might be necessary to start tvheadend with additional parameters, for example to enable debugging or specify webroot for reverse proxy. Be sure to have the right parameters set, as adding the wrong once might lead to the container not starting correctly.\n","changelogs":[{"date":"31.08.22:","desc":"Update sample env vars and how RUN_OPTS are handled."},{"date":"19.08.22:","desc":"Switch to new picons builder."},{"date":"16.04.22:","desc":"Added URL XMLTV grabber."},{"date":"05.01.22:","desc":"Rebase to Alpine 3.15. Disable execinfo to fix builds. Update xmltv."},{"date":"11.05.21:","desc":"Added Intel iHD driver support."},{"date":"02.06.20:","desc":"Update to Alpine 3.12."},{"date":"27.12.19:","desc":"Add requests and perl-json-xs package."},{"date":"27.12.19:","desc":"Update to Alpine 3.11."},{"date":"02.10.19:","desc":"Improve permission fixing on render & dvb devices."},{"date":"18.08.19:","desc":"Add AMD drivers."},{"date":"02.08.19:","desc":"Attempt to automatically fix permissions on /dev/dri and /dev/dvb."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"27.03.19:","desc":"Rebase to Alpine 3.9, fix init logic to only chown once."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"01.03.19:","desc":"Bump xmltv to 0.6.1."},{"date":"28.02.19:","desc":"add perl-lwp-useragent-determined."},{"date":"17.02.19:","desc":"Bump xmltv to 5.70, ensure version tagging works by cloning tvheadend."},{"date":"14.02.19:","desc":"Add picons path to config."},{"date":"15.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"12.09.18:","desc":"Rebase to alpine 3.8 and use buildstage type build."},{"date":"21.04.18:","desc":"Add JSON::XS Perl package for grab_tv_huro."},{"date":"24.03.18:","desc":"Add dvbcsa package."},{"date":"04.03.18:","desc":"Use sourceforge master rather than mirror for xmltv."},{"date":"22.02.18:","desc":"Add lost libva-intel-driver."},{"date":"21.02.18:","desc":"Fix wrong version of iconv used."},{"date":"18.02.18:","desc":"Add vaapi support, some cleanup and dropping of deprecated options."},{"date":"04.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"11.12.17:","desc":"Rebase to alpine 3.7, linting fixes."},{"date":"02.09.17:","desc":"Add codec dependencies."},{"date":"13.07.17:","desc":"Increase uniformity across all archs."},{"date":"08.07.17:","desc":"Update README with full path for comskip."},{"date":"02.07.17:","desc":"Move to one branch for all 4.2 releases."},{"date":"27.05.17:","desc":"Rebase to alpine 3.6."},{"date":"01.05.17:","desc":"Update to tvheadend 4.2.1 stable."},{"date":"18.04.17:","desc":"Use repo version of gnu-libiconv rather than compiling."},{"date":"09.04.17:","desc":"Chain cpanm installs in one block and use --installdeps."},{"date":"09.02.17:","desc":"Perl changes, add picons file to gitignore and update XMLTV to 0.5.69."},{"date":"07.02.17:","desc":"Add variable to add additional runtime paramters."},{"date":"05.02.17:","desc":"Update to alpine 3.5 and change dvb-apps to only compile needed libs."},{"date":"14.11.16:","desc":"Add picons from picons.xyz to /picons folder and add info to README."},{"date":"22.09.16:","desc":"Fix broken tv_grab_wg, libs for xmltv and update README."},{"date":"18.09.16:","desc":"Update XMLTV to 0.5.68 and update README."},{"date":"10.09.16:","desc":"Add layer badges to README."},{"date":"05.09.16:","desc":"Initial Release."}]}},"setup":"The setup depends if you run the one of the stable tags or use latest. Running latest is the easiest as it has a setup wizard.\n\n**Stable**\n\nFirst thing to do is to go to Configuration --> DVB Inputs --> TV adapters and add your LNB/switch info. Then create a new network in the Networks tab and set the correct pre-defined muxes and orbital position.\nGo back to the TV adapters tab and add the newly created network under universal LNB. Go back to the Networks tab and mark the network you created earlier and press the Force Scan button. Tvheadend will now scan the muxes for services.\n\nAfter the scan is done, head to the Services tab and find the services you want as channels, mark them, and press map services. They should now appear under Configuration --> Channel/EPG.\n\n**Latest**\n\nThe first thing to do is to run the setup wizard. If it doesn't pop up at first login, you can find it in Configuration --> General --> Base and click Start Wizard. This will guide you to set up the basic parts of tvheadend.\n\n**Configuring XMLTV grabber**\n\nTo configure the XMLTV grabber, first check if your grabber is listed in Configuration --> Channel/EPG --> EPG Grabber Modules. If it's listed, you will have to configure the grabber before enabling.\nFind the path in the path field of your grabber. We will use the last part. It starts with tv_grab_. Add it after /usr/bin/ in the below command. There should be no space between Usr/bin/ and the part you added.\n\n```\ndocker exec -it -u abc tvheadend /usr/bin/for_you_to_fill_out --configure\n```\n\nNow follow the onscreen progress. If you get asked about cache, just accept the default. After you have configured your grabber, you can go back and enable your grabber.\n\nIf you allready have a configuration file, you can add it in the .xmltv folder where you mapped the /config volume. If it's not created, create it.\n\n**Comskip**\nThis container comes with Comskip for commercial flagging of recordings. This you have to add in the recording config of tvheadend.\nGo to Configuration --> Recording. Change the view level to advanced in the top right corner, and add the below in the Post-processor command field.\n\n```\n/usr/bin/comskip --ini=/config/comskip/comskip.ini \"%f\"\n```\n\nNow comskip will run after each recording is finished. You will find comskip.ini in the comskip folder of your /config volume mapping. See the [Comskip](http://www.kaashoek.com/comskip/) homepage for tuning of the ini file.\n\n\n**FFmpeg**\n\nFFmpeg is installed in /usr/bin/ in case you need to use it with pipe.\n\n**EPG XML file**\n\nIf you have EPG data in XML format from a supplier, you can drop it in the data folder of your /config volume mapping. If it doesn't exist, create it. Then choose the XML file grabber in Configuration --> Channel/EPG --> EPG Grabber Modules.\nIf you use WebGrab+Plus, choose the WebGrab+Plus XML file grabber. The XML file goes in the same path as above.\nThe xml file has to be named guide.xml.\n\nFor advanced setup of tvheadend, go to [Tvheadend][appurl]\n\n**Picons**\n\nWe have added all the picons from [picons](https://github.com/picons/picons) in the folder /picons. To enable the use of these picons, add the path to the Channel icon path in Configuration --> General --> Base.\nYou need to enable minimum advanced view level to see the picons options.\n\n## Additional runtime parameters\n\nIn some cases it might be necessary to start tvheadend with additional parameters, for example to enable debugging or specify webroot for reverse proxy. Be sure to have the right parameters set, as adding the wrong once might lead to the container not starting correctly.\n","_id":"content:apps:tvheadend.json","_type":"json","title":"Tvheadend","_source":"content","_file":"apps/tvheadend.json","_extension":"json"},{"_path":"/apps/ubooquity","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"ubooquity","name":"ubooquity","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, lightweight and easy-to-use home server for your comics and ebooks. Use it to access your files from anywhere, with a tablet, an e-reader, a phone or a computer.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ubooquity-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/ubooquity"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-ubooquity"}],"containers":[{"name":"ubooquity","image":"linuxserver/ubooquity","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."},{"id":"MAXMEM","default":"<maxmem>","description":"To set the maximum memory. ( ex: set '1024' for 1GB )"}],"volumes":[{"container":"/config","description":"Config files and database for ubooquity.","key":"config"},{"container":"/books","description":"Location of books."},{"container":"/comics","description":"Location of comics."},{"container":"/files","description":"Location of raw files."}],"ports":[{"container":"2202","description":"The library port.","protocol":"tcp","web":false},{"container":"2203","description":"The admin port.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"ubooquity","project_url":"https://vaemendis.net/ubooquity/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/ubooquity-banner.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a free, lightweight and easy-to-use home server for your comics and ebooks. Use it to access your files from anywhere, with a tablet, an e-reader, a phone or a computer.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."},{"env_var":"MAXMEM","env_value":"<maxmem>","desc":"To set the maximum memory. ( ex: set '1024' for 1GB )"}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Config files and database for ubooquity."},{"vol_path":"/books","vol_host_path":"<path to books>","desc":"Location of books."},{"vol_path":"/comics","vol_host_path":"<path to comics>","desc":"Location of comics."},{"vol_path":"/files","vol_host_path":"<path to raw files>","desc":"Location of raw files."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"2202","internal_port":"2202","port_desc":"The library port."},{"external_port":"2203","internal_port":"2203","port_desc":"The admin port."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"**IMPORTANT**\nUbooquity has now been upgraded to [version 2](http://vaemendis.net/ubooquity/article19/ubooquity-2-1-0) and for existing v1.x users we recommend cleaning your appdata and reinstalling, due to changes in the application itself making the two versions essentially incompatible with each other. Also the admin page and library pages are now on separate ports as detailed below.\n\nAccess the admin page at `http://<your-ip>:2203/ubooquity/admin` and set a password.\n\nThen you can access the webui at `http://<your-ip>:2202/ubooquity/`\n\nThis container will automatically scan your files at startup.\n\n### MAXMEM\n\nThe quantity of memory allocated to Ubooquity depends on the hardware your are running it on. If this quantity is too small, you might sometime saturate it with when performing memory intensive operations. Thats when you get `java.lang.OutOfMemoryError:` Java heap space errors.\n\nYou can explicitly set the amount of memory Ubooquity is allowed to use (be careful to set a value lower than the actual physical memory of your hardware). Value is a number of megabytes ( put just a number, without MB )\n\nIf no value is set it will default to 512MB.\n","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"28.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"15.10.18:","desc":"Upgrade to Ubooquity 2.1.2."},{"date":"23.08.18:","desc":"Rebase to alpine 3.8."},{"date":"09.12.17:","desc":"Rebase to alpine 3.7."},{"date":"07.10.17:","desc":"Upgrade to Ubooquity 2.1.1."},{"date":"16.07.17:","desc":"Upgrade to Ubooquity 2.1.0, see setting up application section for important info for existing v1.x users."},{"date":"26.05.17:","desc":"Rebase to alpine 3.6."},{"date":"08.04.17:","desc":"Switch to java from 3.5 repo, fixes login crashes."},{"date":"06.02.17:","desc":"Rebase to alpine 3.5."},{"date":"06.12.16:","desc":"Initial Release."}]}},"setup":"**IMPORTANT**\nUbooquity has now been upgraded to [version 2](http://vaemendis.net/ubooquity/article19/ubooquity-2-1-0) and for existing v1.x users we recommend cleaning your appdata and reinstalling, due to changes in the application itself making the two versions essentially incompatible with each other. Also the admin page and library pages are now on separate ports as detailed below.\n\nAccess the admin page at `http://<your-ip>:2203/ubooquity/admin` and set a password.\n\nThen you can access the webui at `http://<your-ip>:2202/ubooquity/`\n\nThis container will automatically scan your files at startup.\n\n### MAXMEM\n\nThe quantity of memory allocated to Ubooquity depends on the hardware your are running it on. If this quantity is too small, you might sometime saturate it with when performing memory intensive operations. Thats when you get `java.lang.OutOfMemoryError:` Java heap space errors.\n\nYou can explicitly set the amount of memory Ubooquity is allowed to use (be careful to set a value lower than the actual physical memory of your hardware). Value is a number of megabytes ( put just a number, without MB )\n\nIf no value is set it will default to 512MB.\n","_id":"content:apps:ubooquity.json","_type":"json","title":"Ubooquity","_source":"content","_file":"apps/ubooquity.json","_extension":"json"},{"_path":"/apps/unifi-controller","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"unifi-controller","name":"unifi-controller","description":"The [{{ project_name|capitalize }}]({{ project_url }}) software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance.","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/unifi-banner.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/unifi-controller"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-unifi-controller"}],"containers":[{"name":"unifi-controller","image":"linuxserver/unifi-controller","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use (e.g. Europe/London) - [see list](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)"},{"id":"MEM_LIMIT","default":"1024","description":"Optionally change the Java memory limit (in Megabytes). Set to `default` to reset to default"},{"id":"MEM_STARTUP","default":"1024","description":"Optionally change the Java initial/minimum memory (in Megabytes). Set to `default` to reset to default"}],"volumes":[{"container":"/config","description":"All Unifi data stored here","key":"config"}],"ports":[{"container":"8443","description":"Unifi web admin port","protocol":"tcp","web":false},{"container":"3478/udp","description":"Unifi STUN port","protocol":"tcp","web":false},{"container":"10001/udp","description":"Required for AP discovery","protocol":"tcp","web":false},{"container":"8080","description":"Required for device communication","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"unifi-controller","project_url":"https://www.ubnt.com/enterprise/#unifi","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/unifi-banner.png","project_blurb":"The [{{ project_name|capitalize }}]({{ project_url }}) software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"}],"development_versions":false,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"All Unifi data stored here"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"8443","internal_port":"8443","port_desc":"Unifi web admin port"},{"external_port":"3478","internal_port":"3478/udp","port_desc":"Unifi STUN port"},{"external_port":"10001","internal_port":"10001/udp","port_desc":"Required for AP discovery"},{"external_port":"8080","internal_port":"8080","port_desc":"Required for device communication"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use (e.g. Europe/London) - [see list](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"MEM_LIMIT","env_value":"1024","desc":"Optionally change the Java memory limit (in Megabytes). Set to `default` to reset to default"},{"env_var":"MEM_STARTUP","env_value":"1024","desc":"Optionally change the Java initial/minimum memory (in Megabytes). Set to `default` to reset to default"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"1900","internal_port":"1900/udp","port_desc":"Required for `Make controller discoverable on L2 network` option"},{"external_port":"8843","internal_port":"8843","port_desc":"Unifi guest portal HTTPS redirect port"},{"external_port":"8880","internal_port":"8880","port_desc":"Unifi guest portal HTTP redirect port"},{"external_port":"6789","internal_port":"6789","port_desc":"For mobile throughput test"},{"external_port":"5514","internal_port":"5514/udp","port_desc":"Remote syslog port"}],"app_setup_block_enabled":true,"app_setup_block":"The webui is at https://ip:8443, setup with the first run wizard.\n\nFor Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption).\n\nIn order to manually adopt a device take these steps:\n\n```\nssh ubnt@$AP-IP\nset-inform http://$address:8080/inform\n```\n\nThe default device password is `ubnt`. `$address` is the IP address of the host you are running this container on and `$AP-IP` is the Access Point IP address.\n\nWhen using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessable) ip address.\n","changelogs":[{"date":"23.01.23:","desc":"Exclude `run` from `/config` volume."},{"date":"30.11.22:","desc":"Bump JRE to 11."},{"date":"01.06.22:","desc":"Deprecate armhf."},{"date":"23.12.21:","desc":"Move min/max memory config from run to system.properties."},{"date":"22.12.21:","desc":"Move deb package install to first init to avoid overlayfs performance issues."},{"date":"13.12.21:","desc":"Rebase 64 bit containers to Focal."},{"date":"11.12.21:","desc":"Add java opts to mitigate CVE-2021-44228."},{"date":"11.06.21:","desc":"Allow for changing Java initial mem via new optional environment variable."},{"date":"12.01.21:","desc":"Deprecate the `LTS` tag as Unifi no longer releases LTS stable builds. Existing users can switch to the `latest` tag. Direct upgrade from 5.6.42 (LTS) to 6.0.42 (latest) tested successfully."},{"date":"17.07.20:","desc":"Rebase 64 bit containers to Bionic and Mongo 3.6."},{"date":"16.06.20:","desc":"Add logrotate."},{"date":"02.06.20:","desc":"Updated port list & descriptions. Moved some ports to optional."},{"date":"14.11.19:","desc":"Changed url for deb package to match new Ubiquity domain."},{"date":"29.07.19:","desc":"Allow for changing Java mem limit via new optional environment variable."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"10.02.19:","desc":"Initial release of new unifi-controller image with new tags and pipeline logic"}]}},"setup":"The webui is at https://ip:8443, setup with the first run wizard.\n\nFor Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption).\n\nIn order to manually adopt a device take these steps:\n\n```\nssh ubnt@$AP-IP\nset-inform http://$address:8080/inform\n```\n\nThe default device password is `ubnt`. `$address` is the IP address of the host you are running this container on and `$AP-IP` is the Access Point IP address.\n\nWhen using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessable) ip address.\n","_id":"content:apps:unifi-controller.json","_type":"json","title":"Unifi Controller","_source":"content","_file":"apps/unifi-controller.json","_extension":"json"},{"_path":"/apps/vikunja","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"vikunja","name":"Vikunja","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/vikunja.png","containers":[{"name":"api","image":"vikunja/api","env":[{"id":"VIKUNJA_DATABASE_HOST","default":"db"},{"id":"VIKUNJA_DATABASE_PASSWORD","default":"secret"},{"id":"VIKUNJA_DATABASE_TYPE","default":"mysql"},{"id":"VIKUNJA_DATABASE_USER","default":"vikunja"},{"id":"VIKUNJA_DATABASE_DATABASE","default":"vikunja"},{"id":"VIKUNJA_SERVICE_JWTSECRET","default":"<random>"},{"id":"VIKUNJA_SERVICE_FRONTENDURL","default":"http://localhost:8888"}],"volumes":[{"container":"/app/vikunja/files","description":"Path to your Config","key":"config"}],"ports":[{"key":"api","container":3456,"description":"API","protocol":"tcp","web":true}]},{"name":"frontend","image":"vikunja/frontend","env":[{"id":"VIKUNJA_API_URL","default":"http://<your-ip-here>:3456/api/v1"}],"ports":[{"key":"webui","container":80,"description":"WebUI","protocol":"tcp","web":true}]}],"_id":"content:apps:vikunja.json","_type":"json","title":"Vikunja","_source":"content","_file":"apps/vikunja.json","_extension":"json"},{"_path":"/apps/webgrabplus","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"webgrabplus","name":"webgrabplus","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-site incremental xmltv epg grabber. It collects tv-program guide data from selected tvguide sites for your favourite channels.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/webgrabplus.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/webgrabplus"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-webgrabplus"}],"containers":[{"name":"webgrabplus","image":"linuxserver/webgrabplus","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"}],"volumes":[{"container":"/config","description":"Where webgrabplus should store it's config files.","key":"config"},{"container":"/data","description":"Where webgrabplus should store it's data files."}]}],"meta":{"readme-vars":{"project_name":"webgrabplus","project_url":"http://www.webgrabplus.com","project_logo":"http://www.webgrabplus.com/sites/default/themes/WgTheme/images/slideshows/EPG_fading.jpg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a multi-site incremental xmltv epg grabber. It collects tv-program guide data from selected tvguide sites for your favourite channels.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_hostname":true,"param_hostname":"webgrabplus","param_hostname_desc":"Set the hostname for the container for the license check.","param_usage_include_mac_address":true,"param_mac_address":"00:00:00:00:00:00","param_mac_address_desc":"Set the mac_address for the container for the license check.","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Where webgrabplus should store it's config files."},{"vol_path":"/data","vol_host_path":"/path/to/data","desc":"Where webgrabplus should store it's data files."}],"param_usage_include_ports":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"To configure WebGrab+Plus follow the [documentation](http://www.webgrabplus.com/documentation/configuration/)\n\n**Please note that depending on your host this container may not work with the `no-new-privileges=true` security-opt.**\n\nNote that there are some things in the guide that does not apply to this container. Below you can find the changes.\n\n**The configuration files are found where your config volume is mounted.**\n**Do not change the filename tag in the configuration file!**\n\nThe /data volume mapping is where WebGrab+Plus outputs the xml file. To use the xml file in another program, you have to point it to the host path you mapped the /data volume to.\n\nTo adjust the scheduled cron job for grabbing, edit the wg3-cron file found in the `/config` folder. After you have edited the the wg3-cron file, restart the container to apply the new schedule.\nDo not adjust the command!\n\n**Note that due to something in version 3, we had to change the commands for scheduling the grab. If you have a version where there is a wg-cron file in your /config mount, delete it and use wg3-cron instead.**\n\nBelow is the syntax of the cron file.\n\n```\n  minute (0 - 59)\n   hour (0 - 23)\n    day of month (1 - 31)\n     month (1 - 12)\n      day of week (0 - 6) (Sunday to Saturday;\n                                            7 is also Sunday on some systems)\n     \n     \n * * * * *  /bin/bash /defaults/update.sh\n```\n","changelogs":[{"date":"23.03.22:","desc":"Rebase to Alpine 3.16 and s6v3. Update to dotnet 6."},{"date":"29.04.22:","desc":"Add `hostname` and `mac_address` arguments that are needed for the license check to compose and cli samples."},{"date":"23.03.22:","desc":"Rebase to Alpine 3.15."},{"date":"23.03.22:","desc":"Update to use dotnet instead of mono."},{"date":"06.01.22:","desc":"Rebase to Ubuntu focal. Enable auto builds on version updates (beta and stable)."},{"date":"17.12.21:","desc":"Update to version 3.2.2 beta."},{"date":"05.08.21:","desc":"Update to version 3.2.1 beta."},{"date":"05.06.21:","desc":"Added mono-devel dependency."},{"date":"04.06.21:","desc":"Update to version 3.1.8 beta."},{"date":"22.03.21:","desc":"Update to version 3.1.7 beta."},{"date":"07.03.21:","desc":"Update to version 3.1.6 beta."},{"date":"29.01.21:","desc":"Update external version number to show as 3.1.5."},{"date":"24.01.21:","desc":"Update to version 3.1.5 beta."},{"date":"22.12.20:","desc":"Update to version 3.1.4 beta."},{"date":"12.10.20:","desc":"Fix version number in jenkinsfile."},{"date":"12.10.20:","desc":"Update to version 3.1.1 beta."},{"date":"22.06.20:","desc":"Add mono webrequest library."},{"date":"18.06.20:","desc":"Update to v3.1.0."},{"date":"29.03.20:","desc":"Update to v3.0.0. Changed to use wg3-cron file."},{"date":"28.05.19:","desc":"Update to v2.1.0 and beta v2.1.9, rebase to bionic."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"21.03.19:","desc":"Update to beta 2.1.7."},{"date":"19.02.19:","desc":"Add pipeline logic and multi arch."},{"date":"18.01.18:","desc":"Initial Release."}]}},"setup":"To configure WebGrab+Plus follow the [documentation](http://www.webgrabplus.com/documentation/configuration/)\n\n**Please note that depending on your host this container may not work with the `no-new-privileges=true` security-opt.**\n\nNote that there are some things in the guide that does not apply to this container. Below you can find the changes.\n\n**The configuration files are found where your config volume is mounted.**\n**Do not change the filename tag in the configuration file!**\n\nThe /data volume mapping is where WebGrab+Plus outputs the xml file. To use the xml file in another program, you have to point it to the host path you mapped the /data volume to.\n\nTo adjust the scheduled cron job for grabbing, edit the wg3-cron file found in the `/config` folder. After you have edited the the wg3-cron file, restart the container to apply the new schedule.\nDo not adjust the command!\n\n**Note that due to something in version 3, we had to change the commands for scheduling the grab. If you have a version where there is a wg-cron file in your /config mount, delete it and use wg3-cron instead.**\n\nBelow is the syntax of the cron file.\n\n```\n  minute (0 - 59)\n   hour (0 - 23)\n    day of month (1 - 31)\n     month (1 - 12)\n      day of week (0 - 6) (Sunday to Saturday;\n                                            7 is also Sunday on some systems)\n     \n     \n * * * * *  /bin/bash /defaults/update.sh\n```\n","_id":"content:apps:webgrabplus.json","_type":"json","title":"Webgrabplus","_source":"content","_file":"apps/webgrabplus.json","_extension":"json"},{"_path":"/apps/webtop","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"webtop","name":"webtop","description":"[{{ project_name|capitalize }}]({{ project_url }}) - Alpine, Ubuntu, Fedora, and Arch based containers containing full desktop environments in officially supported flavors accessible via any modern web browser.\n","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/webtop-logo.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/webtop"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-webtop"}],"containers":[{"name":"webtop","image":"linuxserver/webtop","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SUBFOLDER","default":"/","description":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"id":"KEYBOARD","default":"en-us-qwerty","description":"See the keyboard layouts section for more information and options."},{"id":"TITLE","default":"Webtop","description":"String which will be used as page/tab title in the web browser."}],"volumes":[{"container":"/var/run/docker.sock","description":"Docker Socket on the system, if you want to use Docker in the container"},{"container":"/config","description":"abc users home directory","key":"config"}],"ports":[{"container":"3000","description":"Web Desktop GUI","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"webtop","project_url":"https://github.com/linuxserver/docker-webtop","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/webtop-logo.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) - Alpine, Ubuntu, Fedora, and Arch based containers containing full desktop environments in officially supported flavors accessible via any modern web browser.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"XFCE Alpine"},{"tag":"ubuntu-xfce","desc":"XFCE Ubuntu"},{"tag":"fedora-xfce","desc":"XFCE Fedora"},{"tag":"arch-xfce","desc":"XFCE Arch"},{"tag":"alpine-kde","desc":"KDE Alpine"},{"tag":"ubuntu-kde","desc":"KDE Ubuntu"},{"tag":"fedora-kde","desc":"KDE Fedora"},{"tag":"arch-kde","desc":"KDE Arch"},{"tag":"alpine-mate","desc":"MATE Alpine"},{"tag":"ubuntu-mate","desc":"MATE Ubuntu"},{"tag":"fedora-mate","desc":"MATE Fedora"},{"tag":"arch-mate","desc":"MATE Arch"},{"tag":"alpine-i3","desc":"i3 Alpine"},{"tag":"ubuntu-i3","desc":"i3 Ubuntu"},{"tag":"fedora-i3","desc":"i3 Fedora"},{"tag":"arch-i3","desc":"i3 Arch"},{"tag":"alpine-openbox","desc":"Openbox Alpine"},{"tag":"ubuntu-openbox","desc":"Openbox Ubuntu"},{"tag":"fedora-openbox","desc":"Openbox Fedora"},{"tag":"arch-openbox","desc":"Openbox Arch"},{"tag":"alpine-icewm","desc":"IceWM Alpine"},{"tag":"ubuntu-icewm","desc":"IceWM Ubuntu"},{"tag":"fedora-icewm","desc":"IceWM Fedora"},{"tag":"arch-icewm","desc":"IceWM Arch"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"abc users home directory"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Web Desktop GUI"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SUBFOLDER","env_value":"/","desc":"Specify a subfolder to use with reverse proxies, IE `/subfolder/`"},{"env_var":"KEYBOARD","env_value":"en-us-qwerty","desc":"See the keyboard layouts section for more information and options."},{"env_var":"TITLE","env_value":"Webtop","desc":"String which will be used as page/tab title in the web browser."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/var/run/docker.sock","vol_host_path":"/var/run/docker.sock","desc":"Docker Socket on the system, if you want to use Docker in the container"}],"opt_custom_params":[{"name":"shm-size","name_compose":"shm_size","value":"1gb","desc":"We set this to 1 gig to prevent modern web browsers from crashing"}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"opt_param_device_map":true,"opt_param_devices":[{"device_path":"/dev/dri","device_host_path":"/dev/dri","desc":"Add this for GL support (Linux hosts only)"}],"app_setup_block_enabled":true,"app_setup_block":"The Webtop can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\nYou can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste, an onscreen keyboard, or a baked in file manager. This can also be accessed by clicking the small circle on the left side of the screen.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\n\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it webtop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt. \n","changelogs":[{"date":"21.10.22:","desc":"Rebase xfce to Alpine 3.16, migrate to s6v3."},{"date":"12.03.22:","desc":"Add documentation for mounting in a GPU."},{"date":"05.02.22:","desc":"Rebase KDE Ubuntu to Jammy, add new documentation for updated gclient, stop recommending priv mode."},{"date":"21.09.21:","desc":"Add Fedora and Arch images, show seccomp settings in readme."},{"date":"26.09.21:","desc":"Rebase to Alpine versions to 3.14."},{"date":"20.04.21:","desc":"Initial release."}]}},"setup":"The Webtop can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nYou can also force login on the '/' path without this parameter by passing the environment variable `-e AUTO_LOGIN=false`.\n\nYou can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste, an onscreen keyboard, or a baked in file manager. This can also be accessed by clicking the small circle on the left side of the screen.\n\n**Modern GUI desktop apps (including some flavors terminals) have issues with the latest Docker and syscall compatibility, you can use Docker with the `--security-opt seccomp=unconfined` setting to allow these syscalls or try [podman](https://podman.io/) as they have updated their codebase to support them**\n\n**Unlike our other containers these Desktops are not designed to be upgraded by Docker, you will keep your home directoy but anything you installed system level will be lost if you upgrade an existing container. To keep packages up to date instead use Ubuntu's own apt, Alpine's apk, Fedora's dnf, or Arch's pacman program**\n\n#### Keyboard Layouts\n\nThis should match the layout on the computer you are accessing the container from.\n\nThe keyboard layouts available for use are:\n* da-dk-qwerty- Danish keyboard\n* de-ch-qwertz- Swiss German keyboard (qwertz)\n* de-de-qwertz- German keyboard (qwertz) - **OSK available**\n* en-gb-qwerty- English (UK) keyboard\n* en-us-qwerty- English (US) keyboard - **OSK available** **DEFAULT**\n* es-es-qwerty- Spanish keyboard - **OSK available**\n* fr-ch-qwertz- Swiss French keyboard (qwertz)\n* fr-fr-azerty- French keyboard (azerty) - **OSK available**\n* it-it-qwerty- Italian keyboard - **OSK available**\n* ja-jp-qwerty- Japanese keyboard\n* pt-br-qwerty- Portuguese Brazilian keyboard\n* sv-se-qwerty- Swedish keyboard\n* tr-tr-qwerty- Turkish-Q keyboard\n\nIf you ever lose your password you can always reset it by execing into the container as root:\n```\ndocker exec -it webtop passwd abc\n```\nBy default we perform all logic for the abc user and we reccomend using that user only in the container, but new users can be added as long as there is a `startwm.sh` executable script in their home directory.\nAll of these containers are configured with passwordless sudo, we make no efforts to secure or harden these containers and we do not reccomend ever publishing their ports to the public Internet.\n\n## Hardware Acceleration (Ubuntu Container Only)\n\nMany desktop application will need access to a GPU to function properly and even some Desktop Environments have compisitor effects that will not function without a GPU. This is not a hard requirement and all base images will function without a video device mounted into the container.\n\n### Intel/ATI/AMD\n\nTo leverage hardware acceleration you will need to mount /dev/dri video device inside of the conainer.\n```\n--device=/dev/dri:/dev/dri\n```\nWe will automatically ensure the abc user inside of the container has the proper permissions to access this device.\n### Nvidia\n\nHardware acceleration users for Nvidia will need to install the container runtime provided by Nvidia on their host, instructions can be found here:\nhttps://github.com/NVIDIA/nvidia-docker\n\nWe automatically add the necessary environment variable that will utilise all the features available on a GPU on the host. Once nvidia-docker is installed on your host you will need to re/create the docker container with the nvidia container runtime `--runtime=nvidia` and add an environment variable `-e NVIDIA_VISIBLE_DEVICES=all` (can also be set to a specific gpu's UUID, this can be discovered by running `nvidia-smi --query-gpu=gpu_name,gpu_uuid --format=csv` ). NVIDIA automatically mounts the GPU and drivers from your host into the container.\n\n### Arm Devices\n\nBest effort is made to install tools to allow mounting in /dev/dri on Arm devices. In most cases if /dev/dri exists on the host it should just work. If running a Raspberry Pi 4 be sure to enable `dtoverlay=vc4-fkms-v3d` in your usercfg.txt. \n","_id":"content:apps:webtop.json","_type":"json","title":"Webtop","_source":"content","_file":"apps/webtop.json","_extension":"json"},{"_path":"/apps/wikijs","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"wikijs","name":"wikijs","description":"[{{ project_name|capitalize }}]({{ project_url }}) A modern, lightweight and powerful wiki app built on NodeJS.","icon":"https://static.requarks.io/logo/wikijs-full.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wikijs"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wikijs"}],"containers":[{"name":"wikijs","image":"linuxserver/wikijs","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where Wiki.js config is stored.","key":"config"},{"container":"/data","description":"Where Wiki.js data is stored."}],"ports":[{"container":"3000","description":"Port for Wiki.js's web interface.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"wikijs","project_url":"https://github.com/Requarks/wiki","project_logo":"https://static.requarks.io/logo/wikijs-full.svg","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) A modern, lightweight and powerful wiki app built on NodeJS.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"project_blurb_optional_extras":[],"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"development_versions_items":null,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to config>","desc":"Where Wiki.js config is stored."},{"vol_path":"/data","vol_host_path":"<path to data>","desc":"Where Wiki.js data is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"Port for Wiki.js's web interface."}],"opt_param_usage_include_env":false,"opt_param_env_vars":null,"opt_param_usage_include_vols":false,"opt_param_volumes":null,"opt_param_usage_include_ports":false,"opt_param_ports":null,"opt_param_device_map":false,"opt_param_devices":null,"opt_cap_add_param":false,"opt_cap_add_param_vars":null,"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":false,"app_setup_block":"","changelogs":[{"date":"10.10.22:","desc":"Rebasing to alpine 3.16, migrate to s6v3."},{"date":"23.01.21:","desc":"Rebasing to alpine 3.13."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"28.04.20:","desc":"Added python dependency for some NPM modules as well as git for storage module"},{"date":"14.12.19:","desc":"Initial Release."}]}},"_id":"content:apps:wikijs.json","_type":"json","title":"Wikijs","_source":"content","_file":"apps/wikijs.json","_extension":"json"},{"_path":"/apps/wireguard","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"wireguard","name":"wireguard","description":"[WireGuard]({{ project_url }}) is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.","icon":"https://www.wireguard.com/img/wireguard.svg","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wireguard"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wireguard"}],"containers":[{"name":"wireguard","image":"linuxserver/wireguard","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London"},{"id":"SERVERURL","default":"wireguard.domain.com","description":"External IP or domain name for docker host. Used in server mode. If set to `auto`, the container will try to determine and set the external IP automatically"},{"id":"SERVERPORT","default":"51820","description":"External port for docker host. Used in server mode."},{"id":"PEERS","default":"1","description":"Number of peers to create confs for. Required for server mode. Can also be a list of names: `myPC,myPhone,myTablet` (alphanumeric only)"},{"id":"PEERDNS","default":"auto","description":"DNS server set in peer/client configs (can be set as `8.8.8.8`). Used in server mode. Defaults to `auto`, which uses wireguard docker host's DNS via included CoreDNS forward."},{"id":"INTERNAL_SUBNET","default":"10.13.13.0","description":"Internal subnet for the wireguard and server and peers (only change if it clashes). Used in server mode."},{"id":"ALLOWEDIPS","default":"0.0.0.0/0","description":"The IPs/Ranges that the peers will be able to reach using the VPN connection. If not specified the default value is: '0.0.0.0/0, ::0/0' This will cause ALL traffic to route through the VPN, if you want split tunneling, set this to only the IPs you would like to use the tunnel AND the ip of the server's WG ip, such as 10.13.13.1."},{"id":"PERSISTENTKEEPALIVE_PEERS","default":"","description":"Set to `all` or a list of comma separated peers (ie. `1,4,laptop`) for the wireguard server to send keepalive packets to listed peers every 25 seconds. Useful if server is accessed via domain name and has dynamic IP. Used only in server mode."},{"id":"LOG_CONFS","default":"true","description":"Generated QR codes will be displayed in the docker log. Set to `false` to skip log output."}],"volumes":[{"container":"/lib/modules","description":"Maps host's modules folder. Only required if compiling wireguard modules."},{"container":"/config","description":"Contains all relevant configuration files.","key":"config"}],"ports":[{"container":"51820/udp","description":"wireguard port","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"wireguard","project_url":"https://www.wireguard.com/","project_logo":"https://www.wireguard.com/img/wireguard.svg","project_blurb":"[WireGuard]({{ project_url }}) is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":true,"development_versions_items":[{"tag":"latest","desc":"Stable releases with support for compiling Wireguard modules"},{"tag":"alpine","desc":"Stable releases based on Alpine *without* support for compiling Wireguard modules"}],"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/appdata/config","desc":"Contains all relevant configuration files."}],"opt_param_usage_include_vols":true,"opt_param_volumes":[{"vol_path":"/lib/modules","vol_host_path":"/lib/modules","desc":"Maps host's modules folder. Only required if compiling wireguard modules."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"51820","internal_port":"51820/udp","port_desc":"wireguard port"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London"}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"},{"cap_add_var":"SYS_MODULE"}],"custom_params":[{"name":"sysctl","name_compose":"sysctls","value":["net.ipv4.conf.all.src_valid_mark=1"],"desc":"Required for client mode.","array":"true"}],"opt_param_usage_include_env":true,"opt_param_env_vars":[{"env_var":"SERVERURL","env_value":"wireguard.domain.com","desc":"External IP or domain name for docker host. Used in server mode. If set to `auto`, the container will try to determine and set the external IP automatically"},{"env_var":"SERVERPORT","env_value":"51820","desc":"External port for docker host. Used in server mode."},{"env_var":"PEERS","env_value":"1","desc":"Number of peers to create confs for. Required for server mode. Can also be a list of names: `myPC,myPhone,myTablet` (alphanumeric only)"},{"env_var":"PEERDNS","env_value":"auto","desc":"DNS server set in peer/client configs (can be set as `8.8.8.8`). Used in server mode. Defaults to `auto`, which uses wireguard docker host's DNS via included CoreDNS forward."},{"env_var":"INTERNAL_SUBNET","env_value":"10.13.13.0","desc":"Internal subnet for the wireguard and server and peers (only change if it clashes). Used in server mode."},{"env_var":"ALLOWEDIPS","env_value":"0.0.0.0/0","desc":"The IPs/Ranges that the peers will be able to reach using the VPN connection. If not specified the default value is: '0.0.0.0/0, ::0/0' This will cause ALL traffic to route through the VPN, if you want split tunneling, set this to only the IPs you would like to use the tunnel AND the ip of the server's WG ip, such as 10.13.13.1."},{"env_var":"PERSISTENTKEEPALIVE_PEERS","env_value":"","desc":"Set to `all` or a list of comma separated peers (ie. `1,4,laptop`) for the wireguard server to send keepalive packets to listed peers every 25 seconds. Useful if server is accessed via domain name and has dynamic IP. Used only in server mode."},{"env_var":"LOG_CONFS","env_value":"true","desc":"Generated QR codes will be displayed in the docker log. Set to `false` to skip log output."}],"optional_block_1":false,"optional_block_1_items":"","app_setup_block_enabled":true,"app_setup_block":"During container start, it will first check if the wireguard module is already installed and loaded. Kernels newer than 5.6 generally have the wireguard module built-in (along with some older custom kernels). However, the module may not be enabled. Make sure it is enabled prior to starting the container.\n\nIf the kernel is not built-in, or installed on host, the container will check if the kernel headers are present (in `/usr/src`) and if not, it will attempt to download the necessary kernel headers from the `ubuntu xenial/bionic`, `debian/raspbian buster` repos; then will attempt to compile and install the kernel module. If the kernel headers are not found in either `usr/src` or in the repos mentioned, container will sleep indefinitely as wireguard cannot be installed.\n\nIf you're on a debian/ubuntu based host with a custom or downstream distro provided kernel (ie. Pop!_OS), the container won't be able to install the kernel headers from the regular ubuntu and debian repos. In those cases, you can try installing the headers on the host via `sudo apt install linux-headers-$(uname -r)` (if distro version) and then add a volume mapping for `/usr/src:/usr/src`, or if custom built, map the location of the existing headers to allow the container to use host installed headers to build the kernel module (tested successful on Pop!_OS, ymmv).\n\nWith regards to arm32/64 devices, Raspberry Pi 2-4 running the [official ubuntu images](https://ubuntu.com/download/raspberry-pi) or Raspbian Buster are supported out of the box. For all other devices and OSes, you can try installing the kernel headers on the host, and mapping `/usr/src:/usr/src` and it may just work (no guarantees).\n\nThis can be run as a server or a client, based on the parameters used.\n\n## Server Mode\n\nIf the environment variable `PEERS` is set to a number or a list of strings separated by comma, the container will run in server mode and the necessary server and peer/client confs will be generated. The peer/client config qr codes will be output in the docker log if `LOG_CONFS` is set to `true`. They will also be saved in text and png format under `/config/peerX` in case `PEERS` is a variable and an integer or `/config/peer_X` in case a list of names was provided instead of an integer.\n\nVariables `SERVERURL`, `SERVERPORT`, `INTERNAL_SUBNET`, `PEERDNS`, `INTERFACE`, `ALLOWEDIPS` and `PERSISTENTKEEPALIVE_PEERS` are optional variables used for server mode. Any changes to these environment variables will trigger regeneration of server and peer confs. Peer/client confs will be recreated with existing private/public keys. Delete the peer folders for the keys to be recreated along with the confs.\n\nTo add more peers/clients later on, you increment the `PEERS` environment variable or add more elements to the list and recreate the container.\n\nTo display the QR codes of active peers again, you can use the following command and list the peer numbers as arguments: `docker exec -it wireguard /app/show-peer 1 4 5` or `docker exec -it wireguard /app/show-peer myPC myPhone myTablet` (Keep in mind that the QR codes are also stored as PNGs in the config folder).\n\nThe templates used for server and peer confs are saved under `/config/templates`. Advanced users can modify these templates and force conf generation by deleting `/config/wg0.conf` and restarting the container.\n\n## Client Mode\n\nDo not set the `PEERS` environment variable. Drop your client conf into the config folder as `/config/wg0.conf` and start the container.\n\nIf you get IPv6 related errors in the log and connection cannot be established, edit the `AllowedIPs` line in your peer/client wg0.conf to include only `0.0.0.0/0` and not `::/0`; and restart the container.\n\n## Road warriors, roaming and returning home\n\nIf you plan to use Wireguard both remotely and locally, say on your mobile phone, you will need to consider routing. Most firewalls will not route ports forwarded on your WAN interface correctly to the LAN out of the box. This means that when you return home, even though you can see the Wireguard server, the return packets will probably get lost.\n\nThis is not a Wireguard specific issue and the two generally accepted solutions are NAT reflection (setting your edge router/firewall up in such a way as it translates internal packets correctly) or split horizon DNS (setting your internal DNS to return the private rather than public IP when connecting locally).\n\nBoth of these approaches have positives and negatives however their setup is out of scope for this document as everyone's network layout and equipment will be different.\n\n## Maintaining local access to attached services\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nWhen routing via Wireguard from another container using the `service` option in docker, you might lose access to the containers webUI locally. To avoid this, exclude the docker subnet from being routed via Wireguard by modifying your `wg0.conf` like so (modifying the subnets as you require):\n\n  ```ini\n  [Interface]\n  PrivateKey = <private key>\n  Address = 9.8.7.6/32\n  DNS = 8.8.8.8\n  PostUp = DROUTE=$(ip route | grep default | awk '{print $3}'); HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route add $HOMENET3 via $DROUTE;ip route add $HOMENET2 via $DROUTE; ip route add $HOMENET via $DROUTE;iptables -I OUTPUT -d $HOMENET -j ACCEPT;iptables -A OUTPUT -d $HOMENET2 -j ACCEPT; iptables -A OUTPUT -d $HOMENET3 -j ACCEPT;  iptables -A OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n  PreDown = HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route del $HOMENET3 via $DROUTE;ip route del $HOMENET2 via $DROUTE; ip route del $HOMENET via $DROUTE; iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT; iptables -D OUTPUT -d $HOMENET -j ACCEPT; iptables -D OUTPUT -d $HOMENET2 -j ACCEPT; iptables -D OUTPUT -d $HOMENET3 -j ACCEPT\n  ```\n\n## Site-to-site VPN\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nSite-to-site VPN in server mode requires customizing the `AllowedIPs` statement for a specific peer in `wg0.conf`. Since `wg0.conf` is autogenerated when server vars are changed, it is not recommended to edit it manually.\n\nIn order to customize the `AllowedIPs` statement for a specific peer in `wg0.conf`, you can set an env var `SERVER_ALLOWEDIPS_PEER_<peer name or number>` to the additional subnets you'd like to add, comma separated and excluding the peer IP (ie. `\"192.168.1.0/24,192.168.2.0/24\"`). Replace `<peer name or number>` with either the name or number of a peer (whichever is used in the `PEERS` var).\n\nFor instance `SERVER_ALLOWEDIPS_PEER_laptop=\"192.168.1.0/24,192.168.2.0/24\"` will result in the wg0.conf entry `AllowedIPs = 10.13.13.2,192.168.1.0/24,192.168.2.0/24` for the peer named `laptop`.\n\nKeep in mind that this var will only be considered when the confs are regenerated. Adding this var for an existing peer won't force a regeneration. You can delete wg0.conf and restart the container to force regeneration if necessary.\n\nDon't forget to set the necessary POSTUP and POSTDOWN rules in your client's peer conf for lan access.\n","changelogs":[{"date":"28.01.23:","desc":"Patch wg-quick to suppress false positive sysctl warning."},{"date":"10.01.23:","desc":"Add new var to add `PersistentKeepalive` to server config for select peers to survive server IP changes when domain name is used."},{"date":"26.10.22:","desc":"Better handle unsupported peer names. Improve logging."},{"date":"12.10.22:","desc":"Add Alpine branch. Optimize wg and coredns services."},{"date":"09.10.22:","desc":"Switch back to iptables-legacy due to issues on some hosts."},{"date":"04.10.22:","desc":"Rebase to Jammy. Upgrade to s6v3."},{"date":"16.05.22:","desc":"Improve NAT handling in server mode when multiple ethernet devices are present."},{"date":"23.04.22:","desc":"Add pre-shared key support. Automatically added to all new peer confs generated, existing ones are left without to ensure no breaking changes."},{"date":"10.04.22:","desc":"Rebase to Ubuntu Focal. Add `LOG_CONFS` env var. Remove deprecated `add-peer` command."},{"date":"28.10.21:","desc":"Add site-to-site vpn support."},{"date":"11.02.21:","desc":"Fix bug related to changing internal subnet and named peer confs not updating."},{"date":"06.10.20:","desc":"Disable CoreDNS in client mode, or if port 53 is already in use in server mode."},{"date":"04.10.20:","desc":"Allow to specify a list of names as PEERS and add ALLOWEDIPS environment variable. Also, add peer name/id to each one of the peer sections in wg0.conf. Important: Existing users need to delete `/config/templates/peer.conf` and restart"},{"date":"27.09.20:","desc":"Cleaning service binding example to have accurate PreDown script."},{"date":"06.08.20:","desc":"Replace resolvconf with openresolv due to dns issues when a client based on this image is connected to a server also based on this image. Add IPv6 info to readme. Display kernel version in logs."},{"date":"29.07.20:","desc":"Update Coredns config to detect dns loops (existing users need to delete `/config/coredns/Corefile` and restart)."},{"date":"27.07.20:","desc":"Update Coredns config to prevent issues with non-user-defined bridge networks (existing users need to delete `/config/coredns/Corefile` and restart)."},{"date":"05.07.20:","desc":"Add Debian updates and security repos for headers."},{"date":"25.06.20:","desc":"Simplify module tests, prevent iptables issues from resulting in false negatives."},{"date":"19.06.20:","desc":"Add support for Ubuntu Focal (20.04) kernels. Compile wireguard tools and kernel module instead of using the ubuntu packages. Make module install optional. Improve verbosity in logs."},{"date":"29.05.20:","desc":"Add support for 64bit raspbian."},{"date":"28.04.20:","desc":"Add Buster/Stretch backports repos for Debian. Tested with OMV 5 and OMV 4 (on kernel 4.19.0-0.bpo.8-amd64)."},{"date":"20.04.20:","desc":"Fix typo in client mode conf existence check."},{"date":"13.04.20:","desc":"Fix bug that forced conf recreation on every start."},{"date":"08.04.20:","desc":"Add arm32/64 builds and enable multi-arch (rpi4 with ubuntu and raspbian buster tested). Add CoreDNS for `PEERDNS=auto` setting. Update the `add-peer`/`show-peer` scripts to utilize the templates and the `INTERNAL_SUBNET` var (previously missed, oops)."},{"date":"05.04.20:","desc":"Add `INTERNAL_SUBNET` variable to prevent subnet clashes. Add templates for server and peer confs."},{"date":"01.04.20:","desc":"Add `show-peer` script and include info on host installed headers."},{"date":"31.03.20:","desc":"Initial Release."}]}},"setup":"During container start, it will first check if the wireguard module is already installed and loaded. Kernels newer than 5.6 generally have the wireguard module built-in (along with some older custom kernels). However, the module may not be enabled. Make sure it is enabled prior to starting the container.\n\nIf the kernel is not built-in, or installed on host, the container will check if the kernel headers are present (in `/usr/src`) and if not, it will attempt to download the necessary kernel headers from the `ubuntu xenial/bionic`, `debian/raspbian buster` repos; then will attempt to compile and install the kernel module. If the kernel headers are not found in either `usr/src` or in the repos mentioned, container will sleep indefinitely as wireguard cannot be installed.\n\nIf you're on a debian/ubuntu based host with a custom or downstream distro provided kernel (ie. Pop!_OS), the container won't be able to install the kernel headers from the regular ubuntu and debian repos. In those cases, you can try installing the headers on the host via `sudo apt install linux-headers-$(uname -r)` (if distro version) and then add a volume mapping for `/usr/src:/usr/src`, or if custom built, map the location of the existing headers to allow the container to use host installed headers to build the kernel module (tested successful on Pop!_OS, ymmv).\n\nWith regards to arm32/64 devices, Raspberry Pi 2-4 running the [official ubuntu images](https://ubuntu.com/download/raspberry-pi) or Raspbian Buster are supported out of the box. For all other devices and OSes, you can try installing the kernel headers on the host, and mapping `/usr/src:/usr/src` and it may just work (no guarantees).\n\nThis can be run as a server or a client, based on the parameters used.\n\n## Server Mode\n\nIf the environment variable `PEERS` is set to a number or a list of strings separated by comma, the container will run in server mode and the necessary server and peer/client confs will be generated. The peer/client config qr codes will be output in the docker log if `LOG_CONFS` is set to `true`. They will also be saved in text and png format under `/config/peerX` in case `PEERS` is a variable and an integer or `/config/peer_X` in case a list of names was provided instead of an integer.\n\nVariables `SERVERURL`, `SERVERPORT`, `INTERNAL_SUBNET`, `PEERDNS`, `INTERFACE`, `ALLOWEDIPS` and `PERSISTENTKEEPALIVE_PEERS` are optional variables used for server mode. Any changes to these environment variables will trigger regeneration of server and peer confs. Peer/client confs will be recreated with existing private/public keys. Delete the peer folders for the keys to be recreated along with the confs.\n\nTo add more peers/clients later on, you increment the `PEERS` environment variable or add more elements to the list and recreate the container.\n\nTo display the QR codes of active peers again, you can use the following command and list the peer numbers as arguments: `docker exec -it wireguard /app/show-peer 1 4 5` or `docker exec -it wireguard /app/show-peer myPC myPhone myTablet` (Keep in mind that the QR codes are also stored as PNGs in the config folder).\n\nThe templates used for server and peer confs are saved under `/config/templates`. Advanced users can modify these templates and force conf generation by deleting `/config/wg0.conf` and restarting the container.\n\n## Client Mode\n\nDo not set the `PEERS` environment variable. Drop your client conf into the config folder as `/config/wg0.conf` and start the container.\n\nIf you get IPv6 related errors in the log and connection cannot be established, edit the `AllowedIPs` line in your peer/client wg0.conf to include only `0.0.0.0/0` and not `::/0`; and restart the container.\n\n## Road warriors, roaming and returning home\n\nIf you plan to use Wireguard both remotely and locally, say on your mobile phone, you will need to consider routing. Most firewalls will not route ports forwarded on your WAN interface correctly to the LAN out of the box. This means that when you return home, even though you can see the Wireguard server, the return packets will probably get lost.\n\nThis is not a Wireguard specific issue and the two generally accepted solutions are NAT reflection (setting your edge router/firewall up in such a way as it translates internal packets correctly) or split horizon DNS (setting your internal DNS to return the private rather than public IP when connecting locally).\n\nBoth of these approaches have positives and negatives however their setup is out of scope for this document as everyone's network layout and equipment will be different.\n\n## Maintaining local access to attached services\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nWhen routing via Wireguard from another container using the `service` option in docker, you might lose access to the containers webUI locally. To avoid this, exclude the docker subnet from being routed via Wireguard by modifying your `wg0.conf` like so (modifying the subnets as you require):\n\n  ```ini\n  [Interface]\n  PrivateKey = <private key>\n  Address = 9.8.7.6/32\n  DNS = 8.8.8.8\n  PostUp = DROUTE=$(ip route | grep default | awk '{print $3}'); HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route add $HOMENET3 via $DROUTE;ip route add $HOMENET2 via $DROUTE; ip route add $HOMENET via $DROUTE;iptables -I OUTPUT -d $HOMENET -j ACCEPT;iptables -A OUTPUT -d $HOMENET2 -j ACCEPT; iptables -A OUTPUT -d $HOMENET3 -j ACCEPT;  iptables -A OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n  PreDown = HOMENET=192.168.0.0/16; HOMENET2=10.0.0.0/8; HOMENET3=172.16.0.0/12; ip route del $HOMENET3 via $DROUTE;ip route del $HOMENET2 via $DROUTE; ip route del $HOMENET via $DROUTE; iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT; iptables -D OUTPUT -d $HOMENET -j ACCEPT; iptables -D OUTPUT -d $HOMENET2 -j ACCEPT; iptables -D OUTPUT -d $HOMENET3 -j ACCEPT\n  ```\n\n## Site-to-site VPN\n\n** Note: This is not a supported configuration by Linuxserver.io - use at your own risk.\n\nSite-to-site VPN in server mode requires customizing the `AllowedIPs` statement for a specific peer in `wg0.conf`. Since `wg0.conf` is autogenerated when server vars are changed, it is not recommended to edit it manually.\n\nIn order to customize the `AllowedIPs` statement for a specific peer in `wg0.conf`, you can set an env var `SERVER_ALLOWEDIPS_PEER_<peer name or number>` to the additional subnets you'd like to add, comma separated and excluding the peer IP (ie. `\"192.168.1.0/24,192.168.2.0/24\"`). Replace `<peer name or number>` with either the name or number of a peer (whichever is used in the `PEERS` var).\n\nFor instance `SERVER_ALLOWEDIPS_PEER_laptop=\"192.168.1.0/24,192.168.2.0/24\"` will result in the wg0.conf entry `AllowedIPs = 10.13.13.2,192.168.1.0/24,192.168.2.0/24` for the peer named `laptop`.\n\nKeep in mind that this var will only be considered when the confs are regenerated. Adding this var for an existing peer won't force a regeneration. You can delete wg0.conf and restart the container to force regeneration if necessary.\n\nDon't forget to set the necessary POSTUP and POSTDOWN rules in your client's peer conf for lan access.\n","_id":"content:apps:wireguard.json","_type":"json","title":"Wireguard","_source":"content","_file":"apps/wireguard.json","_extension":"json"},{"_path":"/apps/wireshark","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"wireshark","name":"wireshark","description":"[Wireshark]({{ project_url }}) is the worlds foremost and widely-used network protocol analyzer. It lets you see whats happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Wireshark development thrives thanks to the volunteer contributions of networking experts around the globe and is the continuation of a project started by Gerald Combs in 1998. ","icon":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/wireshark-icon.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/wireshark"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-wireshark"}],"containers":[{"name":"wireshark","image":"linuxserver/wireshark","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Users home directory in the container, stores program settings and potentially dump files.","key":"config"}]}],"meta":{"readme-vars":{"project_name":"wireshark","project_url":"https://www.wireshark.org/","project_logo":"https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/wireshark-icon.png","project_blurb":"[Wireshark]({{ project_url }}) is the worlds foremost and widely-used network protocol analyzer. It lets you see whats happening on your network at a microscopic level and is the de facto (and often de jure) standard across many commercial and non-profit enterprises, government agencies, and educational institutions. Wireshark development thrives thanks to the volunteer contributions of networking experts around the globe and is the continuation of a project started by Gerald Combs in 1998. ","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_env":true,"param_usage_include_ports":false,"param_usage_include_net":true,"param_net":"host","param_net_desc":"Use Host Networking","param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/config","desc":"Users home directory in the container, stores program settings and potentially dump files."}],"cap_add_param":true,"cap_add_param_vars":[{"cap_add_var":"NET_ADMIN"}],"opt_param_usage_include_ports":true,"opt_param_ports":[{"external_port":"3000","internal_port":"3000","port_desc":"WireShark desktop gui, only use this if you are not using host mode and sniffing Docker network traffic."}],"opt_security_opt_param":true,"opt_security_opt_param_vars":[{"run_var":"seccomp=unconfined","compose_var":"seccomp:unconfined","desc":"For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker."}],"app_setup_block_enabled":true,"app_setup_block":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nIn order to dump from an interface you will need to pass `NET_ADMIN` at a minimum, optionally you can use host networking to capture from your host level device or specify a Docker network you want to capture from.\n\nIf you do not specificy host networking you will need to map port 3000 with `-p 3000:3000`.\n","changelogs":[{"date":"23.10.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"14.02.22:","desc":"Rebase to Alpine."},{"date":"31.03.20:","desc":"Initial release."}]}},"setup":"The application can be accessed at:\n\n* http://yourhost:3000/\n\nBy default the user/pass is abc/abc, if you change your password or want to login manually to the GUI session for any reason use the following link:\n\n* http://yourhost:3000/?login=true\n\nIn order to dump from an interface you will need to pass `NET_ADMIN` at a minimum, optionally you can use host networking to capture from your host level device or specify a Docker network you want to capture from.\n\nIf you do not specificy host networking you will need to map port 3000 with `-p 3000:3000`.\n","_id":"content:apps:wireshark.json","_type":"json","title":"Wireshark","_source":"content","_file":"apps/wireshark.json","_extension":"json"},{"_path":"/apps/xbackbone","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"xbackbone","name":"xbackbone","description":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple, self-hosted, lightweight PHP file manager that support the instant sharing tool ShareX and *NIX systems. It supports uploading and displaying images, GIF, video, code, formatted text, and file downloading and uploading. Also have a web UI with multi user management, past uploads history and search support.\n","icon":"https://raw.githubusercontent.com/SergiX44/XBackBone/master/docs/img/xbackbone.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/xbackbone"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-xbackbone"}],"containers":[{"name":"xbackbone","image":"linuxserver/xbackbone","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/Oslo","description":"Timezone (i.e., Europe/Oslo)"}],"volumes":[{"container":"/config","description":"config directory volume mapping","key":"config"}],"ports":[{"container":"80","description":"http gui","protocol":"tcp","web":false},{"container":"443","description":"https gui","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"xbackbone","project_url":"https://github.com/SergiX44/XBackBone","project_logo":"https://raw.githubusercontent.com/SergiX44/XBackBone/master/docs/img/xbackbone.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is a simple, self-hosted, lightweight PHP file manager that support the instant sharing tool ShareX and *NIX systems. It supports uploading and displaying images, GIF, video, code, formatted text, and file downloading and uploading. Also have a web UI with multi user management, past uploads history and search support.\n","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"param_container_name":"{{ project_name }}","param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"/path/to/data","desc":"config directory volume mapping"}],"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/Oslo","desc":"Timezone (i.e., Europe/Oslo)"}],"param_usage_include_ports":true,"param_ports":[{"external_port":"80","internal_port":"80","port_desc":"http gui"},{"external_port":"443","internal_port":"443","port_desc":"https gui"}],"app_setup_block_enabled":true,"app_setup_block":"Access the WebUI at \\<your-ip>:80/443. Follow the installation wizard. For more information, check out [XBackBone](https://github.com/SergiX44/XBackBone).\n\nIf you want to change the PHP max upload size you can override the php.ini file by adding options in `/config/php/php-local.ini`\n\nExample:\n\n```ini\n  upload_max_filesize = 25M\n  post_max_size = 25M\n```\n\nFor reverse proxying, remember to change the `base_url` in `/config/www/xbackbone/config.php` to your domain if you initially set up the application with a local url. E.g. `'base_url' => 'https://images.yourdomain.com',`\n","changelogs":[{"date":"19.01.23:","desc":"Rebase to alpine 3.17 with php8.1."},{"date":"04.11.22:","desc":"Rebase to Alpine 3.16, migrate to s6v3."},{"date":"01.11.22:","desc":"Move application install to /app/www/public, add migration notices for existing users. Container updates should now update the application correctly"},{"date":"20.08.22:","desc":"Rebasing to alpine 3.15 with php8. Restructure nginx configs ([see changes announcement](https://info.linuxserver.io/issues/2022-08-20-nginx-base))."},{"date":"02.08.22:","desc":"Added note about updating."},{"date":"06.06.21:","desc":"Initial Release."}]}},"setup":"Access the WebUI at \\<your-ip>:80/443. Follow the installation wizard. For more information, check out [XBackBone](https://github.com/SergiX44/XBackBone).\n\nIf you want to change the PHP max upload size you can override the php.ini file by adding options in `/config/php/php-local.ini`\n\nExample:\n\n```ini\n  upload_max_filesize = 25M\n  post_max_size = 25M\n```\n\nFor reverse proxying, remember to change the `base_url` in `/config/www/xbackbone/config.php` to your domain if you initially set up the application with a local url. E.g. `'base_url' => 'https://images.yourdomain.com',`\n","_id":"content:apps:xbackbone.json","_type":"json","title":"Xbackbone","_source":"content","_file":"apps/xbackbone.json","_extension":"json"},{"_path":"/apps/yq","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"yq","name":"yq","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/yq.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/yq"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-yq"}],"containers":[{"name":"yq","image":"linuxserver/yq","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"}]}],"meta":{"readme-vars":{"project_name":"yq","full_custom_readme":"{% raw -%}\n[![linuxserver.io](https://raw.githubusercontent.com/linuxserver/docker-templates/master/linuxserver.io/img/linuxserver_medium.png)](https://linuxserver.io)\n\n[![Blog](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Blog)](https://blog.linuxserver.io \"all the things you can do with our containers including How-To guides, opinions and much more!\")\n[![Discord](https://img.shields.io/discord/354974912613449730.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Discord&logo=discord)](https://discord.gg/YWrKVTn \"realtime support / chat with the community and the team.\")\n[![Discourse](https://img.shields.io/discourse/https/discourse.linuxserver.io/topics.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=discourse)](https://discourse.linuxserver.io \"post on our community forum.\")\n[![Fleet](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=Fleet)](https://fleet.linuxserver.io \"an online web interface which displays all of our maintained images.\")\n[![GitHub](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub&logo=github)](https://github.com/linuxserver \"view the source for all of our repositories.\")\n[![Open Collective](https://img.shields.io/opencollective/all/linuxserver.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=Supporters&logo=open%20collective)](https://opencollective.com/linuxserver \"please consider helping us by either donating or contributing to our budget\")\n\nThe [LinuxServer.io](https://linuxserver.io) team brings you another container release featuring:\n\n* regular and timely application updates\n* easy user mappings (PGID, PUID)\n* custom base image with s6 overlay\n* weekly base OS updates with common layers across the entire LinuxServer.io ecosystem to minimise space usage, down time and bandwidth\n* regular security updates\n\nFind us at:\n* [Blog](https://blog.linuxserver.io) - all the things you can do with our containers including How-To guides, opinions and much more!\n* [Discord](https://discord.gg/YWrKVTn) - realtime support / chat with the community and the team.\n* [Discourse](https://discourse.linuxserver.io) - post on our community forum.\n* [Fleet](https://fleet.linuxserver.io) - an online web interface which displays all of our maintained images.\n* [GitHub](https://github.com/linuxserver) - view the source for all of our repositories.\n* [Open Collective](https://opencollective.com/linuxserver) - please consider helping us by either donating or contributing to our budget\n\n# [linuxserver/yq](https://github.com/linuxserver/docker-yq)\n\n[![GitHub Stars](https://img.shields.io/github/stars/linuxserver/docker-yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-yq)\n[![GitHub Release](https://img.shields.io/github/release/linuxserver/docker-yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&logo=github)](https://github.com/linuxserver/docker-yq/releases)\n[![GitHub Package Repository](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitHub%20Package&logo=github)](https://github.com/linuxserver/docker-yq/packages)\n[![GitLab Container Registry](https://img.shields.io/static/v1.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=linuxserver.io&message=GitLab%20Registry&logo=gitlab)](https://gitlab.com/Linuxserver.io/docker-yq/container_registry)\n[![MicroBadger Layers](https://img.shields.io/microbadger/layers/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge)](https://microbadger.com/images/linuxserver/yq \"Get your own version badge on microbadger.com\")\n[![Docker Pulls](https://img.shields.io/docker/pulls/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=pulls&logo=docker)](https://hub.docker.com/r/linuxserver/yq)\n[![Docker Stars](https://img.shields.io/docker/stars/linuxserver/yq.svg?color=94398d&labelColor=555555&logoColor=ffffff&style=for-the-badge&label=stars&logo=docker)](https://hub.docker.com/r/linuxserver/yq)\n[![Jenkins Build](https://img.shields.io/jenkins/build?labelColor=555555&logoColor=ffffff&style=for-the-badge&jobUrl=https%3A%2F%2Fci.linuxserver.io%2Fjob%2FDocker-Pipeline-Builders%2Fjob%2Fdocker-yq%2Fjob%2Fmaster%2F&logo=jenkins)](https://ci.linuxserver.io/job/Docker-Pipeline-Builders/job/docker-yq/job/master/)\n\n[yq](https://github.com/kislyuk/yq): Command-line YAML/XML processor - jq wrapper for YAML and XML documents. This image includes `yq`, `jq`, and `xq`.\n\n## Supported Architectures\n\nOur images support multiple architectures such as `x86-64`, `arm64` and `armhf`. We utilise the docker manifest for multi-platform awareness. More information is available from docker [here](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md#manifest-list) and our announcement [here](https://blog.linuxserver.io/2019/02/21/the-lsio-pipeline-project/).\n\nSimply pulling `linuxserver/yq` should retrieve the correct image for your arch, but you can also pull specific arch images via tags.\n\nThe architectures supported by this image are:\n\n| Architecture | Tag |\n| :----: | --- |\n| x86-64 | amd64-latest |\n| arm64 | arm64v8-latest |\n| armhf | arm32v7-latest |\n\n## Usage\n\n### Docker cli\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint yq \\\n  linuxserver/yq \\\n  .foo.bar input.yml\n```\nYou can replace the last line with any yq command and argument, which will be passed to yq inside the image.\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint jq \\\n  linuxserver/yq \\\n  .foo.bar input.json\n```\nYou can replace the last line with any jq command and argument, which will be passed to jq inside the image.\n\n```\ndocker run --rm \\\n  -v \"$PWD:$PWD\" \\\n  -w=\"$PWD\" \\\n  --entrypoint xq \\\n  linuxserver/yq \\\n  .foo.bar input.xml\n```\nYou can replace the last line with any xq command and argument, which will be passed to xq inside the image.\n\n### Recommended method\n\nWe provide a very convenient script that allows the yq container to run as if it was installed natively:\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-yq.sh -o /usr/local/bin/yq\nsudo chmod +x /usr/local/bin/yq\n```\nRunning these two commands on your docker host once will let you issue commands such as `yq .foo.bar input.yml` and the yq container will do its job behind the scenes.\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-jq.sh -o /usr/local/bin/jq\nsudo chmod +x /usr/local/bin/jq\n```\nRunning these two commands on your docker host once will let you issue commands such as `jq .foo.bar input.json` and the jq container will do its job behind the scenes.\n\n```\nsudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-yq/master/run-xq.sh -o /usr/local/bin/xq\nsudo chmod +x /usr/local/bin/xq\n```\nRunning these two commands on your docker host once will let you issue commands such as `xq .foo.bar input.xml` and the xq container will do its job behind the scenes.\n\n## Docker Mods\n[![Docker Mods](https://img.shields.io/badge/dynamic/yaml?style=for-the-badge&color=E68523&label=mods&query=%24.mods%5B%27yq%27%5D.mod_count&url=https%3A%2F%2Fraw.githubusercontent.com%2Flinuxserver%2Fdocker-mods%2Fmaster%2Fmod-list.yml)](https://mods.linuxserver.io/?mod=yq \"view available mods for this container.\")\n\nWe publish various [Docker Mods](https://github.com/linuxserver/docker-mods) to enable additional functionality within the containers. The list of Mods available for this image (if any) can be accessed via the dynamic badge above.\n\n\n## Support Info\n\n* image version number\n  * `docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/yq`\n\n## Updating Info\n\n### Via Docker Cli\n* Update the image: `docker pull linuxserver/yq`\n* You can also remove the old dangling images: `docker image prune`\n\n\n## Building locally\n\nIf you want to make local modifications to these images for development purposes or just to customize the logic:\n```\ngit clone https://github.com/linuxserver/docker-yq.git\ncd docker-yq\ndocker build \\\n  --no-cache \\\n  --pull \\\n  -t linuxserver/yq:latest .\n```\n\nThe ARM variants can be built on x86_64 hardware using `multiarch/qemu-user-static`\n```\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\nOnce registered you can define the dockerfile to use with `-f Dockerfile.aarch64`.\n\n## Versions\n\n* **19.09.22:** - Rebase to 3.17.\n* **19.09.22:** - Rebase to 3.15.\n* **18.05.21:** - Rebase to 3.13. add linuxserver wheel repo.\n* **09.10.20:** - Fix run scripts evaluating `$` in cases where they should not (ex: inside single quotes). Please rerun the [Recommended method](https://github.com/linuxserver/docker-yq#recommended-method) install/setup commands.\n* **07.10.20:** - Initial Release.\n\n{%- endraw %}\n"}},"_id":"content:apps:yq.json","_type":"json","title":"Yq","_source":"content","_file":"apps/yq.json","_extension":"json"},{"_path":"/apps/znc","_dir":"apps","_draft":false,"_partial":false,"_locale":"en","id":"znc","name":"znc","description":"[{{ project_name|capitalize }}]({{ project_url }}) is an IRC network bouncer or BNC. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC.","icon":"https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/png/znc.png","links":[{"type":"docker","url":"https://hub.docker.com/r/linuxserver/znc"},{"type":"docs","url":"https://docs.linuxserver.io/images/docker-znc"}],"containers":[{"name":"znc","image":"linuxserver/znc","env":[{"id":"PUID","key":"PUID","description":"User ID","default":"100"},{"id":"PGID","key":"PGID","description":"Group ID","default":"100"},{"id":"TZ","default":"Europe/London","description":"Specify a timezone to use EG Europe/London."}],"volumes":[{"container":"/config","description":"Where local ZNC data is stored.","key":"config"}],"ports":[{"container":"6501","description":"Port ZNC listens on.","protocol":"tcp","web":false}]}],"meta":{"readme-vars":{"project_name":"znc","project_url":"http://wiki.znc.in/ZNC","project_logo":"http://wiki.znc.in/resources/assets/wiki.png","project_blurb":"[{{ project_name|capitalize }}]({{ project_url }}) is an IRC network bouncer or BNC. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC.","project_lsio_github_repo_url":"https://github.com/linuxserver/docker-{{ project_name }}","project_blurb_optional_extras_enabled":false,"available_architectures":[{"arch":"{{ arch_x86_64 }}","tag":"amd64-latest"},{"arch":"{{ arch_arm64 }}","tag":"arm64v8-latest"},{"arch":"{{ arch_armhf }}","tag":"arm32v7-latest"}],"development_versions":false,"common_param_env_vars_enabled":true,"param_container_name":"{{ project_name }}","param_usage_include_net":false,"param_usage_include_env":true,"param_env_vars":[{"env_var":"TZ","env_value":"Europe/London","desc":"Specify a timezone to use EG Europe/London."}],"param_usage_include_vols":true,"param_volumes":[{"vol_path":"/config","vol_host_path":"<path to data>","desc":"Where local ZNC data is stored."}],"param_usage_include_ports":true,"param_ports":[{"external_port":"6501","internal_port":"6501","port_desc":"Port ZNC listens on."}],"param_device_map":false,"cap_add_param":false,"opt_param_usage_include_env":false,"opt_param_usage_include_vols":false,"opt_param_usage_include_ports":false,"opt_param_device_map":false,"opt_cap_add_param":false,"optional_block_1":false,"app_setup_block_enabled":true,"app_setup_block":"To log in to the application, browse to http://<hostip>:6501.\n\n* Default User: admin\n* Default Password: admin\n`change password ASAP.`\n","changelogs":[{"date":"19.01.22:","desc":"Rebasing to alpine 3.15."},{"date":"01.06.20:","desc":"Rebasing to alpine 3.12."},{"date":"19.12.19:","desc":"Rebasing to alpine 3.11."},{"date":"02.11.19:","desc":"Add znc-palaver module."},{"date":"28.06.19:","desc":"Rebasing to alpine 3.10."},{"date":"23.03.19:","desc":"Switching to new Base images, shift to arm32v7 tag."},{"date":"22.02.19:","desc":"Rebasing to alpine 3.9."},{"date":"31.01.19:","desc":"Add pipeline logic and multi arch."},{"date":"30.01.19:","desc":"Add push and clientbuffer modules."},{"date":"17.08.18:","desc":"Rebase to alpine 3.8, use buildstage."},{"date":"03.01.18:","desc":"Deprecate cpu_core routine lack of scaling."},{"date":"07.12.17:","desc":"Rebase alpine linux 3.7."},{"date":"25.10.17:","desc":"Remove debug switch from run command."},{"date":"26.05.17:","desc":"Rebase alpine linux 3.6."},{"date":"06.02.17:","desc":"Rebase alpine linux 3.5."},{"date":"19.01.17:","desc":"Add playback module."},{"date":"07.01.17:","desc":"Add ca-certificates package, resolve sasl issues."},{"date":"07.12.16:","desc":"Use scanelf to determine runtime dependencies. Fix error with continuation."},{"date":"14.10.16:","desc":"Add version layer information."},{"date":"30.09.16:","desc":"Fix umask."},{"date":"11.09.16:","desc":"Add layer badges to README."},{"date":"28.08.16:","desc":"Add badges to README."},{"date":"20.08.16:","desc":"Rebase to alpine linux, move to main repository."},{"date":"11.12.15:","desc":"Initial Release."}]}},"setup":"To log in to the application, browse to http://<hostip>:6501.\n\n* Default User: admin\n* Default Password: admin\n`change password ASAP.`\n","_id":"content:apps:znc.json","_type":"json","title":"Znc","_source":"content","_file":"apps/znc.json","_extension":"json"}],"navigation":[{"title":"All","_path":"/all"},{"title":"Apps","_path":"/apps","children":[{"title":"Adguardhome Sync","_path":"/apps/adguardhome-sync"},{"title":"Airsonic Advanced","_path":"/apps/airsonic-advanced"},{"title":"Apprise Api","_path":"/apps/apprise-api"},{"title":"Audacity","_path":"/apps/audacity"},{"title":"Audiobookshelf","_path":"/apps/audiobookshelf"},{"title":"Babybuddy","_path":"/apps/babybuddy"},{"title":"Bazarr","_path":"/apps/bazarr"},{"title":"Beets","_path":"/apps/beets"},{"title":"Blender","_path":"/apps/blender"},{"title":"Boinc","_path":"/apps/boinc"},{"title":"Booksonic Air","_path":"/apps/booksonic-air"},{"title":"Bookstack","_path":"/apps/bookstack"},{"title":"Budge","_path":"/apps/budge"},{"title":"Calibre Web","_path":"/apps/calibre-web"},{"title":"Calibre","_path":"/apps/calibre"},{"title":"ChangedetectionIo","_path":"/apps/changedetection.io"},{"title":"Code Server","_path":"/apps/code-server"},{"title":"Cops","_path":"/apps/cops"},{"title":"Daapd","_path":"/apps/daapd"},{"title":"Darktable","_path":"/apps/darktable"},{"title":"Davos","_path":"/apps/davos"},{"title":"Ddclient","_path":"/apps/ddclient"},{"title":"Deluge","_path":"/apps/deluge"},{"title":"Digikam","_path":"/apps/digikam"},{"title":"Dillinger","_path":"/apps/dillinger"},{"title":"Diskover","_path":"/apps/diskover"},{"title":"Docker Compose","_path":"/apps/docker-compose"},{"title":"Dokuwiki","_path":"/apps/dokuwiki"},{"title":"Domoticz","_path":"/apps/domoticz"},{"title":"Doplarr","_path":"/apps/doplarr"},{"title":"Doublecommander","_path":"/apps/doublecommander"},{"title":"Duckdns","_path":"/apps/duckdns"},{"title":"Duplicati","_path":"/apps/duplicati"},{"title":"Emby","_path":"/apps/emby"},{"title":"Embystat","_path":"/apps/embystat"},{"title":"Emulatorjs","_path":"/apps/emulatorjs"},{"title":"Endlessh","_path":"/apps/endlessh"},{"title":"Fail2ban","_path":"/apps/fail2ban"},{"title":"Feed2toot","_path":"/apps/feed2toot"},{"title":"Ffmpeg","_path":"/apps/ffmpeg"},{"title":"Filezilla","_path":"/apps/filezilla"},{"title":"Firefox","_path":"/apps/firefox"},{"title":"Fleet","_path":"/apps/fleet"},{"title":"Foldingathome","_path":"/apps/foldingathome"},{"title":"Freshrss","_path":"/apps/freshrss"},{"title":"Grav","_path":"/apps/grav"},{"title":"Grocy","_path":"/apps/grocy"},{"title":"Guacd","_path":"/apps/guacd"},{"title":"Habridge","_path":"/apps/habridge"},{"title":"Headphones","_path":"/apps/headphones"},{"title":"Healthchecks","_path":"/apps/healthchecks"},{"title":"Hedgedoc","_path":"/apps/hedgedoc"},{"title":"Heimdall","_path":"/apps/heimdall"},{"title":"Homeassistant","_path":"/apps/homeassistant"},{"title":"Homer","_path":"/apps/homer"},{"title":"Htpcmanager","_path":"/apps/htpcmanager"},{"title":"Ipfs","_path":"/apps/ipfs"},{"title":"Jackett","_path":"/apps/jackett"},{"title":"Jellyfin","_path":"/apps/jellyfin"},{"title":"Jenkins Builder","_path":"/apps/jenkins-builder"},{"title":"Kasm","_path":"/apps/kasm"},{"title":"Kdenlive","_path":"/apps/kdenlive"},{"title":"Lazylibrarian","_path":"/apps/lazylibrarian"},{"title":"Ldap Auth","_path":"/apps/ldap-auth"},{"title":"Libreoffice","_path":"/apps/libreoffice"},{"title":"Librespeed","_path":"/apps/librespeed"},{"title":"Lidarr","_path":"/apps/lidarr"},{"title":"Limnoria","_path":"/apps/limnoria"},{"title":"Lychee","_path":"/apps/lychee"},{"title":"Mariadb","_path":"/apps/mariadb"},{"title":"Mastodon","_path":"/apps/mastodon"},{"title":"Medusa","_path":"/apps/medusa"},{"title":"Minetest","_path":"/apps/minetest"},{"title":"Minisatip","_path":"/apps/minisatip"},{"title":"Mods","_path":"/apps/mods"},{"title":"Mstream","_path":"/apps/mstream"},{"title":"Mylar3","_path":"/apps/mylar3"},{"title":"Mysql Workbench","_path":"/apps/mysql-workbench"},{"title":"Nano Wallet","_path":"/apps/nano-wallet"},{"title":"Nano","_path":"/apps/nano"},{"title":"Netbootxyz","_path":"/apps/netbootxyz"},{"title":"Netbox","_path":"/apps/netbox"},{"title":"Nextcloud","_path":"/apps/nextcloud"},{"title":"Nginx","_path":"/apps/nginx"},{"title":"Ngircd","_path":"/apps/ngircd"},{"title":"Nntp2nntp","_path":"/apps/nntp2nntp"},{"title":"Nzbget","_path":"/apps/nzbget"},{"title":"Nzbhydra2","_path":"/apps/nzbhydra2"},{"title":"Ombi","_path":"/apps/ombi"},{"title":"Openssh Server","_path":"/apps/openssh-server"},{"title":"Openvscode Server","_path":"/apps/openvscode-server"},{"title":"Oscam","_path":"/apps/oscam"},{"title":"Overseerr","_path":"/apps/overseerr"},{"title":"Papermerge","_path":"/apps/papermerge"},{"title":"Phpmyadmin","_path":"/apps/phpmyadmin"},{"title":"Pidgin","_path":"/apps/pidgin"},{"title":"Piwigo","_path":"/apps/piwigo"},{"title":"Plex Meta Manager","_path":"/apps/plex-meta-manager"},{"title":"Plex","_path":"/apps/plex"},{"title":"Projectsend","_path":"/apps/projectsend"},{"title":"Prowlarr","_path":"/apps/prowlarr"},{"title":"Pwndrop","_path":"/apps/pwndrop"},{"title":"Pydio Cells","_path":"/apps/pydio-cells"},{"title":"Pyload Ng","_path":"/apps/pyload-ng"},{"title":"Pylon","_path":"/apps/pylon"},{"title":"Qbittorrent","_path":"/apps/qbittorrent"},{"title":"Qdirstat","_path":"/apps/qdirstat"},{"title":"Quassel Core","_path":"/apps/quassel-core"},{"title":"Quassel Web","_path":"/apps/quassel-web"},{"title":"Radarr","_path":"/apps/radarr"},{"title":"Raneto","_path":"/apps/raneto"},{"title":"Rdesktop","_path":"/apps/rdesktop"},{"title":"Readarr","_path":"/apps/readarr"},{"title":"Remmina","_path":"/apps/remmina"},{"title":"Requestrr","_path":"/apps/requestrr"},{"title":"Resilio Sync","_path":"/apps/resilio-sync"},{"title":"Rsnapshot","_path":"/apps/rsnapshot"},{"title":"Sabnzbd","_path":"/apps/sabnzbd"},{"title":"Sickchill","_path":"/apps/sickchill"},{"title":"Sickgear","_path":"/apps/sickgear"},{"title":"Smokeping","_path":"/apps/smokeping"},{"title":"Snapdrop","_path":"/apps/snapdrop"},{"title":"Snipe It","_path":"/apps/snipe-it"},{"title":"Sonarr","_path":"/apps/sonarr"},{"title":"Sqlitebrowser","_path":"/apps/sqlitebrowser"},{"title":"Swag","_path":"/apps/swag"},{"title":"Synclounge","_path":"/apps/synclounge"},{"title":"Syncthing","_path":"/apps/syncthing"},{"title":"Syslog Ng","_path":"/apps/syslog-ng"},{"title":"Tautulli","_path":"/apps/tautulli"},{"title":"Thelounge","_path":"/apps/thelounge"},{"title":"Transmission","_path":"/apps/transmission"},{"title":"Tvheadend","_path":"/apps/tvheadend"},{"title":"Ubooquity","_path":"/apps/ubooquity"},{"title":"Unifi Controller","_path":"/apps/unifi-controller"},{"title":"Vikunja","_path":"/apps/vikunja"},{"title":"Webgrabplus","_path":"/apps/webgrabplus"},{"title":"Webtop","_path":"/apps/webtop"},{"title":"Wikijs","_path":"/apps/wikijs"},{"title":"Wireguard","_path":"/apps/wireguard"},{"title":"Wireshark","_path":"/apps/wireshark"},{"title":"Xbackbone","_path":"/apps/xbackbone"},{"title":"Yq","_path":"/apps/yq"},{"title":"Znc","_path":"/apps/znc"}]}]}